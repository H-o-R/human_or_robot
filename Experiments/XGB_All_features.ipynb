{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    "# import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "# from tensorflow.keras.models import Sequential\n",
    "# from tensorflow.keras.layers import Dense\n",
    "# from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../new_train.csv\")\n",
    "test = pd.read_csv(\"../new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>...</th>\n",
       "      <th>max_url_per_auction</th>\n",
       "      <th>min_url_per_auction</th>\n",
       "      <th>std_url_per_auction</th>\n",
       "      <th>total_no_of_participated_auctions</th>\n",
       "      <th>no_of_auction_exceeds_threshold</th>\n",
       "      <th>percentage_of_auctions_above_threshold</th>\n",
       "      <th>total_no_of_bidded_category</th>\n",
       "      <th>no_of_merchandise_exceeds_threshold</th>\n",
       "      <th>percentage_of_merchandise_above_threshold</th>\n",
       "      <th>on_url_that_has_a_bot_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.644263</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3     4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4     4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...                                     ...   \n",
       "2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country     ip  ...  max_url_per_auction  \\\n",
       "0       14.0   24.0      6.0   20.0  ...                  1.0   \n",
       "1        2.0    3.0      1.0    3.0  ...                  2.0   \n",
       "2        2.0    4.0      1.0    4.0  ...                  1.0   \n",
       "3        1.0    1.0      1.0    1.0  ...                  1.0   \n",
       "4       53.0  155.0      2.0  123.0  ...                 21.0   \n",
       "...      ...    ...      ...    ...  ...                  ...   \n",
       "2008     4.0   33.0      4.0    5.0  ...                  1.0   \n",
       "2009     1.0    1.0      1.0    1.0  ...                  1.0   \n",
       "2010     2.0    2.0      1.0    2.0  ...                  1.0   \n",
       "2011     1.0    1.0      1.0    1.0  ...                  1.0   \n",
       "2012     1.0    2.0      1.0    1.0  ...                  1.0   \n",
       "\n",
       "      min_url_per_auction  std_url_per_auction  \\\n",
       "0                     1.0             0.000000   \n",
       "1                     2.0             0.000000   \n",
       "2                     1.0             0.000000   \n",
       "3                     1.0             0.000000   \n",
       "4                     1.0             5.644263   \n",
       "...                   ...                  ...   \n",
       "2008                  1.0             0.000000   \n",
       "2009                  1.0             0.000000   \n",
       "2010                  1.0             0.000000   \n",
       "2011                  1.0             0.000000   \n",
       "2012                  1.0             0.000000   \n",
       "\n",
       "      total_no_of_participated_auctions  no_of_auction_exceeds_threshold  \\\n",
       "0                                  18.0                              0.0   \n",
       "1                                   1.0                              0.0   \n",
       "2                                   4.0                              0.0   \n",
       "3                                   1.0                              0.0   \n",
       "4                                  23.0                              1.0   \n",
       "...                                 ...                              ...   \n",
       "2008                               25.0                              1.0   \n",
       "2009                                1.0                              0.0   \n",
       "2010                                1.0                              0.0   \n",
       "2011                                1.0                              0.0   \n",
       "2012                                1.0                              0.0   \n",
       "\n",
       "      percentage_of_auctions_above_threshold  total_no_of_bidded_category  \\\n",
       "0                                   0.000000                          1.0   \n",
       "1                                   0.000000                          1.0   \n",
       "2                                   0.000000                          1.0   \n",
       "3                                   0.000000                          1.0   \n",
       "4                                   0.043478                          1.0   \n",
       "...                                      ...                          ...   \n",
       "2008                                0.040000                          1.0   \n",
       "2009                                0.000000                          1.0   \n",
       "2010                                0.000000                          1.0   \n",
       "2011                                0.000000                          1.0   \n",
       "2012                                0.000000                          1.0   \n",
       "\n",
       "      no_of_merchandise_exceeds_threshold  \\\n",
       "0                                     0.0   \n",
       "1                                     0.0   \n",
       "2                                     0.0   \n",
       "3                                     0.0   \n",
       "4                                     0.0   \n",
       "...                                   ...   \n",
       "2008                                  0.0   \n",
       "2009                                  0.0   \n",
       "2010                                  0.0   \n",
       "2011                                  0.0   \n",
       "2012                                  0.0   \n",
       "\n",
       "      percentage_of_merchandise_above_threshold  on_url_that_has_a_bot_mean  \n",
       "0                                           0.0                    1.000000  \n",
       "1                                           0.0                    0.500000  \n",
       "2                                           0.0                    0.500000  \n",
       "3                                           0.0                    1.000000  \n",
       "4                                           0.0                    0.010989  \n",
       "...                                         ...                         ...  \n",
       "2008                                        0.0                    0.500000  \n",
       "2009                                        0.0                    0.000000  \n",
       "2010                                        0.0                    0.000000  \n",
       "2011                                        0.0                    0.000000  \n",
       "2012                                        0.0                    0.000000  \n",
       "\n",
       "[2013 rows x 57 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "test.drop(test.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['bidder_id', 'payment_account', 'address', 'outcome','merchandise']) \n",
    "y = train['outcome']\n",
    "X_test = test.drop(columns=['bidder_id', 'payment_account', 'address', 'merchandise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaled_features = data.copy()\n",
    "col_names = ['auction', 'device', 'time', 'country', 'ip', 'url', 'num_bids',\n",
    "       'num_first_bids', 'num_last_bids', 'time_to_bid', 'inst_resp',\n",
    "       'perc_inst_resp', 'num_bids_per_auction',\n",
    "       'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip',\n",
    "       'on_ip_that_has_a_bot_mean', 'ip_entropy', 'url_entropy',\n",
    "       'mean_country_per_auction', 'max_country_per_auction',\n",
    "       'min_country_per_auction', 'std_country_per_auction',\n",
    "       'mean_devices_per_auction', 'max_devices_per_auction',\n",
    "       'min_devices_per_auction', 'std_devices_per_auction',\n",
    "       'mean_ip_per_auction', 'max_ip_per_auction', 'min_ip_per_auction',\n",
    "       'std_ip_per_auction', 'mean_url_per_auction', 'max_url_per_auction',\n",
    "       'min_url_per_auction', 'std_url_per_auction',\n",
    "       'total_no_of_participated_auctions', 'no_of_auction_exceeds_threshold',\n",
    "       'percentage_of_auctions_above_threshold', 'total_no_of_bidded_category',\n",
    "       'no_of_merchandise_exceeds_threshold',\n",
    "       'percentage_of_merchandise_above_threshold',\n",
    "       'on_url_that_has_a_bot_mean']\n",
    "features = X[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "X[col_names] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying SMOTE to the Scaled Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "      <th>num_bids</th>\n",
       "      <th>num_first_bids</th>\n",
       "      <th>num_last_bids</th>\n",
       "      <th>time_to_bid</th>\n",
       "      <th>...</th>\n",
       "      <th>max_url_per_auction</th>\n",
       "      <th>min_url_per_auction</th>\n",
       "      <th>std_url_per_auction</th>\n",
       "      <th>total_no_of_participated_auctions</th>\n",
       "      <th>no_of_auction_exceeds_threshold</th>\n",
       "      <th>percentage_of_auctions_above_threshold</th>\n",
       "      <th>total_no_of_bidded_category</th>\n",
       "      <th>no_of_merchandise_exceeds_threshold</th>\n",
       "      <th>percentage_of_merchandise_above_threshold</th>\n",
       "      <th>on_url_that_has_a_bot_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.298399</td>\n",
       "      <td>-0.340208</td>\n",
       "      <td>-0.132190</td>\n",
       "      <td>-0.304887</td>\n",
       "      <td>-0.135706</td>\n",
       "      <td>-0.127977</td>\n",
       "      <td>-0.102907</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.654541</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.298399</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>2.164678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.404530</td>\n",
       "      <td>-0.134389</td>\n",
       "      <td>-0.519330</td>\n",
       "      <td>-0.139281</td>\n",
       "      <td>-0.127601</td>\n",
       "      <td>-0.104346</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.552542</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.193631</td>\n",
       "      <td>1.774257</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>0.730297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.394030</td>\n",
       "      <td>-0.404530</td>\n",
       "      <td>-0.134285</td>\n",
       "      <td>-0.519330</td>\n",
       "      <td>-0.139070</td>\n",
       "      <td>-0.127601</td>\n",
       "      <td>-0.104278</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.521954</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.394030</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>0.730297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.409890</td>\n",
       "      <td>-0.134599</td>\n",
       "      <td>-0.519330</td>\n",
       "      <td>-0.139701</td>\n",
       "      <td>-0.127977</td>\n",
       "      <td>-0.104483</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>3.159798</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>2.164678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.264244</td>\n",
       "      <td>-0.131162</td>\n",
       "      <td>-0.118474</td>\n",
       "      <td>-0.476442</td>\n",
       "      <td>-0.114046</td>\n",
       "      <td>-0.094108</td>\n",
       "      <td>-0.093930</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.852382</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.127279</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>0.009616</td>\n",
       "      <td>-0.264244</td>\n",
       "      <td>-0.196489</td>\n",
       "      <td>-0.106261</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>-0.672558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>-0.250583</td>\n",
       "      <td>-0.393809</td>\n",
       "      <td>-0.131248</td>\n",
       "      <td>-0.390664</td>\n",
       "      <td>-0.138860</td>\n",
       "      <td>-0.127601</td>\n",
       "      <td>-0.102085</td>\n",
       "      <td>1.832251</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.077373</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.250583</td>\n",
       "      <td>-0.196489</td>\n",
       "      <td>-0.130120</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>0.730297</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.409890</td>\n",
       "      <td>-0.134599</td>\n",
       "      <td>-0.519330</td>\n",
       "      <td>-0.139701</td>\n",
       "      <td>-0.127977</td>\n",
       "      <td>-0.104483</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>3.090534</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>-0.704083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.404530</td>\n",
       "      <td>-0.134494</td>\n",
       "      <td>-0.519330</td>\n",
       "      <td>-0.139491</td>\n",
       "      <td>-0.127977</td>\n",
       "      <td>-0.104415</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.506158</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>-0.704083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.409890</td>\n",
       "      <td>-0.134599</td>\n",
       "      <td>-0.519330</td>\n",
       "      <td>-0.139701</td>\n",
       "      <td>-0.127977</td>\n",
       "      <td>-0.104483</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.707190</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>-0.704083</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.409890</td>\n",
       "      <td>-0.134494</td>\n",
       "      <td>-0.519330</td>\n",
       "      <td>-0.139701</td>\n",
       "      <td>-0.127977</td>\n",
       "      <td>-0.104415</td>\n",
       "      <td>-0.545777</td>\n",
       "      <td>-0.529655</td>\n",
       "      <td>-0.531281</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.197123</td>\n",
       "      <td>-0.103545</td>\n",
       "      <td>-0.257464</td>\n",
       "      <td>-0.414523</td>\n",
       "      <td>-0.213799</td>\n",
       "      <td>-0.404496</td>\n",
       "      <td>0.114687</td>\n",
       "      <td>-0.369671</td>\n",
       "      <td>-0.370524</td>\n",
       "      <td>-0.704083</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       auction    device      time   country        ip       url  num_bids  \\\n",
       "0    -0.298399 -0.340208 -0.132190 -0.304887 -0.135706 -0.127977 -0.102907   \n",
       "1    -0.414523 -0.404530 -0.134389 -0.519330 -0.139281 -0.127601 -0.104346   \n",
       "2    -0.394030 -0.404530 -0.134285 -0.519330 -0.139070 -0.127601 -0.104278   \n",
       "3    -0.414523 -0.409890 -0.134599 -0.519330 -0.139701 -0.127977 -0.104483   \n",
       "4    -0.264244 -0.131162 -0.118474 -0.476442 -0.114046 -0.094108 -0.093930   \n",
       "...        ...       ...       ...       ...       ...       ...       ...   \n",
       "2008 -0.250583 -0.393809 -0.131248 -0.390664 -0.138860 -0.127601 -0.102085   \n",
       "2009 -0.414523 -0.409890 -0.134599 -0.519330 -0.139701 -0.127977 -0.104483   \n",
       "2010 -0.414523 -0.404530 -0.134494 -0.519330 -0.139491 -0.127977 -0.104415   \n",
       "2011 -0.414523 -0.409890 -0.134599 -0.519330 -0.139701 -0.127977 -0.104483   \n",
       "2012 -0.414523 -0.409890 -0.134494 -0.519330 -0.139701 -0.127977 -0.104415   \n",
       "\n",
       "      num_first_bids  num_last_bids  time_to_bid  ...  max_url_per_auction  \\\n",
       "0          -0.545777      -0.529655    -0.654541  ...            -0.197123   \n",
       "1          -0.545777      -0.529655    -0.552542  ...            -0.193631   \n",
       "2          -0.545777      -0.529655    -0.521954  ...            -0.197123   \n",
       "3          -0.545777      -0.529655     3.159798  ...            -0.197123   \n",
       "4          -0.545777      -0.529655    -0.852382  ...            -0.127279   \n",
       "...              ...            ...          ...  ...                  ...   \n",
       "2008        1.832251      -0.529655    -0.077373  ...            -0.197123   \n",
       "2009       -0.545777      -0.529655     3.090534  ...            -0.197123   \n",
       "2010       -0.545777      -0.529655    -0.506158  ...            -0.197123   \n",
       "2011       -0.545777      -0.529655    -0.707190  ...            -0.197123   \n",
       "2012       -0.545777      -0.529655    -0.531281  ...            -0.197123   \n",
       "\n",
       "      min_url_per_auction  std_url_per_auction  \\\n",
       "0               -0.103545            -0.257464   \n",
       "1                1.774257            -0.257464   \n",
       "2               -0.103545            -0.257464   \n",
       "3               -0.103545            -0.257464   \n",
       "4               -0.103545             0.009616   \n",
       "...                   ...                  ...   \n",
       "2008            -0.103545            -0.257464   \n",
       "2009            -0.103545            -0.257464   \n",
       "2010            -0.103545            -0.257464   \n",
       "2011            -0.103545            -0.257464   \n",
       "2012            -0.103545            -0.257464   \n",
       "\n",
       "      total_no_of_participated_auctions  no_of_auction_exceeds_threshold  \\\n",
       "0                             -0.298399                        -0.213799   \n",
       "1                             -0.414523                        -0.213799   \n",
       "2                             -0.394030                        -0.213799   \n",
       "3                             -0.414523                        -0.213799   \n",
       "4                             -0.264244                        -0.196489   \n",
       "...                                 ...                              ...   \n",
       "2008                          -0.250583                        -0.196489   \n",
       "2009                          -0.414523                        -0.213799   \n",
       "2010                          -0.414523                        -0.213799   \n",
       "2011                          -0.414523                        -0.213799   \n",
       "2012                          -0.414523                        -0.213799   \n",
       "\n",
       "      percentage_of_auctions_above_threshold  total_no_of_bidded_category  \\\n",
       "0                                  -0.404496                     0.114687   \n",
       "1                                  -0.404496                     0.114687   \n",
       "2                                  -0.404496                     0.114687   \n",
       "3                                  -0.404496                     0.114687   \n",
       "4                                  -0.106261                     0.114687   \n",
       "...                                      ...                          ...   \n",
       "2008                               -0.130120                     0.114687   \n",
       "2009                               -0.404496                     0.114687   \n",
       "2010                               -0.404496                     0.114687   \n",
       "2011                               -0.404496                     0.114687   \n",
       "2012                               -0.404496                     0.114687   \n",
       "\n",
       "      no_of_merchandise_exceeds_threshold  \\\n",
       "0                               -0.369671   \n",
       "1                               -0.369671   \n",
       "2                               -0.369671   \n",
       "3                               -0.369671   \n",
       "4                               -0.369671   \n",
       "...                                   ...   \n",
       "2008                            -0.369671   \n",
       "2009                            -0.369671   \n",
       "2010                            -0.369671   \n",
       "2011                            -0.369671   \n",
       "2012                            -0.369671   \n",
       "\n",
       "      percentage_of_merchandise_above_threshold  on_url_that_has_a_bot_mean  \n",
       "0                                     -0.370524                    2.164678  \n",
       "1                                     -0.370524                    0.730297  \n",
       "2                                     -0.370524                    0.730297  \n",
       "3                                     -0.370524                    2.164678  \n",
       "4                                     -0.370524                   -0.672558  \n",
       "...                                         ...                         ...  \n",
       "2008                                  -0.370524                    0.730297  \n",
       "2009                                  -0.370524                   -0.704083  \n",
       "2010                                  -0.370524                   -0.704083  \n",
       "2011                                  -0.370524                   -0.704083  \n",
       "2012                                  -0.370524                   -0.704083  \n",
       "\n",
       "[2013 rows x 52 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Final Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traaining all models on using train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# sm = SMOTE(sampling_strategy='minority', random_state = 42)\n",
    "# X_train, y_train = sm.fit_resample(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# selected_features = ['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile', 'no_of_auction_exceeds_threshold', 'num_first_bids', 'ip', 'url', 'jewelry', 'num_bids_per_auction', 'max_ip_per_auction', 'inst_resp', 'computers', 'url_entropy', 'on_ip_that_has_a_bot_mean', 'device', 'home goods', 'time', 'std_url_per_auction', 'country', 'sporting goods', 'num_bids', 'perc_inst_resp', 'max_country_per_auction', 'mean_ip_per_auction', 'std_devices_per_auction', 'max_url_per_auction', 'std_ip_per_auction', 'mean_devices_per_auction', 'mean_url_per_auction', 'total_no_of_participated_auctions', 'std_country_per_auction', 'ip_entropy', 'mean_country_per_auction']\n",
    "\n",
    "# X = X[selected_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "52"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    print(\"TRAIN\")\n",
    "    train_predictions = model.predict_proba(X_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "        \n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    train_auc_roc_score = roc_auc_score(y_train,train_predictions[:,1])\n",
    "    train_fbeta = fbeta_score(y_train, train_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_train, train_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_train, train_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(train_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(train_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    print(\"TEST\")\n",
    "    \n",
    "    test_predictions = model.predict_proba(X_test)\n",
    "    test_pred = model.predict(X_test)\n",
    "        \n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_auc_roc_score = roc_auc_score(y_test,test_predictions[:,1])\n",
    "    test_fbeta = fbeta_score(y_test, test_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_test, test_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_test, test_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(test_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(test_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    return [train_accuracy, train_auc_roc_score, train_fbeta, test_accuracy, test_auc_roc_score, test_fbeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(arr):\n",
    "    train_accuracy = []\n",
    "    train_auc_roc_score = [] \n",
    "    train_fbeta = []\n",
    "    test_accuracy = []\n",
    "    test_auc_roc_score = []\n",
    "    test_fbeta = []\n",
    "    \n",
    "    for item in arr:\n",
    "        train_accuracy.append(item[0])\n",
    "        train_auc_roc_score.append(item[1])\n",
    "        train_fbeta.append(item[2])\n",
    "        test_accuracy.append(item[3])\n",
    "        test_auc_roc_score.append(item[4])\n",
    "        test_fbeta.append(item[5])\n",
    "    \n",
    "    mean_accuracy = np.array(train_accuracy).mean()\n",
    "    mean_train_auc_roc_score = np.array(train_auc_roc_score).mean()\n",
    "    mean_train_fbeta = np.array(train_fbeta).mean()\n",
    "    mean_test_accuracy = np.array(test_accuracy).mean()\n",
    "    mean_test_auc_roc_score = np.array(test_auc_roc_score).mean()\n",
    "    mean_test_fbeta = np.array(test_fbeta).mean()\n",
    "    \n",
    "    print(\"final train accuracy: \" + str(mean_accuracy))\n",
    "    print(\"final train AUC: \" + str(mean_train_auc_roc_score))\n",
    "    print(\"final train fbeta: \" + str(mean_train_fbeta))\n",
    "    print(\"final test accuracy: \" + str(mean_test_accuracy))\n",
    "    print(\"final test AUC: \" + str(mean_test_auc_roc_score))\n",
    "    print(\"final test fbeta: \" + str(mean_test_fbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Base Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold number 1\n",
      "[00:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "TRAIN"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       342\n",
      "         1.0     1.0000    1.0000    1.0000       171\n",
      "\n",
      "    accuracy                         1.0000       513\n",
      "   macro avg     1.0000    1.0000    1.0000       513\n",
      "weighted avg     1.0000    1.0000    1.0000       513\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9779    0.9267    0.9516       191\n",
      "         1.0     0.3333    0.6364    0.4375        11\n",
      "\n",
      "    accuracy                         0.9109       202\n",
      "   macro avg     0.6556    0.7815    0.6946       202\n",
      "weighted avg     0.9428    0.9109    0.9236       202\n",
      "\n",
      "FBeta Score\n",
      "0.5384615384615384\n",
      "Model Performance\n",
      "Accuracy = 0.9109%.\n",
      "AUC ROC = 0.8953%.\n",
      "****************************************************************************************************\n",
      "Fold number 2\n",
      "[00:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       342\n",
      "         1.0     1.0000    1.0000    1.0000       171\n",
      "\n",
      "    accuracy                         1.0000       513\n",
      "   macro avg     1.0000    1.0000    1.0000       513\n",
      "weighted avg     1.0000    1.0000    1.0000       513\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9721    0.9110    0.9405       191\n",
      "         1.0     0.2609    0.5455    0.3529        11\n",
      "\n",
      "    accuracy                         0.8911       202\n",
      "   macro avg     0.6165    0.7282    0.6467       202\n",
      "weighted avg     0.9333    0.8911    0.9085       202\n",
      "\n",
      "FBeta Score\n",
      "0.44776119402985076\n",
      "Model Performance\n",
      "Accuracy = 0.8911%.\n",
      "AUC ROC = 0.8482%.\n",
      "****************************************************************************************************\n",
      "Fold number 3\n",
      "[00:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       342\n",
      "         1.0     1.0000    1.0000    1.0000       171\n",
      "\n",
      "    accuracy                         1.0000       513\n",
      "   macro avg     1.0000    1.0000    1.0000       513\n",
      "weighted avg     1.0000    1.0000    1.0000       513\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9781    0.9372    0.9572       191\n",
      "         1.0     0.3684    0.6364    0.4667        11\n",
      "\n",
      "    accuracy                         0.9208       202\n",
      "   macro avg     0.6733    0.7868    0.7119       202\n",
      "weighted avg     0.9449    0.9208    0.9305       202\n",
      "\n",
      "FBeta Score\n",
      "0.5555555555555556\n",
      "Model Performance\n",
      "Accuracy = 0.9208%.\n",
      "AUC ROC = 0.9296%.\n",
      "****************************************************************************************************\n",
      "Fold number 4\n",
      "[00:32:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.9971    0.9985       342\n",
      "         1.0     0.9942    1.0000    0.9971       171\n",
      "\n",
      "    accuracy                         0.9981       513\n",
      "   macro avg     0.9971    0.9985    0.9978       513\n",
      "weighted avg     0.9981    0.9981    0.9981       513\n",
      "\n",
      "FBeta Score\n",
      "0.9988317757009345\n",
      "Model Performance\n",
      "Accuracy = 0.9981%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9886    0.9058    0.9454       191\n",
      "         1.0     0.3077    0.8000    0.4444        10\n",
      "\n",
      "    accuracy                         0.9005       201\n",
      "   macro avg     0.6481    0.8529    0.6949       201\n",
      "weighted avg     0.9547    0.9005    0.9204       201\n",
      "\n",
      "FBeta Score\n",
      "0.6060606060606061\n",
      "Model Performance\n",
      "Accuracy = 0.9005%.\n",
      "AUC ROC = 0.9314%.\n",
      "****************************************************************************************************\n",
      "Fold number 5\n",
      "[00:32:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9971    1.0000    0.9985       342\n",
      "         1.0     1.0000    0.9942    0.9971       171\n",
      "\n",
      "    accuracy                         0.9981       513\n",
      "   macro avg     0.9985    0.9971    0.9978       513\n",
      "weighted avg     0.9981    0.9981    0.9980       513\n",
      "\n",
      "FBeta Score\n",
      "0.9953161592505855\n",
      "Model Performance\n",
      "Accuracy = 0.9981%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9887    0.9162    0.9511       191\n",
      "         1.0     0.3333    0.8000    0.4706        10\n",
      "\n",
      "    accuracy                         0.9104       201\n",
      "   macro avg     0.6610    0.8581    0.7108       201\n",
      "weighted avg     0.9561    0.9104    0.9272       201\n",
      "\n",
      "FBeta Score\n",
      "0.625\n",
      "Model Performance\n",
      "Accuracy = 0.9104%.\n",
      "AUC ROC = 0.8838%.\n",
      "****************************************************************************************************\n",
      "Fold number 6\n",
      "[00:32:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       342\n",
      "         1.0     1.0000    1.0000    1.0000       171\n",
      "\n",
      "    accuracy                         1.0000       513\n",
      "   macro avg     1.0000    1.0000    1.0000       513\n",
      "weighted avg     1.0000    1.0000    1.0000       513\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9883    0.8848    0.9337       191\n",
      "         1.0     0.2667    0.8000    0.4000        10\n",
      "\n",
      "    accuracy                         0.8806       201\n",
      "   macro avg     0.6275    0.8424    0.6669       201\n",
      "weighted avg     0.9524    0.8806    0.9071       201\n",
      "\n",
      "FBeta Score\n",
      "0.5714285714285714\n",
      "Model Performance\n",
      "Accuracy = 0.8806%.\n",
      "AUC ROC = 0.9382%.\n",
      "****************************************************************************************************\n",
      "Fold number 7\n",
      "[00:32:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       342\n",
      "         1.0     1.0000    1.0000    1.0000       171\n",
      "\n",
      "    accuracy                         1.0000       513\n",
      "   macro avg     1.0000    1.0000    1.0000       513\n",
      "weighted avg     1.0000    1.0000    1.0000       513\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9826    0.8848    0.9311       191\n",
      "         1.0     0.2414    0.7000    0.3590        10\n",
      "\n",
      "    accuracy                         0.8756       201\n",
      "   macro avg     0.6120    0.7924    0.6451       201\n",
      "weighted avg     0.9457    0.8756    0.9027       201\n",
      "\n",
      "FBeta Score\n",
      "0.5072463768115942\n",
      "Model Performance\n",
      "Accuracy = 0.8756%.\n",
      "AUC ROC = 0.8550%.\n",
      "****************************************************************************************************\n",
      "Fold number 8\n",
      "[00:32:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9971    1.0000    0.9985       342\n",
      "         1.0     1.0000    0.9942    0.9971       171\n",
      "\n",
      "    accuracy                         0.9981       513\n",
      "   macro avg     0.9985    0.9971    0.9978       513\n",
      "weighted avg     0.9981    0.9981    0.9980       513\n",
      "\n",
      "FBeta Score\n",
      "0.9953161592505855\n",
      "Model Performance\n",
      "Accuracy = 0.9981%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9944    0.9215    0.9565       191\n",
      "         1.0     0.3750    0.9000    0.5294        10\n",
      "\n",
      "    accuracy                         0.9204       201\n",
      "   macro avg     0.6847    0.9107    0.7430       201\n",
      "weighted avg     0.9635    0.9204    0.9353       201\n",
      "\n",
      "FBeta Score\n",
      "0.703125\n",
      "Model Performance\n",
      "Accuracy = 0.9204%.\n",
      "AUC ROC = 0.9613%.\n",
      "****************************************************************************************************\n",
      "Fold number 9\n",
      "[00:32:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    0.9971    0.9985       342\n",
      "         1.0     0.9942    1.0000    0.9971       171\n",
      "\n",
      "    accuracy                         0.9981       513\n",
      "   macro avg     0.9971    0.9985    0.9978       513\n",
      "weighted avg     0.9981    0.9981    0.9981       513\n",
      "\n",
      "FBeta Score\n",
      "0.9988317757009345\n",
      "Model Performance\n",
      "Accuracy = 0.9981%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9786    0.9581    0.9683       191\n",
      "         1.0     0.4286    0.6000    0.5000        10\n",
      "\n",
      "    accuracy                         0.9403       201\n",
      "   macro avg     0.7036    0.7791    0.7341       201\n",
      "weighted avg     0.9512    0.9403    0.9450       201\n",
      "\n",
      "FBeta Score\n",
      "0.5555555555555556\n",
      "Model Performance\n",
      "Accuracy = 0.9403%.\n",
      "AUC ROC = 0.9304%.\n",
      "****************************************************************************************************\n",
      "Fold number 10\n",
      "[00:32:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     1.0000    1.0000    1.0000       342\n",
      "         1.0     1.0000    1.0000    1.0000       171\n",
      "\n",
      "    accuracy                         1.0000       513\n",
      "   macro avg     1.0000    1.0000    1.0000       513\n",
      "weighted avg     1.0000    1.0000    1.0000       513\n",
      "\n",
      "FBeta Score\n",
      "1.0\n",
      "Model Performance\n",
      "Accuracy = 1.0000%.\n",
      "AUC ROC = 1.0000%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9941    0.8796    0.9333       191\n",
      "         1.0     0.2812    0.9000    0.4286        10\n",
      "\n",
      "    accuracy                         0.8806       201\n",
      "   macro avg     0.6377    0.8898    0.6810       201\n",
      "weighted avg     0.9586    0.8806    0.9082       201\n",
      "\n",
      "FBeta Score\n",
      "0.625\n",
      "Model Performance\n",
      "Accuracy = 0.8806%.\n",
      "AUC ROC = 0.8937%.\n",
      "****************************************************************************************************\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "counter = 1\n",
    "xgb_accuracy = []\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.1, random_state = 42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.5, random_state = 42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Fold number \" + str(counter))\n",
    "    counter += 1\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "            \n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "\n",
    "    xgb.fit(X_train, y_train)\n",
    "\n",
    "    xgb_accuracy.append(evaluate(xgb, X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying RandomSearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_xgb(X, y):\n",
    "    print(\"RANDOM SEARCH XGB EXPERIMENT\")\n",
    "    xgb_random_grid = {'min_child_weight': range(1,10),\n",
    "                    'gamma': [i/10.0 for i in range(0,10)],\n",
    "                    'subsample': [i/10.0 for i in range(3,10)],\n",
    "                    'colsample_bytree': [i/10.0 for i in range(6,10)],\n",
    "                    'max_depth': [3, 4, 5]}\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.1, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "    \n",
    "    xgb = XGBClassifier(random_state=42)\n",
    "    xgb_random = RandomizedSearchCV(estimator = xgb, param_distributions = xgb_random_grid, n_iter=100, scoring='roc_auc', \n",
    "                                n_jobs=-1, cv=2, random_state = 42)\n",
    "    xgb_random.fit(X_train, y_train)\n",
    "    xgb_best_random = xgb_random.best_estimator_\n",
    "    xgb_random_accuracy = evaluate(xgb_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(xgb_random.best_params_)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RANDOM SEARCH XGB EXPERIMENT\n",
      "[00:33:19] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9925    0.9962    0.9944       266\n",
      "         1.0     0.9924    0.9850    0.9887       133\n",
      "\n",
      "    accuracy                         0.9925       399\n",
      "   macro avg     0.9925    0.9906    0.9915       399\n",
      "weighted avg     0.9925    0.9925    0.9925       399\n",
      "\n",
      "FBeta Score\n",
      "0.9864457831325301\n",
      "Model Performance\n",
      "Accuracy = 0.9925%.\n",
      "AUC ROC = 0.9999%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9887    0.9099    0.9477       577\n",
      "         1.0     0.2877    0.7778    0.4200        27\n",
      "\n",
      "    accuracy                         0.9040       604\n",
      "   macro avg     0.6382    0.8438    0.6838       604\n",
      "weighted avg     0.9574    0.9040    0.9241       604\n",
      "\n",
      "FBeta Score\n",
      "0.5801104972375691\n",
      "Model Performance\n",
      "Accuracy = 0.9040%.\n",
      "AUC ROC = 0.9128%.\n",
      "****************************************************************************************************\n",
      "{'subsample': 0.8, 'min_child_weight': 1, 'max_depth': 5, 'gamma': 0.5, 'colsample_bytree': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "random_search_xgb(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying GridSearch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Getting results from random search to input values to grid search\n",
    "\n",
    "## Best Random Search Param for DT\n",
    "{'min_samples_split': 8, 'min_samples_leaf': 21, 'min_impurity_decrease': 0.0005, 'max_features': 25, 'max_depth': 50, 'criterion': 'entropy'}\n",
    "## Best Random Search Param for RF\n",
    "{'n_estimators': 1200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_features': 5, 'max_depth': 30, 'bootstrap': False}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_xgb(X, y):\n",
    "    print(\"GRID SEARCH XGB EXPERIMENT\")\n",
    "    xgb_grid = {\n",
    "        'max_depth':[4,5,6],\n",
    "        'min_child_weight':[1,3,5],\n",
    "        'gamma':[0.4, 0.5, 0.6],\n",
    "        'subsample':[0.7, 0.8, 0.9],\n",
    "        'colsample_bytree':[0.7, 0.8, 0.9]\n",
    "    }\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.1, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.5, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "    xgb = XGBClassifier(random_state=42, eval_metric=\"error\")\n",
    "    xgb_grid = GridSearchCV(estimator = xgb, param_grid = xgb_grid, scoring='roc_auc',n_jobs=-1, cv=2)\n",
    "    xgb_grid.fit(X_train, y_train)\n",
    "    \n",
    "    xgb_best_grid = xgb_grid.best_estimator_\n",
    "    xgb_grid_accuracy = evaluate(xgb_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(xgb_grid.best_params_)\n",
    "\n",
    "    return xgb_best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GRID SEARCH XGB EXPERIMENT\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9925    0.9962    0.9944       266\n",
      "         1.0     0.9924    0.9850    0.9887       133\n",
      "\n",
      "    accuracy                         0.9925       399\n",
      "   macro avg     0.9925    0.9906    0.9915       399\n",
      "weighted avg     0.9925    0.9925    0.9925       399\n",
      "\n",
      "FBeta Score\n",
      "0.9864457831325301\n",
      "Model Performance\n",
      "Accuracy = 0.9925%.\n",
      "AUC ROC = 0.9999%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9887    0.9116    0.9486       577\n",
      "         1.0     0.2917    0.7778    0.4242        27\n",
      "\n",
      "    accuracy                         0.9056       604\n",
      "   macro avg     0.6402    0.8447    0.6864       604\n",
      "weighted avg     0.9576    0.9056    0.9252       604\n",
      "\n",
      "FBeta Score\n",
      "0.5833333333333333\n",
      "Model Performance\n",
      "Accuracy = 0.9056%.\n",
      "AUC ROC = 0.9155%.\n",
      "****************************************************************************************************\n",
      "{'colsample_bytree': 0.9, 'gamma': 0.6, 'max_depth': 4, 'min_child_weight': 1, 'subsample': 0.8}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    }
   ],
   "source": [
    "xgb_best_grid = grid_search_xgb(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Params Grid Search for DT\n",
    "{'criterion': 'entropy', 'max_depth': 40, 'max_features': 30, 'min_impurity_decrease': 0.0005, 'min_samples_leaf': 26, 'min_samples_split': 6}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Params Grid Search for RF\n",
    "{'bootstrap': False, 'max_depth': 20, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1100}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TRAIN\n",
    "Classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0     1.0000    1.0000    1.0000      1333\n",
    "         1.0     1.0000    1.0000    1.0000      1333\n",
    "\n",
    "    accuracy                         1.0000      2666\n",
    "   macro avg     1.0000    1.0000    1.0000      2666\n",
    "weighted avg     1.0000    1.0000    1.0000      2666\n",
    "\n",
    "FBeta Score\n",
    "1.0\n",
    "Model Performance\n",
    "Accuracy = 1.0000%.\n",
    "AUC ROC = 1.0000%.\n",
    "****************************************************************************************************\n",
    "TEST\n",
    "Classification report\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "         0.0     0.9741    0.9792    0.9767       577\n",
    "         1.0     0.5000    0.4444    0.4706        27\n",
    "\n",
    "    accuracy                         0.9553       604\n",
    "   macro avg     0.7371    0.7118    0.7236       604\n",
    "weighted avg     0.9529    0.9553    0.9540       604\n",
    "\n",
    "FBeta Score\n",
    "0.45454545454545453\n",
    "Model Performance\n",
    "Accuracy = 0.9553%.\n",
    "AUC ROC = 0.8786%.\n",
    "****************************************************************************************************\n",
    "Best Params Grid Search for RF\n",
    "{'bootstrap': False, 'max_depth': 20, 'max_features': 5, 'min_samples_leaf': 1, 'min_samples_split': 2, 'n_estimators': 1100}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Features</th>\n",
       "      <th>xgb_weights</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>num_bids_per_auction</td>\n",
       "      <td>0.175440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>num_bids</td>\n",
       "      <td>0.155699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>inst_resp</td>\n",
       "      <td>0.072187</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>std_url_per_auction</td>\n",
       "      <td>0.044354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>num_bids_per_device</td>\n",
       "      <td>0.041093</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>country</td>\n",
       "      <td>0.032906</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>computers</td>\n",
       "      <td>0.029878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>std_country_per_auction</td>\n",
       "      <td>0.027539</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>num_bids_per_ip</td>\n",
       "      <td>0.024935</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>num_first_bids</td>\n",
       "      <td>0.024373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>max_ip_per_auction</td>\n",
       "      <td>0.019955</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>on_ip_that_has_a_bot_mean</td>\n",
       "      <td>0.019813</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>max_devices_per_auction</td>\n",
       "      <td>0.019510</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>no_of_merchandise_exceeds_threshold</td>\n",
       "      <td>0.018810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>auction</td>\n",
       "      <td>0.018613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>no_of_auction_exceeds_threshold</td>\n",
       "      <td>0.018379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>mean_devices_per_auction</td>\n",
       "      <td>0.016858</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>on_url_that_has_a_bot_mean</td>\n",
       "      <td>0.016344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>std_ip_per_auction</td>\n",
       "      <td>0.016096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>percentage_of_auctions_above_threshold</td>\n",
       "      <td>0.014928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>max_country_per_auction</td>\n",
       "      <td>0.014819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>std_devices_per_auction</td>\n",
       "      <td>0.013934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>num_bids_per_country</td>\n",
       "      <td>0.013599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>time_to_bid</td>\n",
       "      <td>0.012795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>mean_url_per_auction</td>\n",
       "      <td>0.012296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>perc_inst_resp</td>\n",
       "      <td>0.011961</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>url</td>\n",
       "      <td>0.011376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>time</td>\n",
       "      <td>0.010936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>ip</td>\n",
       "      <td>0.010182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>device</td>\n",
       "      <td>0.009764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>mean_country_per_auction</td>\n",
       "      <td>0.009350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>mean_ip_per_auction</td>\n",
       "      <td>0.008967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>home goods</td>\n",
       "      <td>0.008673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>mobile</td>\n",
       "      <td>0.007589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>jewelry</td>\n",
       "      <td>0.006647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>url_entropy</td>\n",
       "      <td>0.006608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>num_last_bids</td>\n",
       "      <td>0.006534</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>sporting goods</td>\n",
       "      <td>0.005587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>max_url_per_auction</td>\n",
       "      <td>0.005353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>ip_entropy</td>\n",
       "      <td>0.005320</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>total_no_of_bidded_category</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>total_no_of_participated_auctions</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>percentage_of_merchandise_above_threshold</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>min_devices_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>min_url_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>min_ip_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>furniture</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>min_country_per_auction</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>auto parts</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>books and music</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>office equipment</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>clothing</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Features  xgb_weights\n",
       "0                        num_bids_per_auction     0.175440\n",
       "1                                    num_bids     0.155699\n",
       "2                                   inst_resp     0.072187\n",
       "3                         std_url_per_auction     0.044354\n",
       "4                         num_bids_per_device     0.041093\n",
       "5                                     country     0.032906\n",
       "6                                   computers     0.029878\n",
       "7                     std_country_per_auction     0.027539\n",
       "8                             num_bids_per_ip     0.024935\n",
       "9                              num_first_bids     0.024373\n",
       "10                         max_ip_per_auction     0.019955\n",
       "11                  on_ip_that_has_a_bot_mean     0.019813\n",
       "12                    max_devices_per_auction     0.019510\n",
       "13        no_of_merchandise_exceeds_threshold     0.018810\n",
       "14                                    auction     0.018613\n",
       "15            no_of_auction_exceeds_threshold     0.018379\n",
       "16                   mean_devices_per_auction     0.016858\n",
       "17                 on_url_that_has_a_bot_mean     0.016344\n",
       "18                         std_ip_per_auction     0.016096\n",
       "19     percentage_of_auctions_above_threshold     0.014928\n",
       "20                    max_country_per_auction     0.014819\n",
       "21                    std_devices_per_auction     0.013934\n",
       "22                       num_bids_per_country     0.013599\n",
       "23                                time_to_bid     0.012795\n",
       "24                       mean_url_per_auction     0.012296\n",
       "25                             perc_inst_resp     0.011961\n",
       "26                                        url     0.011376\n",
       "27                                       time     0.010936\n",
       "28                                         ip     0.010182\n",
       "29                                     device     0.009764\n",
       "30                   mean_country_per_auction     0.009350\n",
       "31                        mean_ip_per_auction     0.008967\n",
       "32                                 home goods     0.008673\n",
       "33                                     mobile     0.007589\n",
       "34                                    jewelry     0.006647\n",
       "35                                url_entropy     0.006608\n",
       "36                              num_last_bids     0.006534\n",
       "37                             sporting goods     0.005587\n",
       "38                        max_url_per_auction     0.005353\n",
       "39                                 ip_entropy     0.005320\n",
       "40                total_no_of_bidded_category     0.000000\n",
       "41          total_no_of_participated_auctions     0.000000\n",
       "42  percentage_of_merchandise_above_threshold     0.000000\n",
       "43                    min_devices_per_auction     0.000000\n",
       "44                        min_url_per_auction     0.000000\n",
       "45                         min_ip_per_auction     0.000000\n",
       "46                                  furniture     0.000000\n",
       "47                    min_country_per_auction     0.000000\n",
       "48                                 auto parts     0.000000\n",
       "49                            books and music     0.000000\n",
       "50                           office equipment     0.000000\n",
       "51                                   clothing     0.000000"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_feat_impt = xgb_best_grid.feature_importances_\n",
    "xgb_features_rank = pd.DataFrame({\"Features\": X.columns, \"xgb_weights\": xgb_feat_impt})\n",
    "xgb_features_rank = xgb_features_rank.sort_values(by=['xgb_weights'], ascending=False)\n",
    "xgb_features_rank = xgb_features_rank.reset_index().drop(columns=['index'])\n",
    "xgb_features_rank"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_features_rank.to_csv('xgb_features.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
