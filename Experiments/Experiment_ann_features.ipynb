{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../new_train.csv\")\n",
    "test = pd.read_csv(\"../new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>...</th>\n",
       "      <th>max_url_per_auction</th>\n",
       "      <th>min_url_per_auction</th>\n",
       "      <th>std_url_per_auction</th>\n",
       "      <th>total_no_of_participated_auctions</th>\n",
       "      <th>no_of_auction_exceeds_threshold</th>\n",
       "      <th>percentage_of_auctions_above_threshold</th>\n",
       "      <th>total_no_of_bidded_category</th>\n",
       "      <th>no_of_merchandise_exceeds_threshold</th>\n",
       "      <th>percentage_of_merchandise_above_threshold</th>\n",
       "      <th>on_url_that_has_a_bot_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>21.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.644263</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.043478</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.010989</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>2008</td>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>2009</td>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>2010</td>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>2011</td>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>2012</td>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Unnamed: 0                              bidder_id  \\\n",
       "0              0  91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1              1  624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2              2  1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3              3  4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4              4  4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...          ...                                    ...   \n",
       "2008        2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009        2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010        2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011        2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012        2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country  ...  max_url_per_auction  min_url_per_auction  \\\n",
       "0       14.0   24.0      6.0  ...                  1.0                  1.0   \n",
       "1        2.0    3.0      1.0  ...                  2.0                  2.0   \n",
       "2        2.0    4.0      1.0  ...                  1.0                  1.0   \n",
       "3        1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "4       53.0  155.0      2.0  ...                 21.0                  1.0   \n",
       "...      ...    ...      ...  ...                  ...                  ...   \n",
       "2008     4.0   33.0      4.0  ...                  1.0                  1.0   \n",
       "2009     1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "2010     2.0    2.0      1.0  ...                  1.0                  1.0   \n",
       "2011     1.0    1.0      1.0  ...                  1.0                  1.0   \n",
       "2012     1.0    2.0      1.0  ...                  1.0                  1.0   \n",
       "\n",
       "      std_url_per_auction  total_no_of_participated_auctions  \\\n",
       "0                0.000000                               18.0   \n",
       "1                0.000000                                1.0   \n",
       "2                0.000000                                4.0   \n",
       "3                0.000000                                1.0   \n",
       "4                5.644263                               23.0   \n",
       "...                   ...                                ...   \n",
       "2008             0.000000                               25.0   \n",
       "2009             0.000000                                1.0   \n",
       "2010             0.000000                                1.0   \n",
       "2011             0.000000                                1.0   \n",
       "2012             0.000000                                1.0   \n",
       "\n",
       "      no_of_auction_exceeds_threshold  percentage_of_auctions_above_threshold  \\\n",
       "0                                 0.0                                0.000000   \n",
       "1                                 0.0                                0.000000   \n",
       "2                                 0.0                                0.000000   \n",
       "3                                 0.0                                0.000000   \n",
       "4                                 1.0                                0.043478   \n",
       "...                               ...                                     ...   \n",
       "2008                              1.0                                0.040000   \n",
       "2009                              0.0                                0.000000   \n",
       "2010                              0.0                                0.000000   \n",
       "2011                              0.0                                0.000000   \n",
       "2012                              0.0                                0.000000   \n",
       "\n",
       "      total_no_of_bidded_category  no_of_merchandise_exceeds_threshold  \\\n",
       "0                             1.0                                  0.0   \n",
       "1                             1.0                                  0.0   \n",
       "2                             1.0                                  0.0   \n",
       "3                             1.0                                  0.0   \n",
       "4                             1.0                                  0.0   \n",
       "...                           ...                                  ...   \n",
       "2008                          1.0                                  0.0   \n",
       "2009                          1.0                                  0.0   \n",
       "2010                          1.0                                  0.0   \n",
       "2011                          1.0                                  0.0   \n",
       "2012                          1.0                                  0.0   \n",
       "\n",
       "      percentage_of_merchandise_above_threshold  on_url_that_has_a_bot_mean  \n",
       "0                                           0.0                    1.000000  \n",
       "1                                           0.0                    0.500000  \n",
       "2                                           0.0                    0.500000  \n",
       "3                                           0.0                    1.000000  \n",
       "4                                           0.0                    0.010989  \n",
       "...                                         ...                         ...  \n",
       "2008                                        0.0                    0.500000  \n",
       "2009                                        0.0                    0.000000  \n",
       "2010                                        0.0                    0.000000  \n",
       "2011                                        0.0                    0.000000  \n",
       "2012                                        0.0                    0.000000  \n",
       "\n",
       "[2013 rows x 58 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "test.drop(test.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['bidder_id', 'payment_account', 'address', 'outcome','merchandise']) \n",
    "y = train['outcome']\n",
    "X_test = test.drop(columns=['bidder_id', 'payment_account', 'address', 'merchandise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaled_features = data.copy()\n",
    "col_names = ['auction', 'device', 'time', 'country', 'ip', 'url', 'num_bids',\n",
    "       'num_first_bids', 'num_last_bids', 'time_to_bid', 'inst_resp',\n",
    "       'perc_inst_resp', 'num_bids_per_auction',\n",
    "       'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip',\n",
    "       'on_ip_that_has_a_bot_mean', 'ip_entropy', 'url_entropy',\n",
    "       'mean_country_per_auction', 'max_country_per_auction',\n",
    "       'min_country_per_auction', 'std_country_per_auction',\n",
    "       'mean_devices_per_auction', 'max_devices_per_auction',\n",
    "       'min_devices_per_auction', 'std_devices_per_auction',\n",
    "       'mean_ip_per_auction', 'max_ip_per_auction', 'min_ip_per_auction',\n",
    "       'std_ip_per_auction', 'mean_url_per_auction', 'max_url_per_auction',\n",
    "       'min_url_per_auction', 'std_url_per_auction',\n",
    "       'total_no_of_participated_auctions', 'no_of_auction_exceeds_threshold',\n",
    "       'percentage_of_auctions_above_threshold', 'total_no_of_bidded_category',\n",
    "       'no_of_merchandise_exceeds_threshold',\n",
    "       'percentage_of_merchandise_above_threshold',\n",
    "       'on_url_that_has_a_bot_mean']\n",
    "features = X[col_names]\n",
    "scaler = StandardScaler().fit(features.values)\n",
    "features = scaler.transform(features.values)\n",
    "X[col_names] = features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "features = X_test[col_names]\n",
    "scaler_test = StandardScaler().fit(features.values)\n",
    "features = scaler_test.transform(features.values)\n",
    "X_test[col_names] = features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### model creation\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_accuracy(selected_features,X,X_test,y):\n",
    "    X = X[selected_features]\n",
    "    X_test = X_test[selected_features]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    sm = SMOTE(sampling_strategy='minority', random_state = 42)\n",
    "    X_train, y_train = sm.fit_resample(X_train, y_train)\n",
    "    kfold = StratifiedKFold(n_splits=3, shuffle = False)\n",
    "    def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "        print(\"TRAIN\")\n",
    "        train_predictions = model.predict_proba(X_train)\n",
    "        train_pred = model.predict(X_train)\n",
    "\n",
    "        train_accuracy = accuracy_score(y_train, train_pred)\n",
    "        train_auc_roc_score = roc_auc_score(y_train,train_predictions[:,1])\n",
    "\n",
    "        print(\"Classification report\")\n",
    "        print(classification_report(y_train, train_pred, digits = 4))\n",
    "\n",
    "        print(\"FBeta Score\")\n",
    "        print(fbeta_score(y_train, train_pred, average='binary', beta=2.0))\n",
    "\n",
    "        print('Model Performance')\n",
    "        print('Accuracy = {:0.4f}%.'.format(train_accuracy))\n",
    "        print('AUC ROC = {:0.4f}%.'.format(train_auc_roc_score))\n",
    "        print(\"*\" * 100)\n",
    "\n",
    "        print(\"TEST\")\n",
    "        test_predictions = model.predict_proba(X_test)\n",
    "        test_pred = model.predict(X_test)\n",
    "\n",
    "        test_accuracy = accuracy_score(y_test, test_pred)\n",
    "        test_auc_roc_score = roc_auc_score(y_test,test_predictions[:,1])\n",
    "\n",
    "        print(\"Classification report\")\n",
    "        print(classification_report(y_test, test_pred, digits = 4))\n",
    "\n",
    "        print(\"FBeta Score\")\n",
    "        print(fbeta_score(y_test, test_pred, average='binary', beta=2.0))\n",
    "\n",
    "        print('Model Performance')\n",
    "        print('Accuracy = {:0.4f}%.'.format(test_accuracy))\n",
    "        print('AUC ROC = {:0.4f}%.'.format(test_auc_roc_score))\n",
    "        print(\"*\" * 100)\n",
    "    def create_model(learn_rate=0.01, momentum=0):\n",
    "        # create model\n",
    "        model = Sequential()\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(64, activation='relu'))\n",
    "        model.add(Dense(1, activation='sigmoid'))\n",
    "        # Compile model\n",
    "        model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "        return model\n",
    "\n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann.fit(X_train, y_train)\n",
    "    print(\"BASED MODEL\")\n",
    "    ann_accuracy = evaluate(ann, X_train, y_train, X_test, y_test)\n",
    "\n",
    "    print(\"RANDOM SEARCH ANN EXPERIMENT\")\n",
    "    learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "    momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "    batch_size = [10, 20, 40, 60, 80, 100]\n",
    "    epochs = [10, 50, 100]\n",
    "\n",
    "    ann_random_grid = dict(learn_rate=learn_rate,momentum=momentum,batch_size=batch_size, epochs=epochs)\n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann_random = RandomizedSearchCV(estimator = ann, param_distributions = ann_random_grid, n_iter = 100, cv = 2, \n",
    "                                verbose=2, random_state=42, n_jobs = -1, scoring='roc_auc')\n",
    "    ann_random.fit(X_train, y_train)\n",
    "    ann_best_random = ann_random.best_estimator_\n",
    "    rand_best_params = ann_random.best_params_\n",
    "    print(ann_random.best_params_)\n",
    "    ann_random_accuracy = evaluate(ann_best_random, X_train, y_train, X_test, y_test)\n",
    "\n",
    "\n",
    "    print(\"GRID SEARCH ANN EXPERIMENT\")\n",
    "    #     from random search\n",
    "    #     'momentum': 0.0, 'learn_rate': 0.3, 'epochs': 100, 'batch_size': 10\n",
    "    # learn_rate = [0.3, 0.1, 0.2]\n",
    "    # momentum = [0.0, 0.2, 0.4]\n",
    "    # batch_size = [5, 10, 20]\n",
    "    # epochs = [50, 100, 150]\n",
    "    learn_rate = [rand_best_params['learn_rate'],rand_best_params['learn_rate']*1.5,rand_best_params['learn_rate']/1.5]\n",
    "    momentum = [rand_best_params['momentum'],rand_best_params['momentum']*1.5,rand_best_params['momentum']/1.5]\n",
    "    batch_size = [rand_best_params['batch_size'],rand_best_params['batch_size']*1.5,rand_best_params['batch_size']/1.5]\n",
    "    epochs = [rand_best_params['epochs'],rand_best_params['epochs']*1.5,rand_best_params['epochs']/1.5]\n",
    "    ann_grid = dict(learn_rate=learn_rate,momentum=momentum,batch_size=batch_size, epochs=epochs)\n",
    "    # ann_grid = rand_best_params\n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann_grid = GridSearchCV(estimator = ann, param_grid = ann_grid, n_jobs=-1, cv=2, scoring='roc_auc')\n",
    "    ann_grid.fit(X_train, y_train)\n",
    "    ann_best_grid = ann_grid.best_estimator_\n",
    "    grid_best_parms = ann_grid.best_params_\n",
    "    ann_grid_accuracy = evaluate(ann_best_grid, X_train, y_train, X_test, y_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Other number of Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features_10 = ['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile']\n",
    "selected_features_15 = ['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile', 'no_of_auction_exceeds_threshold', 'num_first_bids', 'ip', 'url', 'jewelry']\n",
    "selected_features_20 =['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile', 'no_of_auction_exceeds_threshold', 'num_first_bids', 'ip', 'url', 'jewelry', 'num_bids_per_auction', 'max_ip_per_auction', 'inst_resp', 'computers', 'url_entropy']\n",
    "selected_features_25= ['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile', 'no_of_auction_exceeds_threshold', 'num_first_bids', 'ip', 'url', 'jewelry', 'num_bids_per_auction', 'max_ip_per_auction', 'inst_resp', 'computers', 'url_entropy', 'on_ip_that_has_a_bot_mean', 'device', 'home goods', 'time', 'std_url_per_auction']\n",
    "selected_features_30=['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile', 'no_of_auction_exceeds_threshold', 'num_first_bids', 'ip', 'url', 'jewelry', 'num_bids_per_auction', 'max_ip_per_auction', 'inst_resp', 'computers', 'url_entropy', 'on_ip_that_has_a_bot_mean', 'device', 'home goods', 'time', 'std_url_per_auction', 'country', 'sporting goods', 'num_bids', 'perc_inst_resp', 'max_country_per_auction']\n",
    "selected_features_35=['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile', 'no_of_auction_exceeds_threshold', 'num_first_bids', 'ip', 'url', 'jewelry', 'num_bids_per_auction', 'max_ip_per_auction', 'inst_resp', 'computers', 'url_entropy', 'on_ip_that_has_a_bot_mean', 'device', 'home goods', 'time', 'std_url_per_auction', 'country', 'sporting goods', 'num_bids', 'perc_inst_resp', 'max_country_per_auction', 'mean_ip_per_auction', 'std_devices_per_auction', 'max_url_per_auction', 'std_ip_per_auction', 'mean_devices_per_auction']\n",
    "selected_features_40=['num_bids_per_device', 'percentage_of_auctions_above_threshold', 'time_to_bid', 'num_bids_per_ip', 'on_url_that_has_a_bot_mean', 'num_bids_per_country', 'auction', 'max_devices_per_auction', 'num_last_bids', 'mobile', 'no_of_auction_exceeds_threshold', 'num_first_bids', 'ip', 'url', 'jewelry', 'num_bids_per_auction', 'max_ip_per_auction', 'inst_resp', 'computers', 'url_entropy', 'on_ip_that_has_a_bot_mean', 'device', 'home goods', 'time', 'std_url_per_auction', 'country', 'sporting goods', 'num_bids', 'perc_inst_resp', 'max_country_per_auction', 'mean_ip_per_auction', 'std_devices_per_auction', 'max_url_per_auction', 'std_ip_per_auction', 'mean_devices_per_auction', 'mean_url_per_auction', 'total_no_of_participated_auctions', 'std_country_per_auction', 'ip_entropy', 'mean_country_per_auction']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASED MODEL\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8236    0.6969    0.7550      1333\n",
      "         1.0     0.7373    0.8507    0.7900      1333\n",
      "\n",
      "    accuracy                         0.7738      2666\n",
      "   macro avg     0.7805    0.7738    0.7725      2666\n",
      "weighted avg     0.7805    0.7738    0.7725      2666\n",
      "\n",
      "FBeta Score\n",
      "0.8253275109170306\n",
      "Model Performance\n",
      "Accuracy = 0.7738%.\n",
      "AUC ROC = 0.8338%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9927    0.7036    0.8235       577\n",
      "         1.0     0.1231    0.8889    0.2162        27\n",
      "\n",
      "    accuracy                         0.7119       604\n",
      "   macro avg     0.5579    0.7963    0.5199       604\n",
      "weighted avg     0.9538    0.7119    0.7964       604\n",
      "\n",
      "FBeta Score\n",
      "0.39603960396039606\n",
      "Model Performance\n",
      "Accuracy = 0.7119%.\n",
      "AUC ROC = 0.8352%.\n",
      "****************************************************************************************************\n",
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-06 01:25:36.602134: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.602137: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.602133: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.602165: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.602169: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.602175: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.602132: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.602391: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-06 01:25:36.854540: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-06 01:25:36.854537: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-06 01:25:36.854535: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-06 01:25:36.854555: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-06 01:25:36.854536: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-06 01:25:36.854559: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-06 01:25:36.854566: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-06 01:25:36.854530: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'momentum': 0.9, 'learn_rate': 0.3, 'epochs': 100, 'batch_size': 10}\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9940    0.8770    0.9318      1333\n",
      "         1.0     0.8899    0.9947    0.9394      1333\n",
      "\n",
      "    accuracy                         0.9359      2666\n",
      "   macro avg     0.9420    0.9359    0.9356      2666\n",
      "weighted avg     0.9420    0.9359    0.9356      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9718557607739666\n",
      "Model Performance\n",
      "Accuracy = 0.9359%.\n",
      "AUC ROC = 0.9861%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9760    0.8440    0.9052       577\n",
      "         1.0     0.1429    0.5556    0.2273        27\n",
      "\n",
      "    accuracy                         0.8311       604\n",
      "   macro avg     0.5594    0.6998    0.5662       604\n",
      "weighted avg     0.9387    0.8311    0.8749       604\n",
      "\n",
      "FBeta Score\n",
      "0.352112676056338\n",
      "Model Performance\n",
      "Accuracy = 0.8311%.\n",
      "AUC ROC = 0.7530%.\n",
      "****************************************************************************************************\n",
      "GRID SEARCH ANN EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 150.0 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 66.66666666666667 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1320.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1320.0] of type 'list' instead. Error: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1326.6666666666667\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1326.6666666666667] of type 'list' instead. Error: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.93364047 0.8992145  0.91401392 0.93219722 0.93963362 0.91261959\n",
      " 0.92510057 0.93086812 0.87799793        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9888    0.9280    0.9574      1333\n",
      "         1.0     0.9322    0.9895    0.9600      1333\n",
      "\n",
      "    accuracy                         0.9587      2666\n",
      "   macro avg     0.9605    0.9587    0.9587      2666\n",
      "weighted avg     0.9605    0.9587    0.9587      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9774714688009487\n",
      "Model Performance\n",
      "Accuracy = 0.9587%.\n",
      "AUC ROC = 0.9932%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9809    0.8891    0.9327       577\n",
      "         1.0     0.2099    0.6296    0.3148        27\n",
      "\n",
      "    accuracy                         0.8775       604\n",
      "   macro avg     0.5954    0.7594    0.6238       604\n",
      "weighted avg     0.9464    0.8775    0.9051       604\n",
      "\n",
      "FBeta Score\n",
      "0.44973544973544977\n",
      "Model Performance\n",
      "Accuracy = 0.8775%.\n",
      "AUC ROC = 0.7357%.\n",
      "****************************************************************************************************\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   6.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   3.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   4.7s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   8.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=  13.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.6s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=  12.0s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   7.9s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  21.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   4.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  32.2s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   5.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   9.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.4s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   5.0s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  15.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  31.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  30.0s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   3.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.0s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.6s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  15.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.2s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   7.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  46.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   8.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   6.8s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   5.1s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  19.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  32.1s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=  12.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  28.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.5s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=  10.6s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=  12.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=  10.0s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  30.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   7.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   9.8s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.8s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  40.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=  10.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   7.0s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   4.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   4.7s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   7.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.9s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=  24.4s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.7s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   5.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   9.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.3s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   5.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.5s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  30.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  30.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  14.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   1.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   7.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.4s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  40.3s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   7.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  42.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=  22.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  30.3s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  15.2s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  29.9s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   8.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  30.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  28.1s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   9.3s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   6.0s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  40.2s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   7.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  42.6s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   9.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   8.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.7s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  15.5s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   6.2s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.7s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=  10.9s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=   9.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  43.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   7.3s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  16.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.7s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   7.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  46.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   6.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   6.7s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  20.1s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=  22.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.4s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  29.2s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.5s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  30.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  31.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  26.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   6.8s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   3.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   4.7s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   8.9s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=  13.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.2s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=  11.4s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   8.3s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  21.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   8.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   9.3s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   9.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  15.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.7s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.2s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  30.1s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   8.1s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=  10.0s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  17.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  14.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  25.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  40.2s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=  10.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   6.7s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   4.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   7.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=  24.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  30.4s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  15.2s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  15.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  31.8s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.7s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  17.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   4.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  25.9s\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(selected_features_10,X,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASED MODEL\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6495    0.8980    0.7538      1333\n",
      "         1.0     0.8348    0.5154    0.6373      1333\n",
      "\n",
      "    accuracy                         0.7067      2666\n",
      "   macro avg     0.7421    0.7067    0.6955      2666\n",
      "weighted avg     0.7421    0.7067    0.6955      2666\n",
      "\n",
      "FBeta Score\n",
      "0.5580828594638506\n",
      "Model Performance\n",
      "Accuracy = 0.7067%.\n",
      "AUC ROC = 0.6242%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9705    0.9116    0.9401       577\n",
      "         1.0     0.1774    0.4074    0.2472        27\n",
      "\n",
      "    accuracy                         0.8891       604\n",
      "   macro avg     0.5739    0.6595    0.5937       604\n",
      "weighted avg     0.9350    0.8891    0.9091       604\n",
      "\n",
      "FBeta Score\n",
      "0.32352941176470584\n",
      "Model Performance\n",
      "Accuracy = 0.8891%.\n",
      "AUC ROC = 0.5259%.\n",
      "****************************************************************************************************\n",
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-11-05 23:55:09.309906: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.309907: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.309909: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.309924: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.309945: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.309947: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.309911: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.309923: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2021-11-05 23:55:09.452975: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-05 23:55:09.453038: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-05 23:55:09.452975: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-05 23:55:09.453224: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-05 23:55:09.453437: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-05 23:55:09.453453: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-05 23:55:09.456636: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n",
      "2021-11-05 23:55:09.476986: I tensorflow/compiler/mlir/mlir_graph_optimization_pass.cc:185] None of the MLIR Optimization Passes are enabled (registered 2)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'momentum': 0.4, 'learn_rate': 0.01, 'epochs': 100, 'batch_size': 10}\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9731    0.8957    0.9328      1333\n",
      "         1.0     0.9034    0.9752    0.9380      1333\n",
      "\n",
      "    accuracy                         0.9355      2666\n",
      "   macro avg     0.9383    0.9355    0.9354      2666\n",
      "weighted avg     0.9383    0.9355    0.9354      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9599763698124353\n",
      "Model Performance\n",
      "Accuracy = 0.9355%.\n",
      "AUC ROC = 0.9811%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9724    0.8544    0.9096       577\n",
      "         1.0     0.1340    0.4815    0.2097        27\n",
      "\n",
      "    accuracy                         0.8377       604\n",
      "   macro avg     0.5532    0.6680    0.5596       604\n",
      "weighted avg     0.9349    0.8377    0.8783       604\n",
      "\n",
      "FBeta Score\n",
      "0.31707317073170727\n",
      "Model Performance\n",
      "Accuracy = 0.8377%.\n",
      "AUC ROC = 0.6414%.\n",
      "****************************************************************************************************\n",
      "GRID SEARCH ANN EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 150.0 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 66.66666666666667 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1320.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1320.0] of type 'list' instead. Error: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1326.6666666666667\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1326.6666666666667] of type 'list' instead. Error: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.9198005  0.8917618  0.9198603  0.92333659 0.89110404 0.91594097\n",
      " 0.91668297 0.90136171 0.88198521        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9706    0.8912    0.9292      1333\n",
      "         1.0     0.8994    0.9730    0.9348      1333\n",
      "\n",
      "    accuracy                         0.9321      2666\n",
      "   macro avg     0.9350    0.9321    0.9320      2666\n",
      "weighted avg     0.9350    0.9321    0.9320      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9573368762917034\n",
      "Model Performance\n",
      "Accuracy = 0.9321%.\n",
      "AUC ROC = 0.9792%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9764    0.8596    0.9143       577\n",
      "         1.0     0.1562    0.5556    0.2439        27\n",
      "\n",
      "    accuracy                         0.8460       604\n",
      "   macro avg     0.5663    0.7076    0.5791       604\n",
      "weighted avg     0.9397    0.8460    0.8843       604\n",
      "\n",
      "FBeta Score\n",
      "0.36764705882352944\n",
      "Model Performance\n",
      "Accuracy = 0.8460%.\n",
      "AUC ROC = 0.7062%.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(selected_features_15,X,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASED MODEL\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8647    0.7142    0.7823      1333\n",
      "         1.0     0.7565    0.8882    0.8171      1333\n",
      "\n",
      "    accuracy                         0.8012      2666\n",
      "   macro avg     0.8106    0.8012    0.7997      2666\n",
      "weighted avg     0.8106    0.8012    0.7997      2666\n",
      "\n",
      "FBeta Score\n",
      "0.8583442076265042\n",
      "Model Performance\n",
      "Accuracy = 0.8012%.\n",
      "AUC ROC = 0.8531%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9927    0.7054    0.8247       577\n",
      "         1.0     0.1237    0.8889    0.2172        27\n",
      "\n",
      "    accuracy                         0.7136       604\n",
      "   macro avg     0.5582    0.7971    0.5210       604\n",
      "weighted avg     0.9538    0.7136    0.7976       604\n",
      "\n",
      "FBeta Score\n",
      "0.3973509933774835\n",
      "Model Performance\n",
      "Accuracy = 0.7136%.\n",
      "AUC ROC = 0.8070%.\n",
      "****************************************************************************************************\n",
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n",
      "{'momentum': 0.9, 'learn_rate': 0.1, 'epochs': 100, 'batch_size': 10}\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9722    0.8410    0.9019      1333\n",
      "         1.0     0.8599    0.9760    0.9143      1333\n",
      "\n",
      "    accuracy                         0.9085      2666\n",
      "   macro avg     0.9161    0.9085    0.9081      2666\n",
      "weighted avg     0.9161    0.9085    0.9081      2666\n",
      "\n",
      "FBeta Score\n",
      "0.950328707085464\n",
      "Model Performance\n",
      "Accuracy = 0.9085%.\n",
      "AUC ROC = 0.9713%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9772    0.8163    0.8895       577\n",
      "         1.0     0.1311    0.5926    0.2148        27\n",
      "\n",
      "    accuracy                         0.8063       604\n",
      "   macro avg     0.5542    0.7044    0.5521       604\n",
      "weighted avg     0.9394    0.8063    0.8594       604\n",
      "\n",
      "FBeta Score\n",
      "0.34782608695652173\n",
      "Model Performance\n",
      "Accuracy = 0.8063%.\n",
      "AUC ROC = 0.7355%.\n",
      "****************************************************************************************************\n",
      "GRID SEARCH ANN EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 150.0 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 66.66666666666667 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1320.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1320.0] of type 'list' instead. Error: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1326.6666666666667\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1326.6666666666667] of type 'list' instead. Error: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.91650359 0.91288052 0.91722929 0.92835399 0.90434062 0.88064797\n",
      " 0.92639704 0.93013155 0.92789737        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8052    0.9115    0.8550      1333\n",
      "         1.0     0.8980    0.7794    0.8345      1333\n",
      "\n",
      "    accuracy                         0.8455      2666\n",
      "   macro avg     0.8516    0.8455    0.8448      2666\n",
      "weighted avg     0.8516    0.8455    0.8448      2666\n",
      "\n",
      "FBeta Score\n",
      "0.8005856064108492\n",
      "Model Performance\n",
      "Accuracy = 0.8455%.\n",
      "AUC ROC = 0.9009%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9624    0.8873    0.9234       577\n",
      "         1.0     0.0972    0.2593    0.1414        27\n",
      "\n",
      "    accuracy                         0.8593       604\n",
      "   macro avg     0.5298    0.5733    0.5324       604\n",
      "weighted avg     0.9237    0.8593    0.8884       604\n",
      "\n",
      "FBeta Score\n",
      "0.19444444444444445\n",
      "Model Performance\n",
      "Accuracy = 0.8593%.\n",
      "AUC ROC = 0.5461%.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(selected_features_20,X,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASED MODEL\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6147    0.9227    0.7379      1333\n",
      "         1.0     0.8451    0.4216    0.5626      1333\n",
      "\n",
      "    accuracy                         0.6722      2666\n",
      "   macro avg     0.7299    0.6722    0.6502      2666\n",
      "weighted avg     0.7299    0.6722    0.6502      2666\n",
      "\n",
      "FBeta Score\n",
      "0.46856761714190437\n",
      "Model Performance\n",
      "Accuracy = 0.6722%.\n",
      "AUC ROC = 0.5785%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9671    0.9168    0.9413       577\n",
      "         1.0     0.1579    0.3333    0.2143        27\n",
      "\n",
      "    accuracy                         0.8907       604\n",
      "   macro avg     0.5625    0.6251    0.5778       604\n",
      "weighted avg     0.9309    0.8907    0.9088       604\n",
      "\n",
      "FBeta Score\n",
      "0.27272727272727276\n",
      "Model Performance\n",
      "Accuracy = 0.8907%.\n",
      "AUC ROC = 0.4849%.\n",
      "****************************************************************************************************\n",
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n",
      "{'momentum': 0.2, 'learn_rate': 0.2, 'epochs': 100, 'batch_size': 10}\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9711    0.8815    0.9241      1333\n",
      "         1.0     0.8915    0.9737    0.9308      1333\n",
      "\n",
      "    accuracy                         0.9276      2666\n",
      "   macro avg     0.9313    0.9276    0.9275      2666\n",
      "weighted avg     0.9313    0.9276    0.9275      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9560989982321745\n",
      "Model Performance\n",
      "Accuracy = 0.9276%.\n",
      "AUC ROC = 0.9611%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9819    0.8475    0.9098       577\n",
      "         1.0     0.1698    0.6667    0.2707        27\n",
      "\n",
      "    accuracy                         0.8394       604\n",
      "   macro avg     0.5759    0.7571    0.5902       604\n",
      "weighted avg     0.9456    0.8394    0.8812       604\n",
      "\n",
      "FBeta Score\n",
      "0.42056074766355134\n",
      "Model Performance\n",
      "Accuracy = 0.8394%.\n",
      "AUC ROC = 0.7581%.\n",
      "****************************************************************************************************\n",
      "GRID SEARCH ANN EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 150.0 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 66.66666666666667 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1320.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1320.0] of type 'list' instead. Error: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1326.6666666666667\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1326.6666666666667] of type 'list' instead. Error: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.91677267 0.89126441 0.87979452 0.85892314 0.89978528 0.84269678\n",
      " 0.81386171 0.86577789 0.89972277        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9788    0.8650    0.9184      1333\n",
      "         1.0     0.8790    0.9812    0.9273      1333\n",
      "\n",
      "    accuracy                         0.9231      2666\n",
      "   macro avg     0.9289    0.9231    0.9228      2666\n",
      "weighted avg     0.9289    0.9231    0.9228      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9589442815249268\n",
      "Model Performance\n",
      "Accuracy = 0.9231%.\n",
      "AUC ROC = 0.9603%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9837    0.8371    0.9045       577\n",
      "         1.0     0.1681    0.7037    0.2714        27\n",
      "\n",
      "    accuracy                         0.8311       604\n",
      "   macro avg     0.5759    0.7704    0.5880       604\n",
      "weighted avg     0.9472    0.8311    0.8762       604\n",
      "\n",
      "FBeta Score\n",
      "0.4298642533936652\n",
      "Model Performance\n",
      "Accuracy = 0.8311%.\n",
      "AUC ROC = 0.7873%.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(selected_features_25,X,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASED MODEL\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6248    0.7119    0.6655      1333\n",
      "         1.0     0.6652    0.5724    0.6153      1333\n",
      "\n",
      "    accuracy                         0.6422      2666\n",
      "   macro avg     0.6450    0.6422    0.6404      2666\n",
      "weighted avg     0.6450    0.6422    0.6404      2666\n",
      "\n",
      "FBeta Score\n",
      "0.5888254360240779\n",
      "Model Performance\n",
      "Accuracy = 0.6422%.\n",
      "AUC ROC = 0.5939%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9752    0.6828    0.8033       577\n",
      "         1.0     0.0850    0.6296    0.1498        27\n",
      "\n",
      "    accuracy                         0.6805       604\n",
      "   macro avg     0.5301    0.6562    0.4765       604\n",
      "weighted avg     0.9355    0.6805    0.7741       604\n",
      "\n",
      "FBeta Score\n",
      "0.275974025974026\n",
      "Model Performance\n",
      "Accuracy = 0.6805%.\n",
      "AUC ROC = 0.6368%.\n",
      "****************************************************************************************************\n",
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n",
      "{'momentum': 0.9, 'learn_rate': 0.3, 'epochs': 100, 'batch_size': 10}\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9520    0.8920    0.9210      1333\n",
      "         1.0     0.8984    0.9550    0.9258      1333\n",
      "\n",
      "    accuracy                         0.9235      2666\n",
      "   macro avg     0.9252    0.9235    0.9234      2666\n",
      "weighted avg     0.9252    0.9235    0.9234      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9431026818787969\n",
      "Model Performance\n",
      "Accuracy = 0.9235%.\n",
      "AUC ROC = 0.9640%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9842    0.8631    0.9197       577\n",
      "         1.0     0.1939    0.7037    0.3040        27\n",
      "\n",
      "    accuracy                         0.8560       604\n",
      "   macro avg     0.5890    0.7834    0.6118       604\n",
      "weighted avg     0.9489    0.8560    0.8921       604\n",
      "\n",
      "FBeta Score\n",
      "0.46116504854368934\n",
      "Model Performance\n",
      "Accuracy = 0.8560%.\n",
      "AUC ROC = 0.8213%.\n",
      "****************************************************************************************************\n",
      "GRID SEARCH ANN EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 150.0 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 66.66666666666667 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1320.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1320.0] of type 'list' instead. Error: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1326.6666666666667\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1326.6666666666667] of type 'list' instead. Error: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.73806534 0.87694608 0.81493531 0.78924766 0.83074853 0.85734127\n",
      " 0.72938411 0.84742607 0.83239563        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9766    0.8777    0.9245      1333\n",
      "         1.0     0.8890    0.9790    0.9318      1333\n",
      "\n",
      "    accuracy                         0.9284      2666\n",
      "   macro avg     0.9328    0.9284    0.9282      2666\n",
      "weighted avg     0.9328    0.9284    0.9282      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9595588235294118\n",
      "Model Performance\n",
      "Accuracy = 0.9284%.\n",
      "AUC ROC = 0.9607%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9863    0.8752    0.9275       577\n",
      "         1.0     0.2174    0.7407    0.3361        27\n",
      "\n",
      "    accuracy                         0.8692       604\n",
      "   macro avg     0.6019    0.8080    0.6318       604\n",
      "weighted avg     0.9520    0.8692    0.9010       604\n",
      "\n",
      "FBeta Score\n",
      "0.49999999999999994\n",
      "Model Performance\n",
      "Accuracy = 0.8692%.\n",
      "AUC ROC = 0.8434%.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(selected_features_30,X,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASED MODEL\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.6016    0.7997    0.6866      1333\n",
      "         1.0     0.7013    0.4704    0.5631      1333\n",
      "\n",
      "    accuracy                         0.6350      2666\n",
      "   macro avg     0.6515    0.6350    0.6249      2666\n",
      "weighted avg     0.6515    0.6350    0.6249      2666\n",
      "\n",
      "FBeta Score\n",
      "0.5035335689045937\n",
      "Model Performance\n",
      "Accuracy = 0.6350%.\n",
      "AUC ROC = 0.5237%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9736    0.7678    0.8585       577\n",
      "         1.0     0.1007    0.5556    0.1705        27\n",
      "\n",
      "    accuracy                         0.7583       604\n",
      "   macro avg     0.5371    0.6617    0.5145       604\n",
      "weighted avg     0.9346    0.7583    0.8278       604\n",
      "\n",
      "FBeta Score\n",
      "0.2918287937743191\n",
      "Model Performance\n",
      "Accuracy = 0.7583%.\n",
      "AUC ROC = 0.6094%.\n",
      "****************************************************************************************************\n",
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n",
      "{'momentum': 0.0, 'learn_rate': 0.3, 'epochs': 100, 'batch_size': 10}\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9878    0.8515    0.9146      1333\n",
      "         1.0     0.8695    0.9895    0.9256      1333\n",
      "\n",
      "    accuracy                         0.9205      2666\n",
      "   macro avg     0.9286    0.9205    0.9201      2666\n",
      "weighted avg     0.9286    0.9205    0.9201      2666\n",
      "\n",
      "FBeta Score\n",
      "0.9629142940575266\n",
      "Model Performance\n",
      "Accuracy = 0.9205%.\n",
      "AUC ROC = 0.9525%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9877    0.8319    0.9031       577\n",
      "         1.0     0.1780    0.7778    0.2897        27\n",
      "\n",
      "    accuracy                         0.8295       604\n",
      "   macro avg     0.5828    0.8048    0.5964       604\n",
      "weighted avg     0.9515    0.8295    0.8757       604\n",
      "\n",
      "FBeta Score\n",
      "0.4646017699115044\n",
      "Model Performance\n",
      "Accuracy = 0.8295%.\n",
      "AUC ROC = 0.8361%.\n",
      "****************************************************************************************************\n",
      "GRID SEARCH ANN EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 150.0 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 66.66666666666667 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1320.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1320.0] of type 'list' instead. Error: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1326.6666666666667\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1326.6666666666667] of type 'list' instead. Error: Expected int32, got 1326.6666666666667 of type 'float' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.85287019 0.77095564 0.65392748 0.79421613 0.88226245 0.84657262\n",
      " 0.68539628 0.83118613 0.88744836        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9689    0.8425    0.9013      1333\n",
      "         1.0     0.8607    0.9730    0.9134      1333\n",
      "\n",
      "    accuracy                         0.9077      2666\n",
      "   macro avg     0.9148    0.9077    0.9073      2666\n",
      "weighted avg     0.9148    0.9077    0.9073      2666\n",
      "\n",
      "FBeta Score\n",
      "0.948238046498026\n",
      "Model Performance\n",
      "Accuracy = 0.9077%.\n",
      "AUC ROC = 0.9501%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9854    0.8180    0.8939       577\n",
      "         1.0     0.1600    0.7407    0.2632        27\n",
      "\n",
      "    accuracy                         0.8146       604\n",
      "   macro avg     0.5727    0.7794    0.5785       604\n",
      "weighted avg     0.9485    0.8146    0.8657       604\n",
      "\n",
      "FBeta Score\n",
      "0.4291845493562232\n",
      "Model Performance\n",
      "Accuracy = 0.8146%.\n",
      "AUC ROC = 0.8158%.\n",
      "****************************************************************************************************\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(selected_features_35,X,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BASED MODEL\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.5543    0.9302    0.6947      1333\n",
      "         1.0     0.7832    0.2521    0.3814      1333\n",
      "\n",
      "    accuracy                         0.5911      2666\n",
      "   macro avg     0.6688    0.5911    0.5380      2666\n",
      "weighted avg     0.6688    0.5911    0.5380      2666\n",
      "\n",
      "FBeta Score\n",
      "0.29161603888213855\n",
      "Model Performance\n",
      "Accuracy = 0.5911%.\n",
      "AUC ROC = 0.3727%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9640    0.9272    0.9452       577\n",
      "         1.0     0.1429    0.2593    0.1842        27\n",
      "\n",
      "    accuracy                         0.8974       604\n",
      "   macro avg     0.5534    0.5932    0.5647       604\n",
      "weighted avg     0.9273    0.8974    0.9112       604\n",
      "\n",
      "FBeta Score\n",
      "0.22292993630573243\n",
      "Model Performance\n",
      "Accuracy = 0.8974%.\n",
      "AUC ROC = 0.3627%.\n",
      "****************************************************************************************************\n",
      "RANDOM SEARCH ANN EXPERIMENT\n",
      "Fitting 2 folds for each of 100 candidates, totalling 200 fits\n",
      "{'momentum': 0.2, 'learn_rate': 0.2, 'epochs': 100, 'batch_size': 60}\n",
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.8445    0.8717    0.8579      1333\n",
      "         1.0     0.8674    0.8395    0.8532      1333\n",
      "\n",
      "    accuracy                         0.8556      2666\n",
      "   macro avg     0.8560    0.8556    0.8556      2666\n",
      "weighted avg     0.8560    0.8556    0.8556      2666\n",
      "\n",
      "FBeta Score\n",
      "0.8449109030504378\n",
      "Model Performance\n",
      "Accuracy = 0.8556%.\n",
      "AUC ROC = 0.9301%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9786    0.8735    0.9231       577\n",
      "         1.0     0.1798    0.5926    0.2759        27\n",
      "\n",
      "    accuracy                         0.8609       604\n",
      "   macro avg     0.5792    0.7330    0.5995       604\n",
      "weighted avg     0.9429    0.8609    0.8941       604\n",
      "\n",
      "FBeta Score\n",
      "0.4060913705583756\n",
      "Model Performance\n",
      "Accuracy = 0.8609%.\n",
      "AUC ROC = 0.7797%.\n",
      "****************************************************************************************************\n",
      "GRID SEARCH ANN EXPERIMENT\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py:372: FitFailedWarning: \n",
      "144 fits failed out of a total of 162.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 150.0 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "54 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 271, in __init__\n",
      "    indices_dataset = indices_dataset.repeat(epochs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1262, in repeat\n",
      "    return RepeatDataset(self, count)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4409, in __init__\n",
      "    self._count = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_conversion_registry.py\", line 52, in _default_conversion_function\n",
      "    return constant_op.constant(value, dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 283, in _constant_impl\n",
      "    return _constant_eager_impl(ctx, value, dtype, shape, verify_shape)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 308, in _constant_eager_impl\n",
      "    t = convert_to_eager_tensor(value, ctx, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 106, in convert_to_eager_tensor\n",
      "    return ops.EagerTensor(value, ctx.device_name, dtype)\n",
      "TypeError: Cannot convert 66.66666666666667 to EagerTensor of dtype int64\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1260.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1260.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1260.0] of type 'list' instead. Error: Expected int32, got 1260.0 of type 'float' instead.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "18 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 330, in _AssertCompatible\n",
      "    fn(values)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 269, in inner\n",
      "    _check_failed(v)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 250, in _check_failed\n",
      "    raise ValueError(v)\n",
      "ValueError: 1320.0\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 517, in _apply_op_helper\n",
      "    values = ops.convert_to_tensor(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/profiler/trace.py\", line 163, in wrapped\n",
      "    return func(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/ops.py\", line 1566, in convert_to_tensor\n",
      "    ret = conversion_func(value, dtype=dtype, name=name, as_ref=as_ref)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 346, in _constant_tensor_conversion_function\n",
      "    return constant(v, dtype=dtype, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 271, in constant\n",
      "    return _constant_impl(value, dtype, shape, name, verify_shape=False,\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/constant_op.py\", line 288, in _constant_impl\n",
      "    tensor_util.make_tensor_proto(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 457, in make_tensor_proto\n",
      "    _AssertCompatible(values, dtype)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/tensor_util.py\", line 336, in _AssertCompatible\n",
      "    raise TypeError(\"Expected %s, got %s of type '%s' instead.\" %\n",
      "TypeError: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_validation.py\", line 681, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 219, in fit\n",
      "    return super(KerasClassifier, self).fit(x, y, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/wrappers/scikit_learn.py\", line 162, in fit\n",
      "    history = self.model.fit(x, y, **fit_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/training.py\", line 1134, in fit\n",
      "    data_handler = data_adapter.get_data_handler(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1383, in get_data_handler\n",
      "    return DataHandler(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 1138, in __init__\n",
      "    self._adapter = adapter_cls(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 320, in __init__\n",
      "    indices_dataset = indices_dataset.flat_map(slice_batch_indices)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 1903, in flat_map\n",
      "    return FlatMapDataset(self, map_func)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 5062, in __init__\n",
      "    self._map_func = StructuredFunctionWrapper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4218, in __init__\n",
      "    self._function = fn_factory()\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3150, in get_concrete_function\n",
      "    graph_function = self._get_concrete_function_garbage_collected(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3116, in _get_concrete_function_garbage_collected\n",
      "    graph_function, _ = self._maybe_define_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3463, in _maybe_define_function\n",
      "    graph_function = self._create_graph_function(args, kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/eager/function.py\", line 3298, in _create_graph_function\n",
      "    func_graph_module.func_graph_from_py_func(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/func_graph.py\", line 1007, in func_graph_from_py_func\n",
      "    func_outputs = python_func(*func_args, **func_kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4195, in wrapped_fn\n",
      "    ret = wrapper_helper(*args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/data/ops/dataset_ops.py\", line 4125, in wrapper_helper\n",
      "    ret = autograph.tf_convert(self._func, ag_ctx)(*nested_args)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 692, in wrapper\n",
      "    return converted_call(f, args, kwargs, options=options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 382, in converted_call\n",
      "    return _call_unconverted(f, args, kwargs, options)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/autograph/impl/api.py\", line 463, in _call_unconverted\n",
      "    return f(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/keras/engine/data_adapter.py\", line 305, in slice_batch_indices\n",
      "    first_k_indices = tf.slice(indices, [0], [num_in_full_batch])\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/util/dispatch.py\", line 206, in wrapper\n",
      "    return target(*args, **kwargs)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/array_ops.py\", line 1108, in slice\n",
      "    return gen_array_ops._slice(input_, begin, size, name=name)\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/ops/gen_array_ops.py\", line 9416, in _slice\n",
      "    _, _, _op, _outputs = _op_def_library._apply_op_helper(\n",
      "  File \"/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/tensorflow/python/framework/op_def_library.py\", line 527, in _apply_op_helper\n",
      "    raise TypeError(\n",
      "TypeError: Expected int32 passed to parameter 'size' of op 'Slice', got [1320.0] of type 'list' instead. Error: Expected int32, got 1320.0 of type 'float' instead.\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "/Users/brennanszeto/Environments/dsenv/lib/python3.9/site-packages/sklearn/model_selection/_search.py:969: UserWarning: One or more of the test scores are non-finite: [0.67192596 0.6980349  0.82652207 0.68035714 0.70407697 0.68717656\n",
      " 0.7583279  0.80380246 0.70225321        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan        nan        nan        nan\n",
      "        nan        nan        nan]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TRAIN\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.7934    0.8642    0.8273      1333\n",
      "         1.0     0.8509    0.7749    0.8112      1333\n",
      "\n",
      "    accuracy                         0.8196      2666\n",
      "   macro avg     0.8221    0.8196    0.8192      2666\n",
      "weighted avg     0.8221    0.8196    0.8192      2666\n",
      "\n",
      "FBeta Score\n",
      "0.7890314695997556\n",
      "Model Performance\n",
      "Accuracy = 0.8196%.\n",
      "AUC ROC = 0.8777%.\n",
      "****************************************************************************************************\n",
      "TEST\n",
      "Classification report\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0     0.9744    0.8579    0.9124       577\n",
      "         1.0     0.1458    0.5185    0.2276        27\n",
      "\n",
      "    accuracy                         0.8427       604\n",
      "   macro avg     0.5601    0.6882    0.5700       604\n",
      "weighted avg     0.9374    0.8427    0.8818       604\n",
      "\n",
      "FBeta Score\n",
      "0.3431372549019608\n",
      "Model Performance\n",
      "Accuracy = 0.8427%.\n",
      "AUC ROC = 0.6715%.\n",
      "****************************************************************************************************\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   5.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  26.0s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  13.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  13.9s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   3.7s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  15.6s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  19.9s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  27.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  28.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  15.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   3.1s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   8.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  28.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.0s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.2s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   7.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.5s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   8.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  17.6s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  12.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  28.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  27.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  17.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.1s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.1s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.9s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  27.6s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  24.7s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  12.2s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   3.7s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.8s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   4.9s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.3s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   3.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   4.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   1.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.8s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   6.0s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=  10.0s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  30.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  15.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.8s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  14.5s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.9s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   8.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  15.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.8s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   6.1s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.2s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   7.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  17.2s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  15.5s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  15.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  30.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  42.8s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   9.3s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.4s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   2.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   9.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   4.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  26.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  27.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.7s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.7s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=   9.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  29.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  16.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  26.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.5s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   5.2s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=  10.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.1s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   3.4s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   7.3s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.3s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.2s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   6.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.2s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  31.3s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.7s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=  10.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.7s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  17.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   6.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   5.2s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  25.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  26.6s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   1.8s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  14.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  32.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   4.1s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  13.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  28.0s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  15.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   5.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  14.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   3.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   4.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   8.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   2.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  14.2s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  29.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   3.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   1.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.7s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.6s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.9s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=   9.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  26.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  28.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.9s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   2.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.9s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   8.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  42.3s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   3.7s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  14.7s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  14.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.8s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  14.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  29.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  43.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  29.4s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  15.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   5.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.0s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.3s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.8s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  15.5s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  29.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.9s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=  10.1s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.8s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  16.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  13.8s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   4.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  23.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  30.2s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.8s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.7s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.9s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.1s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  16.0s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  14.6s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  29.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=   9.4s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.8s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.2s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  17.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   7.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.3s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  16.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  31.7s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   4.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  15.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   5.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  27.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   6.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   4.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  31.8s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  30.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  16.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=  10.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   5.0s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   1.9s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.7s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   7.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   2.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  25.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   6.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  27.0s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=  10.4s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.2s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=   8.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  28.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  27.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.1s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   4.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  29.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  14.8s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  42.4s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   3.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  29.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  27.3s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  17.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.1s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  15.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  28.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   4.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   1.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  12.3s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=  11.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  26.9s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   9.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  29.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  30.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  15.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.8s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  29.5s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  14.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  31.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.8s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.0s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  30.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  28.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  24.7s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   4.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  30.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.2s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  15.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   5.1s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.6s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.3s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  16.2s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.9s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.2s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   1.8s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   5.2s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=  10.0s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=  12.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  31.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  16.2s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=  11.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   3.0s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   3.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  31.9s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  26.3s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   4.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=  12.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   7.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  29.5s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.5s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=  10.1s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=  10.6s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=  10.1s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  30.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   7.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=  10.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  26.6s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   1.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.9s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   9.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   8.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   7.2s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   5.3s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  27.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=   9.3s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  28.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  24.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  29.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.2s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   3.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   3.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  17.6s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  12.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  14.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   3.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  43.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  16.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   5.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  24.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   2.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   8.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   1.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   2.7s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  14.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   1.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   6.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  42.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  28.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.7s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=   9.7s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  29.8s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   1.6s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  24.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   6.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  30.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.8s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   5.1s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   9.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.2s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   7.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  17.3s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  29.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.9s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=  10.1s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.8s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  16.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   4.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.5s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.1s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  30.0s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   4.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   3.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.6s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.6s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  28.8s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  15.0s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  30.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  30.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  16.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   5.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  31.7s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   8.9s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  29.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  14.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   3.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  32.4s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.6s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  17.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   6.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  25.6s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  26.6s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.9s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  15.6s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  19.9s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  27.0s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  28.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  27.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  29.1s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  14.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.7s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   8.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  29.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   3.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  29.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=  12.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  28.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.1s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.3s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  15.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  42.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.2s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   5.9s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   4.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.2s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   3.8s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  26.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.4s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.7s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   9.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  29.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=   9.3s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  16.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   6.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   3.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  24.8s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.9s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   8.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  26.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.9s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=  12.3s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  31.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   9.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  29.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  30.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  26.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.0s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=   9.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  30.4s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  15.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   6.3s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   3.0s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.9s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   3.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  29.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  29.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  28.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=  12.1s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  31.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   3.9s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.1s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  14.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.8s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.7s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   6.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.7s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  14.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   3.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  32.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  30.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  15.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.9s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  26.5s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   1.7s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  14.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  32.7s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   4.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  13.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  28.0s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.0s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  28.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  14.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.6s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   3.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   4.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  29.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  14.8s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.2s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   9.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   4.0s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.7s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   4.9s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   4.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  14.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  29.3s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   4.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  28.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.7s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   8.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.9s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.2s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   4.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  27.7s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   1.8s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.9s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  22.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   4.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  25.8s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.2s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.5s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  28.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  29.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  26.8s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=  11.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   4.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  29.5s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.5s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  14.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   9.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  28.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.7s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   3.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.8s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.6s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=  10.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  30.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  14.5s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.2s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   7.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=  12.3s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   6.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  30.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.9; total time=   2.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  15.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.0s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   6.2s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.5s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.2s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   4.9s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.9s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   8.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  29.7s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.0s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=   9.6s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.6s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  17.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   6.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.9s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.01, momentum=0.9; total time=  11.2s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   2.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.6s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   5.2s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=  10.1s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   3.9s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  26.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   5.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  27.4s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.9s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  28.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   9.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  29.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  28.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   9.6s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   6.0s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   5.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  25.9s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  13.5s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.6s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  13.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   3.7s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   8.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   7.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   7.8s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   4.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  26.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  28.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  15.4s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  24.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  28.8s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  25.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   5.9s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.3s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   9.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   5.7s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   7.2s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   4.9s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.6; total time=   3.5s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  29.0s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   6.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=   9.4s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   4.7s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.0s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   2.6s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  16.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   5.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  24.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  27.6s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.2, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   2.8s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  13.8s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.4s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.2s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   1.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.3s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.1s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   4.8s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  13.8s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   4.1s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  14.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  29.5s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   3.5s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  16.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   6.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.0s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   2.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  14.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.4; total time=  29.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.6; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   3.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.1, momentum=0.2; total time=   2.5s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.3, momentum=0.9; total time=   2.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.4; total time=   5.4s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.9s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.2s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.2, momentum=0.6; total time=   4.8s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.2, momentum=0.4; total time=   8.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.001, momentum=0.4; total time=   3.3s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.01, momentum=0.0; total time=   6.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   5.1s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  15.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=  10.1s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.8; total time=   2.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  43.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  14.4s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  30.0s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  26.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   4.0s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  27.5s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  14.6s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.4; total time=   5.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  28.9s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   7.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  29.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  28.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=  10.3s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   6.0s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  31.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   2.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  14.5s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.0s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.7s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.001, momentum=0.9; total time=   8.9s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.8; total time=   2.6s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.5s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  15.8s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  15.2s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.1s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=  10.1s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=  10.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  29.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  28.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   9.6s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   6.0s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.1s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   5.1s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   1.9s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.6s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.3s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   7.6s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   2.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  25.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.6s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   6.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  27.2s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=  10.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.2s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.5s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.3s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.6s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.2s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.4s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.3s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=   8.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.8; total time=   9.2s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.0; total time=   5.4s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.1, momentum=0.0; total time=   2.9s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.6; total time=  16.1s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.001, momentum=0.0; total time=   5.3s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.4; total time=   6.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.01, momentum=0.2; total time=   3.1s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   8.7s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.3s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.01, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   4.0s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.7s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   8.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   2.7s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  26.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.9s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   2.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.1, momentum=0.4; total time=   5.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  29.3s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   4.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   4.8s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   2.6s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.1, momentum=0.4; total time=   3.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   1.8s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   5.0s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   5.7s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.2s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=   9.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  26.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  28.7s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   8.6s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   6.0s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.2s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   4.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  27.6s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   1.8s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.01, momentum=0.9; total time=   3.0s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  14.0s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.0s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.8; total time=   4.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   1.3s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.1, momentum=0.4; total time=   1.6s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   5.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.4s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   7.8s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  14.7s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.9; total time=   4.5s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.001, momentum=0.2; total time=   5.1s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.2s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   3.7s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   1.9s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.1, momentum=0.8; total time=   4.9s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.3, momentum=0.2; total time=   6.0s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.0; total time=   3.8s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.4; total time=   2.5s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.0; total time=   9.6s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.3, momentum=0.9; total time=   9.9s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  29.5s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  26.8s\n",
      "[CV] END batch_size=20, epochs=50, learn_rate=0.1, momentum=0.9; total time=   8.9s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.01, momentum=0.6; total time=   5.8s\n",
      "[CV] END batch_size=80, epochs=100, learn_rate=0.3, momentum=0.8; total time=   4.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.2; total time=  29.4s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.3, momentum=0.6; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.6; total time=  26.4s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.01, momentum=0.9; total time=   3.9s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.0; total time=  28.4s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.3, momentum=0.2; total time=   5.9s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=100, epochs=100, learn_rate=0.2, momentum=0.0; total time=   5.0s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.8s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.01, momentum=0.6; total time=   9.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.8; total time=  29.3s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.01, momentum=0.4; total time=  30.2s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.0; total time=  26.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  14.6s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   4.4s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   4.4s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.2; total time=   1.9s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.3, momentum=0.6; total time=   2.8s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.8; total time=   4.8s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.1, momentum=0.0; total time=   9.2s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.2, momentum=0.9; total time=   4.7s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.01, momentum=0.0; total time=   4.1s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.4; total time=   1.9s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.1, momentum=0.4; total time=   3.3s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.3, momentum=0.2; total time=  15.1s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.3, momentum=0.6; total time=   6.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.4; total time=  14.6s\n",
      "[CV] END batch_size=100, epochs=50, learn_rate=0.01, momentum=0.4; total time=   4.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.2; total time=   2.7s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.2; total time=  28.8s\n",
      "[CV] END batch_size=60, epochs=50, learn_rate=0.3, momentum=0.2; total time=   4.0s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.01, momentum=0.4; total time=  15.0s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.01, momentum=0.8; total time=   2.7s\n",
      "[CV] END batch_size=60, epochs=10, learn_rate=0.001, momentum=0.2; total time=   2.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.0; total time=  30.2s\n",
      "[CV] END batch_size=40, epochs=10, learn_rate=0.3, momentum=0.9; total time=   3.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.2, momentum=0.8; total time=  30.2s\n",
      "[CV] END batch_size=100, epochs=10, learn_rate=0.2, momentum=0.8; total time=   2.5s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.8; total time=   4.4s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.3, momentum=0.9; total time=  27.0s\n",
      "[CV] END batch_size=40, epochs=50, learn_rate=0.2, momentum=0.2; total time=   5.1s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.9; total time=  43.2s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.1, momentum=0.9; total time=  15.4s\n",
      "[CV] END batch_size=80, epochs=10, learn_rate=0.01, momentum=0.9; total time=   2.2s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.2, momentum=0.2; total time=   7.4s\n",
      "[CV] END batch_size=80, epochs=50, learn_rate=0.3, momentum=0.0; total time=   3.3s\n",
      "[CV] END batch_size=40, epochs=100, learn_rate=0.3, momentum=0.8; total time=   8.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.2, momentum=0.9; total time=  15.9s\n",
      "[CV] END batch_size=10, epochs=50, learn_rate=0.001, momentum=0.0; total time=  22.6s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.1, momentum=0.8; total time=  30.1s\n",
      "[CV] END batch_size=60, epochs=100, learn_rate=0.001, momentum=0.9; total time=   8.8s\n",
      "[CV] END batch_size=10, epochs=100, learn_rate=0.001, momentum=0.6; total time=  30.4s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.3, momentum=0.6; total time=  16.5s\n",
      "[CV] END batch_size=20, epochs=10, learn_rate=0.001, momentum=0.0; total time=   3.7s\n",
      "[CV] END batch_size=20, epochs=100, learn_rate=0.001, momentum=0.6; total time=  15.8s\n",
      "[CV] END batch_size=10, epochs=10, learn_rate=0.2, momentum=0.0; total time=   5.1s\n"
     ]
    }
   ],
   "source": [
    "model_accuracy(selected_features_40,X,X_test,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
