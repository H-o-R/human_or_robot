{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_df= pd.read_csv('data/bids.csv')\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df= pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid_id</th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8dac2b259fd1c6d1120e519fb1ac14fbqvax8</td>\n",
       "      <td>ewmzr</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone0</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>us</td>\n",
       "      <td>69.166.231.58</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>668d393e858e8126275433046bbd35c6tywop</td>\n",
       "      <td>aeqok</td>\n",
       "      <td>furniture</td>\n",
       "      <td>phone1</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>in</td>\n",
       "      <td>50.201.125.84</td>\n",
       "      <td>jmqlhflrzwuay9c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aa5f360084278b35d746fa6af3a7a1a5ra3xe</td>\n",
       "      <td>wa00e</td>\n",
       "      <td>home goods</td>\n",
       "      <td>phone2</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>py</td>\n",
       "      <td>112.54.208.157</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3939ac3ef7d472a59a9c5f893dd3e39fh9ofi</td>\n",
       "      <td>jefix</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone4</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>in</td>\n",
       "      <td>18.99.175.133</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8393c48eaf4b8fa96886edc7cf27b372dsibi</td>\n",
       "      <td>jefix</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone5</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>in</td>\n",
       "      <td>145.138.5.37</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656329</th>\n",
       "      <td>7656329</td>\n",
       "      <td>626159dd6f2228ede002d9f9340f75b7puk8d</td>\n",
       "      <td>3e64w</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone91</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>ru</td>\n",
       "      <td>140.204.227.63</td>\n",
       "      <td>cghhmomsaxi6pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656330</th>\n",
       "      <td>7656330</td>\n",
       "      <td>a318ea333ceee1ba39a494476386136a826dv</td>\n",
       "      <td>xn0y0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>phone236</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>pl</td>\n",
       "      <td>24.232.159.118</td>\n",
       "      <td>wgggpdg2gx5pesn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656331</th>\n",
       "      <td>7656331</td>\n",
       "      <td>f5b2bbad20d1d7ded3ed960393bec0f40u6hn</td>\n",
       "      <td>gja6c</td>\n",
       "      <td>sporting goods</td>\n",
       "      <td>phone80</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>za</td>\n",
       "      <td>80.237.28.246</td>\n",
       "      <td>5xgysg14grlersa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656332</th>\n",
       "      <td>7656332</td>\n",
       "      <td>d4bd412590f5106b9d887a43c51b254eldo4f</td>\n",
       "      <td>hmwk8</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone349</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>my</td>\n",
       "      <td>91.162.27.152</td>\n",
       "      <td>bhtrek44bzi2wfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656333</th>\n",
       "      <td>7656333</td>\n",
       "      <td>0ea62aaa9c3ffcc6db584cb69c1f6c4bcripp</td>\n",
       "      <td>c9ox9</td>\n",
       "      <td>mobile</td>\n",
       "      <td>phone82</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>jo</td>\n",
       "      <td>160.243.101.60</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7656334 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          bid_id                              bidder_id auction  \\\n",
       "0              0  8dac2b259fd1c6d1120e519fb1ac14fbqvax8   ewmzr   \n",
       "1              1  668d393e858e8126275433046bbd35c6tywop   aeqok   \n",
       "2              2  aa5f360084278b35d746fa6af3a7a1a5ra3xe   wa00e   \n",
       "3              3  3939ac3ef7d472a59a9c5f893dd3e39fh9ofi   jefix   \n",
       "4              4  8393c48eaf4b8fa96886edc7cf27b372dsibi   jefix   \n",
       "...          ...                                    ...     ...   \n",
       "7656329  7656329  626159dd6f2228ede002d9f9340f75b7puk8d   3e64w   \n",
       "7656330  7656330  a318ea333ceee1ba39a494476386136a826dv   xn0y0   \n",
       "7656331  7656331  f5b2bbad20d1d7ded3ed960393bec0f40u6hn   gja6c   \n",
       "7656332  7656332  d4bd412590f5106b9d887a43c51b254eldo4f   hmwk8   \n",
       "7656333  7656333  0ea62aaa9c3ffcc6db584cb69c1f6c4bcripp   c9ox9   \n",
       "\n",
       "            merchandise    device              time country              ip  \\\n",
       "0               jewelry    phone0  9759243157894736      us   69.166.231.58   \n",
       "1             furniture    phone1  9759243157894736      in   50.201.125.84   \n",
       "2            home goods    phone2  9759243157894736      py  112.54.208.157   \n",
       "3               jewelry    phone4  9759243157894736      in   18.99.175.133   \n",
       "4               jewelry    phone5  9759243157894736      in    145.138.5.37   \n",
       "...                 ...       ...               ...     ...             ...   \n",
       "7656329         jewelry   phone91  9709222052631578      ru  140.204.227.63   \n",
       "7656330          mobile  phone236  9709222052631578      pl  24.232.159.118   \n",
       "7656331  sporting goods   phone80  9709222052631578      za   80.237.28.246   \n",
       "7656332         jewelry  phone349  9709222052631578      my   91.162.27.152   \n",
       "7656333          mobile   phone82  9709222052631578      jo  160.243.101.60   \n",
       "\n",
       "                     url  \n",
       "0        vasstdc27m7nks3  \n",
       "1        jmqlhflrzwuay9c  \n",
       "2        vasstdc27m7nks3  \n",
       "3        vasstdc27m7nks3  \n",
       "4        vasstdc27m7nks3  \n",
       "...                  ...  \n",
       "7656329  cghhmomsaxi6pug  \n",
       "7656330  wgggpdg2gx5pesn  \n",
       "7656331  5xgysg14grlersa  \n",
       "7656332  bhtrek44bzi2wfl  \n",
       "7656333  vasstdc27m7nks3  \n",
       "\n",
       "[7656334 rows x 9 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_unique= bids_df.groupby('bidder_id').nunique()\n",
    "bids_unique = bids_unique.drop([\"bid_id\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From bids_unique dataframe, we may be interested in the number of times a bidder has \n",
    "1. Bidded in a different auction\n",
    "2. Bidded from a different url\n",
    "3. Bidded on a different device\n",
    "4. Bidded from a different country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidder_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001068c415025a009fee375a12cff4fcnht8y</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002d229ffb247009810828f648afc2ef593rb</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0030a2dd87ad2733e0873062e4f83954mkj86</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00486a11dff552c4bd7696265724ff81yeo9v</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbc0fdfbf19a8a9116b68714138f2902cc13</th>\n",
       "      <td>637</td>\n",
       "      <td>1</td>\n",
       "      <td>792</td>\n",
       "      <td>23487</td>\n",
       "      <td>102</td>\n",
       "      <td>18726</td>\n",
       "      <td>8039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd62646d600b759a985d45918bd6f0431vmz</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>664</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff2c070d8200e0a09150bd81452ce29ngcnv</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       auction  merchandise  device   time  \\\n",
       "bidder_id                                                                    \n",
       "001068c415025a009fee375a12cff4fcnht8y        1            1       1      1   \n",
       "002d229ffb247009810828f648afc2ef593rb        1            1       2      2   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86        1            1       1      1   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        3            1       3      3   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v       13            1       8     20   \n",
       "...                                        ...          ...     ...    ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13      637            1     792  23487   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3       15            1      13     22   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl        1            1       1      1   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz       55            1      96    664   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv        1            1       1      1   \n",
       "\n",
       "                                       country     ip   url  \n",
       "bidder_id                                                    \n",
       "001068c415025a009fee375a12cff4fcnht8y        1      1     1  \n",
       "002d229ffb247009810828f648afc2ef593rb        1      1     1  \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86        1      1     1  \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        1      3     2  \n",
       "00486a11dff552c4bd7696265724ff81yeo9v        1     10     7  \n",
       "...                                        ...    ...   ...  \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13      102  18726  8039  \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3        6     18    12  \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl        1      1     1  \n",
       "ffd62646d600b759a985d45918bd6f0431vmz        1     37   144  \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv        1      1     1  \n",
       "\n",
       "[6614 rows x 7 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_df_count= bids_df.groupby(\"bidder_id\")\n",
    "counts= bids_df_count['url'].count().reset_index().rename(columns = {'url':'num_bids'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From counts dataframe, we know the number of times that a unique bidder has performed a bid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>num_bids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>25075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  num_bids\n",
       "0     001068c415025a009fee375a12cff4fcnht8y         1\n",
       "1     002d229ffb247009810828f648afc2ef593rb         2\n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86         1\n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o         3\n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v        20\n",
       "...                                     ...       ...\n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13     25075\n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3        22\n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl         1\n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz       664\n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv         1\n",
       "\n",
       "[6614 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining the new features together with the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train_df.merge(bids_unique, how= 'left', on = 'bidder_id')\n",
    "new_train = new_train.merge(counts, how= 'left')\n",
    "new_train.fillna(0,inplace = True)\n",
    "\n",
    "new_test = test_df.merge(bids_unique, how= 'left', on = 'bidder_id')\n",
    "new_test = new_test.merge(counts, how= 'left')\n",
    "new_test.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the size new training and test dataset is the same as the old training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of old train: (2013, 4)\n",
      "Size of new train: (2013, 12)\n",
      "Size of old test: (4700, 3)\n",
      "Size of new test: (4700, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of old train: \" + str(train_df.shape))\n",
    "print(\"Size of new train: \" + str(new_train.shape))\n",
    "print(\"Size of old test: \" + str(test_df.shape))\n",
    "print(\"Size of new test: \" + str(new_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of number of first and last bids for each bidder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions = bids_df.groupby('auction')\n",
    "first_bid_list = set(auctions.first()['bidder_id'])\n",
    "last_bid_list = set(auctions.last()['bidder_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to add a counter if a particular bidder id is in the first and/or last bid\n",
    "def check_first_bid(dummy):\n",
    "    count = 0\n",
    "    for bidder_id in first_bid_list:\n",
    "        if(dummy == bidder_id):\n",
    "            count+=1\n",
    "    return count\n",
    "        \n",
    "def check_last_bid(dummy):\n",
    "    count = 0\n",
    "    for bidder_id in last_bid_list:\n",
    "        if(dummy == bidder_id):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_first_bids_train = new_train['bidder_id'].apply(func = check_first_bid)\n",
    "num_last_bids_train = new_train['bidder_id'].apply(func = check_last_bid)\n",
    "\n",
    "num_first_bids_test = new_test['bidder_id'].apply(func = check_first_bid)\n",
    "num_last_bids_test = new_test['bidder_id'].apply(func = check_last_bid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "      <th>num_bids</th>\n",
       "      <th>num_first_bids</th>\n",
       "      <th>num_last_bids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3     4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4     4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...                                     ...   \n",
       "2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country     ip   url  num_bids  num_first_bids  \\\n",
       "0       14.0   24.0      6.0   20.0   1.0      24.0               0   \n",
       "1        2.0    3.0      1.0    3.0   2.0       3.0               0   \n",
       "2        2.0    4.0      1.0    4.0   2.0       4.0               0   \n",
       "3        1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "4       53.0  155.0      2.0  123.0  91.0     155.0               0   \n",
       "...      ...    ...      ...    ...   ...       ...             ...   \n",
       "2008     4.0   33.0      4.0    5.0   2.0      36.0               1   \n",
       "2009     1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "2010     2.0    2.0      1.0    2.0   1.0       2.0               0   \n",
       "2011     1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "2012     1.0    2.0      1.0    1.0   1.0       2.0               0   \n",
       "\n",
       "      num_last_bids  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "2008              0  \n",
       "2009              0  \n",
       "2010              0  \n",
       "2011              0  \n",
       "2012              0  \n",
       "\n",
       "[2013 rows x 14 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining the new train and test with the number of first and last bids\n",
    "new_train['num_first_bids'] = num_first_bids_train\n",
    "new_train['num_last_bids'] = num_last_bids_train\n",
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "      <th>num_bids</th>\n",
       "      <th>num_first_bids</th>\n",
       "      <th>num_last_bids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49bb5a3c944b8fc337981cc7a9ccae41u31d7</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228htx90</td>\n",
       "      <td>5d9fa1b71f992e7c7a106ce4b07a0a754le7c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a921612b85a1494456e74c09393ccb65ylp4y</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228rs17i</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228klidn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b601e72a4d264dab9ace9d7b229b47479v6i</td>\n",
       "      <td>925381cce086b8cc9594eee1c77edf665zjpl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228aght0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eaf0ed0afc9689779417274b4791726cn5udi</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228nclv5</td>\n",
       "      <td>b5714de1fd69d4a0d2e39d59e53fe9e15vwat</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdecd8d02ed8c6037e38042c7745f688mx5sf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228dtdkd</td>\n",
       "      <td>c3b363a3c3b838d58c85acf0fc9964cb4pnfa</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>bef56983ba78b2ee064443ae95972877jfkyd</td>\n",
       "      <td>0f235a6dfea5a5885d63968826b748b4q4dra</td>\n",
       "      <td>a98a4841db165de919d29cb49d0bc306cq21h</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>4da45cc915c32d4368ac7e773d92d4affwqrr</td>\n",
       "      <td>9e0adf7481c422654d4d0a849e0e50abiumen</td>\n",
       "      <td>e23d9777cddc347de82d839b2e54b22ecopkp</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>0d0e6220bf59ab9a0c5b5987fb2c34a9p33f9</td>\n",
       "      <td>7df4ebd184668b4257f740b11d4519afq7kr1</td>\n",
       "      <td>b650404e1ab5d177020221277c3e9306qegyl</td>\n",
       "      <td>419.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>4981c32c54dde65b79dbc48fd9ab6457caqze</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2284qlm0</td>\n",
       "      <td>9c35320088eaf32046a51a96ebb2e658i479u</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>7ade70030d559a6c255be2f6feca17acnrqs0</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vo1hu</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228la8g8</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4700 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     49bb5a3c944b8fc337981cc7a9ccae41u31d7   \n",
       "1     a921612b85a1494456e74c09393ccb65ylp4y   \n",
       "2     6b601e72a4d264dab9ace9d7b229b47479v6i   \n",
       "3     eaf0ed0afc9689779417274b4791726cn5udi   \n",
       "4     cdecd8d02ed8c6037e38042c7745f688mx5sf   \n",
       "...                                     ...   \n",
       "4695  bef56983ba78b2ee064443ae95972877jfkyd   \n",
       "4696  4da45cc915c32d4368ac7e773d92d4affwqrr   \n",
       "4697  0d0e6220bf59ab9a0c5b5987fb2c34a9p33f9   \n",
       "4698  4981c32c54dde65b79dbc48fd9ab6457caqze   \n",
       "4699  7ade70030d559a6c255be2f6feca17acnrqs0   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228htx90   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228rs17i   \n",
       "2     925381cce086b8cc9594eee1c77edf665zjpl   \n",
       "3     a3d2de7675556553a5f08e4c88d2c228nclv5   \n",
       "4     a3d2de7675556553a5f08e4c88d2c228dtdkd   \n",
       "...                                     ...   \n",
       "4695  0f235a6dfea5a5885d63968826b748b4q4dra   \n",
       "4696  9e0adf7481c422654d4d0a849e0e50abiumen   \n",
       "4697  7df4ebd184668b4257f740b11d4519afq7kr1   \n",
       "4698  a3d2de7675556553a5f08e4c88d2c2284qlm0   \n",
       "4699  a3d2de7675556553a5f08e4c88d2c228vo1hu   \n",
       "\n",
       "                                    address  auction  merchandise  device  \\\n",
       "0     5d9fa1b71f992e7c7a106ce4b07a0a754le7c      3.0          1.0     2.0   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228klidn      2.0          1.0     3.0   \n",
       "2     a3d2de7675556553a5f08e4c88d2c228aght0     14.0          1.0     4.0   \n",
       "3     b5714de1fd69d4a0d2e39d59e53fe9e15vwat     90.0          1.0    81.0   \n",
       "4     c3b363a3c3b838d58c85acf0fc9964cb4pnfa     20.0          1.0    17.0   \n",
       "...                                     ...      ...          ...     ...   \n",
       "4695  a98a4841db165de919d29cb49d0bc306cq21h     41.0          1.0     9.0   \n",
       "4696  e23d9777cddc347de82d839b2e54b22ecopkp     32.0          1.0    29.0   \n",
       "4697  b650404e1ab5d177020221277c3e9306qegyl    419.0          1.0   376.0   \n",
       "4698  9c35320088eaf32046a51a96ebb2e658i479u      5.0          1.0     4.0   \n",
       "4699  a3d2de7675556553a5f08e4c88d2c228la8g8    116.0          1.0   117.0   \n",
       "\n",
       "        time  country      ip     url  num_bids  num_first_bids  num_last_bids  \n",
       "0        4.0      3.0     4.0     3.0       4.0               0              0  \n",
       "1        3.0      2.0     2.0     1.0       3.0               0              0  \n",
       "2       17.0      3.0     4.0     2.0      17.0               0              0  \n",
       "3      148.0     14.0   129.0    80.0     148.0               0              0  \n",
       "4       23.0      2.0    17.0     1.0      23.0               0              0  \n",
       "...      ...      ...     ...     ...       ...             ...            ...  \n",
       "4695   466.0      5.0    22.0     4.0     983.0               0              0  \n",
       "4696    66.0     10.0    49.0    18.0      66.0               0              0  \n",
       "4697  2156.0     86.0  1460.0  1049.0    2162.0               1              1  \n",
       "4698     5.0      1.0     5.0     2.0       5.0               0              0  \n",
       "4699   382.0     10.0   347.0   246.0     382.0               0              0  \n",
       "\n",
       "[4700 rows x 13 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test['num_first_bids'] = num_first_bids_test\n",
    "new_test['num_last_bids'] = num_last_bids_test\n",
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdev of time per bid (skipz first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>time_to_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>7.439058e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>1.455263e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>7.263689e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>6.854544e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>1.904773e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>5.719356e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>2.954407e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>1.044305e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>5.369726e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>7.325305e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id   time_to_bid\n",
       "0     001068c415025a009fee375a12cff4fcnht8y  7.439058e+13\n",
       "1     002d229ffb247009810828f648afc2ef593rb  1.455263e+11\n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86  7.263689e+13\n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o  6.854544e+12\n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v  1.904773e+13\n",
       "...                                     ...           ...\n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13  5.719356e+12\n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3  2.954407e+13\n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl  1.044305e+13\n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz  5.369726e+12\n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv  7.325305e+13\n",
       "\n",
       "[6614 rows x 2 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean response time\n",
    "def find_time_to_bid(auction_id, time):\n",
    "    starttime = timing_dict[auction_id]['starttime']\n",
    "    return int(time) - int(starttime)\n",
    "\n",
    "end_auction_time= bids_df.groupby('auction').time.max().reset_index()\n",
    "end_auction_time= end_auction_time.rename(columns= {'time': 'endtime'})\n",
    "\n",
    "start_auction_time= bids_df.groupby('auction').time.min().reset_index()\n",
    "start_auction_time= start_auction_time.rename(columns= {'time': 'starttime'})\n",
    "\n",
    "start_end_times= pd.merge(start_auction_time, end_auction_time, on= 'auction', how= 'left')\n",
    "start_end_times = start_end_times.set_index('auction')\n",
    "\n",
    "timing_dict = start_end_times.to_dict('index')\n",
    "\n",
    "start_auction_time= bids_df.groupby('auction').time.min().reset_index()\n",
    "start_auction_time= start_auction_time.rename(columns= {'time': 'starttime'})\n",
    "timing_dict = start_end_times.to_dict('index')\n",
    "\n",
    "bids_df['time_to_bid'] = bids_df.apply(lambda row: find_time_to_bid(row['auction'], row['time']), axis=1)\n",
    "\n",
    "bids_df_time = bids_df\n",
    "bids_df_time_mean = bids_df_time.groupby('bidder_id')['time_to_bid'].mean().reset_index()\n",
    "bids_df_time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>inst_resp</th>\n",
       "      <th>perc_inst_resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>3068.0</td>\n",
       "      <td>0.122353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  inst_resp  perc_inst_resp\n",
       "0     001068c415025a009fee375a12cff4fcnht8y        0.0        0.000000\n",
       "1     002d229ffb247009810828f648afc2ef593rb        0.0        0.000000\n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86        0.0        0.000000\n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        0.0        0.000000\n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v        0.0        0.000000\n",
       "...                                     ...        ...             ...\n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13     3068.0        0.122353\n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3        0.0        0.000000\n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl        0.0        0.000000\n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz        0.0        0.000000\n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv        0.0        0.000000\n",
       "\n",
       "[6614 rows x 3 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of simul bids per bidder\n",
    "results = bids_df.groupby(['bidder_id','time']).count()[bids_df.groupby(['bidder_id','time']).count()['bid_id'] > 1 ]\n",
    "inst_resp = results.groupby(\"bidder_id\").sum()\n",
    "needed_df = bids_df.groupby(['bidder_id','time']).count()[bids_df.groupby(['bidder_id','time']).count()['bid_id'] > 0 ]\n",
    "num_resp = needed_df.groupby(\"bidder_id\").sum()\n",
    "num_resp = num_resp.reset_index()\n",
    "inst_resp = inst_resp.reset_index()\n",
    "num_resp = num_resp[['bidder_id','bid_id']]\n",
    "inst_resp = inst_resp[['bidder_id','bid_id']]\n",
    "num_resp.rename(columns={\"bid_id\": \"num_bids\"}, inplace= True)\n",
    "inst_resp.rename(columns={\"bid_id\": \"inst_resp\"}, inplace= True)\n",
    "total_inst_resp = num_resp.merge(inst_resp, how= 'left',on='bidder_id')\n",
    "total_inst_resp.fillna(0, inplace = True)\n",
    "total_inst_resp['perc_inst_resp'] = total_inst_resp['inst_resp']/total_inst_resp['num_bids']\n",
    "total_inst_resp.drop(axis = 1 , columns = 'num_bids', inplace=True)\n",
    "total_inst_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto parts</th>\n",
       "      <th>books and music</th>\n",
       "      <th>clothing</th>\n",
       "      <th>computers</th>\n",
       "      <th>furniture</th>\n",
       "      <th>home goods</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>mobile</th>\n",
       "      <th>office equipment</th>\n",
       "      <th>sporting goods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidder_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001068c415025a009fee375a12cff4fcnht8y</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002d229ffb247009810828f648afc2ef593rb</th>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0030a2dd87ad2733e0873062e4f83954mkj86</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00486a11dff552c4bd7696265724ff81yeo9v</th>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbc0fdfbf19a8a9116b68714138f2902cc13</th>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "      <td>25075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</th>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd62646d600b759a985d45918bd6f0431vmz</th>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff2c070d8200e0a09150bd81452ce29ngcnv</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       auto parts  books and music  clothing  \\\n",
       "bidder_id                                                                      \n",
       "001068c415025a009fee375a12cff4fcnht8y           1                1         1   \n",
       "002d229ffb247009810828f648afc2ef593rb           2                2         2   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86           1                1         1   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o           3                3         3   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v          20               20        20   \n",
       "...                                           ...              ...       ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13       25075            25075     25075   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3          22               22        22   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl           1                1         1   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz         664              664       664   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv           1                1         1   \n",
       "\n",
       "                                       computers  furniture  home goods  \\\n",
       "bidder_id                                                                 \n",
       "001068c415025a009fee375a12cff4fcnht8y          1          1           1   \n",
       "002d229ffb247009810828f648afc2ef593rb          2          2           2   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86          1          1           1   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o          3          3           3   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v         20         20          20   \n",
       "...                                          ...        ...         ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13      25075      25075       25075   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3         22         22          22   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl          1          1           1   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz        664        664         664   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv          1          1           1   \n",
       "\n",
       "                                       jewelry  mobile  office equipment  \\\n",
       "bidder_id                                                                  \n",
       "001068c415025a009fee375a12cff4fcnht8y        1       1                 1   \n",
       "002d229ffb247009810828f648afc2ef593rb        2       2                 2   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86        1       1                 1   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        3       3                 3   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v       20      20                20   \n",
       "...                                        ...     ...               ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13    25075   25075             25075   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3       22      22                22   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl        1       1                 1   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz      664     664               664   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv        1       1                 1   \n",
       "\n",
       "                                       sporting goods  \n",
       "bidder_id                                              \n",
       "001068c415025a009fee375a12cff4fcnht8y               1  \n",
       "002d229ffb247009810828f648afc2ef593rb               2  \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86               1  \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o               3  \n",
       "00486a11dff552c4bd7696265724ff81yeo9v              20  \n",
       "...                                               ...  \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13           25075  \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3              22  \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl               1  \n",
       "ffd62646d600b759a985d45918bd6f0431vmz             664  \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv               1  \n",
       "\n",
       "[6614 rows x 10 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding merchandise - working\n",
    "one_hot = pd.get_dummies(bids_df['merchandise'])\n",
    "one_hot_df = bids_df.join(one_hot)\n",
    "one_hot_df = one_hot_df.drop('merchandise', axis=1)\n",
    "# one_hot_df = one_hot_df.join(one_hot)\n",
    "# one_hot_df = one_hot_df.rename(columns={1.0:'merchandise=1.0',2.0:'merchandise=2.0'})\n",
    "one_hot_df.set_index(\"bidder_id\", inplace=True)\n",
    "one_hot_df = one_hot_df[['auto parts', 'books and music', 'clothing', 'computers',\n",
    "       'furniture', 'home goods', 'jewelry', 'mobile', 'office equipment',\n",
    "       'sporting goods']]\n",
    "one_hot_df = one_hot_df.groupby(\"bidder_id\").count()\n",
    "one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent instant resp (skipz first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per auction\n",
    "bids_auction_count= bids_df.groupby([\"bidder_id\", \"auction\"])\n",
    "bids_auction_count_df = bids_auction_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_auction_count_df = pd.DataFrame(bids_auction_count_df, columns = ['bidder_id', 'bid_id', 'auction', 'merchandise', \n",
    "                                                                       'time', 'country', 'ip', 'url'])\n",
    "bids_auction_count_df = bids_auction_count_df[['bidder_id','bid_id']]\n",
    "bids_auction_count_df.rename(columns={\"bid_id\": \"num_bids_per_auction\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per device\n",
    "bids_device_count= bids_df.groupby([\"bidder_id\", \"device\"])\n",
    "bids_device_count_df = bids_device_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_device_count_df = pd.DataFrame(bids_device_count_df, columns = ['bidder_id', 'bid_id', 'auction', 'merchandise', \n",
    "                                                                     'time', 'country', 'ip', 'url'])\n",
    "bids_device_count_df = bids_device_count_df[['bidder_id','bid_id']]\n",
    "bids_device_count_df.rename(columns={\"bid_id\": \"num_bids_per_device\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per country\n",
    "bids_country_count= bids_df.groupby([\"bidder_id\", \"country\"])\n",
    "bids_country_count_df = bids_country_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_country_count_df = pd.DataFrame(bids_country_count_df, columns = ['bidder_id', 'bid_id', 'auction', 'merchandise', \n",
    "                                                                       'time', 'country', 'ip', 'url'])\n",
    "bids_country_count_df = bids_country_count_df[['bidder_id','bid_id']]\n",
    "bids_country_count_df.rename(columns={\"bid_id\": \"num_bids_per_country\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per ip\n",
    "bids_ip_count= bids_df.groupby([\"bidder_id\", \"ip\"])\n",
    "bids_ip_count_df = bids_ip_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_ip_count_df = pd.DataFrame(bids_ip_count_df, columns = ['bidder_id', 'bid_id', 'auction', \n",
    "                                                             'merchandise', 'time', 'country', 'ip', 'url'])\n",
    "bids_ip_count_df = bids_ip_count_df[['bidder_id','bid_id']]\n",
    "bids_ip_count_df.rename(columns={\"bid_id\": \"num_bids_per_ip\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>num_bids_per_auction</th>\n",
       "      <th>num_bids_per_device</th>\n",
       "      <th>num_bids_per_country</th>\n",
       "      <th>num_bids_per_ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>39.364207</td>\n",
       "      <td>31.660354</td>\n",
       "      <td>245.833333</td>\n",
       "      <td>1.339047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>1.692308</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>12.072727</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>664.000000</td>\n",
       "      <td>17.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  num_bids_per_auction  \\\n",
       "0     001068c415025a009fee375a12cff4fcnht8y              1.000000   \n",
       "1     002d229ffb247009810828f648afc2ef593rb              2.000000   \n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86              1.000000   \n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o              1.000000   \n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v              1.538462   \n",
       "...                                     ...                   ...   \n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13             39.364207   \n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3              1.466667   \n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl              1.000000   \n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz             12.072727   \n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv              1.000000   \n",
       "\n",
       "      num_bids_per_device  num_bids_per_country  num_bids_per_ip  \n",
       "0                1.000000              1.000000         1.000000  \n",
       "1                1.000000              2.000000         2.000000  \n",
       "2                1.000000              1.000000         1.000000  \n",
       "3                1.000000              3.000000         1.000000  \n",
       "4                2.500000             20.000000         2.000000  \n",
       "...                   ...                   ...              ...  \n",
       "6609            31.660354            245.833333         1.339047  \n",
       "6610             1.692308              3.666667         1.222222  \n",
       "6611             1.000000              1.000000         1.000000  \n",
       "6612             6.916667            664.000000        17.945946  \n",
       "6613             1.000000              1.000000         1.000000  \n",
       "\n",
       "[6614 rows x 5 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = bids_auction_count_df.merge(bids_device_count_df, how= 'left', on = 'bidder_id')\n",
    "merged_df = merged_df.merge(bids_country_count_df, how= 'left', on = 'bidder_id')\n",
    "merged_df = merged_df.merge(bids_ip_count_df, how= 'left', on = 'bidder_id')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df.fillna(0,inplace = True)\n",
    "merged_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all features together again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>...</th>\n",
       "      <th>furniture</th>\n",
       "      <th>home goods</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>mobile</th>\n",
       "      <th>office equipment</th>\n",
       "      <th>sporting goods</th>\n",
       "      <th>num_bids_per_auction</th>\n",
       "      <th>num_bids_per_device</th>\n",
       "      <th>num_bids_per_country</th>\n",
       "      <th>num_bids_per_ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>6.739130</td>\n",
       "      <td>2.924528</td>\n",
       "      <td>77.5</td>\n",
       "      <td>1.260163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.200000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3     4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4     4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...                                     ...   \n",
       "2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country     ip  ...  furniture  home goods  jewelry  \\\n",
       "0       14.0   24.0      6.0   20.0  ...       24.0        24.0     24.0   \n",
       "1        2.0    3.0      1.0    3.0  ...        3.0         3.0      3.0   \n",
       "2        2.0    4.0      1.0    4.0  ...        4.0         4.0      4.0   \n",
       "3        1.0    1.0      1.0    1.0  ...        1.0         1.0      1.0   \n",
       "4       53.0  155.0      2.0  123.0  ...      155.0       155.0    155.0   \n",
       "...      ...    ...      ...    ...  ...        ...         ...      ...   \n",
       "2008     4.0   33.0      4.0    5.0  ...       36.0        36.0     36.0   \n",
       "2009     1.0    1.0      1.0    1.0  ...        1.0         1.0      1.0   \n",
       "2010     2.0    2.0      1.0    2.0  ...        2.0         2.0      2.0   \n",
       "2011     1.0    1.0      1.0    1.0  ...        1.0         1.0      1.0   \n",
       "2012     1.0    2.0      1.0    1.0  ...        2.0         2.0      2.0   \n",
       "\n",
       "      mobile  office equipment  sporting goods  num_bids_per_auction  \\\n",
       "0       24.0              24.0            24.0              1.333333   \n",
       "1        3.0               3.0             3.0              3.000000   \n",
       "2        4.0               4.0             4.0              1.000000   \n",
       "3        1.0               1.0             1.0              1.000000   \n",
       "4      155.0             155.0           155.0              6.739130   \n",
       "...      ...               ...             ...                   ...   \n",
       "2008    36.0              36.0            36.0              1.440000   \n",
       "2009     1.0               1.0             1.0              1.000000   \n",
       "2010     2.0               2.0             2.0              2.000000   \n",
       "2011     1.0               1.0             1.0              1.000000   \n",
       "2012     2.0               2.0             2.0              2.000000   \n",
       "\n",
       "      num_bids_per_device  num_bids_per_country  num_bids_per_ip  \n",
       "0                1.714286                   4.0         1.200000  \n",
       "1                1.500000                   3.0         1.000000  \n",
       "2                2.000000                   4.0         1.000000  \n",
       "3                1.000000                   1.0         1.000000  \n",
       "4                2.924528                  77.5         1.260163  \n",
       "...                   ...                   ...              ...  \n",
       "2008             9.000000                   9.0         7.200000  \n",
       "2009             1.000000                   1.0         1.000000  \n",
       "2010             1.000000                   2.0         1.000000  \n",
       "2011             1.000000                   1.0         1.000000  \n",
       "2012             2.000000                   2.0         2.000000  \n",
       "\n",
       "[2013 rows x 31 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_2 = new_train.merge(bids_df_time_mean, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(total_inst_resp, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(one_hot_df, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(merged_df, how= 'left',on='bidder_id')\n",
    "merged_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = merged_df_2\n",
    "new_train.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_3 = new_test.merge(bids_df_time_mean, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(total_inst_resp, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(one_hot_df, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(merged_df, how= 'left',on='bidder_id')\n",
    "new_test = merged_df_3\n",
    "new_test.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_train.drop(columns=['bidder_id', 'payment_account', 'address', 'outcome','merchandise'])\n",
    "y = new_train['outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29839867, -0.34020786, -0.13219046, ..., -0.09752657,\n",
       "        -0.18026161, -0.06771407],\n",
       "       [-0.41452291, -0.40452956, -0.13438925, ..., -0.09892274,\n",
       "        -0.18443652, -0.06906652],\n",
       "       [-0.39403039, -0.40452956, -0.13428454, ..., -0.095665  ,\n",
       "        -0.18026161, -0.06906652],\n",
       "       ...,\n",
       "       [-0.41452291, -0.40452956, -0.13449395, ..., -0.10218048,\n",
       "        -0.18861143, -0.06906652],\n",
       "       [-0.41452291, -0.4098897 , -0.13459866, ..., -0.10218048,\n",
       "        -0.19278634, -0.06906652],\n",
       "       [-0.41452291, -0.4098897 , -0.13449395, ..., -0.095665  ,\n",
       "        -0.18861143, -0.06230423]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Stratified K-Fold with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def training_model(model, num_splits, X, y):\n",
    "#     skfolds = StratifiedKFold(n_splits=num_splits)\n",
    "\n",
    "#     for train_index, test_index in skfolds.split(X, y):\n",
    "#         X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "#         y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "# #         print(y_train.value_counts())\n",
    "        \n",
    "#         sm = SMOTE()\n",
    "#         X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "# #         print(y_train_oversampled.value_counts())\n",
    "        \n",
    "#         model = model\n",
    "#         model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "#         y_pred = model.predict(X_test)\n",
    "        \n",
    "#         print(f'Accuracy: {model.score(X_test, y_test)}')\n",
    "#         print(f'f-score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = XGBClassifier()\n",
    "# num_splits = 10\n",
    "# training_model(model, num_splits, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination\n",
    "Feed all possible features, then iteratively remove the worst performing features one by one till the overall performance of the model comes in acceptable range. Uses pvalue as the performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:130: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                   2.525711e-02\n",
       "auction                 2.586140e-02\n",
       "device                  1.174873e-02\n",
       "time                    9.495195e-04\n",
       "country                 7.420696e-01\n",
       "ip                      1.592679e-04\n",
       "url                     2.529328e-01\n",
       "num_bids                1.847400e-03\n",
       "num_first_bids          1.952623e-05\n",
       "num_last_bids           3.511042e-02\n",
       "time_to_bid             6.471747e-01\n",
       "inst_resp               2.336094e-03\n",
       "perc_inst_resp          7.199014e-19\n",
       "auto parts              1.847497e-03\n",
       "books and music         1.847496e-03\n",
       "clothing                1.847496e-03\n",
       "computers               1.847496e-03\n",
       "furniture               1.847496e-03\n",
       "home goods              1.847496e-03\n",
       "jewelry                 1.847496e-03\n",
       "mobile                  1.847496e-03\n",
       "office equipment        1.847496e-03\n",
       "sporting goods          1.847496e-03\n",
       "num_bids_per_auction    1.337073e-01\n",
       "num_bids_per_device     3.444767e-13\n",
       "num_bids_per_country    3.234530e-02\n",
       "num_bids_per_ip         7.419480e-15\n",
       "dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from this step we can see which pvalues are significant\n",
    "X_1 = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['device', 'time', 'ip', 'num_bids', 'num_first_bids', 'num_last_bids', 'inst_resp', 'perc_inst_resp', 'auto parts', 'books and music', 'clothing', 'computers', 'furniture', 'home goods', 'jewelry', 'mobile', 'office equipment', 'sporting goods', 'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip']\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "pmax = 1 # we can adjust this\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p = []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "Recursively removing attributes and building a model on those attributes that remain. Uses accuracy as the performance metric to rank the feature according to their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=1 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=2 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=4 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=6 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=7 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=8 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=9 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nof_list = np.arange(1,11) # 11 is our maximum number of features\n",
    "high_score = 0 # keeps track of the highest accuracy model\n",
    "\n",
    "nof = 0 # returns us the ideal number of features based on the highest accuracy\n",
    "score_list = []\n",
    "for n in range(len(nof_list)):\n",
    "    # we can modify to add smote and stratified kfold later\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0) \n",
    "\n",
    "    model = XGBClassifier()\n",
    "    rfe = RFE(model, nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "    model.fit(X_train_rfe, y_train)\n",
    "    score = model.score(X_test_rfe, y_test)\n",
    "    score_list.append(score)\n",
    "    if score > high_score:\n",
    "        high_score = score\n",
    "#         nof = nof_list[n]\n",
    "#         for i in range(X.shape[1]):\n",
    "#             print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support[i], rfe.ranking_[i]))\n",
    "        \n",
    "nof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Method\n",
    "Takes care of each iteration of the model training process and carefully extract features which contribute the most to the training for a particular iteration. Uses regularization methods to penalize a feature given a coefficient threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.831818442803254, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.81413247288903, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.8288241824836, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.97614054593432, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07923867094974, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 4.286481953135414, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.073424366023076, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.96080466679484, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.859727461064494, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.013909449442422783, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.049466375407732244, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.835036113797766, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05040869992727437, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.015188899095008424, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.04355869031163, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.585075867724626, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.016588262785560914, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05296493521315426, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.566445567072876, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.018116909489251043, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.54590332825457, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019825905950483502, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05570774015745883, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.36910835095858, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 16.489638460910058, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.05867003474128296, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06191222381825412, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.02178333009995015, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.652589862340086, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.50754815149249, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06541188155021871, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.18259037815361978, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.554695226099234, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.031883788680431735, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.2661260926606843, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.717668251455734, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.2832392858192, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.06928783633472335, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.79723548332612, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.282438790750021, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.24144236300425, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.342944906035676, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3004336338564002, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.59496266028661, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.482469367951055, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.174188825338575, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 15.064084923875388, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.19448413699894, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.739239892454925, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03155565515193359, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.914756138901794, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.688727318315344, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.21755391768393, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.672637075566726, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.08242669446627, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.7553184847809, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.143760158432656, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.32026615405196424, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.91513462929481, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.22910715199639, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.90757098575352, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.051034916329925295, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.913923976506208, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.01259025117241, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.826926631023305, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.366049410450835, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.3448551571088, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.24349121235418636, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.640316761659044, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 9.45904919398658, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.143495052986395, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.690518745716176, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.437374440058406, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.744636270041863, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.78757207357154, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.855759012350966, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.26969886644214114, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.02389036896563, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.018009831091764, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.677721570392954, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.167907265747615, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.83027705102223, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 2.4413689183972522, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.206568454677324, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.557158924409336, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.20662137903594, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.17400041049559, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.53218684347928, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.22165368095342, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.42355805223407, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15526371110378, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 1.3224766068749858, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.63983644588635, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.25366985554663, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.98603529343231, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.30018226952427085, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.55218109194101, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.322362148922906, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.17964922647794, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93997924135496, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.170874419319176, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.14397264386215, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.80474360482708, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3360998418659875, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.367431261422176, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 18.984738022115792, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.7722188643508, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.83964143683778, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.3789973458322322, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.485806158005786, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.11719977311577, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.07819644663934, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.08493324670956, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.56886139420669, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.26847316669892, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.44001076284203, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.73427959140044, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.603203019592232, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.13057898896967, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.64429871247266, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.60907159448476, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.72489934375598, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.133269743258815, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.089883561638175, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.464305226220006, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.96484220195864, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.046089340532895, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.35824016823928, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.70583558008668, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.400033773749293, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.70930804318998, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.98601467211262, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.29405057862501, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.99921418081432, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.02101442326759, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.1525030521894, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.019771753084128818, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.567062558109818, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.00855737927338, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.770539874336144, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.06128155735073, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.39815558324509, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.0320938791892047, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06570391371563, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.03740175314327132, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.873061502028264, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.3325852877482, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.964610254657288, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.109180807319625, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.53022701185176, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.396133534814254, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53752953312959, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24783433156659, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.77464980887123, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.57395876347913, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06252339767286, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.43183689858397, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.38901251706645, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.13119882984597, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.38078979360179, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.73725899812716, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.91217194234872, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.681969032932095, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23216458928133, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.32575629918596, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.89343411525545, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.574175785272274, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.56267034890113, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.549853795736816, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.642382939434114, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.629767311414255, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.51714416333622, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.529026039541385, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.01181663445987624, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.11517679933837144, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.46618150558236, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.12233513971452226, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1301230442028185, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.425239462608054, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 23.692481096420366, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.13859016146085423, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.38078270248775, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.207814915140574, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.68590187048567, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.14788361100011116, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.17034114709933, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.762993179720404, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.33269560233714, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.74346952281474, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.94338425130759, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.062847796124, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.47336562746282, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.71996625548284, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.208764431664406, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.52087016151311, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.44402349613995, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.28095282269726, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.29963094811204, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.892441927603606, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.58772223119277, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.7277593373577, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.01696845770001, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.022163049883915, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.864127757535556, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 30.970340585482973, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.08124206492540509, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07540007805902, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.64712905380191, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07486945098323, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.14213013121302, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.09013054049989933, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.67658010529113, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.03879690362935, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.40729604699652, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.645972433538955, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.99974745962082, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.09359359096894, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 0.1052833447811139, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.162184392948326, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.85673750691723, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.6936468997137, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.87434267826418, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.949020736019385, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.41714285099156, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.733642677787955, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.42787736472341, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.632573253171074, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.72771851556428, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.81715563193269, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.924154485393345, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65270530981, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.93526884466592, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.791594349364516, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.95194592983089, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 31.34290465753901, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 24.492869810093296, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.85049232274515, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.66184147709439, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.235239577495975, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.94407434944176, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 25.982847394795503, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.17091883694134, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.927127747234486, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.33514249614842, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 29.191419090482476, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 27.114037718249683, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.11508649352186, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.62397250406386, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.58409618496805, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 26.612356794199496, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 34.526354425947396, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.909197957266194, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.78287130737962, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.841673573437454, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58274126157161, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.88326210936931, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.85281122913222, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.00007005113381, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.14310219028612, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.53816014471161, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.40740170800204, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.422947896387356, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.521765005898445, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.14098104636654, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.34201515389427, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.642251617393065, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.890032591089565, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.68367581231389, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 32.94752883624222, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.48452599692942, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.577563901384536, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.25106746251732, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07621487090838, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.20489622238892, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 33.552853691473125, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.625361946729285, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.76153554908239, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.104407061553616, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.5931408403184, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.36717618621648, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6162621990024, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.595079706967304, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.53267613460514, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.875141430138857, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.57107561403738, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.041907855584085, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.08177693884844, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.03977235977033, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.63823246818465, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.87382108815173, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.209811011737855, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.970988601537954, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.54426968237166, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.14896077946831, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.897770015259574, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.924587163226704, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.55037385076691, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.67622497606033, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.51466095715569, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.391948716657225, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.56294943521192, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.02685623138319, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53408872865608, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.25875466304811, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.490803562083165, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.64606789490377, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.91376191617698, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.73016247443524, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.18516121144599, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.44480827369871, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.395740086363105, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.88991823090416, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34359841281861, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.47847373309775, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.83355371101174, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.923361747340664, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.05216742870268, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.96379082115321, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.72567700626731, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.51075116118327, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.298597400100356, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.403648798371385, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.92767811062013, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.31548128123756, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.858585881312, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.9780898136643, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.49279907223519, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.43222514031339, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.80298542615325, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.05528578685803, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.93874074090719, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.366889717545575, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.80824158671555, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.906498508865624, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.31148629333104, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.297421314282644, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.96583174108126, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.49783229143964, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.011173420030296, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.22371471641715, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.98509864992656, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.413705338852466, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.00331541107497, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.540865285097254, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.95046004244855, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.11802563033198, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.3240877509509, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 28.096941684380756, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.05320284510654, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.93763109239525, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.075199685096194, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.62424863697075, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.36775989627814, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.002558430080406, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.69829621989452, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.636264344661434, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha using built-in LassoCV: 0.300000\n",
      "Best score using built-in LassoCV: 0.081853\n",
      "Lasso picked 18 variables and eliminated the other 8 variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.162948081760184, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.24900392622886, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.36720859972977, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 35.468434824449844, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.200576722509595, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.88926015246529, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 19.548701590146614, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.13768054553218, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.94045942939283, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 20.606641159555174, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 21.587775657531004, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.60518095889686, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.96087695660833, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 10.756827431399472, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.960099439542844, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.38762182741517, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 17.435644586925818, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.29422600851039, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.578331533476316, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.994207835404666, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.94395727953492, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.60113839829216, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.81361755444221, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.30743415214405, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.129617516845116, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.843616192383486, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44295706448055, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.392261679547126, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.900982209691435, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.14818192704429, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.78619600771085, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.343258464316776, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 46.007179196261724, tolerance: 0.009772975658221562\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature importance using Lasso Model')"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkQAAAJOCAYAAABWexg8AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdeZhdVZ3u8e/LIGGOQOkV2xBFBgUZD8hsUNqrrTK02Cg4gF7TCIq0oM1Vr6Joiy0tgoAQFAIBERkNxAaUeSYVEhJGURIbBSHIGJAoyXv/2KvkcDg1hFTVSdV+P89TT+2zxt/eJ1o/1lpVR7aJiIiIqLPlOh1ARERERKclIYqIiIjaS0IUERERtZeEKCIiImovCVFERETUXhKiiIiIqL0kRBExbCR9WdKPOx3HaCTpLkkTOh3HSCdpsqRvDbDtPEm7DXVMMTySEEWMEOX/fP8iaUHT17qDMOaw/R+67f+w/X+Ga76+SDpS0lmdjmOw2N7E9jWDPa6k/SXdMNjjLq0SlyV9v6V8z1I+uUOhxQiVhChiZPmA7dWavh7qZDCSVujk/K/USI07XuZ3wD4t7+fHgd90KJ4YwZIQRYxwktaU9BNJD0v6o6RvSVq+1K0v6SpJf5b0mKSzJY0tdVOAccAlZbXpS5ImSPpDy/h/X0UqqyrnSzpL0tPA/n3N3ybWv6/KSBpf/kv+AEkPSnpC0oGStpE0W9KTkk5o6ru/pBsl/VDSU5LulfSupvp1JU2V9Lik30r6dMu8zXEfCHyZ6ofpAkl3lHYHSLpH0jOSHpD0r01jTJD0B0mHSXq03O8BTfUrS/ovSb8v8d0gaeVSt52km8o93dHX1lZ5Jm9uev33LRxJ60i6tIzzuKTrJS3Xy/v0c0lnlnu5S1KjacytJM0sdedJOlcD3CZqibWv59VXrP9e/q08I+m+nvdR0kqSfiDpofL1A0kr9RHCn4A5wP8u/dcCdgCmtsS5e3kGT0q6RtJbmuq2lHR7ieVcYExL3/dLmlX63iRpsyV9TjEyJCGKGPnOAF4A3gxsCbwb6NmWEvAdYF3gLcAbgCMBbH8M+B9eXHX6zwHOtwdwPjAWOLuf+Qfi7cAGwD7AD4CvALsBmwD/IukdLW0fANYBvg5cWH4IApwD/KHc697AfzQnTC1x/wT4D+Dccu+blzaPAu8H1gAOAI6VtFXTGP8LWBN4PfAp4ERJry51xwBbU/1AXgv4ErBY0uuBacC3SvnhwAWSupbgGfU4rNxjF/BaqqSut89f2h34WbnfqcAJAJJeBVwETC7xnAPs9Qpigb6fV9tYJW0EfBbYxvbqVMnMvNLnK8B2wBbA5sC2wFf7ieFMqlUhgA8DvwAW9lRK2rDc46Elll9S/UfAq8qzuBiYQvUszgM+2NR3K+A04F+BtYFTgKn9JGkxQiUhihhZLi7/pfqkpIslvRZ4L3Co7WdtPwocS/WDAdu/tf0r2wttzwe+D7yj9+EH5GbbF9teTPWDsNf5B+go28/bvgJ4FjjH9qO2/whcT5Vk9XgU+IHtv9k+F7gPeJ+kNwA7Af9expoF/Bj4WLu4bf+lXSC2p9n+nSvXAlcAOzc1+RvwzTL/L4EFwEZl5eOTwOdt/9H2Its32V4IfBT4pe1flrl/BXQD/7QEz6h5/tcB65UYrnfvH0h5Q5lzEdUP/J6kbztgBeD4MsaFwG2vIJb+nldvsS4CVgLeKmlF2/Ns/6702Y/q+T5a/r1+g5e+h+1cBEyQtCZVYnRmS/0+wLTyv4O/USWuK1MlrtsBK/Liv6nzgelNfT8NnGL71vKenkGVbG23RA8qRoQkRBEjy562x5avPYH1qP4P/eGeRInqv2JfAyDpNZJ+VrYnngbOolpdWRoPNl33Of8APdJ0/Zc2r1drev3HlgTg91QrQusCj9t+pqXu9b3E3Zak90q6pWzxPEmVtDQ/rz/bfqHp9XMlvnWotlp+x8utB3yoKZF9kip5e11/8bTxPeC3wBVli+qIPtr+qSXOMarO2qzLy59jv8+mnX6eV9tYbf+WarXmSODR8u+z55cD1qV633r0vL+9KsntNKqVpHVs39jS5CVjlkT+Qap/G+2eRfP86wGHtbx3b+gvphiZkhBFjGwPUv0X6zpNidIatjcp9d+h2lLZzPYaVKsVaurfurrwLLBKzwtVZ4Fat3Zaf5D2Nf9ge72k5vjHAQ+Vr7Ukrd5S98de4n7Z67INcgHVCsJrbY+l2l4R/XsMeB5Yv03dg8CUpucz1vaqto/uZaznaHoPqLbpqoDtZ2wfZvtNwAeAL7RsCw7Ew7z8Ob5hCcfo93n1Favtn9reiSrhMPDdMuxDpaxHz/vbnzOptuimtKl7yZjlvt9A9W+j3bMY13T9IPDtlvduFdvnDCCmGGGSEEWMYLYfptqm+C9Ja0haTtVB6p5tsdWptnWeLGdZvtgyxCPAm5pe/4ZqJeF9klak+q/uXs9LDGD+wfYa4BBJK0r6ENW5qF/afhC4CfiOpDHl4OunqM449eYRYHzPQV/gVVT3Oh94QdJ7qc5D9ausOpwGfF/V4e7lJW1fkoazgA9I+t+lfIyqA9r/0Mtws4B9S9v30LTFWQ74vrn8AH+aavtp0UBibHJz6fNZSStI2oPqrE5fVOL++xf9PK/eYpW0kaR3lmfzPNUqYM89nAN8VVKXpHWAr1E9v/5cC/wj8MM2dT+n2lZ9V/k3fRhVEn9TeRYvUP2bWkHSP7c8i1OBAyW9XZVVy/82Vm+dJEa+JEQRI9/HqX443Q08QXVwuGc75hvAVsBTVNsKF7b0/Q7VD6AnJR1u+yngIKrzN3+kWjH6A33ra/7BdivVAezHgG8De9v+c6n7CDCeakXgIuDr5bxOb84r3/8s6fay3XYI1Q/QJ4B9afltpX4cTvUbT9OBx6lWPZYrydoeVIeK51OtOnyR3v//9/NUKypPUp2pubipbgPg11RJ7s3ASV7Cvz1k+6/AP1MljE9SrRpeStNB5DZ2oEpcWr/6el69xboScDTVe/gnqiT3y6XPt6jOV82mepa3l7L+7sm2r7T9eJu6+8o9/rDM+QGqXyT4a9Oz2L/cwz40/W/EdjfVOaITSv1vS9sYhdT7ebyIiGWHpP2B/1O2WmIQSboVONn26Z2OJaJTskIUEVEzkt4h6X+VbaJPAJsBl3U6rohOyl9rjYion42otrpWo/rNuL3LebCI2sqWWURERNRetswiIiKi9rJlVmPrrLOOx48f3+kwIiIihsWMGTMes932Y3OSENXY+PHj6e7u7nQYERERw0LS73ury5ZZRERE1F4SooiIiKi9JEQRERFRezlDFBGxjBh/xLROhxCxTJl39PuGba6sEEVERETtJSGKiIiI2ktCFBEREbW3zCdEkq6R1GhTvrukI3rps2DoI1tykuZJWucV9r1psOOJiIiIyog9VG17KjC103EASFrB9gtDOYftHYZy/IiIiDp7RStEksZLukfSqZLuknSFpJWbV3MkrSNpXrneX9LFki6RNFfSZyV9QdJMSbdIWqufKT8q6SZJd0ratmnME8r1GyXdLGm6pKOa4nydpOskzSp9d+7jnhZI+i9Jt0u6UlJXKV9f0mWSZki6XtLGpXyypO9Luhr4bi9jrl2ezUxJpwBqqvuopNtKbKdIWl7SZyT9Z1Ob/SX9sCe+pvIvSZoj6Q5JR/cVZ5uYJkrqltQ9f/78fh57REREPSzNltkGwIm2NwGeBD7YT/tNgX2BbYFvA8/Z3hK4Gfh4P31XLSskBwGntak/DviR7W2APzWV7wtcbnsLYHNgVl9zALfb3gq4Fvh6KZ8EfM721sDhwElNfTYEdrN9WC9jfh24odznVGAcgKS3APsAO5bYFgH7AecD/9zUfx/g3OYBJb0X2BN4u+3NgZ4Eqq84/872JNsN242urrYf5xIREVE7S7NlNtd2T4IxAxjfT/urbT8DPCPpKeCSUj4H2KyfvucA2L5O0hqSxrbU78iLCdkUXlyxmQ6cJmlF4OKmeNtZzIvJx1nAhZJWA3YAzpP+vrizUlOf82wv6mPMXSgJju1pkp4o5e8Ctgaml3FXBh61PV/SA5K2A+4HNgJubBlzN+B028+VcR8fQJwRERHRh6VJiBY2XS+i+qH+Ai+uOo3po/3ipteLBxCH+3ndtqwkULsA7wOmSPqe7TP7mat5vOWAJ8sqTjvPDnCcVgLOsP1/29SdC/wLcC9wke3W/mozZn9xRkRERB8G+7fM5lGtfADsPYjj7gMgaSfgKdtPtdTfCHy4XO/XUyhpPaqVl1OBnwBb9THHcrwY875UW11PA3MlfaiMJ0mbL0Hc1/XEU7a6Xl3KrwT2lvSaUrdWiRXgQqotsY/Qsl1WXAF8UtIqPX0HIc6IiIhaG+zfMjsG+LmkjwFXDeK4T5RfO18D+GSb+s8DP5X0eeCCpvIJwBcl/Q1YQN9nlZ4FNpE0A3iKkoRRJTQ/kvRVYEXgZ8AdA4z7G8A5km6nOpf0PwC27y7jXSFpOeBvwMHA720/Ielu4K22b2sd0PZlkrYAuiX9Ffgl8OWljDMilgHD+TEFEfFSevmOTD1JWmB7tU7HMZwajYa7u7s7HUZERMSwkDTD9sv+tiGMgD/MGBERETHUlpk/zCjpRKrfFmt2nO3TB3meW3n5b2B9bGlWhyQdQLVt1+xG2we/0jEjIiJi+CwzCdFwJQ+23z4EY54ODGriFhEREcMnW2YRERFRe0mIIiIiovaSEEVERETtJSGKiIiI2ktCFBEREbW3zPyWWURE3Y0/YlqnQ1jm5a95x1DJClFERETUXhKiiIiIqL0kRMsYSWMlHdT0el1J53cypoiIiNEuCdGyZyzw94TI9kO29+5gPBEREaNeEqJBJuliSTMk3SVpYilb0FS/t6TJ5fq1ki6SdEf52gE4Glhf0ixJ35M0XtKdpf0YSadLmiNppqRdS/n+ki6UdJmk+yX957DfeERExAiW3zIbfJ+0/biklYHpki7oo+3xwLW295K0PLAacASwqe0tACSNb2p/MIDtt0naGLhC0oalbgtgS2AhcJ+kH9p+sHXCkqRNBBg3btxS3GZERMTokRWiwXeIpDuAW4A3ABv00fadwI8AbC+y/VQ/Y+8ETCnt7wV+D/QkRFfafsr288DdwHrtBrA9yXbDdqOrq2ug9xQRETGqZYVoEEmaAOwGbG/7OUnXAGMANzUbszRT9FG3sOl6EXlvIyIiBiwrRINrTeCJkgxtDGxXyh+R9BZJywF7NbW/EvgMgKTlJa0BPAOs3sv41wH7lfYbAuOA+wb/NiIiIuolCdHgugxYQdJs4CiqbTOozgVdClwFPNzU/vPArpLmADOATWz/GbhR0p2Svtcy/knA8qX9ucD+thcSERERS0W2+28Vo1Kj0XB3d3enw4iIiBgWkmbYbrSrywpRRERE1F4SooiIiKi9JEQRERFRe0mIIiIiovaSEEVERETtJSGKiIiI2ktCFBEREbWXhCgiIiJqLwlRRERE1F4+ADQiYhkx/ohpnQ5hUM07+n2dDiFiwLJCFBEREbWXhCgiIiJqb5lKiCRdI+llH7omaXdJR/TSZ8HQR9Z5ksZL2rfTcURERIxGy1RC1BvbU20f3ek4ACR16tzVeKBtQtTBmCIiIkaFfhOisjJxj6RTJd0l6QpJKzev5khaR9K8cr2/pIslXSJprqTPSvqCpJmSbpG0Vj9TflTSTZLulLRt05gnlOs3SrpZ0nRJRzXF+TpJ10maVfru3Mc9LZD0X5Jul3SlpK5Svr6kyyTNkHS9pI1L+WRJ35d0NfDdXsZcTdLpkuZImi3pg6X8I6XsTknfbY6h6XpvSZOb5jq+PIMHJO1dmh0N7Fzu79/KMzlP0iXAFZKmSNqjacyzJe3eJs6Jkroldc+fP7+ftyIiIqIeBrpCtAFwou1NgCeBD/bTflOq1YxtgW8Dz9neErgZ+Hg/fVe1vQNwEHBam/rjgB/Z3gb4U1P5vsDltrcANgdm9TUHcLvtrYBrga+X8knA52xvDRwOnNTUZ0NgN9uH9TLm/wOesv0225sBV0lalyqBeiewBbCNpD37iKvH64CdgPdTJUIARwDX297C9rGlbHvgE7bfCfwYOABA0prADsAvWwe2Pcl2w3ajq6trAKFERESMfgNNiOba7kkwZlBt3/TlatvP2J4PPAVcUsrnDKDvOQC2rwPWkDS2pX7HnjbAlKby6cABko4E3mb7mT7mWAycW67PAnaStBpVEnGepFnAKVSJSY/zbC/qY8zdgBN7Xth+AtgGuMb2fNsvAGcDu/QxRo+LbS+2fTfw2j7a/cr242W+a4E3S3oN8BHggjJnRERE9GOgCdHCputFVH+/6IWm/mP6aL+46fVi+v/bR+7ndduykkDtAvwRmCKpv5Wo1vGWA54sKzA9X29pavNsP2OoTVzqZ84efT2/vsZojWkKsB/VStHpffSLiIiIJktzqHoesHW53ruPdktqHwBJO1FtQT3VUn8j8OFyvV9PoaT1gEdtnwr8BNiqjzmW48WY9wVusP00MFfSh8p4krT5EsR9BfDZpnheDdwKvKOcsVqeauXm2tLkEUlvkbQcsNcAxn8GWL2fNpOBQwFs37UEsUdERNTa0iRExwCfkXQTsM4gxQPwRBnzZOBTbeo/DxwsaTqwZlP5BGCWpJlUZ5yO62OOZ4FNJM2gOt/zzVK+H/ApSXcAdwF79NK/nW8Bry6Hp+8AdrX9MPB/gauBO6jOLf2itD8CuBS4Cnh4AOPPBl6QdIekf2vXwPYjwD1kdSgiImKJyG63IzW6SVpge7VOxzHYJK1CdU5rqzYray/TaDTc3d099IFFREQsAyTNsP2yv3cII+TvEEX/JO0G3Av8cCDJUERERLyoI3/QT9KJVL8t1uw424O61SPpVmClluKPLc3qkKQDqLbtmt1o++BXOuZgsP1rYFwnY4iIiBipOpIQDVfyYPvtQzDm6eSMTkRExKiSLbOIiIiovSREERERUXtJiCIiIqL2khBFRERE7SUhioiIiNpLQhQRERG115Ffu4+IiJcbf8S0l7yed/T7OhRJRP1khSgiIiJqLwnRCFc+CDciIiKWQhKiEc72Dp2OISIiYqRLQjTCSVpQvk+QdJ2kiyTdLelkSXl/IyIiBiA/MEeXbYHDgLcB6wP/3NpA0kRJ3ZK658+fP9zxRURELJOSEI0ut9l+wPYi4Bxgp9YGtifZbthudHV1DX+EERERy6AkRKOL+3kdERERbSQhGl22lfTGcnZoH+CGTgcUERExEiQhGl1uBo4G7gTmAhd1NpyIiIiRIX+peoSzvVrTy+ds79OxYCIiIkaoJEQREcuIfFRHROckIRolbF8DXNPhMCIiIkaknCGKiIiI2ktCFBEREbWXhCgiIiJqLwlRRERE1F4SooiIiKi9JEQRERFRe0mIIiIiovaSEEVERETtJSGKiFhGjD9iGuOPmNbpMCJqKQlRRERE1F4SomEm6UhJh7+Cft+UtNtQxBQREVF3+SyzEcL21zodQ0RExGiVFaJhIOkrku6T9Gtgo1K2vqTLJM2QdL2kjSWtKWmepOVKm1UkPShpRUmTJe1dyreRdJOkOyTdJml1SctL+p6k6ZJmS/rXDt5yRETEiJIVoiEmaWvgw8CWVM/7dmAGMAk40Pb9kt4OnGT7nZLuAN4BXA18ALjc9t8k9Yz3KuBcYB/b0yWtAfwF+BTwlO1tJK0E3CjpCttzW+KZCEwEGDdu3FDffkRExIiQhGjo7QxcZPs5AElTgTHADsB5PYkOsFL5fi6wD1VC9GHgpJbxNgIetj0dwPbTZdx3A5v1rCIBawIbAC9JiGxPokrGaDQaHpxbjIiIGNmSEA2P1sRjOeBJ21u0aTsV+I6ktYCtgata6tVmvJ7yz9m+fGmDjYiIqJucIRp61wF7SVpZ0upU22DPAXMlfQhAlc0BbC8AbgOOAy61vahlvHuBdSVtU/quLmkF4HLgM5JWLOUbSlp1GO4vIiJixMsK0RCzfbukc4FZwO+B60vVfsCPJH0VWBH4GXBHqTsXOA+Y0Ga8v0raB/ihpJWpzg/tBvwYGA/crmofbj6w5xDdVkRExKiShGgY2P428O02Ve/ppf35VFtgzWX7N11PB7Zr0/XL5SsiIiKWQBKiiIhlxLyj39fpECJqK2eIIiIiovaSEEVERETtJSGKiIiI2ktCFBEREbWXhCgiIiJqLwlRRERE1F4SooiIiKi9JEQRERFRe0mIIiIiovaSEEVELCPGHzGt0yFE1FYSooiIiKi9JEQRERFRe0mIljGSrpHUaFO+u6QjeumzYOgji4iIGL3yafcjhO2pwNROxxERETEaZYVoACSNl3SPpFMl3SXpCkkrN6/mSFpH0rxyvb+kiyVdImmupM9K+oKkmZJukbRWP1N+VNJNku6UtG3TmCeU6zdKulnSdElHNcX5OknXSZpV+u7c5l4mSuqW1D1//vzBekQREREjWhKigdsAONH2JsCTwAf7ab8psC+wLfBt4DnbWwI3Ax/vp++qtncADgJOa1N/HPAj29sAf2oq3xe43PYWwObArNaOtifZbthudHV19RNGREREPSQhGri5tnsSjBnA+H7aX237GdvzgaeAS0r5nAH0PQfA9nXAGpLGttTv2NMGmNJUPh04QNKRwNtsP9PPPBEREUESoiWxsOl6EdX5qxd48RmO6aP94qbXi+n/7Jb7ed22rCRQuwB/BKZI6m8lKiIiIkhCtLTmAVuX670Hcdx9ACTtBDxl+6mW+huBD5fr/XoKJa0HPGr7VOAnwFaDGFNERMSolYRo6RwDfEbSTcA6gzjuE2XMk4FPtan/PHCwpOnAmk3lE4BZkmZSnXE6bhBjioghNu/o93U6hIjakt1uNybqoNFouLu7u9NhREREDAtJM2y/7G/9QVaIIiIiIvKHGTtF0olUvy3W7Djbp3cinoiIiDpLQtQhtg/udAwRERFRyZZZRERE1F4SooiIiKi9JEQRERFRe0mIIiIiovaSEEVERETtJSGKiIiI2ktCFBGxjBh/xLROhxBRW0mIIiIiovaSEA0SSXtKeuswzzlW0kHDOWdERMRolIRo8OwJDFtCJGl5YCyQhCgiImIpJSHqhaSLJc2QdJekiU3lC5qu95Y0WdIOwO7A9yTNkrS+pC0k3SJptqSLJL26zRyTJZ0s6XpJv5H0/lI+vpTdXr52KOUTJF0t6afAHOBoYP0y5/ckvU7SdeX1nZJ2HuLHFBERMSrks8x690nbj0taGZgu6QLbf27X0PZNkqYCl9o+H0DSbOBztq+V9E3g68ChbbqPB94BrA9cLenNwKPAP9p+XtIGwDlAo7TfFtjU9lxJ48v1FmXOw4DLbX+7rCCt0jpZSe4mAowbN27Jn0pERMQolBWi3h0i6Q7gFuANwAYD7ShpTWCs7WtL0RnALr00/7ntxbbvBx4ANgZWBE6VNAc4j5duxd1me24vY00HDpB0JPA228+0NrA9yXbDdqOrq2ugtxQRETGqJSFqQ9IEYDdge9ubAzOBMaXaTU3HsPTc5vW/AY8Am1OtDL2qqf7ZXgeyr6NKvP4ITJH08UGILyIiYtRLQtTemsATtp+TtDGwXVPdI5LeImk5YK+m8meA1QFsPwU80XSG52PAtbT3IUnLSVofeBNwX5n/YduLS9/le+n79zkBJK0HPGr7VOAnwFYDvuOIiIgayxmi9i4DDizngO6j2jbrcQRwKfAgcCewWin/GdU21yHA3sAngJMlrUK1FXZAL3PdR5UsvRY4sJwbOgm4QNKHgKvpZVXI9p8l3SjpTuC/SzxflPQ3YAGQFaKIiIgBkN26YxPDRdJkmg5iD7dGo+Hu7u5OTB0RETHsJM2w3WhXly2ziIiIqL1smXWQ7f07HUNERERkhSgiIiIiCVFEREREEqKIiIiovSREERERUXtJiCIiIqL2khBFRERE7SUhioiIiNpLQhQRERG1l4QoIiIiai8JUURERNReEqKIiIiovSRES0jSTa+w356S3jrY8URERMTSS0K0hGzv8Aq77gkMOCGSlA/ejYiIGCZJiJaQpAXl+wRJ10g6X9K9ks6WpFJ3tKS7Jc2WdIykHYDdge9JmiVp/V7GvkbSf0i6Fvi8pK0lXStphqTLJb2utDukafyflbIjJU2RdJWk+yV9upc5JkrqltQ9f/78IXhCERERI09WIZbOlsAmwEPAjcCOku4G9gI2tm1JY20/KWkqcKnt8/sZc6ztd0haEbgW2MP2fEn7AN8GPgkcAbzR9kJJY5v6bgZsB6wKzJQ0zfZDzYPbngRMAmg0Gl7K+4+IiBgVskK0dG6z/Qfbi4FZwHjgaeB54MeS/hl4bgnHPLd83wjYFPiVpFnAV4F/KHWzgbMlfRR4oanvL2z/xfZjwNXAtq/gniIiImonCdHSWdh0vQhYwfYLVInIBVTnhi5bwjGfLd8F3GV7i/L1NtvvLnXvA04EtgZmNJ03al3xyQpQRETEACQhGmSSVgPWtP1L4FBgi1L1DLD6Egx1H9Alafsy7oqSNpG0HPAG21cDXwLGAquVPntIGiNpbWACMH2pbygiIqIGcoZo8K0O/ELSGKpVnn8r5T8DTpV0CLC37d/1NYjtv0raGzhe0ppU79UPgN8AZ5UyAceWM0oAtwHTgHHAUa3nhyIiIqI92dlVGQ0kHQkssH3MQPs0Gg13d3cPXVARERHLEEkzbDfa1WXLLCIiImovW2YdIOlEYMeW4uNsn/5Kx7R95FIFFRERUWNJiDrA9sGdjiEiIiJelC2ziIiIqL0kRBEREVF7SYgiIiKi9pIQRURERO0lIYqIiIjaS0IUERERtZeEKCIiImovCVFERETU3jKXEEkaL+nOQRprnqR1BmOsJZx3cvlg1uGYa3dJRwzHXBEREaNV/lL1CGd7KjC103FERESMZMvcClGxgqQzJM2WdL6kVQAkvUvSTElzJJ0maaW+yntIWlnSZZI+LWlVSdMk3SHpTkn7tE5e2k0vbS5omn+ypOMl3STpgZ5VIFVOkHS3pGnAa9rdlKRrJB0r6TpJ90jaRtKFku6X9K3S5iUrZJIOL59kj6RDyhyzJf2slO0v6YRy/SAiMpMAACAASURBVFpJF5W475C0w9K+EREREXWwrCZEGwGTbG8GPA0cJGkMMBnYx/bbqFa3PtNbedNYqwGXAD+1fSrwHuAh25vb3hS4rM38F9rexvbmwD3Ap5rqXgfsBLwfOLqU7VVifhvwaaCvROSvtncBTgZ+ARwMbArsL2ntfp7LEcCW5bkc2Kb+eODaEvdWwF2tDSRNlNQtqXv+/Pn9TBcREVEPy2pC9KDtG8v1WVQJyEbAXNu/KeVnALv0Ud7jF8Dpts8sr+cAu0n6rqSdbT/VZv5NJV0vaQ6wH7BJU93Fthfbvht4bSnbBTjH9iLbDwFX9XFvPdtbc4C7bD9seyHwAPCGPvoBzAbOlvRR4IU29e8EfgRQYnnZvdmeZLthu9HV1dXPdBEREfWwrCZEbvNavbTtrbzHjcB7JQmgJE5bUyUk35H0tTZ9JgOfLStO3wDGNNUt7GXu1ph709N/cctYi6lWt17gpe9L89zvA04s8c+QlDNgERERg2BZTYjGSdq+XH8EuAG4Fxgv6c2l/GPAtX2U9/ga8GfgJABJ6wLP2T4LOIZqa6nV6sDDklakWiHqz3XAhyUtL+l1wK4Du822HgFeI2ntchbq/SXu5YA32L4a+BIwlmo7sNmVlO3CEssaSxFHREREbSyrCdE9wCckzQbWAn5k+3ngAOC8spW1GDi5t/KW8Q4Fxkj6T6pzPrdJmgV8BfhWm/n/H3Ar8CuqhKs/FwH3U606/YiXJmRLxPbfgG+W+S9tmn954KxyjzOBY20/2dL988Cupc0MXrrVFxEREb2QPdCdnhhtGo2Gu7u7Ox1GRETEsJA0w3ajXd2yukIUERERMWySEEVERETtJSGKiIiI2ktCFBEREbWXhCgiIiJqLwlRRERE1F4SooiIiKi9JEQRERFRe0mIIiIiovaSEEVERETtJSGKiIiI2ktCFBEREbVXq4RI0nhJd3Y6jsEmaZ6kdTodR0RExEhVq4QoIiIiop06JkTLSzpV0l2SrpC0MoCkLSTdImm2pIskvbqUXyPpWEnXSbpH0jaSLpR0v6Rv9Qwq6aOSbpM0S9IpkpZvnVjSP0m6V9INko6XdGkpX0vSxWXuWyRt1k/52iX2mZJOAVTKV5U0TdIdku6UtM+QP82IiIhRoI4J0QbAibY3AZ4EPljKzwT+3fZmwBzg6019/mp7F+Bk4BfAwcCmwP4lOXkLsA+wo+0tgEXAfs2TShoDnAK81/ZOQFdT9TeAmWXuL5dY+ir/OnCD7S2BqcC4Uv4e4CHbm9veFLis9eYlTZTULal7/vz5A3xkERERo1sdE6K5tmeV6xnAeElrAmNtX1vKzwB2aeoztXyfA9xl+2HbC4EHgDcA7wK2BqZLmlVev6ll3o2BB2zPLa/PaarbCZgCYPsqYO0SU2/luwBnlfJpwBNN8e0m6buSdrb9VOvN255ku2G70dXV1VodERFRSyt0OoAOWNh0vQhYeQn6LG7pv5jqGQo4w/b/7WMMLWGd+yhv/v5ihf0bSVsD/wR8R9IVtr/Zx7wRERFBPVeIXqaspDwhaedS9DHg2j66tLoS2FvSa+DvZ3/Wa2lzL/AmSePL6+bzPddRttgkTQAes/30AMvfC/Scd1oXeM72WcAxwFZLcA8RERG1VccVot58AjhZ0ipUW2EHDLSj7bslfRW4QtJywN+ozhn9vqnNXyQdBFwm6THgtqYhjgROlzQbeK7E0lf5N4BzJN1Olbj9Tyl/G/A9SYtLDJ8Z6D1ERETUmeyX7bzEEJG0mu0FkgScCNxv+9hOxdNoNNzd3d2p6SMiIoaVpBm2G+3qsmU2vD5dDl3fBaxJ9VtnERER0WHZMhtGZTWoYytCERER0V5WiCIiIqL2khBFRERE7SUhioiIiNpLQhQRERG1l4QoIiIiai8JUURERNReEqKIiIiovSREERERUXtJiCIiIqL2khBFRERE7SUhGiKSbhqica+R1PaD6SIiIuKVSUI0RGzvMJzzSVp+OOeLiIgYTZIQDRFJC8r3L0qaLmm2pG+Usi9JOqRcHyvpqnL9Lklnlet3S7pZ0u2SzpO0Wrs5JH1T0q3AVyVd1FT3j5IuHIZbjYiIGPGSEA0hSe8GNgC2BbYAtpa0C3AdsHNp1gBWk7QisBNwvaR1gK8Cu9neCugGvtBmilWBO22/Hfgm8BZJXaXuAOD0NjFNlNQtqXv+/PmDdasREREjWhKiofXu8jUTuB3YmCpBmkGVHK0OLARupkqMdgauB7YD3grcKGkW8AlgvTbjLwIuALBtYArwUUljge2B/27tYHuS7YbtRldXV2t1RERELa3Q6QBGOQHfsX3KyyqkeVSrODcBs4FdgfWBe8r3X9n+SD/jP297UdPr04FLgOeB82y/sNR3EBERUQNZIRpalwOf7Dn/I+n1kl5T6q4DDi/frwcOBGaVlZ5bgB0lvbn0W0XShv1NZvsh4CGq7bbJg3wvERERo1YSoqFj21cAPwVuljQHOB9YvdRfD7wOuNn2I1SrOteXjvOB/YFzJM2mSpA2HuC8ZwMP2r57sG4kIiJitMuW2RCQtDbwOIDt44DjWtvYvhJYsen1hi31VwHbtOk3oen6Zb95RnUw+9RXGHpEREQtJSEaZJLWBa4BjunA3DOAZ4HDhnvuiIiIkSwJ0SAr53j6Pe8zRHNv3Yl5IyIiRrqcIYqIiIjaS0IUERERtZeEKCIiImovCVFERETUXhKiiIiIqL0kRBEREVF7SYgiIiKi9pIQRURERO0lIYqIiIjaS0IUERERtZeEaBkl6UhJh7cpX1fS+eV6gqRLhz+6iIiI0SWfZTbClM9K27vTcURERIwmWSEaQpLGS7pX0o8l3SnpbEm7SbpR0v2StpW0lqSLJc2WdIukzZqG2FzSVaXtp5vGvLPNXKtKOk3SdEkzJe0xbDcaERExwmWFaOi9GfgQMBGYDuwL7ATsDnwZeBCYaXtPSe8EzgS2KH03A7YDVgVmSprWxzxfAa6y/UlJY4HbJP3a9rPNjSRNLLEwbty4QbrFiIiIkS0rRENvru05thcDdwFX2jYwBxhPlRxNAbB9FbC2pDVL31/Y/ovtx4CrgW37mOfdwBGSZgHXAGOAl2U8tifZbthudHV1DcoNRkREjHRZIRp6C5uuFze9Xkz1/F9o08ct31vL2xHwQdv3vZIgIyIi6iwrRJ13HbAfVL81Bjxm++lSt4ekMZLWBiZQbbn15nLgc5JUxtpyyCKOiIgYZbJC1HlHAqdLmg08B3yiqe42YBrV1tdRth+SNL6XcY4CfgDMLknRPOD9QxNyRETE6KLqOEvUUaPRcHd3d6fDiIiIGBaSZthutKvLlllERETUXhKiiIiIqL0kRBEREVF7SYgiIiKi9pIQRURERO0lIYqIiIjaS0IUERERtZeEKCIiImovCVFERETUXhKiiIiIqL0kRBEREVF7SYgiIiKi9kZMQiTpEEn3SDpb0kqSfi1plqR9JP1Y0ls7HWMPSQ1Jx3do7rGSDurE3BERESPVCp0OYAkcBLzX9lxJ2wEr2t6i1J3bwbhexnY30KmPkR9L9axO6tD8ERERI84yt0Ik6QuS7ixfh5ayk4E3AVMl/TtwFrBFWSFaX9I1khql7Xsk3S7pDklXlrJVJZ0mabqkmZL26GXuL5Y2syV9o6n8K5LuK6tS50g6vJQ3z7uOpHnleoKkS8v1kZKmSLpK0v2SPt3U5lpJP5f0G0lHS9pP0m2S5khav7TrknRBiWu6pB2bxj2txPCApENKuEcD65dn871BfGsiIiJGrWVqhUjS1sABwNsBAbdKutb2gZLeA+xq+zFJtwKH235/6dfTvws4FdilrCStVYb+CnCV7U9KGgvcJunXtp9tmvvdwAbAtmXuqZJ2AZ4FPgxsSfW8bgdmLOGtbQZsB6wKzJQ0rZRvDrwFeBx4APix7W0lfR74HHAocBxwrO0bJI0DLi99ADYGdgVWB+6T9CPgCGDTptWz1mc8EZgIMG7cuCW8jYiIiNFpmUqIgJ2Ai3oSFUkXAjsDMwfYfzvgOttzAWw/XsrfDezes7IDjAHGAfc09X13+eqZazWqBGn1EtNzJaapr+C+fmH7L8BfJF1NlXQ9CUy3/XAZ93fAFaX9HKpEB2A34K09SR+whqTVy/U02wuBhZIeBV7bXyC2JwGTABqNhl/BvURERIw6y1pCpP6b9Nu/3Q95AR+0fV8/fb9j+5SXFFbbdr0lDi/w4rbjmD7Gbu3f83phU9nipteLefG9WQ7YviRUzXG19l/Esvd+RkREjAjL2hmi64A9Ja0iaVVgL+D6Jeh/M/AOSW8EaNoyuxz4nEoWIWnLNn0vBz4pabXS5vWSXlNi2kvSymVl5gNNfeYBW5frvfuIaw9JYyStDUwApi/BPV0BfLbnhaS2W2FNnqFa1YqIiIgBWqYSItu3A5OB24Bbqc7UDHS7DNvzqc7HXCjpDl787bOjgBWB2ZLuLK9b+14B/BS4WdIc4Hxg9RLTucAs4AJemqAdA3xG0k3AOn2EdhswDbgFOMr2QwO9J+AQoFEOet8NHNhXY9t/Bm4sh9JzqDoiImIAZOcYyZKQdCSwwPYxQ9F+ODUaDXd3d+qvA0RERAwvSTNsN9rVLVMrRBERERGdkEO4S8j2kUPZPiIiIoZfVogiIiKi9pIQRURERO0lIYqIiIjaS0IUERERtZeEKCIiImovCVFERETUXhKiiIiIqL0kRBEREVF7SYgiIiKi9pIQtZA0QdIOTa8PlPTxTsbUH0nzJPX14bIRERHRh3x0RxNJKwATgAXATQC2T+5kTBERETH0RmxCJGlV4OfAPwDLA0fZPlfSPOBcYNfSdF/bv5W0HnAa0AXMBw6w/T+SJgOPA1uW7zsCiyR9FPgc8C7Kp9VLuga4tYw9FviU7eslrQJMBjYG7gHGAwfbfslHyUv6J+D7wGPA7cCbbL9f0loltjcBzwETbc/uo3xt4JxyL7cB6uuZLNWDjoiIqIGRvGX2HuAh25vb3hS4rKnuadvbAicAPyhlJwBn2t4MOBs4vqn9hsButj8InAwca3sL29e3mXeFMvahwNdL2UHAE2Xso4CtWztJGgOcArzX9k5UyUyPbwAzS/8vA2f2U/514AbbWwJTgXEDeCY9cUyU1C2pe/78+W1uLyIion5GckI0B9hN0ncl7Wz7qaa6c5q+b1+utwd+Wq6nADs1tT/P9qIBznth+T6DaiWIMtbPAGzfCcxu029j4AHbc1ti7Ok/pfS/Clhb0pp9lO8CnFXKpwFPlHH6eiaU9pNsN2w3urq6WqsjIiJqacQmRLZ/Q7USMwf4jqSvNVf3ck0v5c8uwdQLy/dFvLjlqAH066tNuzr3Ud78/cWKvp9JRERE9GLEJkSS1gWes30WcAywVVP1Pk3fby7XNwEfLtf7ATf0MvQzwOpLGM4NwL+UuN4KvK1Nm3uBN0ka3xIjwHUlJiRNAB6z/fQAy98LvLpc9/VMIiIiohcj9lA1VdLxPUmLgb8Bn2mqW0nSrVQJ30dK2SHAaZK+SDlU3cu4lwDnS9qD6lD1QJwEnCFpNjCTasvsJdtVtv8i6SDgMkmPUR2G7nEkcHrp/xzwiX7KvwGcI+l24Frgf0p5X88kIiIieiG7tx2lkan8llnD9mPDOOfywIq2n5e0PnAlsKHtv7a0W832AkkCTgTut33scMXZqtFouLu7u/+GERERo4CkGbYb7epG8grRsmQV4GpJK1Kd+/lMazJUfFrSJ4BXUa0knTKMMUZEREQvRl1CZHt8B+Z8Bmibcba0Oxbo2IpQREREtDdiD1VHREREDJYkRBEREVF7SYgiIiKi9pIQRURERO0lIYqIiIjaS0IUERERtZeEKCIiImovCVFERETUXhKiiIiIqL0kRBEREVF7SYhGCEmHSlql03FERESMRkmIRo5DqT5E9mUkLT/MsURERIwqSYgGkaSPS5ot6Q5JUyStJ+nKUnalpHGl3WRJezf1W1C+T5B0jaTzJd0r6WxVDgHWBa6WdHVPH0nflHQr8FVJFzWN94+SLhzWm4+IiBjBRt2n3XeKpE2ArwA72n5M0lrAGcCZts+Q9EngeGDPfobaEtgEeAi4sYx3vKQvALvafqy0WxW40/bXJAm4R1KX7fnAAcDpvcQ5EZgIMG7cuKW55YiIiFEjK0SD553A+T0Ji+3Hge2Bn5b6KcBOAxjnNtt/sL0YmAWM76XdIuCCMpfL+B+VNLbM+9/tOtmeZLthu9HV1TWgG4uIiBjtskI0eAS4nzY99S9QktGyuvOqpjYLm64X0ft79LztRU2vTwcuAZ4HzrP9wgDjjoiIqL2sEA2eK4F/kbQ2QNkyuwn4cKnfD7ihXM8Dti7XewArDmD8Z4DVe6u0/RDVNttXgclLFnpERES9ZYVokNi+S9K3gWslLQJmAocAp0n6ItBztgfgVOAXkm6jSqSeHcAUk4D/lvSw7V17aXM20GX77qW5l4iIiLpRdfwkRgNJJwAzbf9kIO0bjYa7u7uHOKqIiIhlg6QZthvt6rJCNEpImkG10nRYp2OJiIgYaZIQjRK2t+6/VURERLSTQ9URERFRe0mIIiIiovaSEEVERETtJSGKiIiI2ktCFBEREbWXhCgiIiJqLwlRRERE1F4SooiIiKi9JEQRERFRe0mIIiIiovaSEL1Ckg6RdI+kswdhrG9K2q1cHypplaWPMCIiIgYqn2X2yh0EvNf23P4aShIg24vb1dv+WtPLQ4GzgOcGGoikFWy/MND2ERER8VJZIXoFJJ0MvAmYKukpSYc31d0paXz5ukfSScDtwM7l9amS7pJ0haSVS5/JkvaWdAiwLnC1pKtL3YKmsfeWNLmpz/dLu+9KWl/SZZJmSLpe0sbD9TwiIiJGuiREr4DtA4GHgF2BY/touhFwpu0tgd8DGwAn2t4EeBL4YMu4x/eMa3vXAYSyIbCb7cOAScDnyqfeHw6c1K6DpImSuiV1z58/fwBTREREjH7ZMhtav7d9S9PrubZnlesZwPilHP8824skrQbsAJxX7c4BsFK7DrYnUSVPNBoNL+X8ERERo0ISoqX3Ai9daRvTdP1sS9uFTdeLgJUHMH5z0jKmpa5n/OWAJ21vMYDxIiIiokW2zJbePGArAElbAW9cyvGeAVZvev2IpLdIWg7Yq10H208DcyV9qMQhSZsvZRwRERG1kYRo6V0ArCVpFvAZ4DdLOd4k4L97DlUDRwCXAlcBD/fRbz/g/7d373Fy1/W9x1/vgNwvAVkptIVoji2aQAIMWO6B0paCFVug2GAQq+VBRUQp1HjwAEqpIFCFcjM8CihUhaByCKjQYgiXALKBQBK5HUnOaUXLohAT0BTI+/wx3zXDMrs7u9nr/N7Px2Me+53v/TOTkA/f3292PiLpMWAZcOR67iMiIqIyZOc2kqqq1Wru7Owc7W1ERESMCEmLbNeateWEKCIiIiovCVFERERUXhKiiIiIqLwkRBEREVF5SYgiIiKi8pIQRUREROUlIYqIiIjKS0IUERERlZeEKCIiIiovCVFERERUXhKiiIiIqLwkRBEREVF5SYjGGEnTJR0+2vuIiIiokiREY890YEAJkaQNh2kvERERlZCEqAdJx0t6XNJjkq6XtLOku0rdXZJ2Kv2uk3SlpPmSnpV0kKRrJD0h6bqG+VZLuljSI2V8R6m/W1KtlLeTtELSRsDngWMlLZZ0rKTNy7wPS3pU0pFlzAmS5kqaB9wpaQdJ95RxSyUdMNKvXURExHiVhKiBpCnAmcAhtqcBpwKXAV+zvRvwr8ClDUO2AQ4BPgXMA74ETAF2lTS99NkceMT2HsAC4Oze1rf938BZwI22p9u+seznB7b3Ag4GLpS0eRmyD/Ah24cAM4E7bE8HpgGLe4nxREmdkjq7uroG8vJERES0rSREb3QIcLPtFwBs/4J60vH10n49sH9D/3m2DSwB/sv2EttrgWXApNJnLXBjKd/QY3wr/hiYLWkxcDewCbBTafu3skeAh4EPSzoH2NX2qmaT2Z5ju2a71tHRMcCtREREtKckRG8kwP30aWxfU36ubSh3P+/tvp7u8a+x7vXfpJ89HVVOjKbb3sn2E6Xt5d9Mat8DHAj8BLhe0vH9xBERERFFEqI3ugv4S0lvBZC0LbAQ+EBpPw64b4BzTgCOLuWZDeNXAHuW8tEN/VcBWzY8vwM4RZLKnnZvtoiknYHnbV8N/AuwxwD3GRERUVn5dFID28sknQcskPQ68CjwCeAaSWcAXcCHBzjty8AUSYuAlcCxpf4i4CZJs4AfNPSfz7pLZF8AzgW+DDxekqIVwHubrDMDOEPSq8BqICdEERERLVL9FpgYLpJW295itPfRTK1Wc2dn52hvIyIiYkRIWmS71qwtl8wiIiKi8pIQDbOxejoUERER6yQhioiIiMpLQhQRERGVl4QoIiIiKi8JUURERFReEqKIiIiovCREERERUXlJiCIiIqLykhBFRERE5SUhioiIiMpLQhQRERGVl4RoGEg6R9Lp/fQ5QdKODc9XSNquSb/3SZo9HPuMiIiIug1HewMVdgKwFHiur062bwVuHYkNRUREVFVOiIaApOMlPS7pMUnX92ibLunB0v4dSdtIOhqoAf8qabGkTUv3UyQ9ImmJpF3K+BMkXVbK10m6VNJCSc+WeZA0QdIVkpZJuk3Sd7vbIiIion9JiNaTpCnAmcAhtqcBp/bo8jXg07Z3A5YAZ9u+GegEjrM93favSt8XbO8BXAn0dsltB2B/4L3A+aXuL4BJwK7AR4F9+tjviZI6JXV2dXUNLNiIiIg2lYRo/R0C3Gz7BQDbv+hukLQ1MNH2glL1VeDAPub6dvm5iHqC08wtttfa/hGwfanbH5hb6n8GzO9tAdtzbNds1zo6OvoJLSIiohqSEK0/AR6iudaUn6/T+/1daxrK6vEzIiIiBiEJ0fq7C/hLSW8FkLRtd4PtlcCLkg4oVbOA7tOiVcCWQ7SH+4Cjyr1E2wMzhmjeiIiISsinzNaT7WWSzgMWSHodeBRY0dDlQ8BVkjYDngU+XOqvK/W/oo97flr0LeAPqX9q7WngIWDles4ZERFRGbKH6mpPjCZJW9heXU6qfgjsV+4n6lWtVnNnZ+fIbDAiImKUSVpku9asLSdE7eM2SROBjYBz+0uGIiIiYp0kRG3C9ozR3kNERMR4lZuqIyIiovKSEEVERETlJSGKiIiIyktCFBEREZWXhCgiIiIqLwlRREREVF4SooiIiKi8JEQRERFReUmIIiIiovKSEEVERETlJSGKiIiIyktCNACSapIuHeTYT0rabKj3FBEREeuv8gmRpJa/4NZ2p+1PDHKpTwItJ0SSNhjkOhERETFAbZEQSZok6UlJX5X0uKSbJW0maU9JCyQtknSHpB1K/7sl/aOkBcCpkvaStFDSY5J+KGnLXtaZIem2Uj5H0jVlrmclfaLUby7p9jLXUknHlrYdgfmS5vcRx2pJn5f0ELCPpA+W/SyW9BVJG5THdWXuJZI+1RDTl0scSyXt3csaJ0rqlNTZ1dW1Pi97RERE22j5dGQc+H3gI7bvl3QNcDLw58CRtrskHQucB/x16T/R9kGSNgKeBI61/bCkrYBftbjmLsDBwJbAU5KuBA4DnrN9BICkrW2vlHQacLDtF/qYb3Ngqe2zJL0L+DSwn+1XJV0BHAcsA37b9tQy/8TG8bb3lXQgcA0wtecCtucAcwBqtZpbjDMiIqKttVNC9B+27y/lG4D/ST0h+DdJABsAP23of2P5+fvAT20/DGD7lwNY83bba4A1kp4HtgeWABdJugC4zfa9A5jvdeBbpfyHwJ7Aw2X/mwLPA/OAd0j6Z+B24M6G8d8oMdwjaStJE22/NID1IyIiKqmdEqKepx2rgGW29+ml/8vlp5qMbdWahvLrwIa2n5a0J3A48AVJd9r+fIvz/dr26w37+qrtz/TsJGka8CfUT8H+knWnXj3jyAlQREREC9riHqJiJ0ndyc9fAQ8CHd11kt4iaUqTcU8CO0raq/TbciA3WvckaUfgFds3ABcBe5SmVdQvrbXqLuBoSW8r824raWdJ2wETbH8L+F8N8wMcW/ruD6y0vXKwcURERFRJO50QPQF8SNJXgGeAfwbuAC6VtDX1WL9M/R6c37D93+X+on+WtCn1+4cOBVYPch+7AhdKWgu8CvxtqZ8DfE/ST20f3N8ktn8k6bPAnZImlLlOLvu7ttQBNJ4gvShpIbAV606NIiIioh+yx/9VFUmTqN+v86abiKtC0t3A6bY7Wx1Tq9Xc2dly94iIiHFN0iLbtWZt7XTJLCIiImJQ2uKSme0VNPmI+WBJ+hPggh7Vy23/+RDN/xCwcY/qWbaXDHZO2zPWa1MREREV1hYJ0VCzfQf1+4+Ga/73DNfcERERMXC5ZBYRERGVl4QoIiIiKi8JUURERFReEqKIiIiovCREERERUXlJiCIiIqLykhBFRERE5SUhioiIiMpLQhQRERGVl4RoECRdJ+noQYybIWnfwcwtqSbp0l7GrJC03UD3ExEREXX56o6RNQNYDSwc6MDyLfb5avqIiIhh0DYnRJImSXpC0tWSlkm6U9Kmku6WVCt9tpO0opRPkHSLpHmSlkv6uKTTJD0q6UFJ27a47lmSHpa0VNIcSSr1n5D0I0mPS/qmpEnAScCnJC2WdEAf0x4q6V5JT0t6b5lvhqTbSvmtJb5HJX0F6F5zc0m3S3qs7OfYJvs9UVKnpM6urq4WX92IiIj21jYJUfFO4HLbU4CXgKP66T8VmAnsDZwHvGJ7d+AB4PgW17zM9l62pwKbAu8t9bOB3W3vBpxkewVwFfAl29Nt39vHnJOAg4AjgKskbdKj/WzgvrLXW4GdSv1hwHO2p5X9fL/nxLbn2K7ZrnV0dLQYYkRERHtrt4Roue3FpbyIemLRl/m2V9nuAlYC80r9khbG3917LwAAFvlJREFUdjtY0kOSlgCHAFNK/ePAv0r6IPBai3N1u8n2WtvPAM8Cu/RoPxC4AcD27cCLDfs+VNIFkg6wvXKA60ZERFRSuyVEaxrKr1O/R+o11sXZ86Slsf/ahudraeH+qnJycwVwtO1dgasb1jgCuBzYE1gkaSD3a7mf503rbD9d1lsCfEHSWQNYMyIiorLaLSFqZgX1JAFgwJ8M60d38vOCpC2655c0Afhd2/OBvwcmAlsAq4AtW5j3GEkTJE0G3gE81aP9HuC4stafAtuU8o7UL/vdAFwE7LEesUVERFRGFT5ldhFwk6RZwA+GcmLbL0m6mvqJzArg4dK0AXCDpK2p3/D8pdJ3HnCzpCOBU/q4j+gpYAGwPfX7j35d7tXu9jngG5IeKf3+X6nfFbhQ0lrgVeBvhyjUiIiItia72dWYqIJarebOznySPyIiqkHSItu1Zm1VuGQWERER0acqXDIbNEmXA/v1qL7E9rVDMPeZwDE9qufaPm99546IiIiBSULUB9snD+Pc51H/3UcRERExynLJLCIiIiovCVFERERUXhKiiIiIqLwkRBEREVF5SYgiIiKi8pIQRUREROUlIYqIiIjKS0IUERERlZeEKCIiIiovCdEASNpF0mJJj0qaLGnhAMd/UtJm/fRZ3Uv95yUd2qR+hqTbBrKPiIiIeKMkRAPzfuB/297d9o9t79uzg6QN+hj/SaDPhKg3ts+y/e+DGRsRERF9G/cJkaRJkp6QdLWkZZLulLSppLsl1Uqf7SStKOUTJN0iaZ6k5ZI+Lum0curzoKRte1nncOoJzUclzS91q8vPGZLmS/o6sETS5pJul/SYpKWSjpX0CWBHYH73+D5iuljSI5LuktRR6q6TdHQpHybpSUn3AX/RMO6gcoLVfYq1ZZO5T5TUKamzq6trgK92REREexr3CVHxTuBy21OAl4Cj+uk/FZgJ7E39C1Zfsb078ABwfLMBtr8LXAV8yfbBTbrsDZxp+93AYcBztqfZngp83/alwHPAwb2M77Y58IjtPYAFwNmNjZI2Aa4G/gw4APithubTgZNtTy9tv2oSxxzbNdu1jo6OPrYRERFRHe2SEC23vbiUFwGT+uk/3/Yq213ASmBeqV/Swtje/ND28oZ5DpV0gaQDbK8cwDxrgRtL+QZg/x7tu1CP9xnbLn263Q/8UzmNmmj7tYGHERERUT3tkhCtaSi/DmwIvMa6+Dbpo//ahudry9jBeLm7YPtpYE/qidEXJJ01yDkB3GIdts8HPgpsCjwoaZf1WDciIqIy2iUhamYF9aQE4OiRXFjSjtQvw90AXATsUZpWAW+6r6eHCazb70zgvh7tTwJvlzS5PP+rhnUn215i+wKgk/ppUkRERPRjsKch48FFwE2SZgE/GOG1dwUulLQWeBX421I/B/iepJ/2cR/Ry8AUSYuoX847trHR9q8lnQjcLukF6gnT1NL8SUkHUz8l+xHwvaEMKiIiol2pfhtKVFGtVnNnZ+dobyMiImJESFpku9asrZ0vmUVERES0pJ0vmQ2apMuB/XpUX2L72iFc4yFg4x7Vs2wvGao1IiIiojVJiJqwffIIrPGe4V4jIiIiWpNLZhEREVF5SYgiIiKi8pIQRUREROUlIYqIiIjKS0IUERERlZeEKCIiIiovCVFERERUXhKiiIiIqLwkRBEREVF5Yy4hknS3pDd98Zqk90ma3cuY1cO/s5EjaYakfRuenyTp+NHcU0RERDsbN1/dYftW4NbR3geApA1tvzaMS8wAVgMLAWxfNYxrRUREVF5LJ0SSJkl6QtLVkpZJulPSpo2nOZK2k7SilE+QdIukeZKWS/q4pNMkPSrpQUnb9rPkByUtlLRU0t4Nc15Wym+X9ICkhyWd27DPHSTdI2lxGXtAHzGtlnSxpEck3SWpo9RPlvR9SYsk3Stpl1J/naR/kjQfuKCXOfcu+360/Pz9nnsvz2+TNKOUDyt7eKzsYxJwEvCpEscBks6RdHrpP728ho9L+o6kbUr93ZIukPRDSU/3FrukEyV1Surs6urq522IiIiohoFcMnsncLntKcBLwFH99J8KzAT2Bs4DXrG9O/AA0N/ln81t7wt8DLimSfslwJW29wJ+1lA/E7jD9nRgGrC4rzWAR2zvASwAzi71c4BTbO8JnA5c0TDm94BDbf9dL3M+CRxY4jwL+Mc+1qckYVcDR9meBhxjewVwFfAl29Nt39tj2NeAT9veDVjSsG+ADW3vDXyyR/1v2J5ju2a71tHR0df2IiIiKmMgl8yW2+5OMBYBk/rpP9/2KmCVpJXAvFK/BNitn7HfALB9j6StJE3s0b4f6xKy61l3YvMwcI2ktwC3NOy3mbXAjaV8A/BtSVsA+wJzJXX327hhzFzbr/cx59bAVyW9EzDwlj76AvwBcI/t5QC2f9FXZ0lbAxNtLyhVXwXmNnT5dvnZyvsTERERxUBOiNY0lF+nnky91jDHJn30X9vwfC39J2Lu53nTOtv3AAcCPwGuH+CNyKYey0vlZKb78a6GPi/3M8e51BPBqcCfse41aXydaKhXszjWQ/dr3P3+RERERAvW91NmK4A9S/no9Zyr0bEAkvYHVtpe2aP9fuADpXxcd6WknYHnbV8N/AuwRx9rTGDdnmcC99n+JbBc0jFlPkmaNoB9b009GQM4oaF+BTBd0gRJv0v9MiLULx8eJOntZb3ue6tWAVv2nLy8Di823B80i/rlvoiIiFgP63uKcBFwk6RZwA+GYD/dXpS0ENgK+Osm7acCX5d0KvCthvoZwBmSXqX+Ka2+ToheBqZIWgSspCRh1BOsKyV9lvolr28Cj7W47y9Sv2R2Gm98Pe4HllO/XLgUeATAdpekE6lfrpsAPA/8EfXLizdLOhI4pccaHwKukrQZ8Czw4Rb3FhEREb2QPZRXbMYPSattbzHa+xhNtVrNnZ2do72NiIiIESFpke03/a5DGIO/mDEiIiJipI3ajbeSLqf+abFGl9i+dojXeYg3flIMYNb6nA5J+jD1y3aN7rd98mDnjIiIiNEzagnRSCUPtt8zDHNeCwxp4hYRERGjJ5fMIiIiovKSEEVERETlJSGKiIiIyktCFBEREZWXhCgiIiIqLwlRREREVF4SooiIiKi8JEQRERFReUmIIiIiovIqmxBJmijpY6W8o6Sbh3Gt90t69yDH3i3pTV9EJ+l9kmb3Mmb1YNaKiIioqsomRMBE4GMAtp+zffQwrvV+YFAJUW9s32r7/KGcMyIioqqqnBCdD0yWtFjSXElLASSdIOkWSfMkLZf0cUmnSXpU0oOSti39Jkv6vqRFku6VtEuzRSTtC7wPuLCsNVnS9DLX45K+I2mbfvb6QUkLJS2VtHfDPi8r5bdLekDSw5LO7WsiSSdK6pTU2dXVNbBXLCIiok1VOSGaDfzY9nTgjB5tU4GZwN7AecArtncHHgCOL33mAKfY3hM4Hbii2SK2FwK3AmfYnm77x8DXgE/b3g1YApzdz143t70v9ROta5q0XwJcaXsv4Gd9TWR7ju2a7VpHR0c/y0ZERFTDqH3b/Rg33/YqYJWklcC8Ur8E2E3SFsC+wFxJ3WM2bmViSVsDE20vKFVfBeb2M+wbALbvkbSVpIk92vcDjirl64ELWtlLRERE1CUham5NQ3ltw/O11F+zCcBL5XRpJLif573VRURERAuqfMlsFbDlYAba/iWwXNIxAKqb1spatlcCL0o6oLTNAhb0NrA4tqyzP7CyzNHofuADpXxcy4FEREQEUOGEyPbPgfvLzdQXDmKK44CPSHoMWAYc2UffbwJnlBuzJwMfon6T9ePAdODz/az1oqSFwFXAR5q0nwqcLOlhYOsBxhEREVF5snOlpapqtZo7OztHexsREREjQtIi22/63X5Q4ROiiIiIiG65qXoISToTOKZH9Vzb57Uw9nLqnxZrdInta4dqfxEREdFcEqIhVBKffpOfXsaePMTbiYiIiBblkllERERUXhKiiIiIqLwkRBEREVF5SYgiIiKi8pIQRUREROXlU2YREaNo0uzbf1Necf4Ro7iTiGrLCVFERERUXhKiiIiIqLwkRG1I0jmSTh/tfURERIwXSYjajKTcFxYRETFA+cdzHJE0CbjN9tTy/HRgC2AGsJD6d6HdOkrbi4iIGLdyQtQ+Jto+yPbFfXWSdKKkTkmdXV1dI7W3iIiIMS0JUfu4sZVOtufYrtmudXR0DPeeIiIixoUkROPLa7zxPdukofzyCO8lIiKibSQhGl/+C3ibpLdK2hh472hvKCIioh3kpupxxParkj4PPAQsB54c5S1FRES0Bdke7T3EKKnVau7s7BztbURERIwISYts15q15ZJZREREVF4SooiIiKi8JEQRERFReUmIIiIiovKSEEVERETlJSGKiIiIyktCFBEREZWXhCgiIiIqLwlRREREVF6+uiMiYhRNmn37b8orzj9iFHcSUW05IYqIiIjKS0I0RkiaKOljpbyjpJtHe08RERFVkYRo7JgIfAzA9nO2jx7l/URERFRG7iEaO84HJktaDDwDvMv2VEknAO8HNgCmAhcDGwGzgDXA4bZ/IWkycDnQAbwC/I3tJ0c+jIiIiPEnJ0Rjx2zgx7anA2f0aJsKzAT2Bs4DXrG9O/AAcHzpMwc4xfaewOnAFc0WkXSipE5JnV1dXcMQRkRExPiTE6LxYb7tVcAqSSuBeaV+CbCbpC2AfYG5krrHbNxsIttzqCdP1Go1D+uuIyIixokkROPDmoby2obna6m/hxOAl8rpUkRERAxQLpmNHauALQcz0PYvgeWSjgFQ3bSh3FxEREQ7S0I0Rtj+OXC/pKXAhYOY4jjgI5IeA5YBRw7l/iIiItpZLpmNIbZnNqm7Driu4fmkZm22lwOHDe8OIyIi2lMSooiIUZSv64gYG3LJLCIiIiovCVFERERUXhKiiIiIqLwkRBEREVF5SYgiIiKi8pIQRUREROUlIYqIiIjKS0IUERERlZeEKCIiIiovv6k6hsyk2beP9hYixrX81uqI0ZMTooiIiKi8JEQRERFReZVPiCTdLanWpP59kmb3Mmb18O+sf33tMSIiIlqXe4h6YftW4NbR3geApA1tv9azfiztMSIiYjwbkydEkiZJekLS1ZKWSbpT0qaNpzmStpO0opRPkHSLpHmSlkv6uKTTJD0q6UFJ2/az5AclLZS0VNLeDXNeVspvl/SApIclnduwzx0k3SNpcRl7QB8xrZZ0saRHJN0lqaPUT5b0fUmLJN0raZdSf52kf5I0H7iglzkb93idpKvKHE9Lem8vY06U1Cmps6urq5+XJSIiohrGZEJUvBO43PYU4CXgqH76TwVmAnsD5wGv2N4deAA4vp+xm9veF/gYcE2T9kuAK23vBfysoX4mcIft6cA0YHFfawCP2N4DWACcXernAKfY3hM4HbiiYczvAYfa/rt+9t9tEnAQcARwlaRNenawPcd2zXato6OjxWkjIiLa21i+ZLbcdneCsYj6P/Z9mW97FbBK0kpgXqlfAuzWz9hvANi+R9JWkib2aN+PdQnZ9aw7sXkYuEbSW4BbGvbbzFrgxlK+Afi2pC2AfYG5krr7bdwwZq7t1/vZe6ObbK8FnpH0LLALfSdpERERwdg+IVrTUH6devL2Guv23PP0o7H/2obna+k/8XM/z5vW2b4HOBD4CXC9pP5OonrONwF4yfb0hse7Gvq8PID5mu2xWRwRERHRw1hOiJpZAexZykcP4bzHAkjaH1hpe2WP9vuBD5Tycd2VknYGnrd9NfAvwB59rDGBdXueCdxn+5fAcknHlPkkadp6xHGMpAmSJgPvAJ5aj7kiIiIqYyxfMmvmIuAmSbOAHwzhvC9KWghsBfx1k/ZTga9LOhX4VkP9DOAMSa8Cq+n7XqWXgSmSFgErKUkY9QTrSkmfBd4CfBN4bJBxPEX9/qTtgZNs/3qQ80RERFSK7FxVGQmSVtveYhjnvw64zfbNrY6p1Wru7Owcri1FRESMKZIW2X7T7x6E8XfJLCIiImLIjbdLZoMm6XLqnxZrdInta4d4nYd44yfFAGatz+mQpA9Tv2zX6H7bJ3c/sX3CYOePiIiousokRI3JwzCv855hmPNaYEgTt4iIiFgnl8wiIiKi8nJTdYVJ6gL+72jvY5htB7ww2psYZlWIEaoRZxVihGrEWYUYYfzFubPtpl/TkIQo2pqkzt4+UdAuqhAjVCPOKsQI1YizCjFCe8WZS2YRERFReUmIIiIiovKSEEW7mzPaGxgBVYgRqhFnFWKEasRZhRihjeLMPUQRERFReTkhioiIiMpLQhQRERGVl4QoxgVJ20r6N0nPlJ/b9NLvMElPSfo/kma3Ml7SZ0r/pyT9SUP9RpLmSHpa0pOSjhreKEcnzob2WyUtHZ7I3rDOiMYoaTNJt5f3cJmk84cxtqZ7bmiXpEtL++OS9hjqeEfCSMYp6Y8kLZK0pPw8pN1ibGjfSdJqSacPb3RvWHOk/8zuJumB8ndxiaRNhj/KFtnOI48x/wC+CMwu5dnABU36bAD8GHgHsBHwGPDuvsYD7y79NgbeXsZvUNo+B/xDKU8AtmvHOEv7XwBfB5a2W4zAZsDBpc9GwL3Anw5DXL3uuaHP4cD3AAF/ADw0XO/pML5/Ix3n7sCOpTwV+Em7xdgw57eAucDpwx3jKL2XGwKPA9PK87eOxJ/Zll+P0d5AHnm08gCeAnYo5R2Ap5r02Qe4o+H5Z4DP9DW+sU95fgewTyn/B7B5BeLcAriP+j+wI5EQjXiMPea+BPibYYir1z031H0F+Kuer8Vwxjve4+wxr4CfAxu3W4zA+4ELgXMYuYRopP/MHg7cMBKxDeaRS2YxXmxv+6cA5efbmvT5bepJTLf/LHV9jW86RtLE8vxcSY9Imitp+6EJpU8jGmcpnwtcDLwyFAG0YDRiBKC8r38G3LWeMTTT7/p99BmWeIfJSMfZ6CjgUdtrBr371oxojJI2Bz5N/VR6JI30e/l7gCXdUf67+vdDEsUQqcy33cfYJ+nfgd9q0nRmq1M0qevv90r0NmZD4HeA+22fJuk04CJgVot76X3BMRSnpOnA/7D9KUmTWly/X2MpxoY9bQh8A7jU9rMt7mMgWtlzb32GPN5hNNJx1ieUpgAXAH/cSv/1NNIxfg74ku3VUrPhw2ak49wQ2B/Yi/r/gN0laZHt4fgflAFLQhRjhu1De2uT9F+SdrD9U0k7AM836fafwO82PP8d4LlS7m18b2N+Tv0v7HdK/VzgIwONqZkxFuc+wJ6SVlD/78HbJN1te8YgQvuNMRZjtznAM7a/PMBwWtXf+n312aiPsYONd7iMdJxI+h3qfxePt/3jIYmibyMd43uAoyV9EZgIrJX0a9uXDUk0vRuNP7MLbL8AIOm7wB4Mz4ntwI32Nbs88mjlQf3aeuNNel9s0mdD4FnqN5h23+Q3pa/xwBTeeGPqs6y7qfqbwCGlfAIwtx3jbJh3EiNzD9FovJf/QP2G1QnDGFeve27ocwRvvEH1h8P5nrZJnBNLv6OGO7bRirHHvOcwcvcQjfR7uQ3wCPUPOmwI/DtwxEi9r/2+HqO9gTzyaOVB/dMIdwHPlJ/blvodge829DsceJr6px/O7G98aTuz9H+Khk8fATsD91D/VMRdwE7tGGdD+yRGJiEa0Rip/5+rgSeAxeXx0WGK7U17Bk4CTiplAZeX9iVAbTjf02F8D0csTuCzwMsN791i4G3tFGOPdc9hhBKiUfoz+0FgGbCUJgnhaD7y1R0RERFRefmUWURERFReEqKIiIiovCREERERUXlJiCIiIqLykhBFRERE5SUhioiIiMpLQhQRERGV9/8BRdzSOwiiHA4AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model = LassoCV(alphas=np.arange(0.1, 10, 0.1), cv=cv, n_jobs=-1)\n",
    "\n",
    "model.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % model.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %model.score(X,y))\n",
    "coef = pd.Series(model.coef_, index = X.columns)\n",
    "\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
