{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    "import sklearn.metrics as f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_df= pd.read_csv('data/bids.csv')\n",
    "train_df = pd.read_csv('data/train.csv')\n",
    "test_df= pd.read_csv('data/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bid_id</th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>8dac2b259fd1c6d1120e519fb1ac14fbqvax8</td>\n",
       "      <td>ewmzr</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone0</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>us</td>\n",
       "      <td>69.166.231.58</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>668d393e858e8126275433046bbd35c6tywop</td>\n",
       "      <td>aeqok</td>\n",
       "      <td>furniture</td>\n",
       "      <td>phone1</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>in</td>\n",
       "      <td>50.201.125.84</td>\n",
       "      <td>jmqlhflrzwuay9c</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>aa5f360084278b35d746fa6af3a7a1a5ra3xe</td>\n",
       "      <td>wa00e</td>\n",
       "      <td>home goods</td>\n",
       "      <td>phone2</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>py</td>\n",
       "      <td>112.54.208.157</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3939ac3ef7d472a59a9c5f893dd3e39fh9ofi</td>\n",
       "      <td>jefix</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone4</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>in</td>\n",
       "      <td>18.99.175.133</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>8393c48eaf4b8fa96886edc7cf27b372dsibi</td>\n",
       "      <td>jefix</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone5</td>\n",
       "      <td>9759243157894736</td>\n",
       "      <td>in</td>\n",
       "      <td>145.138.5.37</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656329</th>\n",
       "      <td>7656329</td>\n",
       "      <td>626159dd6f2228ede002d9f9340f75b7puk8d</td>\n",
       "      <td>3e64w</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone91</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>ru</td>\n",
       "      <td>140.204.227.63</td>\n",
       "      <td>cghhmomsaxi6pug</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656330</th>\n",
       "      <td>7656330</td>\n",
       "      <td>a318ea333ceee1ba39a494476386136a826dv</td>\n",
       "      <td>xn0y0</td>\n",
       "      <td>mobile</td>\n",
       "      <td>phone236</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>pl</td>\n",
       "      <td>24.232.159.118</td>\n",
       "      <td>wgggpdg2gx5pesn</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656331</th>\n",
       "      <td>7656331</td>\n",
       "      <td>f5b2bbad20d1d7ded3ed960393bec0f40u6hn</td>\n",
       "      <td>gja6c</td>\n",
       "      <td>sporting goods</td>\n",
       "      <td>phone80</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>za</td>\n",
       "      <td>80.237.28.246</td>\n",
       "      <td>5xgysg14grlersa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656332</th>\n",
       "      <td>7656332</td>\n",
       "      <td>d4bd412590f5106b9d887a43c51b254eldo4f</td>\n",
       "      <td>hmwk8</td>\n",
       "      <td>jewelry</td>\n",
       "      <td>phone349</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>my</td>\n",
       "      <td>91.162.27.152</td>\n",
       "      <td>bhtrek44bzi2wfl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7656333</th>\n",
       "      <td>7656333</td>\n",
       "      <td>0ea62aaa9c3ffcc6db584cb69c1f6c4bcripp</td>\n",
       "      <td>c9ox9</td>\n",
       "      <td>mobile</td>\n",
       "      <td>phone82</td>\n",
       "      <td>9709222052631578</td>\n",
       "      <td>jo</td>\n",
       "      <td>160.243.101.60</td>\n",
       "      <td>vasstdc27m7nks3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7656334 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          bid_id                              bidder_id auction  \\\n",
       "0              0  8dac2b259fd1c6d1120e519fb1ac14fbqvax8   ewmzr   \n",
       "1              1  668d393e858e8126275433046bbd35c6tywop   aeqok   \n",
       "2              2  aa5f360084278b35d746fa6af3a7a1a5ra3xe   wa00e   \n",
       "3              3  3939ac3ef7d472a59a9c5f893dd3e39fh9ofi   jefix   \n",
       "4              4  8393c48eaf4b8fa96886edc7cf27b372dsibi   jefix   \n",
       "...          ...                                    ...     ...   \n",
       "7656329  7656329  626159dd6f2228ede002d9f9340f75b7puk8d   3e64w   \n",
       "7656330  7656330  a318ea333ceee1ba39a494476386136a826dv   xn0y0   \n",
       "7656331  7656331  f5b2bbad20d1d7ded3ed960393bec0f40u6hn   gja6c   \n",
       "7656332  7656332  d4bd412590f5106b9d887a43c51b254eldo4f   hmwk8   \n",
       "7656333  7656333  0ea62aaa9c3ffcc6db584cb69c1f6c4bcripp   c9ox9   \n",
       "\n",
       "            merchandise    device              time country              ip  \\\n",
       "0               jewelry    phone0  9759243157894736      us   69.166.231.58   \n",
       "1             furniture    phone1  9759243157894736      in   50.201.125.84   \n",
       "2            home goods    phone2  9759243157894736      py  112.54.208.157   \n",
       "3               jewelry    phone4  9759243157894736      in   18.99.175.133   \n",
       "4               jewelry    phone5  9759243157894736      in    145.138.5.37   \n",
       "...                 ...       ...               ...     ...             ...   \n",
       "7656329         jewelry   phone91  9709222052631578      ru  140.204.227.63   \n",
       "7656330          mobile  phone236  9709222052631578      pl  24.232.159.118   \n",
       "7656331  sporting goods   phone80  9709222052631578      za   80.237.28.246   \n",
       "7656332         jewelry  phone349  9709222052631578      my   91.162.27.152   \n",
       "7656333          mobile   phone82  9709222052631578      jo  160.243.101.60   \n",
       "\n",
       "                     url  \n",
       "0        vasstdc27m7nks3  \n",
       "1        jmqlhflrzwuay9c  \n",
       "2        vasstdc27m7nks3  \n",
       "3        vasstdc27m7nks3  \n",
       "4        vasstdc27m7nks3  \n",
       "...                  ...  \n",
       "7656329  cghhmomsaxi6pug  \n",
       "7656330  wgggpdg2gx5pesn  \n",
       "7656331  5xgysg14grlersa  \n",
       "7656332  bhtrek44bzi2wfl  \n",
       "7656333  vasstdc27m7nks3  \n",
       "\n",
       "[7656334 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_unique= bids_df.groupby('bidder_id').nunique()\n",
    "bids_unique = bids_unique.drop([\"bid_id\"],axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From bids_unique dataframe, we may be interested in the number of times a bidder has \n",
    "1. Bidded in a different auction\n",
    "2. Bidded from a different url\n",
    "3. Bidded on a different device\n",
    "4. Bidded from a different country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidder_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001068c415025a009fee375a12cff4fcnht8y</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002d229ffb247009810828f648afc2ef593rb</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0030a2dd87ad2733e0873062e4f83954mkj86</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00486a11dff552c4bd7696265724ff81yeo9v</th>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbc0fdfbf19a8a9116b68714138f2902cc13</th>\n",
       "      <td>637</td>\n",
       "      <td>1</td>\n",
       "      <td>792</td>\n",
       "      <td>23487</td>\n",
       "      <td>102</td>\n",
       "      <td>18726</td>\n",
       "      <td>8039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</th>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>22</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd62646d600b759a985d45918bd6f0431vmz</th>\n",
       "      <td>55</td>\n",
       "      <td>1</td>\n",
       "      <td>96</td>\n",
       "      <td>664</td>\n",
       "      <td>1</td>\n",
       "      <td>37</td>\n",
       "      <td>144</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff2c070d8200e0a09150bd81452ce29ngcnv</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows Ã— 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       auction  merchandise  device   time  \\\n",
       "bidder_id                                                                    \n",
       "001068c415025a009fee375a12cff4fcnht8y        1            1       1      1   \n",
       "002d229ffb247009810828f648afc2ef593rb        1            1       2      2   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86        1            1       1      1   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        3            1       3      3   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v       13            1       8     20   \n",
       "...                                        ...          ...     ...    ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13      637            1     792  23487   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3       15            1      13     22   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl        1            1       1      1   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz       55            1      96    664   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv        1            1       1      1   \n",
       "\n",
       "                                       country     ip   url  \n",
       "bidder_id                                                    \n",
       "001068c415025a009fee375a12cff4fcnht8y        1      1     1  \n",
       "002d229ffb247009810828f648afc2ef593rb        1      1     1  \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86        1      1     1  \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        1      3     2  \n",
       "00486a11dff552c4bd7696265724ff81yeo9v        1     10     7  \n",
       "...                                        ...    ...   ...  \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13      102  18726  8039  \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3        6     18    12  \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl        1      1     1  \n",
       "ffd62646d600b759a985d45918bd6f0431vmz        1     37   144  \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv        1      1     1  \n",
       "\n",
       "[6614 rows x 7 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bids_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "bids_df_count= bids_df.groupby(\"bidder_id\")\n",
    "counts= bids_df_count['url'].count().reset_index().rename(columns = {'url':'num_bids'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### From counts dataframe, we know the number of times that a unique bidder has performed a bid "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>num_bids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>25075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>664</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  num_bids\n",
       "0     001068c415025a009fee375a12cff4fcnht8y         1\n",
       "1     002d229ffb247009810828f648afc2ef593rb         2\n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86         1\n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o         3\n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v        20\n",
       "...                                     ...       ...\n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13     25075\n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3        22\n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl         1\n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz       664\n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv         1\n",
       "\n",
       "[6614 rows x 2 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Joining the new features together with the training dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = train_df.merge(bids_unique, how= 'left', on = 'bidder_id')\n",
    "new_train = new_train.merge(counts, how= 'left')\n",
    "new_train.fillna(0,inplace = True)\n",
    "\n",
    "new_test = test_df.merge(bids_unique, how= 'left', on = 'bidder_id')\n",
    "new_test = new_test.merge(counts, how= 'left')\n",
    "new_test.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Check that the size new training and test dataset is the same as the old training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of old train: (2013, 4)\n",
      "Size of new train: (2013, 12)\n",
      "Size of old test: (4700, 3)\n",
      "Size of new test: (4700, 11)\n"
     ]
    }
   ],
   "source": [
    "print(\"Size of old train: \" + str(train_df.shape))\n",
    "print(\"Size of new train: \" + str(new_train.shape))\n",
    "print(\"Size of old test: \" + str(test_df.shape))\n",
    "print(\"Size of new test: \" + str(new_test.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Count of number of first and last bids for each bidder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "auctions = bids_df.groupby('auction')\n",
    "first_bid_list = set(auctions.first()['bidder_id'])\n",
    "last_bid_list = set(auctions.last()['bidder_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions to add a counter if a particular bidder id is in the first and/or last bid\n",
    "def check_first_bid(dummy):\n",
    "    count = 0\n",
    "    for bidder_id in first_bid_list:\n",
    "        if(dummy == bidder_id):\n",
    "            count+=1\n",
    "    return count\n",
    "        \n",
    "def check_last_bid(dummy):\n",
    "    count = 0\n",
    "    for bidder_id in last_bid_list:\n",
    "        if(dummy == bidder_id):\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_first_bids_train = new_train['bidder_id'].apply(func = check_first_bid)\n",
    "num_last_bids_train = new_train['bidder_id'].apply(func = check_last_bid)\n",
    "\n",
    "num_first_bids_test = new_test['bidder_id'].apply(func = check_first_bid)\n",
    "num_last_bids_test = new_test['bidder_id'].apply(func = check_last_bid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "      <th>num_bids</th>\n",
       "      <th>num_first_bids</th>\n",
       "      <th>num_last_bids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3     4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4     4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...                                     ...   \n",
       "2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country     ip   url  num_bids  num_first_bids  \\\n",
       "0       14.0   24.0      6.0   20.0   1.0      24.0               0   \n",
       "1        2.0    3.0      1.0    3.0   2.0       3.0               0   \n",
       "2        2.0    4.0      1.0    4.0   2.0       4.0               0   \n",
       "3        1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "4       53.0  155.0      2.0  123.0  91.0     155.0               0   \n",
       "...      ...    ...      ...    ...   ...       ...             ...   \n",
       "2008     4.0   33.0      4.0    5.0   2.0      36.0               1   \n",
       "2009     1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "2010     2.0    2.0      1.0    2.0   1.0       2.0               0   \n",
       "2011     1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "2012     1.0    2.0      1.0    1.0   1.0       2.0               0   \n",
       "\n",
       "      num_last_bids  \n",
       "0                 0  \n",
       "1                 0  \n",
       "2                 0  \n",
       "3                 0  \n",
       "4                 0  \n",
       "...             ...  \n",
       "2008              0  \n",
       "2009              0  \n",
       "2010              0  \n",
       "2011              0  \n",
       "2012              0  \n",
       "\n",
       "[2013 rows x 14 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# joining the new train and test with the number of first and last bids\n",
    "new_train['num_first_bids'] = num_first_bids_train\n",
    "new_train['num_last_bids'] = num_last_bids_train\n",
    "new_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "      <th>num_bids</th>\n",
       "      <th>num_first_bids</th>\n",
       "      <th>num_last_bids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>49bb5a3c944b8fc337981cc7a9ccae41u31d7</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228htx90</td>\n",
       "      <td>5d9fa1b71f992e7c7a106ce4b07a0a754le7c</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>a921612b85a1494456e74c09393ccb65ylp4y</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228rs17i</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228klidn</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>6b601e72a4d264dab9ace9d7b229b47479v6i</td>\n",
       "      <td>925381cce086b8cc9594eee1c77edf665zjpl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228aght0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>eaf0ed0afc9689779417274b4791726cn5udi</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228nclv5</td>\n",
       "      <td>b5714de1fd69d4a0d2e39d59e53fe9e15vwat</td>\n",
       "      <td>90.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>80.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>cdecd8d02ed8c6037e38042c7745f688mx5sf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228dtdkd</td>\n",
       "      <td>c3b363a3c3b838d58c85acf0fc9964cb4pnfa</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4695</th>\n",
       "      <td>bef56983ba78b2ee064443ae95972877jfkyd</td>\n",
       "      <td>0f235a6dfea5a5885d63968826b748b4q4dra</td>\n",
       "      <td>a98a4841db165de919d29cb49d0bc306cq21h</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>466.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>983.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4696</th>\n",
       "      <td>4da45cc915c32d4368ac7e773d92d4affwqrr</td>\n",
       "      <td>9e0adf7481c422654d4d0a849e0e50abiumen</td>\n",
       "      <td>e23d9777cddc347de82d839b2e54b22ecopkp</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4697</th>\n",
       "      <td>0d0e6220bf59ab9a0c5b5987fb2c34a9p33f9</td>\n",
       "      <td>7df4ebd184668b4257f740b11d4519afq7kr1</td>\n",
       "      <td>b650404e1ab5d177020221277c3e9306qegyl</td>\n",
       "      <td>419.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>376.0</td>\n",
       "      <td>2156.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>1460.0</td>\n",
       "      <td>1049.0</td>\n",
       "      <td>2162.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4698</th>\n",
       "      <td>4981c32c54dde65b79dbc48fd9ab6457caqze</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2284qlm0</td>\n",
       "      <td>9c35320088eaf32046a51a96ebb2e658i479u</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4699</th>\n",
       "      <td>7ade70030d559a6c255be2f6feca17acnrqs0</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vo1hu</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228la8g8</td>\n",
       "      <td>116.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>117.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>347.0</td>\n",
       "      <td>246.0</td>\n",
       "      <td>382.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4700 rows Ã— 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     49bb5a3c944b8fc337981cc7a9ccae41u31d7   \n",
       "1     a921612b85a1494456e74c09393ccb65ylp4y   \n",
       "2     6b601e72a4d264dab9ace9d7b229b47479v6i   \n",
       "3     eaf0ed0afc9689779417274b4791726cn5udi   \n",
       "4     cdecd8d02ed8c6037e38042c7745f688mx5sf   \n",
       "...                                     ...   \n",
       "4695  bef56983ba78b2ee064443ae95972877jfkyd   \n",
       "4696  4da45cc915c32d4368ac7e773d92d4affwqrr   \n",
       "4697  0d0e6220bf59ab9a0c5b5987fb2c34a9p33f9   \n",
       "4698  4981c32c54dde65b79dbc48fd9ab6457caqze   \n",
       "4699  7ade70030d559a6c255be2f6feca17acnrqs0   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228htx90   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228rs17i   \n",
       "2     925381cce086b8cc9594eee1c77edf665zjpl   \n",
       "3     a3d2de7675556553a5f08e4c88d2c228nclv5   \n",
       "4     a3d2de7675556553a5f08e4c88d2c228dtdkd   \n",
       "...                                     ...   \n",
       "4695  0f235a6dfea5a5885d63968826b748b4q4dra   \n",
       "4696  9e0adf7481c422654d4d0a849e0e50abiumen   \n",
       "4697  7df4ebd184668b4257f740b11d4519afq7kr1   \n",
       "4698  a3d2de7675556553a5f08e4c88d2c2284qlm0   \n",
       "4699  a3d2de7675556553a5f08e4c88d2c228vo1hu   \n",
       "\n",
       "                                    address  auction  merchandise  device  \\\n",
       "0     5d9fa1b71f992e7c7a106ce4b07a0a754le7c      3.0          1.0     2.0   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228klidn      2.0          1.0     3.0   \n",
       "2     a3d2de7675556553a5f08e4c88d2c228aght0     14.0          1.0     4.0   \n",
       "3     b5714de1fd69d4a0d2e39d59e53fe9e15vwat     90.0          1.0    81.0   \n",
       "4     c3b363a3c3b838d58c85acf0fc9964cb4pnfa     20.0          1.0    17.0   \n",
       "...                                     ...      ...          ...     ...   \n",
       "4695  a98a4841db165de919d29cb49d0bc306cq21h     41.0          1.0     9.0   \n",
       "4696  e23d9777cddc347de82d839b2e54b22ecopkp     32.0          1.0    29.0   \n",
       "4697  b650404e1ab5d177020221277c3e9306qegyl    419.0          1.0   376.0   \n",
       "4698  9c35320088eaf32046a51a96ebb2e658i479u      5.0          1.0     4.0   \n",
       "4699  a3d2de7675556553a5f08e4c88d2c228la8g8    116.0          1.0   117.0   \n",
       "\n",
       "        time  country      ip     url  num_bids  num_first_bids  num_last_bids  \n",
       "0        4.0      3.0     4.0     3.0       4.0               0              0  \n",
       "1        3.0      2.0     2.0     1.0       3.0               0              0  \n",
       "2       17.0      3.0     4.0     2.0      17.0               0              0  \n",
       "3      148.0     14.0   129.0    80.0     148.0               0              0  \n",
       "4       23.0      2.0    17.0     1.0      23.0               0              0  \n",
       "...      ...      ...     ...     ...       ...             ...            ...  \n",
       "4695   466.0      5.0    22.0     4.0     983.0               0              0  \n",
       "4696    66.0     10.0    49.0    18.0      66.0               0              0  \n",
       "4697  2156.0     86.0  1460.0  1049.0    2162.0               1              1  \n",
       "4698     5.0      1.0     5.0     2.0       5.0               0              0  \n",
       "4699   382.0     10.0   347.0   246.0     382.0               0              0  \n",
       "\n",
       "[4700 rows x 13 columns]"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_test['num_first_bids'] = num_first_bids_test\n",
    "new_test['num_last_bids'] = num_last_bids_test\n",
    "new_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entropy\n",
    "def log_entropy(x):\n",
    "    e = np.sum(np.log(np.array(range(1,np.sum(x)))))\n",
    "    for i in x:\n",
    "        e -= np.sum(np.log(np.array(range(1,i))))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>url</th>\n",
       "      <th>num_bids</th>\n",
       "      <th>num_first_bids</th>\n",
       "      <th>num_last_bids</th>\n",
       "      <th>ip_entropy</th>\n",
       "      <th>url_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>49.8149</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.7918</td>\n",
       "      <td>1.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>601.0291</td>\n",
       "      <td>460.9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0870</td>\n",
       "      <td>9.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3     4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4     4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...                                     ...   \n",
       "2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country     ip   url  num_bids  num_first_bids  \\\n",
       "0       14.0   24.0      6.0   20.0   1.0      24.0               0   \n",
       "1        2.0    3.0      1.0    3.0   2.0       3.0               0   \n",
       "2        2.0    4.0      1.0    4.0   2.0       4.0               0   \n",
       "3        1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "4       53.0  155.0      2.0  123.0  91.0     155.0               0   \n",
       "...      ...    ...      ...    ...   ...       ...             ...   \n",
       "2008     4.0   33.0      4.0    5.0   2.0      36.0               1   \n",
       "2009     1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "2010     2.0    2.0      1.0    2.0   1.0       2.0               0   \n",
       "2011     1.0    1.0      1.0    1.0   1.0       1.0               0   \n",
       "2012     1.0    2.0      1.0    1.0   1.0       2.0               0   \n",
       "\n",
       "      num_last_bids  ip_entropy  url_entropy  \n",
       "0                 0     49.8149       0.0000  \n",
       "1                 0      0.6931       0.6931  \n",
       "2                 0      1.7918       1.0986  \n",
       "3                 0      0.0000       0.0000  \n",
       "4                 0    601.0291     460.9263  \n",
       "...             ...         ...          ...  \n",
       "2008              0     26.0870       9.8851  \n",
       "2009              0      0.0000       0.0000  \n",
       "2010              0      0.0000       0.0000  \n",
       "2011              0      0.0000       0.0000  \n",
       "2012              0      0.0000       0.0000  \n",
       "\n",
       "[2013 rows x 16 columns]"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entropy_df = new_train.copy()\n",
    "entropy_df['ip_entropy'] = 0\n",
    "entropy_df['url_entropy'] = 0\n",
    "# entropy_df\n",
    "for bidder in entropy_df['bidder_id']:\n",
    "    temp_df = bids_df[bids_df['bidder_id'] == bidder][['ip','url']]\n",
    "    entropy_df.loc[entropy_df[entropy_df['bidder_id'] == bidder].index, ['ip_entropy', 'url_entropy']] = \\\n",
    "                    round(log_entropy(temp_df.ip.groupby(temp_df.ip).count()),4), \\\n",
    "                    round(log_entropy(temp_df.url.groupby(temp_df.url).count()),4)\n",
    "    \n",
    "entropy_df = entropy_df[['bidder_id', 'ip_entropy', 'url_entropy']]\n",
    "entropy_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# median time between a userâ€™s bid and his previous bid (yk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# minimum and median times between a userâ€™s bid and previous bid by another user in the same auction (yk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of each bidderâ€™s bids that were in each day (bren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# proportion of each bidderâ€™s bids that were in each of 8 3-hour time slots (bren)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean time of day for the bids of each bidder (yk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of auctions a bidder has participated in, in an hour (wq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the maximum number of bids in a 20 min span (guang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# most frequent used url for each bidder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# number of bids placed by the user on each of the three weekdays in the data (guang)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-48-1af5c6ff741d>:21: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
      "  bids = bids.drop('outcome', 1)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>has_ip_used_by_a_bot</th>\n",
       "      <th>on_ip_that_has_a_bot_mean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.260163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows Ã— 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3     4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4     4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...                                     ...   \n",
       "2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  has_ip_used_by_a_bot  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0                     1   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0                     0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0                     1   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0                     1   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0                     1   \n",
       "...                                     ...      ...                   ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0                     1   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0                     0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0                     1   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0                     1   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0                     0   \n",
       "\n",
       "      on_ip_that_has_a_bot_mean  \n",
       "0                      0.400000  \n",
       "1                      0.000000  \n",
       "2                      1.000000  \n",
       "3                      1.000000  \n",
       "4                      0.260163  \n",
       "...                         ...  \n",
       "2008                   0.800000  \n",
       "2009                   0.000000  \n",
       "2010                   0.500000  \n",
       "2011                   1.000000  \n",
       "2012                   0.000000  \n",
       "\n",
       "[2013 rows x 6 columns]"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fraction of IPs used by a bidder which were also used by another user which was a bot (jf)\n",
    "#bids per ip used by bots\n",
    "bot_or_human = train_df\n",
    "ip_used_by_bot = pd.merge(bids_df, bot_or_human[['bidder_id', 'outcome']], on='bidder_id', how='left')\n",
    "\n",
    "# #make outcome num a float num\n",
    "ip_used_by_bot['outcome'] = 1.0 * (ip_used_by_bot['outcome'] == 1)\n",
    "\n",
    "#get unique ip by each bidder \n",
    "unique_ip_per_bidder = ip_used_by_bot.groupby(['ip', 'bidder_id']).outcome.mean().reset_index() \n",
    "\n",
    "#identify ips that are a bot\n",
    "bot_ips = unique_ip_per_bidder.groupby('ip').outcome.sum().reset_index() \n",
    "bot_ips['num_bots_on_ip'] = bot_ips.outcome\n",
    "bids = pd.merge(ip_used_by_bot, bot_ips[['ip', 'num_bots_on_ip']], on='ip', how='left')\n",
    "\n",
    "#find out bidders that are using ips used by bots\n",
    "bids['has_ip_used_by_a_bot'] = 1 * ((bids['num_bots_on_ip'] - bids['outcome']) >= 1) \n",
    "\n",
    "#drop bidders who are already identified as bots in train dataset\n",
    "bids = bids.drop('outcome', 1)\n",
    "\n",
    "#group by unique ip and bidder\n",
    "unique_ip_per_bidder = bids.groupby(['bidder_id', 'ip']).has_ip_used_by_a_bot.mean().reset_index() \n",
    "\n",
    "#get bidder that has ips used by a bot\n",
    "bot_ips = unique_ip_per_bidder.groupby('bidder_id').has_ip_used_by_a_bot.mean().reset_index()\n",
    "\n",
    "#final dataframe\n",
    "bot_or_human = pd.merge(bot_or_human, bot_ips[['bidder_id', 'has_ip_used_by_a_bot']], on='bidder_id', how='left')\n",
    "bot_or_human['on_ip_that_has_a_bot_mean'] = bot_or_human['has_ip_used_by_a_bot'].fillna(0)\n",
    "bot_or_human['has_ip_used_by_a_bot'] = 1*(bot_or_human['has_ip_used_by_a_bot'].fillna(0) > 0)\n",
    "bot_or_human = bot_or_human[['bidder_id', 'on_ip_that_has_a_bot_mean']]\n",
    "bot_or_human"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# stdev of time per bid (skipz first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>time_to_bid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>7.439058e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>1.455263e+11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>7.263689e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>6.854544e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>1.904773e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>5.719356e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>2.954407e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>1.044305e+13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>5.369726e+12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>7.325305e+13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id   time_to_bid\n",
       "0     001068c415025a009fee375a12cff4fcnht8y  7.439058e+13\n",
       "1     002d229ffb247009810828f648afc2ef593rb  1.455263e+11\n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86  7.263689e+13\n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o  6.854544e+12\n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v  1.904773e+13\n",
       "...                                     ...           ...\n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13  5.719356e+12\n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3  2.954407e+13\n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl  1.044305e+13\n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz  5.369726e+12\n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv  7.325305e+13\n",
       "\n",
       "[6614 rows x 2 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mean response time\n",
    "def find_time_to_bid(auction_id, time):\n",
    "    starttime = timing_dict[auction_id]['starttime']\n",
    "    return int(time) - int(starttime)\n",
    "\n",
    "end_auction_time= bids_df.groupby('auction').time.max().reset_index()\n",
    "end_auction_time= end_auction_time.rename(columns= {'time': 'endtime'})\n",
    "\n",
    "start_auction_time= bids_df.groupby('auction').time.min().reset_index()\n",
    "start_auction_time= start_auction_time.rename(columns= {'time': 'starttime'})\n",
    "\n",
    "start_end_times= pd.merge(start_auction_time, end_auction_time, on= 'auction', how= 'left')\n",
    "start_end_times = start_end_times.set_index('auction')\n",
    "\n",
    "timing_dict = start_end_times.to_dict('index')\n",
    "\n",
    "start_auction_time= bids_df.groupby('auction').time.min().reset_index()\n",
    "start_auction_time= start_auction_time.rename(columns= {'time': 'starttime'})\n",
    "timing_dict = start_end_times.to_dict('index')\n",
    "\n",
    "bids_df['time_to_bid'] = bids_df.apply(lambda row: find_time_to_bid(row['auction'], row['time']), axis=1)\n",
    "\n",
    "bids_df_time = bids_df\n",
    "bids_df_time_mean = bids_df_time.groupby('bidder_id')['time_to_bid'].mean().reset_index()\n",
    "bids_df_time_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>inst_resp</th>\n",
       "      <th>perc_inst_resp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>3068.0</td>\n",
       "      <td>0.122353</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows Ã— 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  inst_resp  perc_inst_resp\n",
       "0     001068c415025a009fee375a12cff4fcnht8y        0.0        0.000000\n",
       "1     002d229ffb247009810828f648afc2ef593rb        0.0        0.000000\n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86        0.0        0.000000\n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        0.0        0.000000\n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v        0.0        0.000000\n",
       "...                                     ...        ...             ...\n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13     3068.0        0.122353\n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3        0.0        0.000000\n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl        0.0        0.000000\n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz        0.0        0.000000\n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv        0.0        0.000000\n",
       "\n",
       "[6614 rows x 3 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# number of simul bids per bidder\n",
    "results = bids_df.groupby(['bidder_id','time']).count()[bids_df.groupby(['bidder_id','time']).count()['bid_id'] > 1 ]\n",
    "inst_resp = results.groupby(\"bidder_id\").sum()\n",
    "needed_df = bids_df.groupby(['bidder_id','time']).count()[bids_df.groupby(['bidder_id','time']).count()['bid_id'] > 0 ]\n",
    "num_resp = needed_df.groupby(\"bidder_id\").sum()\n",
    "num_resp = num_resp.reset_index()\n",
    "inst_resp = inst_resp.reset_index()\n",
    "num_resp = num_resp[['bidder_id','bid_id']]\n",
    "inst_resp = inst_resp[['bidder_id','bid_id']]\n",
    "num_resp.rename(columns={\"bid_id\": \"num_bids\"}, inplace= True)\n",
    "inst_resp.rename(columns={\"bid_id\": \"inst_resp\"}, inplace= True)\n",
    "total_inst_resp = num_resp.merge(inst_resp, how= 'left',on='bidder_id')\n",
    "total_inst_resp.fillna(0, inplace = True)\n",
    "total_inst_resp['perc_inst_resp'] = total_inst_resp['inst_resp']/total_inst_resp['num_bids']\n",
    "total_inst_resp.drop(axis = 1 , columns = 'num_bids', inplace=True)\n",
    "total_inst_resp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>auto parts</th>\n",
       "      <th>books and music</th>\n",
       "      <th>clothing</th>\n",
       "      <th>computers</th>\n",
       "      <th>furniture</th>\n",
       "      <th>home goods</th>\n",
       "      <th>jewelry</th>\n",
       "      <th>mobile</th>\n",
       "      <th>office equipment</th>\n",
       "      <th>sporting goods</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bidder_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>001068c415025a009fee375a12cff4fcnht8y</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>002d229ffb247009810828f648afc2ef593rb</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0030a2dd87ad2733e0873062e4f83954mkj86</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>00486a11dff552c4bd7696265724ff81yeo9v</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffbc0fdfbf19a8a9116b68714138f2902cc13</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25075.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ffd62646d600b759a985d45918bd6f0431vmz</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>664.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fff2c070d8200e0a09150bd81452ce29ngcnv</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows Ã— 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       auto parts  books and music  clothing  \\\n",
       "bidder_id                                                                      \n",
       "001068c415025a009fee375a12cff4fcnht8y         0.0              0.0       0.0   \n",
       "002d229ffb247009810828f648afc2ef593rb         0.0              0.0       0.0   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86         0.0              0.0       0.0   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o         0.0              0.0       0.0   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v         0.0              0.0       0.0   \n",
       "...                                           ...              ...       ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13         0.0              0.0       0.0   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3         0.0              0.0       0.0   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl         0.0              0.0       0.0   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz         0.0              0.0       0.0   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv         0.0              0.0       0.0   \n",
       "\n",
       "                                       computers  furniture  home goods  \\\n",
       "bidder_id                                                                 \n",
       "001068c415025a009fee375a12cff4fcnht8y        0.0        0.0         0.0   \n",
       "002d229ffb247009810828f648afc2ef593rb        0.0        0.0         0.0   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86        0.0        0.0         0.0   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o        0.0        0.0         0.0   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v        0.0        0.0        20.0   \n",
       "...                                          ...        ...         ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13        0.0        0.0         0.0   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3        0.0        0.0         0.0   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl        0.0        0.0         0.0   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz        0.0        0.0         0.0   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv        0.0        0.0         1.0   \n",
       "\n",
       "                                       jewelry   mobile  office equipment  \\\n",
       "bidder_id                                                                   \n",
       "001068c415025a009fee375a12cff4fcnht8y      1.0      0.0               0.0   \n",
       "002d229ffb247009810828f648afc2ef593rb      0.0      2.0               0.0   \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86      0.0      1.0               0.0   \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o      0.0      3.0               0.0   \n",
       "00486a11dff552c4bd7696265724ff81yeo9v      0.0      0.0               0.0   \n",
       "...                                        ...      ...               ...   \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13      0.0  25075.0               0.0   \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3      0.0     22.0               0.0   \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl      0.0      0.0               0.0   \n",
       "ffd62646d600b759a985d45918bd6f0431vmz      0.0    664.0               0.0   \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv      0.0      0.0               0.0   \n",
       "\n",
       "                                       sporting goods  \n",
       "bidder_id                                              \n",
       "001068c415025a009fee375a12cff4fcnht8y             0.0  \n",
       "002d229ffb247009810828f648afc2ef593rb             0.0  \n",
       "0030a2dd87ad2733e0873062e4f83954mkj86             0.0  \n",
       "003180b29c6a5f8f1d84a6b7b6f7be57tjj1o             0.0  \n",
       "00486a11dff552c4bd7696265724ff81yeo9v             0.0  \n",
       "...                                               ...  \n",
       "ffbc0fdfbf19a8a9116b68714138f2902cc13             0.0  \n",
       "ffc4e2dd2cc08249f299cab46ecbfacfobmr3             0.0  \n",
       "ffd29eb307a4c54610dd2d3d212bf3bagmmpl             1.0  \n",
       "ffd62646d600b759a985d45918bd6f0431vmz             0.0  \n",
       "fff2c070d8200e0a09150bd81452ce29ngcnv             0.0  \n",
       "\n",
       "[6614 rows x 10 columns]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# one-hot encoding merchandise - working\n",
    "one_hot = pd.get_dummies(bids_df['merchandise'])\n",
    "one_hot_df = bids_df.join(one_hot)\n",
    "one_hot_df = one_hot_df.drop('merchandise', axis=1)\n",
    "# one_hot_df = one_hot_df.join(one_hot)\n",
    "# one_hot_df = one_hot_df.rename(columns={1.0:'merchandise=1.0',2.0:'merchandise=2.0'})\n",
    "one_hot_df.set_index(\"bidder_id\", inplace=True)\n",
    "one_hot_df = one_hot_df[['auto parts', 'books and music', 'clothing', 'computers',\n",
    "       'furniture', 'home goods', 'jewelry', 'mobile', 'office equipment',\n",
    "       'sporting goods']]\n",
    "one_hot_df = one_hot_df.groupby(\"bidder_id\").sum()\n",
    "one_hot_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# percent instant resp (skipz first)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per auction\n",
    "bids_auction_count= bids_df.groupby([\"bidder_id\", \"auction\"])\n",
    "bids_auction_count_df = bids_auction_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_auction_count_df = pd.DataFrame(bids_auction_count_df, columns = ['bidder_id', 'bid_id', 'auction', 'merchandise', \n",
    "                                                                       'time', 'country', 'ip', 'url'])\n",
    "bids_auction_count_df = bids_auction_count_df[['bidder_id','bid_id']]\n",
    "bids_auction_count_df.rename(columns={\"bid_id\": \"num_bids_per_auction\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per device\n",
    "bids_device_count= bids_df.groupby([\"bidder_id\", \"device\"])\n",
    "bids_device_count_df = bids_device_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_device_count_df = pd.DataFrame(bids_device_count_df, columns = ['bidder_id', 'bid_id', 'auction', 'merchandise', \n",
    "                                                                     'time', 'country', 'ip', 'url'])\n",
    "bids_device_count_df = bids_device_count_df[['bidder_id','bid_id']]\n",
    "bids_device_count_df.rename(columns={\"bid_id\": \"num_bids_per_device\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per country\n",
    "bids_country_count= bids_df.groupby([\"bidder_id\", \"country\"])\n",
    "bids_country_count_df = bids_country_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_country_count_df = pd.DataFrame(bids_country_count_df, columns = ['bidder_id', 'bid_id', 'auction', 'merchandise', \n",
    "                                                                       'time', 'country', 'ip', 'url'])\n",
    "bids_country_count_df = bids_country_count_df[['bidder_id','bid_id']]\n",
    "bids_country_count_df.rename(columns={\"bid_id\": \"num_bids_per_country\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per ip\n",
    "bids_ip_count= bids_df.groupby([\"bidder_id\", \"ip\"])\n",
    "bids_ip_count_df = bids_ip_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_ip_count_df = pd.DataFrame(bids_ip_count_df, columns = ['bidder_id', 'bid_id', 'auction', \n",
    "                                                             'merchandise', 'time', 'country', 'ip', 'url'])\n",
    "bids_ip_count_df = bids_ip_count_df[['bidder_id','bid_id']]\n",
    "bids_ip_count_df.rename(columns={\"bid_id\": \"num_bids_per_ip\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bids per url\n",
    "bids_url_count= bids_df.groupby([\"bidder_id\", \"url\"])\n",
    "bids_url_count_df = bids_url_count.nunique().groupby(\"bidder_id\").mean().reset_index()\n",
    "bids_url_count_df = pd.DataFrame(bids_url_count_df, columns = ['bidder_id', 'bid_id', 'auction', 'merchandise', \n",
    "                                                                     'time', 'country', 'ip', 'url'])\n",
    "bids_url_count_df = bids_url_count_df[['bidder_id','bid_id']]\n",
    "bids_url_count_df.rename(columns={\"bid_id\": \"num_bids_per_url\"}, inplace= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>num_bids_per_auction</th>\n",
       "      <th>num_bids_per_device</th>\n",
       "      <th>num_bids_per_country</th>\n",
       "      <th>num_bids_per_ip</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>001068c415025a009fee375a12cff4fcnht8y</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>002d229ffb247009810828f648afc2ef593rb</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0030a2dd87ad2733e0873062e4f83954mkj86</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>003180b29c6a5f8f1d84a6b7b6f7be57tjj1o</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>00486a11dff552c4bd7696265724ff81yeo9v</td>\n",
       "      <td>1.538462</td>\n",
       "      <td>2.500000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6609</th>\n",
       "      <td>ffbc0fdfbf19a8a9116b68714138f2902cc13</td>\n",
       "      <td>39.364207</td>\n",
       "      <td>31.660354</td>\n",
       "      <td>245.833333</td>\n",
       "      <td>1.339047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6610</th>\n",
       "      <td>ffc4e2dd2cc08249f299cab46ecbfacfobmr3</td>\n",
       "      <td>1.466667</td>\n",
       "      <td>1.692308</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>1.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6611</th>\n",
       "      <td>ffd29eb307a4c54610dd2d3d212bf3bagmmpl</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6612</th>\n",
       "      <td>ffd62646d600b759a985d45918bd6f0431vmz</td>\n",
       "      <td>12.072727</td>\n",
       "      <td>6.916667</td>\n",
       "      <td>664.000000</td>\n",
       "      <td>17.945946</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6613</th>\n",
       "      <td>fff2c070d8200e0a09150bd81452ce29ngcnv</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6614 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  num_bids_per_auction  \\\n",
       "0     001068c415025a009fee375a12cff4fcnht8y              1.000000   \n",
       "1     002d229ffb247009810828f648afc2ef593rb              2.000000   \n",
       "2     0030a2dd87ad2733e0873062e4f83954mkj86              1.000000   \n",
       "3     003180b29c6a5f8f1d84a6b7b6f7be57tjj1o              1.000000   \n",
       "4     00486a11dff552c4bd7696265724ff81yeo9v              1.538462   \n",
       "...                                     ...                   ...   \n",
       "6609  ffbc0fdfbf19a8a9116b68714138f2902cc13             39.364207   \n",
       "6610  ffc4e2dd2cc08249f299cab46ecbfacfobmr3              1.466667   \n",
       "6611  ffd29eb307a4c54610dd2d3d212bf3bagmmpl              1.000000   \n",
       "6612  ffd62646d600b759a985d45918bd6f0431vmz             12.072727   \n",
       "6613  fff2c070d8200e0a09150bd81452ce29ngcnv              1.000000   \n",
       "\n",
       "      num_bids_per_device  num_bids_per_country  num_bids_per_ip  \n",
       "0                1.000000              1.000000         1.000000  \n",
       "1                1.000000              2.000000         2.000000  \n",
       "2                1.000000              1.000000         1.000000  \n",
       "3                1.000000              3.000000         1.000000  \n",
       "4                2.500000             20.000000         2.000000  \n",
       "...                   ...                   ...              ...  \n",
       "6609            31.660354            245.833333         1.339047  \n",
       "6610             1.692308              3.666667         1.222222  \n",
       "6611             1.000000              1.000000         1.000000  \n",
       "6612             6.916667            664.000000        17.945946  \n",
       "6613             1.000000              1.000000         1.000000  \n",
       "\n",
       "[6614 rows x 5 columns]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = bids_auction_count_df.merge(bids_device_count_df, how= 'left', on = 'bidder_id')\n",
    "merged_df = merged_df.merge(bids_country_count_df, how= 'left', on = 'bidder_id')\n",
    "merged_df = merged_df.merge(bids_ip_count_df, how= 'left', on = 'bidder_id')\n",
    "merged_df = pd.DataFrame(merged_df)\n",
    "merged_df.fillna(0,inplace = True)\n",
    "merged_df "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging all features together again"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bidder_id</th>\n",
       "      <th>payment_account</th>\n",
       "      <th>address</th>\n",
       "      <th>outcome</th>\n",
       "      <th>auction</th>\n",
       "      <th>merchandise</th>\n",
       "      <th>device</th>\n",
       "      <th>time</th>\n",
       "      <th>country</th>\n",
       "      <th>ip</th>\n",
       "      <th>...</th>\n",
       "      <th>mobile</th>\n",
       "      <th>office equipment</th>\n",
       "      <th>sporting goods</th>\n",
       "      <th>num_bids_per_auction</th>\n",
       "      <th>num_bids_per_device</th>\n",
       "      <th>num_bids_per_country</th>\n",
       "      <th>num_bids_per_ip</th>\n",
       "      <th>on_ip_that_has_a_bot_mean</th>\n",
       "      <th>ip_entropy</th>\n",
       "      <th>url_entropy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>91a3c57b13234af24875c56fb7e2b2f4rb56a</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228754av</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228vt0u4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>24.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.333333</td>\n",
       "      <td>1.714286</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.200000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>49.8149</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>624f258b49e77713fc34034560f93fb3hu3jo</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228v1sga</td>\n",
       "      <td>ae87054e5a97a8f840a3991d12611fdcrfbq3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.500000</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.6931</td>\n",
       "      <td>0.6931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1c5f4fc669099bfbfac515cd26997bd12ruaj</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2280cybl</td>\n",
       "      <td>92520288b50f03907041887884ba49c0cl0pd</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.7918</td>\n",
       "      <td>1.0986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4bee9aba2abda51bf43d639013d6efe12iycd</td>\n",
       "      <td>51d80e233f7b6a7dfdee484a3c120f3b2ita8</td>\n",
       "      <td>4cb9717c8ad7e88a9a284989dd79b98dbevyi</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4ab12bc61c82ddd9c2d65e60555808acqgos1</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22857ddh</td>\n",
       "      <td>2a96c3ce94b3be921e0296097b88b56a7x1ji</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>123.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>155.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.739130</td>\n",
       "      <td>2.924528</td>\n",
       "      <td>77.5</td>\n",
       "      <td>1.260163</td>\n",
       "      <td>0.260163</td>\n",
       "      <td>601.0291</td>\n",
       "      <td>460.9263</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2008</th>\n",
       "      <td>369515b3af4f8ca582f90271d30b14b6r52aw</td>\n",
       "      <td>a1f85275793c4a782f0a668711f41b927ivc9</td>\n",
       "      <td>e6882cf204a9482edd042b6e31791dfctxzx8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.440000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>9.0</td>\n",
       "      <td>7.200000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>26.0870</td>\n",
       "      <td>9.8851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2009</th>\n",
       "      <td>f939c17ffc7c39ac9b35b69e5e75179fv9pe2</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c2286s1m2</td>\n",
       "      <td>b9b03d5a127eb07aeb9163cdcf524e1344ac9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2010</th>\n",
       "      <td>c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c22856leq</td>\n",
       "      <td>d02c2b288b8aabd79ff47118aff41a2dqwzwc</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2011</th>\n",
       "      <td>0381a69b7a061e9ace2798fd48f1f537mgq57</td>\n",
       "      <td>fd87037ce0304077079c749f420f0b4c54uo0</td>\n",
       "      <td>f030a221726fbcdfc4dc7dfd1b381a112hieq</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2012</th>\n",
       "      <td>84a769adc98498f52debfe57b93a0789556f4</td>\n",
       "      <td>fbe0ce34d6546ebd9e4c63afc68b085byd2tf</td>\n",
       "      <td>a3d2de7675556553a5f08e4c88d2c228fib6p</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2013 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                  bidder_id  \\\n",
       "0     91a3c57b13234af24875c56fb7e2b2f4rb56a   \n",
       "1     624f258b49e77713fc34034560f93fb3hu3jo   \n",
       "2     1c5f4fc669099bfbfac515cd26997bd12ruaj   \n",
       "3     4bee9aba2abda51bf43d639013d6efe12iycd   \n",
       "4     4ab12bc61c82ddd9c2d65e60555808acqgos1   \n",
       "...                                     ...   \n",
       "2008  369515b3af4f8ca582f90271d30b14b6r52aw   \n",
       "2009  f939c17ffc7c39ac9b35b69e5e75179fv9pe2   \n",
       "2010  c806dbb2decba0ed3c4ff5e2e60a74c2wjvbl   \n",
       "2011  0381a69b7a061e9ace2798fd48f1f537mgq57   \n",
       "2012  84a769adc98498f52debfe57b93a0789556f4   \n",
       "\n",
       "                            payment_account  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228754av   \n",
       "1     a3d2de7675556553a5f08e4c88d2c228v1sga   \n",
       "2     a3d2de7675556553a5f08e4c88d2c2280cybl   \n",
       "3     51d80e233f7b6a7dfdee484a3c120f3b2ita8   \n",
       "4     a3d2de7675556553a5f08e4c88d2c22857ddh   \n",
       "...                                     ...   \n",
       "2008  a1f85275793c4a782f0a668711f41b927ivc9   \n",
       "2009  a3d2de7675556553a5f08e4c88d2c2286s1m2   \n",
       "2010  a3d2de7675556553a5f08e4c88d2c22856leq   \n",
       "2011  fd87037ce0304077079c749f420f0b4c54uo0   \n",
       "2012  fbe0ce34d6546ebd9e4c63afc68b085byd2tf   \n",
       "\n",
       "                                    address  outcome  auction  merchandise  \\\n",
       "0     a3d2de7675556553a5f08e4c88d2c228vt0u4      0.0     18.0          1.0   \n",
       "1     ae87054e5a97a8f840a3991d12611fdcrfbq3      0.0      1.0          1.0   \n",
       "2     92520288b50f03907041887884ba49c0cl0pd      0.0      4.0          1.0   \n",
       "3     4cb9717c8ad7e88a9a284989dd79b98dbevyi      0.0      1.0          1.0   \n",
       "4     2a96c3ce94b3be921e0296097b88b56a7x1ji      0.0     23.0          1.0   \n",
       "...                                     ...      ...      ...          ...   \n",
       "2008  e6882cf204a9482edd042b6e31791dfctxzx8      0.0     25.0          1.0   \n",
       "2009  b9b03d5a127eb07aeb9163cdcf524e1344ac9      0.0      1.0          1.0   \n",
       "2010  d02c2b288b8aabd79ff47118aff41a2dqwzwc      0.0      1.0          1.0   \n",
       "2011  f030a221726fbcdfc4dc7dfd1b381a112hieq      0.0      1.0          1.0   \n",
       "2012  a3d2de7675556553a5f08e4c88d2c228fib6p      0.0      1.0          1.0   \n",
       "\n",
       "      device   time  country     ip  ...  mobile  office equipment  \\\n",
       "0       14.0   24.0      6.0   20.0  ...     0.0               0.0   \n",
       "1        2.0    3.0      1.0    3.0  ...     0.0               3.0   \n",
       "2        2.0    4.0      1.0    4.0  ...     0.0               0.0   \n",
       "3        1.0    1.0      1.0    1.0  ...     0.0               0.0   \n",
       "4       53.0  155.0      2.0  123.0  ...     0.0             155.0   \n",
       "...      ...    ...      ...    ...  ...     ...               ...   \n",
       "2008     4.0   33.0      4.0    5.0  ...    36.0               0.0   \n",
       "2009     1.0    1.0      1.0    1.0  ...     1.0               0.0   \n",
       "2010     2.0    2.0      1.0    2.0  ...     2.0               0.0   \n",
       "2011     1.0    1.0      1.0    1.0  ...     0.0               1.0   \n",
       "2012     1.0    2.0      1.0    1.0  ...     0.0               0.0   \n",
       "\n",
       "      sporting goods  num_bids_per_auction  num_bids_per_device  \\\n",
       "0                0.0              1.333333             1.714286   \n",
       "1                0.0              3.000000             1.500000   \n",
       "2                4.0              1.000000             2.000000   \n",
       "3                0.0              1.000000             1.000000   \n",
       "4                0.0              6.739130             2.924528   \n",
       "...              ...                   ...                  ...   \n",
       "2008             0.0              1.440000             9.000000   \n",
       "2009             0.0              1.000000             1.000000   \n",
       "2010             0.0              2.000000             1.000000   \n",
       "2011             0.0              1.000000             1.000000   \n",
       "2012             0.0              2.000000             2.000000   \n",
       "\n",
       "      num_bids_per_country  num_bids_per_ip  on_ip_that_has_a_bot_mean  \\\n",
       "0                      4.0         1.200000                   0.400000   \n",
       "1                      3.0         1.000000                   0.000000   \n",
       "2                      4.0         1.000000                   1.000000   \n",
       "3                      1.0         1.000000                   1.000000   \n",
       "4                     77.5         1.260163                   0.260163   \n",
       "...                    ...              ...                        ...   \n",
       "2008                   9.0         7.200000                   0.800000   \n",
       "2009                   1.0         1.000000                   0.000000   \n",
       "2010                   2.0         1.000000                   0.500000   \n",
       "2011                   1.0         1.000000                   1.000000   \n",
       "2012                   2.0         2.000000                   0.000000   \n",
       "\n",
       "      ip_entropy  url_entropy  \n",
       "0        49.8149       0.0000  \n",
       "1         0.6931       0.6931  \n",
       "2         1.7918       1.0986  \n",
       "3         0.0000       0.0000  \n",
       "4       601.0291     460.9263  \n",
       "...          ...          ...  \n",
       "2008     26.0870       9.8851  \n",
       "2009      0.0000       0.0000  \n",
       "2010      0.0000       0.0000  \n",
       "2011      0.0000       0.0000  \n",
       "2012      0.0000       0.0000  \n",
       "\n",
       "[2013 rows x 34 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df_2 = new_train.merge(bids_df_time_mean, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(total_inst_resp, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(one_hot_df, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(merged_df, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(bot_or_human, how= 'left',on='bidder_id')\n",
    "merged_df_2 = merged_df_2.merge(entropy_df, how= 'left',on='bidder_id')\n",
    "merged_df_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_train = merged_df_2\n",
    "new_train.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df_3 = new_test.merge(bids_df_time_mean, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(total_inst_resp, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(one_hot_df, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(merged_df, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(bot_or_human, how= 'left',on='bidder_id')\n",
    "merged_df_3 = merged_df_3.merge(entropy_df, how= 'left',on='bidder_id')\n",
    "new_test = merged_df_3\n",
    "new_test.fillna(0,inplace = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitting X and y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = new_train.drop(columns=['bidder_id', 'payment_account', 'address', 'outcome','merchandise'])\n",
    "y = new_train['outcome']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scaling the values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.29839867, -0.34020786, -0.13219046, ..., -0.03161872,\n",
       "        -0.09716323, -0.09081306],\n",
       "       [-0.41452291, -0.40452956, -0.13438925, ..., -1.23847127,\n",
       "        -0.09758335, -0.09080254],\n",
       "       [-0.39403039, -0.40452956, -0.13428454, ...,  1.77866011,\n",
       "        -0.09757396, -0.09079638],\n",
       "       ...,\n",
       "       [-0.41452291, -0.40452956, -0.13449395, ...,  0.27009442,\n",
       "        -0.09758928, -0.09081306],\n",
       "       [-0.41452291, -0.4098897 , -0.13459866, ...,  1.77866011,\n",
       "        -0.09758928, -0.09081306],\n",
       "       [-0.41452291, -0.4098897 , -0.13449395, ..., -1.23847127,\n",
       "        -0.09758928, -0.09081306]])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_train.to_csv(\"new_train.csv\")\n",
    "# new_test.to_csv(\"new_test.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Performing Stratified K-Fold with SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_model(model, num_splits, X, y):\n",
    "    skfolds = StratifiedKFold(n_splits=num_splits)\n",
    "\n",
    "    for train_index, test_index in skfolds.split(X, y):\n",
    "        X_train, X_test = X[train_index], X[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "#         print(y_train.value_counts())\n",
    "        \n",
    "        sm = SMOTE()\n",
    "        X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "#         print(y_train_oversampled.value_counts())\n",
    "        \n",
    "        model = model\n",
    "        model.fit(X_train_oversampled, y_train_oversampled )  \n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        print(f'Accuracy: {model.score(X_test, y_test)}')\n",
    "        print(f'f-score: {f1_score(y_test, y_pred)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:12:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "Accuracy: 0.940387481371088\n",
      "f-score: 0.5\n",
      "[20:12:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9284649776453056\n",
      "f-score: 0.35135135135135137\n",
      "[20:12:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9493293591654247\n",
      "f-score: 0.5\n"
     ]
    }
   ],
   "source": [
    "model = XGBClassifier()\n",
    "num_splits = 3\n",
    "training_model(model, num_splits, X_scaled, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:17:11] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9382978723404255"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sm = SMOTE()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.7, random_state=42)\n",
    "X_train_oversampled, y_train_oversampled = sm.fit_resample(X_train, y_train)\n",
    "model.fit(X_train_oversampled, y_train_oversampled)  \n",
    "y_pred = model.predict(X_test)\n",
    "model.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WITHOUT SMOTE\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "182/182 [==============================] - 1s 887us/step - loss: 32252288061.5519 - accuracy: 0.9059\n",
      "Epoch 2/10\n",
      "182/182 [==============================] - 0s 849us/step - loss: 9938621016.8306 - accuracy: 0.9136\n",
      "Epoch 3/10\n",
      "182/182 [==============================] - 0s 812us/step - loss: 10766263794.0109 - accuracy: 0.9357\n",
      "Epoch 4/10\n",
      "182/182 [==============================] - 0s 851us/step - loss: 16538445810.0109 - accuracy: 0.8943\n",
      "Epoch 5/10\n",
      "182/182 [==============================] - 0s 885us/step - loss: 9745966715.1038 - accuracy: 0.8908\n",
      "Epoch 6/10\n",
      "182/182 [==============================] - 0s 865us/step - loss: 4183832922.9290 - accuracy: 0.9370\n",
      "Epoch 7/10\n",
      "182/182 [==============================] - 0s 904us/step - loss: 7256086508.4153 - accuracy: 0.9083\n",
      "Epoch 8/10\n",
      "182/182 [==============================] - 0s 777us/step - loss: 13886757506.0984 - accuracy: 0.9176\n",
      "Epoch 9/10\n",
      "182/182 [==============================] - 0s 799us/step - loss: 3393892746.4918 - accuracy: 0.9075\n",
      "Epoch 10/10\n",
      "182/182 [==============================] - 0s 808us/step - loss: 13617097455.2131 - accuracy: 0.9163\n",
      "WITH SMOTE\n",
      "****************************************************************************************************\n",
      "Epoch 1/10\n",
      "114/114 [==============================] - 0s 891us/step - loss: 37306757120.0000 - accuracy: 0.4920\n",
      "Epoch 2/10\n",
      "114/114 [==============================] - 0s 803us/step - loss: 31391690752.0000 - accuracy: 0.4903\n",
      "Epoch 3/10\n",
      "114/114 [==============================] - 0s 877us/step - loss: 12248996864.0000 - accuracy: 0.4947\n",
      "Epoch 4/10\n",
      "114/114 [==============================] - ETA: 0s - loss: 13136968704.0000 - accuracy: 0.50 - 0s 865us/step - loss: 11698567168.0000 - accuracy: 0.4894\n",
      "Epoch 5/10\n",
      "114/114 [==============================] - 0s 817us/step - loss: 15576012800.0000 - accuracy: 0.5300\n",
      "Epoch 6/10\n",
      "114/114 [==============================] - 0s 900us/step - loss: 12154795008.0000 - accuracy: 0.4965\n",
      "Epoch 7/10\n",
      "114/114 [==============================] - 0s 864us/step - loss: 10425853952.0000 - accuracy: 0.5159\n",
      "Epoch 8/10\n",
      "114/114 [==============================] - 0s 850us/step - loss: 9754130432.0000 - accuracy: 0.5124\n",
      "Epoch 9/10\n",
      "114/114 [==============================] - 0s 830us/step - loss: 5502598656.0000 - accuracy: 0.5292\n",
      "Epoch 10/10\n",
      "114/114 [==============================] - 0s 828us/step - loss: 7397841920.0000 - accuracy: 0.5053\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d81fdb18e0>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "classifier = Sequential()\n",
    "classifier.add(Dense(29,activation = 'relu'))\n",
    "classifier.add(Dense(100, activation = 'relu'))\n",
    "classifier.add(Dense(1, activation = 'sigmoid'))\n",
    "classifier.compile(optimizer = 'adam', loss = 'binary_crossentropy', metrics = ['accuracy'])\n",
    "print(\"WITHOUT SMOTE\")\n",
    "print(\"*\" * 100)\n",
    "classifier.fit(X_train, y_train, batch_size = 10, epochs = 10)\n",
    "print(\"WITH SMOTE\")\n",
    "print(\"*\" * 100)\n",
    "classifier.fit(X_train_oversampled, y_train_oversampled, batch_size = 10, epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:25:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013276\n",
      "0:\tlearn: 0.6677735\ttotal: 71ms\tremaining: 1m 10s\n",
      "1:\tlearn: 0.6429650\ttotal: 74.8ms\tremaining: 37.3s\n",
      "2:\tlearn: 0.6191078\ttotal: 78.6ms\tremaining: 26.1s\n",
      "3:\tlearn: 0.5969400\ttotal: 82.2ms\tremaining: 20.5s\n",
      "4:\tlearn: 0.5747878\ttotal: 85.9ms\tremaining: 17.1s\n",
      "5:\tlearn: 0.5539094\ttotal: 89.8ms\tremaining: 14.9s\n",
      "6:\tlearn: 0.5343422\ttotal: 93.9ms\tremaining: 13.3s\n",
      "7:\tlearn: 0.5166145\ttotal: 97.8ms\tremaining: 12.1s\n",
      "8:\tlearn: 0.5016520\ttotal: 101ms\tremaining: 11.2s\n",
      "9:\tlearn: 0.4846587\ttotal: 105ms\tremaining: 10.4s\n",
      "10:\tlearn: 0.4692641\ttotal: 109ms\tremaining: 9.77s\n",
      "11:\tlearn: 0.4535062\ttotal: 112ms\tremaining: 9.23s\n",
      "12:\tlearn: 0.4386501\ttotal: 116ms\tremaining: 8.79s\n",
      "13:\tlearn: 0.4249066\ttotal: 119ms\tremaining: 8.4s\n",
      "14:\tlearn: 0.4116689\ttotal: 123ms\tremaining: 8.07s\n",
      "15:\tlearn: 0.3987571\ttotal: 128ms\tremaining: 7.85s\n",
      "16:\tlearn: 0.3885483\ttotal: 131ms\tremaining: 7.59s\n",
      "17:\tlearn: 0.3777166\ttotal: 135ms\tremaining: 7.35s\n",
      "18:\tlearn: 0.3669174\ttotal: 138ms\tremaining: 7.14s\n",
      "19:\tlearn: 0.3565985\ttotal: 142ms\tremaining: 6.94s\n",
      "20:\tlearn: 0.3473525\ttotal: 145ms\tremaining: 6.77s\n",
      "21:\tlearn: 0.3403638\ttotal: 149ms\tremaining: 6.62s\n",
      "22:\tlearn: 0.3306779\ttotal: 153ms\tremaining: 6.5s\n",
      "23:\tlearn: 0.3237592\ttotal: 158ms\tremaining: 6.44s\n",
      "24:\tlearn: 0.3154888\ttotal: 163ms\tremaining: 6.35s\n",
      "25:\tlearn: 0.3078190\ttotal: 167ms\tremaining: 6.26s\n",
      "26:\tlearn: 0.3014410\ttotal: 171ms\tremaining: 6.16s\n",
      "27:\tlearn: 0.2939532\ttotal: 175ms\tremaining: 6.07s\n",
      "28:\tlearn: 0.2878813\ttotal: 179ms\tremaining: 6s\n",
      "29:\tlearn: 0.2815151\ttotal: 183ms\tremaining: 5.91s\n",
      "30:\tlearn: 0.2750591\ttotal: 187ms\tremaining: 5.84s\n",
      "31:\tlearn: 0.2682535\ttotal: 191ms\tremaining: 5.77s\n",
      "32:\tlearn: 0.2622109\ttotal: 195ms\tremaining: 5.7s\n",
      "33:\tlearn: 0.2568735\ttotal: 198ms\tremaining: 5.63s\n",
      "34:\tlearn: 0.2521714\ttotal: 202ms\tremaining: 5.57s\n",
      "35:\tlearn: 0.2471498\ttotal: 206ms\tremaining: 5.51s\n",
      "36:\tlearn: 0.2422706\ttotal: 209ms\tremaining: 5.44s\n",
      "37:\tlearn: 0.2378735\ttotal: 213ms\tremaining: 5.39s\n",
      "38:\tlearn: 0.2336556\ttotal: 217ms\tremaining: 5.34s\n",
      "39:\tlearn: 0.2291484\ttotal: 220ms\tremaining: 5.29s\n",
      "40:\tlearn: 0.2249860\ttotal: 224ms\tremaining: 5.24s\n",
      "41:\tlearn: 0.2212541\ttotal: 227ms\tremaining: 5.19s\n",
      "42:\tlearn: 0.2172802\ttotal: 232ms\tremaining: 5.16s\n",
      "43:\tlearn: 0.2133458\ttotal: 235ms\tremaining: 5.11s\n",
      "44:\tlearn: 0.2099664\ttotal: 239ms\tremaining: 5.07s\n",
      "45:\tlearn: 0.2068049\ttotal: 242ms\tremaining: 5.02s\n",
      "46:\tlearn: 0.2033055\ttotal: 246ms\tremaining: 4.98s\n",
      "47:\tlearn: 0.2000925\ttotal: 250ms\tremaining: 4.96s\n",
      "48:\tlearn: 0.1971008\ttotal: 254ms\tremaining: 4.92s\n",
      "49:\tlearn: 0.1942440\ttotal: 257ms\tremaining: 4.88s\n",
      "50:\tlearn: 0.1917156\ttotal: 260ms\tremaining: 4.84s\n",
      "51:\tlearn: 0.1891098\ttotal: 264ms\tremaining: 4.81s\n",
      "52:\tlearn: 0.1865779\ttotal: 268ms\tremaining: 4.78s\n",
      "53:\tlearn: 0.1833755\ttotal: 272ms\tremaining: 4.76s\n",
      "54:\tlearn: 0.1815152\ttotal: 275ms\tremaining: 4.73s\n",
      "55:\tlearn: 0.1782820\ttotal: 279ms\tremaining: 4.7s\n",
      "56:\tlearn: 0.1757663\ttotal: 283ms\tremaining: 4.67s\n",
      "57:\tlearn: 0.1734249\ttotal: 286ms\tremaining: 4.65s\n",
      "58:\tlearn: 0.1717250\ttotal: 290ms\tremaining: 4.63s\n",
      "59:\tlearn: 0.1697098\ttotal: 294ms\tremaining: 4.61s\n",
      "60:\tlearn: 0.1676799\ttotal: 298ms\tremaining: 4.58s\n",
      "61:\tlearn: 0.1655918\ttotal: 301ms\tremaining: 4.56s\n",
      "62:\tlearn: 0.1639393\ttotal: 305ms\tremaining: 4.53s\n",
      "63:\tlearn: 0.1624510\ttotal: 309ms\tremaining: 4.51s\n",
      "64:\tlearn: 0.1607010\ttotal: 313ms\tremaining: 4.5s\n",
      "65:\tlearn: 0.1593787\ttotal: 317ms\tremaining: 4.49s\n",
      "66:\tlearn: 0.1581449\ttotal: 322ms\tremaining: 4.48s\n",
      "67:\tlearn: 0.1566206\ttotal: 325ms\tremaining: 4.46s\n",
      "68:\tlearn: 0.1552225\ttotal: 329ms\tremaining: 4.44s\n",
      "69:\tlearn: 0.1537330\ttotal: 332ms\tremaining: 4.41s\n",
      "70:\tlearn: 0.1526119\ttotal: 336ms\tremaining: 4.39s\n",
      "71:\tlearn: 0.1510956\ttotal: 340ms\tremaining: 4.38s\n",
      "72:\tlearn: 0.1496537\ttotal: 344ms\tremaining: 4.37s\n",
      "73:\tlearn: 0.1485959\ttotal: 348ms\tremaining: 4.36s\n",
      "74:\tlearn: 0.1472236\ttotal: 352ms\tremaining: 4.34s\n",
      "75:\tlearn: 0.1457898\ttotal: 356ms\tremaining: 4.32s\n",
      "76:\tlearn: 0.1447185\ttotal: 359ms\tremaining: 4.31s\n",
      "77:\tlearn: 0.1435034\ttotal: 363ms\tremaining: 4.29s\n",
      "78:\tlearn: 0.1423625\ttotal: 366ms\tremaining: 4.27s\n",
      "79:\tlearn: 0.1413144\ttotal: 370ms\tremaining: 4.25s\n",
      "80:\tlearn: 0.1402363\ttotal: 373ms\tremaining: 4.24s\n",
      "81:\tlearn: 0.1392094\ttotal: 377ms\tremaining: 4.22s\n",
      "82:\tlearn: 0.1381918\ttotal: 381ms\tremaining: 4.21s\n",
      "83:\tlearn: 0.1371281\ttotal: 385ms\tremaining: 4.2s\n",
      "84:\tlearn: 0.1364081\ttotal: 389ms\tremaining: 4.18s\n",
      "85:\tlearn: 0.1354755\ttotal: 392ms\tremaining: 4.17s\n",
      "86:\tlearn: 0.1345581\ttotal: 396ms\tremaining: 4.15s\n",
      "87:\tlearn: 0.1337746\ttotal: 399ms\tremaining: 4.14s\n",
      "88:\tlearn: 0.1327728\ttotal: 403ms\tremaining: 4.13s\n",
      "89:\tlearn: 0.1318998\ttotal: 407ms\tremaining: 4.11s\n",
      "90:\tlearn: 0.1311284\ttotal: 410ms\tremaining: 4.1s\n",
      "91:\tlearn: 0.1302836\ttotal: 414ms\tremaining: 4.08s\n",
      "92:\tlearn: 0.1294686\ttotal: 417ms\tremaining: 4.07s\n",
      "93:\tlearn: 0.1285537\ttotal: 421ms\tremaining: 4.06s\n",
      "94:\tlearn: 0.1276801\ttotal: 424ms\tremaining: 4.04s\n",
      "95:\tlearn: 0.1270742\ttotal: 428ms\tremaining: 4.03s\n",
      "96:\tlearn: 0.1262861\ttotal: 432ms\tremaining: 4.02s\n",
      "97:\tlearn: 0.1256621\ttotal: 435ms\tremaining: 4.01s\n",
      "98:\tlearn: 0.1249505\ttotal: 439ms\tremaining: 4s\n",
      "99:\tlearn: 0.1242361\ttotal: 443ms\tremaining: 3.99s\n",
      "100:\tlearn: 0.1235517\ttotal: 446ms\tremaining: 3.97s\n",
      "101:\tlearn: 0.1227134\ttotal: 450ms\tremaining: 3.96s\n",
      "102:\tlearn: 0.1219870\ttotal: 453ms\tremaining: 3.95s\n",
      "103:\tlearn: 0.1216096\ttotal: 457ms\tremaining: 3.94s\n",
      "104:\tlearn: 0.1210289\ttotal: 460ms\tremaining: 3.92s\n",
      "105:\tlearn: 0.1203615\ttotal: 464ms\tremaining: 3.91s\n",
      "106:\tlearn: 0.1197007\ttotal: 467ms\tremaining: 3.9s\n",
      "107:\tlearn: 0.1192636\ttotal: 471ms\tremaining: 3.89s\n",
      "108:\tlearn: 0.1186213\ttotal: 475ms\tremaining: 3.88s\n",
      "109:\tlearn: 0.1181026\ttotal: 478ms\tremaining: 3.87s\n",
      "110:\tlearn: 0.1172716\ttotal: 482ms\tremaining: 3.86s\n",
      "111:\tlearn: 0.1168870\ttotal: 485ms\tremaining: 3.85s\n",
      "112:\tlearn: 0.1164713\ttotal: 489ms\tremaining: 3.84s\n",
      "113:\tlearn: 0.1159471\ttotal: 493ms\tremaining: 3.83s\n",
      "114:\tlearn: 0.1154918\ttotal: 496ms\tremaining: 3.82s\n",
      "115:\tlearn: 0.1149285\ttotal: 500ms\tremaining: 3.81s\n",
      "116:\tlearn: 0.1144950\ttotal: 504ms\tremaining: 3.8s\n",
      "117:\tlearn: 0.1139960\ttotal: 508ms\tremaining: 3.79s\n",
      "118:\tlearn: 0.1134903\ttotal: 511ms\tremaining: 3.78s\n",
      "119:\tlearn: 0.1130054\ttotal: 515ms\tremaining: 3.78s\n",
      "120:\tlearn: 0.1124530\ttotal: 519ms\tremaining: 3.77s\n",
      "121:\tlearn: 0.1121127\ttotal: 522ms\tremaining: 3.76s\n",
      "122:\tlearn: 0.1116109\ttotal: 526ms\tremaining: 3.75s\n",
      "123:\tlearn: 0.1112118\ttotal: 531ms\tremaining: 3.75s\n",
      "124:\tlearn: 0.1108506\ttotal: 536ms\tremaining: 3.75s\n",
      "125:\tlearn: 0.1102422\ttotal: 540ms\tremaining: 3.74s\n",
      "126:\tlearn: 0.1098829\ttotal: 544ms\tremaining: 3.74s\n",
      "127:\tlearn: 0.1094547\ttotal: 548ms\tremaining: 3.73s\n",
      "128:\tlearn: 0.1088625\ttotal: 552ms\tremaining: 3.73s\n",
      "129:\tlearn: 0.1085005\ttotal: 556ms\tremaining: 3.72s\n",
      "130:\tlearn: 0.1080492\ttotal: 561ms\tremaining: 3.72s\n",
      "131:\tlearn: 0.1077169\ttotal: 565ms\tremaining: 3.71s\n",
      "132:\tlearn: 0.1072817\ttotal: 569ms\tremaining: 3.71s\n",
      "133:\tlearn: 0.1069798\ttotal: 573ms\tremaining: 3.7s\n",
      "134:\tlearn: 0.1065573\ttotal: 576ms\tremaining: 3.69s\n",
      "135:\tlearn: 0.1062769\ttotal: 580ms\tremaining: 3.69s\n",
      "136:\tlearn: 0.1058263\ttotal: 584ms\tremaining: 3.68s\n",
      "137:\tlearn: 0.1053883\ttotal: 588ms\tremaining: 3.67s\n",
      "138:\tlearn: 0.1050588\ttotal: 592ms\tremaining: 3.67s\n",
      "139:\tlearn: 0.1048333\ttotal: 595ms\tremaining: 3.66s\n",
      "140:\tlearn: 0.1043599\ttotal: 599ms\tremaining: 3.65s\n",
      "141:\tlearn: 0.1038454\ttotal: 603ms\tremaining: 3.64s\n",
      "142:\tlearn: 0.1034719\ttotal: 606ms\tremaining: 3.63s\n",
      "143:\tlearn: 0.1030219\ttotal: 610ms\tremaining: 3.63s\n",
      "144:\tlearn: 0.1027833\ttotal: 614ms\tremaining: 3.62s\n",
      "145:\tlearn: 0.1024047\ttotal: 618ms\tremaining: 3.61s\n",
      "146:\tlearn: 0.1021391\ttotal: 622ms\tremaining: 3.61s\n",
      "147:\tlearn: 0.1019717\ttotal: 625ms\tremaining: 3.6s\n",
      "148:\tlearn: 0.1016731\ttotal: 629ms\tremaining: 3.59s\n",
      "149:\tlearn: 0.1013633\ttotal: 633ms\tremaining: 3.58s\n",
      "150:\tlearn: 0.1010024\ttotal: 636ms\tremaining: 3.58s\n",
      "151:\tlearn: 0.1006014\ttotal: 640ms\tremaining: 3.57s\n",
      "152:\tlearn: 0.1002757\ttotal: 644ms\tremaining: 3.57s\n",
      "153:\tlearn: 0.0999481\ttotal: 648ms\tremaining: 3.56s\n",
      "154:\tlearn: 0.0995269\ttotal: 651ms\tremaining: 3.55s\n",
      "155:\tlearn: 0.0992609\ttotal: 655ms\tremaining: 3.55s\n",
      "156:\tlearn: 0.0988392\ttotal: 660ms\tremaining: 3.54s\n",
      "157:\tlearn: 0.0986518\ttotal: 664ms\tremaining: 3.54s\n",
      "158:\tlearn: 0.0982592\ttotal: 667ms\tremaining: 3.53s\n",
      "159:\tlearn: 0.0980266\ttotal: 671ms\tremaining: 3.52s\n",
      "160:\tlearn: 0.0978664\ttotal: 674ms\tremaining: 3.51s\n",
      "161:\tlearn: 0.0975203\ttotal: 678ms\tremaining: 3.51s\n",
      "162:\tlearn: 0.0972412\ttotal: 682ms\tremaining: 3.5s\n",
      "163:\tlearn: 0.0970626\ttotal: 686ms\tremaining: 3.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164:\tlearn: 0.0967203\ttotal: 690ms\tremaining: 3.49s\n",
      "165:\tlearn: 0.0964231\ttotal: 693ms\tremaining: 3.48s\n",
      "166:\tlearn: 0.0961346\ttotal: 697ms\tremaining: 3.47s\n",
      "167:\tlearn: 0.0959015\ttotal: 700ms\tremaining: 3.47s\n",
      "168:\tlearn: 0.0957147\ttotal: 704ms\tremaining: 3.46s\n",
      "169:\tlearn: 0.0955765\ttotal: 707ms\tremaining: 3.45s\n",
      "170:\tlearn: 0.0952688\ttotal: 711ms\tremaining: 3.45s\n",
      "171:\tlearn: 0.0948758\ttotal: 716ms\tremaining: 3.45s\n",
      "172:\tlearn: 0.0946341\ttotal: 720ms\tremaining: 3.44s\n",
      "173:\tlearn: 0.0944423\ttotal: 724ms\tremaining: 3.44s\n",
      "174:\tlearn: 0.0940431\ttotal: 728ms\tremaining: 3.43s\n",
      "175:\tlearn: 0.0938355\ttotal: 732ms\tremaining: 3.43s\n",
      "176:\tlearn: 0.0936296\ttotal: 736ms\tremaining: 3.42s\n",
      "177:\tlearn: 0.0933274\ttotal: 740ms\tremaining: 3.42s\n",
      "178:\tlearn: 0.0930491\ttotal: 743ms\tremaining: 3.41s\n",
      "179:\tlearn: 0.0927876\ttotal: 748ms\tremaining: 3.4s\n",
      "180:\tlearn: 0.0925391\ttotal: 751ms\tremaining: 3.4s\n",
      "181:\tlearn: 0.0923213\ttotal: 755ms\tremaining: 3.39s\n",
      "182:\tlearn: 0.0921498\ttotal: 759ms\tremaining: 3.39s\n",
      "183:\tlearn: 0.0918386\ttotal: 763ms\tremaining: 3.38s\n",
      "184:\tlearn: 0.0915441\ttotal: 767ms\tremaining: 3.38s\n",
      "185:\tlearn: 0.0912552\ttotal: 770ms\tremaining: 3.37s\n",
      "186:\tlearn: 0.0910137\ttotal: 774ms\tremaining: 3.36s\n",
      "187:\tlearn: 0.0906784\ttotal: 778ms\tremaining: 3.36s\n",
      "188:\tlearn: 0.0904607\ttotal: 782ms\tremaining: 3.36s\n",
      "189:\tlearn: 0.0902518\ttotal: 786ms\tremaining: 3.35s\n",
      "190:\tlearn: 0.0900508\ttotal: 789ms\tremaining: 3.34s\n",
      "191:\tlearn: 0.0898318\ttotal: 793ms\tremaining: 3.33s\n",
      "192:\tlearn: 0.0896538\ttotal: 796ms\tremaining: 3.33s\n",
      "193:\tlearn: 0.0894274\ttotal: 800ms\tremaining: 3.32s\n",
      "194:\tlearn: 0.0892480\ttotal: 803ms\tremaining: 3.32s\n",
      "195:\tlearn: 0.0891582\ttotal: 807ms\tremaining: 3.31s\n",
      "196:\tlearn: 0.0890067\ttotal: 811ms\tremaining: 3.3s\n",
      "197:\tlearn: 0.0888585\ttotal: 814ms\tremaining: 3.3s\n",
      "198:\tlearn: 0.0887058\ttotal: 818ms\tremaining: 3.29s\n",
      "199:\tlearn: 0.0885472\ttotal: 821ms\tremaining: 3.28s\n",
      "200:\tlearn: 0.0884060\ttotal: 825ms\tremaining: 3.28s\n",
      "201:\tlearn: 0.0881746\ttotal: 828ms\tremaining: 3.27s\n",
      "202:\tlearn: 0.0880777\ttotal: 831ms\tremaining: 3.26s\n",
      "203:\tlearn: 0.0878580\ttotal: 835ms\tremaining: 3.26s\n",
      "204:\tlearn: 0.0875901\ttotal: 838ms\tremaining: 3.25s\n",
      "205:\tlearn: 0.0874159\ttotal: 842ms\tremaining: 3.25s\n",
      "206:\tlearn: 0.0871931\ttotal: 846ms\tremaining: 3.24s\n",
      "207:\tlearn: 0.0869609\ttotal: 850ms\tremaining: 3.23s\n",
      "208:\tlearn: 0.0866781\ttotal: 853ms\tremaining: 3.23s\n",
      "209:\tlearn: 0.0865240\ttotal: 857ms\tremaining: 3.22s\n",
      "210:\tlearn: 0.0862445\ttotal: 861ms\tremaining: 3.22s\n",
      "211:\tlearn: 0.0860795\ttotal: 865ms\tremaining: 3.21s\n",
      "212:\tlearn: 0.0859587\ttotal: 869ms\tremaining: 3.21s\n",
      "213:\tlearn: 0.0858486\ttotal: 874ms\tremaining: 3.21s\n",
      "214:\tlearn: 0.0856078\ttotal: 878ms\tremaining: 3.21s\n",
      "215:\tlearn: 0.0853454\ttotal: 883ms\tremaining: 3.2s\n",
      "216:\tlearn: 0.0851053\ttotal: 888ms\tremaining: 3.2s\n",
      "217:\tlearn: 0.0849763\ttotal: 892ms\tremaining: 3.2s\n",
      "218:\tlearn: 0.0848277\ttotal: 897ms\tremaining: 3.2s\n",
      "219:\tlearn: 0.0846361\ttotal: 903ms\tremaining: 3.2s\n",
      "220:\tlearn: 0.0844356\ttotal: 908ms\tremaining: 3.2s\n",
      "221:\tlearn: 0.0842463\ttotal: 913ms\tremaining: 3.2s\n",
      "222:\tlearn: 0.0840531\ttotal: 917ms\tremaining: 3.19s\n",
      "223:\tlearn: 0.0838141\ttotal: 922ms\tremaining: 3.19s\n",
      "224:\tlearn: 0.0837345\ttotal: 927ms\tremaining: 3.19s\n",
      "225:\tlearn: 0.0836493\ttotal: 931ms\tremaining: 3.19s\n",
      "226:\tlearn: 0.0833892\ttotal: 936ms\tremaining: 3.19s\n",
      "227:\tlearn: 0.0831978\ttotal: 941ms\tremaining: 3.19s\n",
      "228:\tlearn: 0.0829142\ttotal: 945ms\tremaining: 3.18s\n",
      "229:\tlearn: 0.0826253\ttotal: 949ms\tremaining: 3.18s\n",
      "230:\tlearn: 0.0823967\ttotal: 953ms\tremaining: 3.17s\n",
      "231:\tlearn: 0.0822768\ttotal: 957ms\tremaining: 3.17s\n",
      "232:\tlearn: 0.0820281\ttotal: 961ms\tremaining: 3.16s\n",
      "233:\tlearn: 0.0817907\ttotal: 966ms\tremaining: 3.16s\n",
      "234:\tlearn: 0.0816363\ttotal: 970ms\tremaining: 3.16s\n",
      "235:\tlearn: 0.0814363\ttotal: 974ms\tremaining: 3.15s\n",
      "236:\tlearn: 0.0812632\ttotal: 977ms\tremaining: 3.15s\n",
      "237:\tlearn: 0.0810825\ttotal: 982ms\tremaining: 3.14s\n",
      "238:\tlearn: 0.0809306\ttotal: 987ms\tremaining: 3.14s\n",
      "239:\tlearn: 0.0808017\ttotal: 991ms\tremaining: 3.14s\n",
      "240:\tlearn: 0.0806995\ttotal: 996ms\tremaining: 3.14s\n",
      "241:\tlearn: 0.0804660\ttotal: 1s\tremaining: 3.13s\n",
      "242:\tlearn: 0.0802927\ttotal: 1s\tremaining: 3.13s\n",
      "243:\tlearn: 0.0801573\ttotal: 1.01s\tremaining: 3.12s\n",
      "244:\tlearn: 0.0800655\ttotal: 1.01s\tremaining: 3.12s\n",
      "245:\tlearn: 0.0799093\ttotal: 1.02s\tremaining: 3.12s\n",
      "246:\tlearn: 0.0797387\ttotal: 1.02s\tremaining: 3.11s\n",
      "247:\tlearn: 0.0796193\ttotal: 1.02s\tremaining: 3.1s\n",
      "248:\tlearn: 0.0794346\ttotal: 1.03s\tremaining: 3.1s\n",
      "249:\tlearn: 0.0793196\ttotal: 1.03s\tremaining: 3.1s\n",
      "250:\tlearn: 0.0791308\ttotal: 1.04s\tremaining: 3.1s\n",
      "251:\tlearn: 0.0790193\ttotal: 1.04s\tremaining: 3.09s\n",
      "252:\tlearn: 0.0788981\ttotal: 1.04s\tremaining: 3.09s\n",
      "253:\tlearn: 0.0787610\ttotal: 1.05s\tremaining: 3.08s\n",
      "254:\tlearn: 0.0786276\ttotal: 1.05s\tremaining: 3.08s\n",
      "255:\tlearn: 0.0785741\ttotal: 1.06s\tremaining: 3.08s\n",
      "256:\tlearn: 0.0783191\ttotal: 1.06s\tremaining: 3.08s\n",
      "257:\tlearn: 0.0781549\ttotal: 1.07s\tremaining: 3.07s\n",
      "258:\tlearn: 0.0779916\ttotal: 1.07s\tremaining: 3.07s\n",
      "259:\tlearn: 0.0778441\ttotal: 1.07s\tremaining: 3.06s\n",
      "260:\tlearn: 0.0775970\ttotal: 1.08s\tremaining: 3.06s\n",
      "261:\tlearn: 0.0775192\ttotal: 1.08s\tremaining: 3.05s\n",
      "262:\tlearn: 0.0773393\ttotal: 1.09s\tremaining: 3.05s\n",
      "263:\tlearn: 0.0771626\ttotal: 1.09s\tremaining: 3.04s\n",
      "264:\tlearn: 0.0770464\ttotal: 1.09s\tremaining: 3.04s\n",
      "265:\tlearn: 0.0769230\ttotal: 1.1s\tremaining: 3.03s\n",
      "266:\tlearn: 0.0767761\ttotal: 1.1s\tremaining: 3.03s\n",
      "267:\tlearn: 0.0766944\ttotal: 1.11s\tremaining: 3.02s\n",
      "268:\tlearn: 0.0766297\ttotal: 1.11s\tremaining: 3.02s\n",
      "269:\tlearn: 0.0764130\ttotal: 1.11s\tremaining: 3.01s\n",
      "270:\tlearn: 0.0763400\ttotal: 1.12s\tremaining: 3.01s\n",
      "271:\tlearn: 0.0762474\ttotal: 1.12s\tremaining: 3s\n",
      "272:\tlearn: 0.0761167\ttotal: 1.13s\tremaining: 3s\n",
      "273:\tlearn: 0.0759683\ttotal: 1.13s\tremaining: 2.99s\n",
      "274:\tlearn: 0.0757833\ttotal: 1.13s\tremaining: 2.99s\n",
      "275:\tlearn: 0.0755852\ttotal: 1.14s\tremaining: 2.98s\n",
      "276:\tlearn: 0.0754579\ttotal: 1.14s\tremaining: 2.98s\n",
      "277:\tlearn: 0.0753562\ttotal: 1.14s\tremaining: 2.97s\n",
      "278:\tlearn: 0.0751610\ttotal: 1.15s\tremaining: 2.96s\n",
      "279:\tlearn: 0.0750255\ttotal: 1.15s\tremaining: 2.96s\n",
      "280:\tlearn: 0.0748895\ttotal: 1.15s\tremaining: 2.95s\n",
      "281:\tlearn: 0.0746719\ttotal: 1.16s\tremaining: 2.95s\n",
      "282:\tlearn: 0.0745213\ttotal: 1.16s\tremaining: 2.94s\n",
      "283:\tlearn: 0.0743044\ttotal: 1.17s\tremaining: 2.94s\n",
      "284:\tlearn: 0.0742152\ttotal: 1.17s\tremaining: 2.93s\n",
      "285:\tlearn: 0.0740245\ttotal: 1.17s\tremaining: 2.93s\n",
      "286:\tlearn: 0.0739068\ttotal: 1.18s\tremaining: 2.92s\n",
      "287:\tlearn: 0.0737847\ttotal: 1.18s\tremaining: 2.92s\n",
      "288:\tlearn: 0.0736998\ttotal: 1.19s\tremaining: 2.92s\n",
      "289:\tlearn: 0.0736394\ttotal: 1.19s\tremaining: 2.91s\n",
      "290:\tlearn: 0.0735175\ttotal: 1.19s\tremaining: 2.91s\n",
      "291:\tlearn: 0.0734176\ttotal: 1.2s\tremaining: 2.9s\n",
      "292:\tlearn: 0.0732975\ttotal: 1.2s\tremaining: 2.9s\n",
      "293:\tlearn: 0.0731950\ttotal: 1.2s\tremaining: 2.89s\n",
      "294:\tlearn: 0.0730884\ttotal: 1.21s\tremaining: 2.89s\n",
      "295:\tlearn: 0.0729393\ttotal: 1.21s\tremaining: 2.89s\n",
      "296:\tlearn: 0.0728223\ttotal: 1.22s\tremaining: 2.88s\n",
      "297:\tlearn: 0.0726692\ttotal: 1.22s\tremaining: 2.88s\n",
      "298:\tlearn: 0.0725178\ttotal: 1.23s\tremaining: 2.88s\n",
      "299:\tlearn: 0.0724025\ttotal: 1.23s\tremaining: 2.87s\n",
      "300:\tlearn: 0.0722329\ttotal: 1.23s\tremaining: 2.87s\n",
      "301:\tlearn: 0.0720843\ttotal: 1.24s\tremaining: 2.86s\n",
      "302:\tlearn: 0.0719296\ttotal: 1.24s\tremaining: 2.86s\n",
      "303:\tlearn: 0.0717335\ttotal: 1.25s\tremaining: 2.86s\n",
      "304:\tlearn: 0.0715620\ttotal: 1.25s\tremaining: 2.85s\n",
      "305:\tlearn: 0.0713653\ttotal: 1.25s\tremaining: 2.85s\n",
      "306:\tlearn: 0.0712286\ttotal: 1.26s\tremaining: 2.84s\n",
      "307:\tlearn: 0.0711762\ttotal: 1.26s\tremaining: 2.84s\n",
      "308:\tlearn: 0.0710472\ttotal: 1.27s\tremaining: 2.84s\n",
      "309:\tlearn: 0.0710033\ttotal: 1.27s\tremaining: 2.83s\n",
      "310:\tlearn: 0.0709198\ttotal: 1.28s\tremaining: 2.83s\n",
      "311:\tlearn: 0.0708536\ttotal: 1.28s\tremaining: 2.82s\n",
      "312:\tlearn: 0.0707867\ttotal: 1.28s\tremaining: 2.82s\n",
      "313:\tlearn: 0.0706106\ttotal: 1.29s\tremaining: 2.81s\n",
      "314:\tlearn: 0.0705349\ttotal: 1.29s\tremaining: 2.81s\n",
      "315:\tlearn: 0.0704536\ttotal: 1.29s\tremaining: 2.8s\n",
      "316:\tlearn: 0.0703331\ttotal: 1.3s\tremaining: 2.8s\n",
      "317:\tlearn: 0.0702373\ttotal: 1.3s\tremaining: 2.79s\n",
      "318:\tlearn: 0.0701086\ttotal: 1.31s\tremaining: 2.79s\n",
      "319:\tlearn: 0.0699822\ttotal: 1.31s\tremaining: 2.78s\n",
      "320:\tlearn: 0.0698748\ttotal: 1.31s\tremaining: 2.78s\n",
      "321:\tlearn: 0.0697151\ttotal: 1.32s\tremaining: 2.77s\n",
      "322:\tlearn: 0.0696502\ttotal: 1.32s\tremaining: 2.77s\n",
      "323:\tlearn: 0.0695597\ttotal: 1.32s\tremaining: 2.76s\n",
      "324:\tlearn: 0.0694219\ttotal: 1.33s\tremaining: 2.76s\n",
      "325:\tlearn: 0.0692914\ttotal: 1.33s\tremaining: 2.75s\n",
      "326:\tlearn: 0.0692463\ttotal: 1.34s\tremaining: 2.75s\n",
      "327:\tlearn: 0.0690548\ttotal: 1.34s\tremaining: 2.75s\n",
      "328:\tlearn: 0.0689747\ttotal: 1.34s\tremaining: 2.74s\n",
      "329:\tlearn: 0.0689140\ttotal: 1.35s\tremaining: 2.74s\n",
      "330:\tlearn: 0.0688289\ttotal: 1.35s\tremaining: 2.73s\n",
      "331:\tlearn: 0.0686718\ttotal: 1.36s\tremaining: 2.73s\n",
      "332:\tlearn: 0.0686373\ttotal: 1.36s\tremaining: 2.72s\n",
      "333:\tlearn: 0.0684978\ttotal: 1.36s\tremaining: 2.72s\n",
      "334:\tlearn: 0.0684098\ttotal: 1.37s\tremaining: 2.72s\n",
      "335:\tlearn: 0.0682666\ttotal: 1.37s\tremaining: 2.71s\n",
      "336:\tlearn: 0.0681970\ttotal: 1.38s\tremaining: 2.71s\n",
      "337:\tlearn: 0.0681014\ttotal: 1.38s\tremaining: 2.7s\n",
      "338:\tlearn: 0.0679516\ttotal: 1.38s\tremaining: 2.7s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "339:\tlearn: 0.0678506\ttotal: 1.39s\tremaining: 2.69s\n",
      "340:\tlearn: 0.0676849\ttotal: 1.39s\tremaining: 2.69s\n",
      "341:\tlearn: 0.0675318\ttotal: 1.4s\tremaining: 2.68s\n",
      "342:\tlearn: 0.0674203\ttotal: 1.4s\tremaining: 2.68s\n",
      "343:\tlearn: 0.0673057\ttotal: 1.4s\tremaining: 2.68s\n",
      "344:\tlearn: 0.0671965\ttotal: 1.41s\tremaining: 2.67s\n",
      "345:\tlearn: 0.0671001\ttotal: 1.41s\tremaining: 2.67s\n",
      "346:\tlearn: 0.0669363\ttotal: 1.41s\tremaining: 2.66s\n",
      "347:\tlearn: 0.0668061\ttotal: 1.42s\tremaining: 2.66s\n",
      "348:\tlearn: 0.0667407\ttotal: 1.42s\tremaining: 2.65s\n",
      "349:\tlearn: 0.0666956\ttotal: 1.43s\tremaining: 2.65s\n",
      "350:\tlearn: 0.0666132\ttotal: 1.43s\tremaining: 2.65s\n",
      "351:\tlearn: 0.0664990\ttotal: 1.44s\tremaining: 2.64s\n",
      "352:\tlearn: 0.0664313\ttotal: 1.44s\tremaining: 2.64s\n",
      "353:\tlearn: 0.0663594\ttotal: 1.44s\tremaining: 2.63s\n",
      "354:\tlearn: 0.0662910\ttotal: 1.45s\tremaining: 2.63s\n",
      "355:\tlearn: 0.0661762\ttotal: 1.45s\tremaining: 2.63s\n",
      "356:\tlearn: 0.0660494\ttotal: 1.46s\tremaining: 2.62s\n",
      "357:\tlearn: 0.0658843\ttotal: 1.46s\tremaining: 2.62s\n",
      "358:\tlearn: 0.0658258\ttotal: 1.46s\tremaining: 2.61s\n",
      "359:\tlearn: 0.0656867\ttotal: 1.47s\tremaining: 2.61s\n",
      "360:\tlearn: 0.0655914\ttotal: 1.47s\tremaining: 2.61s\n",
      "361:\tlearn: 0.0655408\ttotal: 1.48s\tremaining: 2.6s\n",
      "362:\tlearn: 0.0654286\ttotal: 1.48s\tremaining: 2.6s\n",
      "363:\tlearn: 0.0653315\ttotal: 1.49s\tremaining: 2.6s\n",
      "364:\tlearn: 0.0651876\ttotal: 1.49s\tremaining: 2.59s\n",
      "365:\tlearn: 0.0651358\ttotal: 1.49s\tremaining: 2.59s\n",
      "366:\tlearn: 0.0650743\ttotal: 1.5s\tremaining: 2.58s\n",
      "367:\tlearn: 0.0650219\ttotal: 1.5s\tremaining: 2.58s\n",
      "368:\tlearn: 0.0649560\ttotal: 1.51s\tremaining: 2.58s\n",
      "369:\tlearn: 0.0648623\ttotal: 1.51s\tremaining: 2.57s\n",
      "370:\tlearn: 0.0647287\ttotal: 1.51s\tremaining: 2.57s\n",
      "371:\tlearn: 0.0646360\ttotal: 1.52s\tremaining: 2.56s\n",
      "372:\tlearn: 0.0645517\ttotal: 1.52s\tremaining: 2.56s\n",
      "373:\tlearn: 0.0645085\ttotal: 1.53s\tremaining: 2.56s\n",
      "374:\tlearn: 0.0644427\ttotal: 1.53s\tremaining: 2.55s\n",
      "375:\tlearn: 0.0643716\ttotal: 1.53s\tremaining: 2.55s\n",
      "376:\tlearn: 0.0642877\ttotal: 1.54s\tremaining: 2.54s\n",
      "377:\tlearn: 0.0641308\ttotal: 1.54s\tremaining: 2.54s\n",
      "378:\tlearn: 0.0640555\ttotal: 1.55s\tremaining: 2.54s\n",
      "379:\tlearn: 0.0639641\ttotal: 1.55s\tremaining: 2.53s\n",
      "380:\tlearn: 0.0638669\ttotal: 1.56s\tremaining: 2.53s\n",
      "381:\tlearn: 0.0637666\ttotal: 1.56s\tremaining: 2.53s\n",
      "382:\tlearn: 0.0636881\ttotal: 1.57s\tremaining: 2.52s\n",
      "383:\tlearn: 0.0635650\ttotal: 1.57s\tremaining: 2.52s\n",
      "384:\tlearn: 0.0634836\ttotal: 1.57s\tremaining: 2.52s\n",
      "385:\tlearn: 0.0632551\ttotal: 1.58s\tremaining: 2.51s\n",
      "386:\tlearn: 0.0631742\ttotal: 1.58s\tremaining: 2.51s\n",
      "387:\tlearn: 0.0631111\ttotal: 1.59s\tremaining: 2.51s\n",
      "388:\tlearn: 0.0630758\ttotal: 1.59s\tremaining: 2.5s\n",
      "389:\tlearn: 0.0629701\ttotal: 1.6s\tremaining: 2.5s\n",
      "390:\tlearn: 0.0628913\ttotal: 1.6s\tremaining: 2.49s\n",
      "391:\tlearn: 0.0627849\ttotal: 1.6s\tremaining: 2.49s\n",
      "392:\tlearn: 0.0626981\ttotal: 1.61s\tremaining: 2.48s\n",
      "393:\tlearn: 0.0625708\ttotal: 1.61s\tremaining: 2.48s\n",
      "394:\tlearn: 0.0624376\ttotal: 1.62s\tremaining: 2.48s\n",
      "395:\tlearn: 0.0623846\ttotal: 1.62s\tremaining: 2.47s\n",
      "396:\tlearn: 0.0623254\ttotal: 1.63s\tremaining: 2.47s\n",
      "397:\tlearn: 0.0622207\ttotal: 1.63s\tremaining: 2.46s\n",
      "398:\tlearn: 0.0621110\ttotal: 1.63s\tremaining: 2.46s\n",
      "399:\tlearn: 0.0620459\ttotal: 1.64s\tremaining: 2.46s\n",
      "400:\tlearn: 0.0619580\ttotal: 1.64s\tremaining: 2.45s\n",
      "401:\tlearn: 0.0619090\ttotal: 1.64s\tremaining: 2.44s\n",
      "402:\tlearn: 0.0618046\ttotal: 1.65s\tremaining: 2.44s\n",
      "403:\tlearn: 0.0617511\ttotal: 1.65s\tremaining: 2.44s\n",
      "404:\tlearn: 0.0616742\ttotal: 1.66s\tremaining: 2.43s\n",
      "405:\tlearn: 0.0615811\ttotal: 1.66s\tremaining: 2.43s\n",
      "406:\tlearn: 0.0615208\ttotal: 1.66s\tremaining: 2.42s\n",
      "407:\tlearn: 0.0614064\ttotal: 1.67s\tremaining: 2.42s\n",
      "408:\tlearn: 0.0613052\ttotal: 1.67s\tremaining: 2.41s\n",
      "409:\tlearn: 0.0612198\ttotal: 1.67s\tremaining: 2.41s\n",
      "410:\tlearn: 0.0611719\ttotal: 1.68s\tremaining: 2.4s\n",
      "411:\tlearn: 0.0610648\ttotal: 1.68s\tremaining: 2.4s\n",
      "412:\tlearn: 0.0609927\ttotal: 1.69s\tremaining: 2.4s\n",
      "413:\tlearn: 0.0608798\ttotal: 1.69s\tremaining: 2.39s\n",
      "414:\tlearn: 0.0608298\ttotal: 1.69s\tremaining: 2.39s\n",
      "415:\tlearn: 0.0607611\ttotal: 1.7s\tremaining: 2.38s\n",
      "416:\tlearn: 0.0606776\ttotal: 1.7s\tremaining: 2.38s\n",
      "417:\tlearn: 0.0605498\ttotal: 1.71s\tremaining: 2.37s\n",
      "418:\tlearn: 0.0604402\ttotal: 1.71s\tremaining: 2.37s\n",
      "419:\tlearn: 0.0603687\ttotal: 1.71s\tremaining: 2.37s\n",
      "420:\tlearn: 0.0602932\ttotal: 1.72s\tremaining: 2.36s\n",
      "421:\tlearn: 0.0602377\ttotal: 1.72s\tremaining: 2.36s\n",
      "422:\tlearn: 0.0601278\ttotal: 1.73s\tremaining: 2.36s\n",
      "423:\tlearn: 0.0600826\ttotal: 1.73s\tremaining: 2.35s\n",
      "424:\tlearn: 0.0600284\ttotal: 1.74s\tremaining: 2.35s\n",
      "425:\tlearn: 0.0599718\ttotal: 1.74s\tremaining: 2.34s\n",
      "426:\tlearn: 0.0598898\ttotal: 1.74s\tremaining: 2.34s\n",
      "427:\tlearn: 0.0597811\ttotal: 1.75s\tremaining: 2.34s\n",
      "428:\tlearn: 0.0597038\ttotal: 1.75s\tremaining: 2.33s\n",
      "429:\tlearn: 0.0596227\ttotal: 1.76s\tremaining: 2.33s\n",
      "430:\tlearn: 0.0595196\ttotal: 1.76s\tremaining: 2.32s\n",
      "431:\tlearn: 0.0594593\ttotal: 1.76s\tremaining: 2.32s\n",
      "432:\tlearn: 0.0593917\ttotal: 1.77s\tremaining: 2.31s\n",
      "433:\tlearn: 0.0593041\ttotal: 1.77s\tremaining: 2.31s\n",
      "434:\tlearn: 0.0591676\ttotal: 1.78s\tremaining: 2.31s\n",
      "435:\tlearn: 0.0590588\ttotal: 1.78s\tremaining: 2.3s\n",
      "436:\tlearn: 0.0590267\ttotal: 1.78s\tremaining: 2.3s\n",
      "437:\tlearn: 0.0589214\ttotal: 1.79s\tremaining: 2.29s\n",
      "438:\tlearn: 0.0588387\ttotal: 1.79s\tremaining: 2.29s\n",
      "439:\tlearn: 0.0587200\ttotal: 1.8s\tremaining: 2.29s\n",
      "440:\tlearn: 0.0586203\ttotal: 1.8s\tremaining: 2.28s\n",
      "441:\tlearn: 0.0585490\ttotal: 1.8s\tremaining: 2.28s\n",
      "442:\tlearn: 0.0584364\ttotal: 1.81s\tremaining: 2.27s\n",
      "443:\tlearn: 0.0583329\ttotal: 1.81s\tremaining: 2.27s\n",
      "444:\tlearn: 0.0582747\ttotal: 1.82s\tremaining: 2.27s\n",
      "445:\tlearn: 0.0581979\ttotal: 1.82s\tremaining: 2.26s\n",
      "446:\tlearn: 0.0581154\ttotal: 1.82s\tremaining: 2.26s\n",
      "447:\tlearn: 0.0580309\ttotal: 1.83s\tremaining: 2.25s\n",
      "448:\tlearn: 0.0579655\ttotal: 1.83s\tremaining: 2.25s\n",
      "449:\tlearn: 0.0578877\ttotal: 1.84s\tremaining: 2.24s\n",
      "450:\tlearn: 0.0578268\ttotal: 1.84s\tremaining: 2.24s\n",
      "451:\tlearn: 0.0577825\ttotal: 1.84s\tremaining: 2.24s\n",
      "452:\tlearn: 0.0577107\ttotal: 1.85s\tremaining: 2.23s\n",
      "453:\tlearn: 0.0576151\ttotal: 1.85s\tremaining: 2.23s\n",
      "454:\tlearn: 0.0574703\ttotal: 1.86s\tremaining: 2.22s\n",
      "455:\tlearn: 0.0573613\ttotal: 1.86s\tremaining: 2.22s\n",
      "456:\tlearn: 0.0572743\ttotal: 1.86s\tremaining: 2.21s\n",
      "457:\tlearn: 0.0571894\ttotal: 1.87s\tremaining: 2.21s\n",
      "458:\tlearn: 0.0571140\ttotal: 1.87s\tremaining: 2.21s\n",
      "459:\tlearn: 0.0570171\ttotal: 1.88s\tremaining: 2.2s\n",
      "460:\tlearn: 0.0568906\ttotal: 1.88s\tremaining: 2.2s\n",
      "461:\tlearn: 0.0568081\ttotal: 1.88s\tremaining: 2.19s\n",
      "462:\tlearn: 0.0567667\ttotal: 1.89s\tremaining: 2.19s\n",
      "463:\tlearn: 0.0567230\ttotal: 1.89s\tremaining: 2.19s\n",
      "464:\tlearn: 0.0565851\ttotal: 1.9s\tremaining: 2.18s\n",
      "465:\tlearn: 0.0565018\ttotal: 1.9s\tremaining: 2.18s\n",
      "466:\tlearn: 0.0564524\ttotal: 1.9s\tremaining: 2.17s\n",
      "467:\tlearn: 0.0563526\ttotal: 1.91s\tremaining: 2.17s\n",
      "468:\tlearn: 0.0563271\ttotal: 1.91s\tremaining: 2.17s\n",
      "469:\tlearn: 0.0562982\ttotal: 1.92s\tremaining: 2.16s\n",
      "470:\tlearn: 0.0562018\ttotal: 1.92s\tremaining: 2.16s\n",
      "471:\tlearn: 0.0561155\ttotal: 1.93s\tremaining: 2.15s\n",
      "472:\tlearn: 0.0560781\ttotal: 1.93s\tremaining: 2.15s\n",
      "473:\tlearn: 0.0560073\ttotal: 1.94s\tremaining: 2.15s\n",
      "474:\tlearn: 0.0559806\ttotal: 1.94s\tremaining: 2.14s\n",
      "475:\tlearn: 0.0559060\ttotal: 1.94s\tremaining: 2.14s\n",
      "476:\tlearn: 0.0558695\ttotal: 1.95s\tremaining: 2.13s\n",
      "477:\tlearn: 0.0558124\ttotal: 1.95s\tremaining: 2.13s\n",
      "478:\tlearn: 0.0557659\ttotal: 1.96s\tremaining: 2.13s\n",
      "479:\tlearn: 0.0556981\ttotal: 1.96s\tremaining: 2.12s\n",
      "480:\tlearn: 0.0556006\ttotal: 1.96s\tremaining: 2.12s\n",
      "481:\tlearn: 0.0555383\ttotal: 1.97s\tremaining: 2.12s\n",
      "482:\tlearn: 0.0554507\ttotal: 1.97s\tremaining: 2.11s\n",
      "483:\tlearn: 0.0553952\ttotal: 1.98s\tremaining: 2.11s\n",
      "484:\tlearn: 0.0552894\ttotal: 1.98s\tremaining: 2.1s\n",
      "485:\tlearn: 0.0552208\ttotal: 1.99s\tremaining: 2.1s\n",
      "486:\tlearn: 0.0551557\ttotal: 1.99s\tremaining: 2.1s\n",
      "487:\tlearn: 0.0550897\ttotal: 2s\tremaining: 2.09s\n",
      "488:\tlearn: 0.0550571\ttotal: 2s\tremaining: 2.09s\n",
      "489:\tlearn: 0.0550173\ttotal: 2s\tremaining: 2.09s\n",
      "490:\tlearn: 0.0549559\ttotal: 2.01s\tremaining: 2.08s\n",
      "491:\tlearn: 0.0548907\ttotal: 2.01s\tremaining: 2.08s\n",
      "492:\tlearn: 0.0547927\ttotal: 2.02s\tremaining: 2.07s\n",
      "493:\tlearn: 0.0547109\ttotal: 2.02s\tremaining: 2.07s\n",
      "494:\tlearn: 0.0546281\ttotal: 2.02s\tremaining: 2.06s\n",
      "495:\tlearn: 0.0545445\ttotal: 2.03s\tremaining: 2.06s\n",
      "496:\tlearn: 0.0545178\ttotal: 2.03s\tremaining: 2.06s\n",
      "497:\tlearn: 0.0544744\ttotal: 2.04s\tremaining: 2.05s\n",
      "498:\tlearn: 0.0543914\ttotal: 2.04s\tremaining: 2.05s\n",
      "499:\tlearn: 0.0543458\ttotal: 2.05s\tremaining: 2.05s\n",
      "500:\tlearn: 0.0542854\ttotal: 2.05s\tremaining: 2.04s\n",
      "501:\tlearn: 0.0542271\ttotal: 2.05s\tremaining: 2.04s\n",
      "502:\tlearn: 0.0541680\ttotal: 2.06s\tremaining: 2.03s\n",
      "503:\tlearn: 0.0540747\ttotal: 2.06s\tremaining: 2.03s\n",
      "504:\tlearn: 0.0539720\ttotal: 2.06s\tremaining: 2.02s\n",
      "505:\tlearn: 0.0539372\ttotal: 2.07s\tremaining: 2.02s\n",
      "506:\tlearn: 0.0538819\ttotal: 2.07s\tremaining: 2.02s\n",
      "507:\tlearn: 0.0538211\ttotal: 2.08s\tremaining: 2.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "508:\tlearn: 0.0538018\ttotal: 2.08s\tremaining: 2.01s\n",
      "509:\tlearn: 0.0537185\ttotal: 2.08s\tremaining: 2s\n",
      "510:\tlearn: 0.0536143\ttotal: 2.09s\tremaining: 2s\n",
      "511:\tlearn: 0.0535582\ttotal: 2.09s\tremaining: 1.99s\n",
      "512:\tlearn: 0.0534952\ttotal: 2.1s\tremaining: 1.99s\n",
      "513:\tlearn: 0.0534368\ttotal: 2.1s\tremaining: 1.99s\n",
      "514:\tlearn: 0.0533634\ttotal: 2.1s\tremaining: 1.98s\n",
      "515:\tlearn: 0.0532928\ttotal: 2.11s\tremaining: 1.98s\n",
      "516:\tlearn: 0.0532314\ttotal: 2.11s\tremaining: 1.98s\n",
      "517:\tlearn: 0.0531966\ttotal: 2.12s\tremaining: 1.97s\n",
      "518:\tlearn: 0.0531675\ttotal: 2.12s\tremaining: 1.97s\n",
      "519:\tlearn: 0.0531433\ttotal: 2.13s\tremaining: 1.96s\n",
      "520:\tlearn: 0.0530744\ttotal: 2.13s\tremaining: 1.96s\n",
      "521:\tlearn: 0.0529785\ttotal: 2.13s\tremaining: 1.95s\n",
      "522:\tlearn: 0.0529108\ttotal: 2.14s\tremaining: 1.95s\n",
      "523:\tlearn: 0.0528629\ttotal: 2.14s\tremaining: 1.95s\n",
      "524:\tlearn: 0.0528034\ttotal: 2.15s\tremaining: 1.94s\n",
      "525:\tlearn: 0.0527230\ttotal: 2.15s\tremaining: 1.94s\n",
      "526:\tlearn: 0.0526586\ttotal: 2.15s\tremaining: 1.93s\n",
      "527:\tlearn: 0.0525999\ttotal: 2.16s\tremaining: 1.93s\n",
      "528:\tlearn: 0.0525580\ttotal: 2.16s\tremaining: 1.93s\n",
      "529:\tlearn: 0.0524944\ttotal: 2.17s\tremaining: 1.92s\n",
      "530:\tlearn: 0.0524324\ttotal: 2.17s\tremaining: 1.92s\n",
      "531:\tlearn: 0.0523111\ttotal: 2.17s\tremaining: 1.91s\n",
      "532:\tlearn: 0.0522593\ttotal: 2.18s\tremaining: 1.91s\n",
      "533:\tlearn: 0.0522081\ttotal: 2.18s\tremaining: 1.91s\n",
      "534:\tlearn: 0.0521403\ttotal: 2.19s\tremaining: 1.9s\n",
      "535:\tlearn: 0.0521061\ttotal: 2.19s\tremaining: 1.9s\n",
      "536:\tlearn: 0.0520564\ttotal: 2.19s\tremaining: 1.89s\n",
      "537:\tlearn: 0.0520457\ttotal: 2.2s\tremaining: 1.89s\n",
      "538:\tlearn: 0.0520150\ttotal: 2.2s\tremaining: 1.88s\n",
      "539:\tlearn: 0.0519712\ttotal: 2.21s\tremaining: 1.88s\n",
      "540:\tlearn: 0.0519199\ttotal: 2.21s\tremaining: 1.88s\n",
      "541:\tlearn: 0.0519022\ttotal: 2.21s\tremaining: 1.87s\n",
      "542:\tlearn: 0.0518480\ttotal: 2.22s\tremaining: 1.87s\n",
      "543:\tlearn: 0.0518115\ttotal: 2.22s\tremaining: 1.86s\n",
      "544:\tlearn: 0.0517522\ttotal: 2.23s\tremaining: 1.86s\n",
      "545:\tlearn: 0.0517031\ttotal: 2.23s\tremaining: 1.85s\n",
      "546:\tlearn: 0.0516200\ttotal: 2.23s\tremaining: 1.85s\n",
      "547:\tlearn: 0.0515974\ttotal: 2.24s\tremaining: 1.85s\n",
      "548:\tlearn: 0.0515560\ttotal: 2.24s\tremaining: 1.84s\n",
      "549:\tlearn: 0.0515288\ttotal: 2.25s\tremaining: 1.84s\n",
      "550:\tlearn: 0.0514828\ttotal: 2.25s\tremaining: 1.83s\n",
      "551:\tlearn: 0.0514568\ttotal: 2.26s\tremaining: 1.83s\n",
      "552:\tlearn: 0.0513677\ttotal: 2.26s\tremaining: 1.83s\n",
      "553:\tlearn: 0.0513191\ttotal: 2.26s\tremaining: 1.82s\n",
      "554:\tlearn: 0.0512288\ttotal: 2.27s\tremaining: 1.82s\n",
      "555:\tlearn: 0.0511739\ttotal: 2.27s\tremaining: 1.81s\n",
      "556:\tlearn: 0.0511295\ttotal: 2.27s\tremaining: 1.81s\n",
      "557:\tlearn: 0.0510747\ttotal: 2.28s\tremaining: 1.8s\n",
      "558:\tlearn: 0.0510141\ttotal: 2.28s\tremaining: 1.8s\n",
      "559:\tlearn: 0.0509763\ttotal: 2.29s\tremaining: 1.8s\n",
      "560:\tlearn: 0.0509265\ttotal: 2.29s\tremaining: 1.79s\n",
      "561:\tlearn: 0.0508833\ttotal: 2.29s\tremaining: 1.79s\n",
      "562:\tlearn: 0.0508414\ttotal: 2.3s\tremaining: 1.78s\n",
      "563:\tlearn: 0.0508014\ttotal: 2.3s\tremaining: 1.78s\n",
      "564:\tlearn: 0.0507712\ttotal: 2.31s\tremaining: 1.77s\n",
      "565:\tlearn: 0.0507357\ttotal: 2.31s\tremaining: 1.77s\n",
      "566:\tlearn: 0.0506581\ttotal: 2.31s\tremaining: 1.77s\n",
      "567:\tlearn: 0.0505238\ttotal: 2.32s\tremaining: 1.76s\n",
      "568:\tlearn: 0.0504421\ttotal: 2.32s\tremaining: 1.76s\n",
      "569:\tlearn: 0.0503472\ttotal: 2.32s\tremaining: 1.75s\n",
      "570:\tlearn: 0.0502950\ttotal: 2.33s\tremaining: 1.75s\n",
      "571:\tlearn: 0.0502237\ttotal: 2.33s\tremaining: 1.74s\n",
      "572:\tlearn: 0.0501576\ttotal: 2.33s\tremaining: 1.74s\n",
      "573:\tlearn: 0.0501348\ttotal: 2.34s\tremaining: 1.73s\n",
      "574:\tlearn: 0.0501113\ttotal: 2.34s\tremaining: 1.73s\n",
      "575:\tlearn: 0.0500476\ttotal: 2.34s\tremaining: 1.73s\n",
      "576:\tlearn: 0.0499789\ttotal: 2.35s\tremaining: 1.72s\n",
      "577:\tlearn: 0.0498921\ttotal: 2.35s\tremaining: 1.72s\n",
      "578:\tlearn: 0.0498508\ttotal: 2.35s\tremaining: 1.71s\n",
      "579:\tlearn: 0.0498028\ttotal: 2.36s\tremaining: 1.71s\n",
      "580:\tlearn: 0.0497559\ttotal: 2.36s\tremaining: 1.7s\n",
      "581:\tlearn: 0.0497210\ttotal: 2.37s\tremaining: 1.7s\n",
      "582:\tlearn: 0.0496887\ttotal: 2.37s\tremaining: 1.7s\n",
      "583:\tlearn: 0.0496478\ttotal: 2.38s\tremaining: 1.69s\n",
      "584:\tlearn: 0.0496179\ttotal: 2.38s\tremaining: 1.69s\n",
      "585:\tlearn: 0.0495567\ttotal: 2.38s\tremaining: 1.68s\n",
      "586:\tlearn: 0.0494816\ttotal: 2.39s\tremaining: 1.68s\n",
      "587:\tlearn: 0.0494511\ttotal: 2.39s\tremaining: 1.68s\n",
      "588:\tlearn: 0.0493478\ttotal: 2.39s\tremaining: 1.67s\n",
      "589:\tlearn: 0.0492958\ttotal: 2.4s\tremaining: 1.67s\n",
      "590:\tlearn: 0.0492733\ttotal: 2.4s\tremaining: 1.66s\n",
      "591:\tlearn: 0.0492535\ttotal: 2.41s\tremaining: 1.66s\n",
      "592:\tlearn: 0.0492133\ttotal: 2.41s\tremaining: 1.66s\n",
      "593:\tlearn: 0.0491765\ttotal: 2.42s\tremaining: 1.65s\n",
      "594:\tlearn: 0.0491368\ttotal: 2.42s\tremaining: 1.65s\n",
      "595:\tlearn: 0.0490940\ttotal: 2.42s\tremaining: 1.64s\n",
      "596:\tlearn: 0.0490820\ttotal: 2.43s\tremaining: 1.64s\n",
      "597:\tlearn: 0.0490475\ttotal: 2.43s\tremaining: 1.64s\n",
      "598:\tlearn: 0.0489947\ttotal: 2.44s\tremaining: 1.63s\n",
      "599:\tlearn: 0.0489569\ttotal: 2.44s\tremaining: 1.63s\n",
      "600:\tlearn: 0.0489314\ttotal: 2.45s\tremaining: 1.62s\n",
      "601:\tlearn: 0.0488955\ttotal: 2.45s\tremaining: 1.62s\n",
      "602:\tlearn: 0.0488807\ttotal: 2.45s\tremaining: 1.62s\n",
      "603:\tlearn: 0.0488439\ttotal: 2.46s\tremaining: 1.61s\n",
      "604:\tlearn: 0.0488080\ttotal: 2.46s\tremaining: 1.61s\n",
      "605:\tlearn: 0.0487797\ttotal: 2.47s\tremaining: 1.6s\n",
      "606:\tlearn: 0.0487457\ttotal: 2.47s\tremaining: 1.6s\n",
      "607:\tlearn: 0.0486480\ttotal: 2.48s\tremaining: 1.6s\n",
      "608:\tlearn: 0.0486224\ttotal: 2.48s\tremaining: 1.59s\n",
      "609:\tlearn: 0.0485142\ttotal: 2.49s\tremaining: 1.59s\n",
      "610:\tlearn: 0.0484269\ttotal: 2.49s\tremaining: 1.58s\n",
      "611:\tlearn: 0.0483449\ttotal: 2.49s\tremaining: 1.58s\n",
      "612:\tlearn: 0.0483088\ttotal: 2.5s\tremaining: 1.58s\n",
      "613:\tlearn: 0.0482694\ttotal: 2.5s\tremaining: 1.57s\n",
      "614:\tlearn: 0.0482340\ttotal: 2.51s\tremaining: 1.57s\n",
      "615:\tlearn: 0.0481463\ttotal: 2.51s\tremaining: 1.56s\n",
      "616:\tlearn: 0.0480924\ttotal: 2.52s\tremaining: 1.56s\n",
      "617:\tlearn: 0.0480683\ttotal: 2.52s\tremaining: 1.56s\n",
      "618:\tlearn: 0.0480498\ttotal: 2.52s\tremaining: 1.55s\n",
      "619:\tlearn: 0.0480296\ttotal: 2.53s\tremaining: 1.55s\n",
      "620:\tlearn: 0.0479538\ttotal: 2.53s\tremaining: 1.54s\n",
      "621:\tlearn: 0.0478897\ttotal: 2.53s\tremaining: 1.54s\n",
      "622:\tlearn: 0.0478555\ttotal: 2.54s\tremaining: 1.54s\n",
      "623:\tlearn: 0.0478211\ttotal: 2.54s\tremaining: 1.53s\n",
      "624:\tlearn: 0.0477805\ttotal: 2.55s\tremaining: 1.53s\n",
      "625:\tlearn: 0.0477242\ttotal: 2.55s\tremaining: 1.52s\n",
      "626:\tlearn: 0.0476910\ttotal: 2.55s\tremaining: 1.52s\n",
      "627:\tlearn: 0.0476455\ttotal: 2.56s\tremaining: 1.51s\n",
      "628:\tlearn: 0.0475763\ttotal: 2.56s\tremaining: 1.51s\n",
      "629:\tlearn: 0.0475425\ttotal: 2.56s\tremaining: 1.51s\n",
      "630:\tlearn: 0.0474913\ttotal: 2.57s\tremaining: 1.5s\n",
      "631:\tlearn: 0.0474592\ttotal: 2.57s\tremaining: 1.5s\n",
      "632:\tlearn: 0.0473974\ttotal: 2.58s\tremaining: 1.49s\n",
      "633:\tlearn: 0.0473593\ttotal: 2.58s\tremaining: 1.49s\n",
      "634:\tlearn: 0.0472957\ttotal: 2.58s\tremaining: 1.49s\n",
      "635:\tlearn: 0.0472586\ttotal: 2.59s\tremaining: 1.48s\n",
      "636:\tlearn: 0.0472267\ttotal: 2.59s\tremaining: 1.48s\n",
      "637:\tlearn: 0.0472067\ttotal: 2.6s\tremaining: 1.47s\n",
      "638:\tlearn: 0.0471784\ttotal: 2.6s\tremaining: 1.47s\n",
      "639:\tlearn: 0.0471219\ttotal: 2.6s\tremaining: 1.46s\n",
      "640:\tlearn: 0.0470934\ttotal: 2.61s\tremaining: 1.46s\n",
      "641:\tlearn: 0.0470418\ttotal: 2.61s\tremaining: 1.46s\n",
      "642:\tlearn: 0.0470079\ttotal: 2.62s\tremaining: 1.45s\n",
      "643:\tlearn: 0.0469764\ttotal: 2.62s\tremaining: 1.45s\n",
      "644:\tlearn: 0.0469377\ttotal: 2.62s\tremaining: 1.44s\n",
      "645:\tlearn: 0.0468480\ttotal: 2.63s\tremaining: 1.44s\n",
      "646:\tlearn: 0.0468140\ttotal: 2.63s\tremaining: 1.44s\n",
      "647:\tlearn: 0.0467849\ttotal: 2.63s\tremaining: 1.43s\n",
      "648:\tlearn: 0.0466879\ttotal: 2.64s\tremaining: 1.43s\n",
      "649:\tlearn: 0.0466592\ttotal: 2.64s\tremaining: 1.42s\n",
      "650:\tlearn: 0.0466306\ttotal: 2.65s\tremaining: 1.42s\n",
      "651:\tlearn: 0.0465921\ttotal: 2.65s\tremaining: 1.42s\n",
      "652:\tlearn: 0.0465623\ttotal: 2.66s\tremaining: 1.41s\n",
      "653:\tlearn: 0.0465364\ttotal: 2.66s\tremaining: 1.41s\n",
      "654:\tlearn: 0.0464888\ttotal: 2.67s\tremaining: 1.4s\n",
      "655:\tlearn: 0.0464539\ttotal: 2.67s\tremaining: 1.4s\n",
      "656:\tlearn: 0.0464110\ttotal: 2.67s\tremaining: 1.4s\n",
      "657:\tlearn: 0.0463479\ttotal: 2.68s\tremaining: 1.39s\n",
      "658:\tlearn: 0.0462842\ttotal: 2.68s\tremaining: 1.39s\n",
      "659:\tlearn: 0.0462516\ttotal: 2.69s\tremaining: 1.38s\n",
      "660:\tlearn: 0.0461954\ttotal: 2.69s\tremaining: 1.38s\n",
      "661:\tlearn: 0.0461678\ttotal: 2.69s\tremaining: 1.38s\n",
      "662:\tlearn: 0.0461324\ttotal: 2.7s\tremaining: 1.37s\n",
      "663:\tlearn: 0.0461004\ttotal: 2.7s\tremaining: 1.37s\n",
      "664:\tlearn: 0.0460601\ttotal: 2.71s\tremaining: 1.36s\n",
      "665:\tlearn: 0.0460174\ttotal: 2.71s\tremaining: 1.36s\n",
      "666:\tlearn: 0.0459925\ttotal: 2.72s\tremaining: 1.36s\n",
      "667:\tlearn: 0.0459454\ttotal: 2.72s\tremaining: 1.35s\n",
      "668:\tlearn: 0.0458830\ttotal: 2.73s\tremaining: 1.35s\n",
      "669:\tlearn: 0.0458688\ttotal: 2.73s\tremaining: 1.34s\n",
      "670:\tlearn: 0.0458252\ttotal: 2.73s\tremaining: 1.34s\n",
      "671:\tlearn: 0.0457680\ttotal: 2.74s\tremaining: 1.34s\n",
      "672:\tlearn: 0.0457520\ttotal: 2.74s\tremaining: 1.33s\n",
      "673:\tlearn: 0.0457286\ttotal: 2.75s\tremaining: 1.33s\n",
      "674:\tlearn: 0.0456992\ttotal: 2.75s\tremaining: 1.32s\n",
      "675:\tlearn: 0.0456716\ttotal: 2.75s\tremaining: 1.32s\n",
      "676:\tlearn: 0.0456053\ttotal: 2.76s\tremaining: 1.32s\n",
      "677:\tlearn: 0.0455733\ttotal: 2.76s\tremaining: 1.31s\n",
      "678:\tlearn: 0.0455449\ttotal: 2.77s\tremaining: 1.31s\n",
      "679:\tlearn: 0.0455188\ttotal: 2.77s\tremaining: 1.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "680:\tlearn: 0.0455038\ttotal: 2.78s\tremaining: 1.3s\n",
      "681:\tlearn: 0.0454728\ttotal: 2.78s\tremaining: 1.3s\n",
      "682:\tlearn: 0.0454375\ttotal: 2.79s\tremaining: 1.29s\n",
      "683:\tlearn: 0.0454105\ttotal: 2.79s\tremaining: 1.29s\n",
      "684:\tlearn: 0.0453832\ttotal: 2.79s\tremaining: 1.28s\n",
      "685:\tlearn: 0.0453370\ttotal: 2.8s\tremaining: 1.28s\n",
      "686:\tlearn: 0.0452811\ttotal: 2.8s\tremaining: 1.28s\n",
      "687:\tlearn: 0.0452382\ttotal: 2.81s\tremaining: 1.27s\n",
      "688:\tlearn: 0.0452134\ttotal: 2.81s\tremaining: 1.27s\n",
      "689:\tlearn: 0.0451930\ttotal: 2.81s\tremaining: 1.26s\n",
      "690:\tlearn: 0.0451332\ttotal: 2.82s\tremaining: 1.26s\n",
      "691:\tlearn: 0.0450642\ttotal: 2.82s\tremaining: 1.26s\n",
      "692:\tlearn: 0.0450358\ttotal: 2.83s\tremaining: 1.25s\n",
      "693:\tlearn: 0.0449544\ttotal: 2.83s\tremaining: 1.25s\n",
      "694:\tlearn: 0.0449216\ttotal: 2.83s\tremaining: 1.24s\n",
      "695:\tlearn: 0.0448971\ttotal: 2.84s\tremaining: 1.24s\n",
      "696:\tlearn: 0.0448409\ttotal: 2.84s\tremaining: 1.24s\n",
      "697:\tlearn: 0.0448170\ttotal: 2.85s\tremaining: 1.23s\n",
      "698:\tlearn: 0.0447776\ttotal: 2.85s\tremaining: 1.23s\n",
      "699:\tlearn: 0.0447583\ttotal: 2.85s\tremaining: 1.22s\n",
      "700:\tlearn: 0.0447411\ttotal: 2.86s\tremaining: 1.22s\n",
      "701:\tlearn: 0.0447117\ttotal: 2.86s\tremaining: 1.22s\n",
      "702:\tlearn: 0.0446789\ttotal: 2.87s\tremaining: 1.21s\n",
      "703:\tlearn: 0.0446363\ttotal: 2.87s\tremaining: 1.21s\n",
      "704:\tlearn: 0.0446123\ttotal: 2.87s\tremaining: 1.2s\n",
      "705:\tlearn: 0.0445747\ttotal: 2.88s\tremaining: 1.2s\n",
      "706:\tlearn: 0.0445370\ttotal: 2.88s\tremaining: 1.19s\n",
      "707:\tlearn: 0.0445112\ttotal: 2.89s\tremaining: 1.19s\n",
      "708:\tlearn: 0.0444974\ttotal: 2.89s\tremaining: 1.19s\n",
      "709:\tlearn: 0.0444735\ttotal: 2.89s\tremaining: 1.18s\n",
      "710:\tlearn: 0.0444009\ttotal: 2.9s\tremaining: 1.18s\n",
      "711:\tlearn: 0.0443772\ttotal: 2.9s\tremaining: 1.17s\n",
      "712:\tlearn: 0.0443451\ttotal: 2.91s\tremaining: 1.17s\n",
      "713:\tlearn: 0.0443060\ttotal: 2.91s\tremaining: 1.17s\n",
      "714:\tlearn: 0.0442530\ttotal: 2.92s\tremaining: 1.16s\n",
      "715:\tlearn: 0.0441655\ttotal: 2.92s\tremaining: 1.16s\n",
      "716:\tlearn: 0.0441284\ttotal: 2.92s\tremaining: 1.15s\n",
      "717:\tlearn: 0.0441051\ttotal: 2.93s\tremaining: 1.15s\n",
      "718:\tlearn: 0.0440757\ttotal: 2.93s\tremaining: 1.15s\n",
      "719:\tlearn: 0.0439983\ttotal: 2.93s\tremaining: 1.14s\n",
      "720:\tlearn: 0.0439714\ttotal: 2.94s\tremaining: 1.14s\n",
      "721:\tlearn: 0.0439479\ttotal: 2.94s\tremaining: 1.13s\n",
      "722:\tlearn: 0.0439090\ttotal: 2.94s\tremaining: 1.13s\n",
      "723:\tlearn: 0.0438716\ttotal: 2.95s\tremaining: 1.12s\n",
      "724:\tlearn: 0.0438316\ttotal: 2.95s\tremaining: 1.12s\n",
      "725:\tlearn: 0.0438038\ttotal: 2.96s\tremaining: 1.11s\n",
      "726:\tlearn: 0.0437807\ttotal: 2.96s\tremaining: 1.11s\n",
      "727:\tlearn: 0.0437473\ttotal: 2.96s\tremaining: 1.11s\n",
      "728:\tlearn: 0.0437146\ttotal: 2.97s\tremaining: 1.1s\n",
      "729:\tlearn: 0.0436622\ttotal: 2.97s\tremaining: 1.1s\n",
      "730:\tlearn: 0.0436367\ttotal: 2.98s\tremaining: 1.09s\n",
      "731:\tlearn: 0.0435873\ttotal: 2.98s\tremaining: 1.09s\n",
      "732:\tlearn: 0.0435639\ttotal: 2.98s\tremaining: 1.09s\n",
      "733:\tlearn: 0.0435261\ttotal: 2.99s\tremaining: 1.08s\n",
      "734:\tlearn: 0.0434950\ttotal: 2.99s\tremaining: 1.08s\n",
      "735:\tlearn: 0.0434653\ttotal: 2.99s\tremaining: 1.07s\n",
      "736:\tlearn: 0.0434334\ttotal: 3s\tremaining: 1.07s\n",
      "737:\tlearn: 0.0433732\ttotal: 3s\tremaining: 1.06s\n",
      "738:\tlearn: 0.0433335\ttotal: 3s\tremaining: 1.06s\n",
      "739:\tlearn: 0.0432875\ttotal: 3.01s\tremaining: 1.06s\n",
      "740:\tlearn: 0.0432366\ttotal: 3.01s\tremaining: 1.05s\n",
      "741:\tlearn: 0.0432073\ttotal: 3.02s\tremaining: 1.05s\n",
      "742:\tlearn: 0.0431766\ttotal: 3.02s\tremaining: 1.04s\n",
      "743:\tlearn: 0.0431532\ttotal: 3.02s\tremaining: 1.04s\n",
      "744:\tlearn: 0.0431142\ttotal: 3.03s\tremaining: 1.04s\n",
      "745:\tlearn: 0.0430879\ttotal: 3.03s\tremaining: 1.03s\n",
      "746:\tlearn: 0.0430629\ttotal: 3.04s\tremaining: 1.03s\n",
      "747:\tlearn: 0.0430364\ttotal: 3.04s\tremaining: 1.02s\n",
      "748:\tlearn: 0.0430056\ttotal: 3.04s\tremaining: 1.02s\n",
      "749:\tlearn: 0.0429718\ttotal: 3.05s\tremaining: 1.01s\n",
      "750:\tlearn: 0.0429440\ttotal: 3.05s\tremaining: 1.01s\n",
      "751:\tlearn: 0.0428970\ttotal: 3.06s\tremaining: 1.01s\n",
      "752:\tlearn: 0.0428750\ttotal: 3.06s\tremaining: 1s\n",
      "753:\tlearn: 0.0428280\ttotal: 3.06s\tremaining: 999ms\n",
      "754:\tlearn: 0.0428126\ttotal: 3.07s\tremaining: 995ms\n",
      "755:\tlearn: 0.0427681\ttotal: 3.07s\tremaining: 991ms\n",
      "756:\tlearn: 0.0427014\ttotal: 3.07s\tremaining: 987ms\n",
      "757:\tlearn: 0.0426472\ttotal: 3.08s\tremaining: 982ms\n",
      "758:\tlearn: 0.0426206\ttotal: 3.08s\tremaining: 978ms\n",
      "759:\tlearn: 0.0425993\ttotal: 3.08s\tremaining: 974ms\n",
      "760:\tlearn: 0.0425668\ttotal: 3.09s\tremaining: 970ms\n",
      "761:\tlearn: 0.0425116\ttotal: 3.09s\tremaining: 966ms\n",
      "762:\tlearn: 0.0424911\ttotal: 3.1s\tremaining: 962ms\n",
      "763:\tlearn: 0.0424595\ttotal: 3.1s\tremaining: 957ms\n",
      "764:\tlearn: 0.0424326\ttotal: 3.1s\tremaining: 953ms\n",
      "765:\tlearn: 0.0423679\ttotal: 3.11s\tremaining: 949ms\n",
      "766:\tlearn: 0.0423416\ttotal: 3.11s\tremaining: 945ms\n",
      "767:\tlearn: 0.0422548\ttotal: 3.11s\tremaining: 941ms\n",
      "768:\tlearn: 0.0421923\ttotal: 3.12s\tremaining: 937ms\n",
      "769:\tlearn: 0.0421646\ttotal: 3.12s\tremaining: 933ms\n",
      "770:\tlearn: 0.0421365\ttotal: 3.13s\tremaining: 929ms\n",
      "771:\tlearn: 0.0420808\ttotal: 3.13s\tremaining: 924ms\n",
      "772:\tlearn: 0.0420442\ttotal: 3.13s\tremaining: 920ms\n",
      "773:\tlearn: 0.0420035\ttotal: 3.14s\tremaining: 916ms\n",
      "774:\tlearn: 0.0419834\ttotal: 3.14s\tremaining: 912ms\n",
      "775:\tlearn: 0.0419611\ttotal: 3.15s\tremaining: 908ms\n",
      "776:\tlearn: 0.0419293\ttotal: 3.15s\tremaining: 904ms\n",
      "777:\tlearn: 0.0418588\ttotal: 3.15s\tremaining: 900ms\n",
      "778:\tlearn: 0.0418344\ttotal: 3.16s\tremaining: 896ms\n",
      "779:\tlearn: 0.0418148\ttotal: 3.16s\tremaining: 892ms\n",
      "780:\tlearn: 0.0417549\ttotal: 3.17s\tremaining: 888ms\n",
      "781:\tlearn: 0.0416870\ttotal: 3.17s\tremaining: 884ms\n",
      "782:\tlearn: 0.0416436\ttotal: 3.17s\tremaining: 880ms\n",
      "783:\tlearn: 0.0415961\ttotal: 3.18s\tremaining: 876ms\n",
      "784:\tlearn: 0.0415712\ttotal: 3.18s\tremaining: 872ms\n",
      "785:\tlearn: 0.0415435\ttotal: 3.19s\tremaining: 867ms\n",
      "786:\tlearn: 0.0415244\ttotal: 3.19s\tremaining: 863ms\n",
      "787:\tlearn: 0.0414984\ttotal: 3.19s\tremaining: 859ms\n",
      "788:\tlearn: 0.0414568\ttotal: 3.2s\tremaining: 855ms\n",
      "789:\tlearn: 0.0414372\ttotal: 3.2s\tremaining: 851ms\n",
      "790:\tlearn: 0.0414213\ttotal: 3.21s\tremaining: 847ms\n",
      "791:\tlearn: 0.0414049\ttotal: 3.21s\tremaining: 843ms\n",
      "792:\tlearn: 0.0413743\ttotal: 3.21s\tremaining: 838ms\n",
      "793:\tlearn: 0.0413504\ttotal: 3.21s\tremaining: 834ms\n",
      "794:\tlearn: 0.0413340\ttotal: 3.22s\tremaining: 830ms\n",
      "795:\tlearn: 0.0412895\ttotal: 3.22s\tremaining: 826ms\n",
      "796:\tlearn: 0.0412310\ttotal: 3.23s\tremaining: 822ms\n",
      "797:\tlearn: 0.0411787\ttotal: 3.23s\tremaining: 818ms\n",
      "798:\tlearn: 0.0411602\ttotal: 3.23s\tremaining: 814ms\n",
      "799:\tlearn: 0.0411266\ttotal: 3.24s\tremaining: 809ms\n",
      "800:\tlearn: 0.0410907\ttotal: 3.24s\tremaining: 805ms\n",
      "801:\tlearn: 0.0410656\ttotal: 3.24s\tremaining: 801ms\n",
      "802:\tlearn: 0.0409953\ttotal: 3.25s\tremaining: 797ms\n",
      "803:\tlearn: 0.0409634\ttotal: 3.25s\tremaining: 793ms\n",
      "804:\tlearn: 0.0409378\ttotal: 3.26s\tremaining: 789ms\n",
      "805:\tlearn: 0.0408977\ttotal: 3.26s\tremaining: 785ms\n",
      "806:\tlearn: 0.0408752\ttotal: 3.26s\tremaining: 781ms\n",
      "807:\tlearn: 0.0408120\ttotal: 3.27s\tremaining: 777ms\n",
      "808:\tlearn: 0.0407439\ttotal: 3.27s\tremaining: 772ms\n",
      "809:\tlearn: 0.0406805\ttotal: 3.27s\tremaining: 768ms\n",
      "810:\tlearn: 0.0406715\ttotal: 3.28s\tremaining: 764ms\n",
      "811:\tlearn: 0.0406179\ttotal: 3.28s\tremaining: 760ms\n",
      "812:\tlearn: 0.0405946\ttotal: 3.29s\tremaining: 756ms\n",
      "813:\tlearn: 0.0405764\ttotal: 3.29s\tremaining: 752ms\n",
      "814:\tlearn: 0.0405596\ttotal: 3.29s\tremaining: 748ms\n",
      "815:\tlearn: 0.0405288\ttotal: 3.3s\tremaining: 744ms\n",
      "816:\tlearn: 0.0405086\ttotal: 3.3s\tremaining: 739ms\n",
      "817:\tlearn: 0.0404937\ttotal: 3.3s\tremaining: 735ms\n",
      "818:\tlearn: 0.0404321\ttotal: 3.31s\tremaining: 731ms\n",
      "819:\tlearn: 0.0403669\ttotal: 3.31s\tremaining: 727ms\n",
      "820:\tlearn: 0.0403087\ttotal: 3.32s\tremaining: 723ms\n",
      "821:\tlearn: 0.0402801\ttotal: 3.32s\tremaining: 719ms\n",
      "822:\tlearn: 0.0402334\ttotal: 3.32s\tremaining: 715ms\n",
      "823:\tlearn: 0.0402124\ttotal: 3.33s\tremaining: 711ms\n",
      "824:\tlearn: 0.0401875\ttotal: 3.33s\tremaining: 707ms\n",
      "825:\tlearn: 0.0401649\ttotal: 3.33s\tremaining: 703ms\n",
      "826:\tlearn: 0.0401330\ttotal: 3.34s\tremaining: 698ms\n",
      "827:\tlearn: 0.0401043\ttotal: 3.34s\tremaining: 694ms\n",
      "828:\tlearn: 0.0400822\ttotal: 3.35s\tremaining: 690ms\n",
      "829:\tlearn: 0.0400542\ttotal: 3.35s\tremaining: 686ms\n",
      "830:\tlearn: 0.0400037\ttotal: 3.35s\tremaining: 682ms\n",
      "831:\tlearn: 0.0399833\ttotal: 3.36s\tremaining: 678ms\n",
      "832:\tlearn: 0.0399373\ttotal: 3.36s\tremaining: 674ms\n",
      "833:\tlearn: 0.0399143\ttotal: 3.37s\tremaining: 670ms\n",
      "834:\tlearn: 0.0398835\ttotal: 3.37s\tremaining: 666ms\n",
      "835:\tlearn: 0.0398647\ttotal: 3.37s\tremaining: 662ms\n",
      "836:\tlearn: 0.0398124\ttotal: 3.38s\tremaining: 658ms\n",
      "837:\tlearn: 0.0397844\ttotal: 3.38s\tremaining: 654ms\n",
      "838:\tlearn: 0.0397513\ttotal: 3.39s\tremaining: 650ms\n",
      "839:\tlearn: 0.0397324\ttotal: 3.39s\tremaining: 646ms\n",
      "840:\tlearn: 0.0397230\ttotal: 3.39s\tremaining: 642ms\n",
      "841:\tlearn: 0.0396610\ttotal: 3.4s\tremaining: 638ms\n",
      "842:\tlearn: 0.0396334\ttotal: 3.4s\tremaining: 634ms\n",
      "843:\tlearn: 0.0395893\ttotal: 3.4s\tremaining: 629ms\n",
      "844:\tlearn: 0.0395121\ttotal: 3.41s\tremaining: 625ms\n",
      "845:\tlearn: 0.0394969\ttotal: 3.41s\tremaining: 621ms\n",
      "846:\tlearn: 0.0394755\ttotal: 3.42s\tremaining: 617ms\n",
      "847:\tlearn: 0.0394553\ttotal: 3.42s\tremaining: 613ms\n",
      "848:\tlearn: 0.0394242\ttotal: 3.42s\tremaining: 609ms\n",
      "849:\tlearn: 0.0394055\ttotal: 3.43s\tremaining: 605ms\n",
      "850:\tlearn: 0.0393507\ttotal: 3.43s\tremaining: 601ms\n",
      "851:\tlearn: 0.0393312\ttotal: 3.43s\tremaining: 597ms\n",
      "852:\tlearn: 0.0393124\ttotal: 3.44s\tremaining: 593ms\n",
      "853:\tlearn: 0.0392590\ttotal: 3.44s\tremaining: 589ms\n",
      "854:\tlearn: 0.0392395\ttotal: 3.45s\tremaining: 584ms\n",
      "855:\tlearn: 0.0391412\ttotal: 3.45s\tremaining: 580ms\n",
      "856:\tlearn: 0.0391220\ttotal: 3.45s\tremaining: 576ms\n",
      "857:\tlearn: 0.0390650\ttotal: 3.46s\tremaining: 572ms\n",
      "858:\tlearn: 0.0390490\ttotal: 3.46s\tremaining: 568ms\n",
      "859:\tlearn: 0.0390284\ttotal: 3.46s\tremaining: 564ms\n",
      "860:\tlearn: 0.0389998\ttotal: 3.47s\tremaining: 560ms\n",
      "861:\tlearn: 0.0389833\ttotal: 3.47s\tremaining: 556ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "862:\tlearn: 0.0389531\ttotal: 3.48s\tremaining: 552ms\n",
      "863:\tlearn: 0.0389362\ttotal: 3.48s\tremaining: 548ms\n",
      "864:\tlearn: 0.0389103\ttotal: 3.48s\tremaining: 543ms\n",
      "865:\tlearn: 0.0388797\ttotal: 3.48s\tremaining: 539ms\n",
      "866:\tlearn: 0.0388616\ttotal: 3.49s\tremaining: 535ms\n",
      "867:\tlearn: 0.0388370\ttotal: 3.49s\tremaining: 531ms\n",
      "868:\tlearn: 0.0388086\ttotal: 3.5s\tremaining: 527ms\n",
      "869:\tlearn: 0.0387925\ttotal: 3.5s\tremaining: 523ms\n",
      "870:\tlearn: 0.0387030\ttotal: 3.5s\tremaining: 519ms\n",
      "871:\tlearn: 0.0386912\ttotal: 3.51s\tremaining: 515ms\n",
      "872:\tlearn: 0.0386200\ttotal: 3.51s\tremaining: 511ms\n",
      "873:\tlearn: 0.0385918\ttotal: 3.52s\tremaining: 507ms\n",
      "874:\tlearn: 0.0385413\ttotal: 3.52s\tremaining: 503ms\n",
      "875:\tlearn: 0.0385297\ttotal: 3.52s\tremaining: 499ms\n",
      "876:\tlearn: 0.0384943\ttotal: 3.53s\tremaining: 495ms\n",
      "877:\tlearn: 0.0384828\ttotal: 3.53s\tremaining: 491ms\n",
      "878:\tlearn: 0.0384609\ttotal: 3.54s\tremaining: 487ms\n",
      "879:\tlearn: 0.0384353\ttotal: 3.54s\tremaining: 483ms\n",
      "880:\tlearn: 0.0383647\ttotal: 3.54s\tremaining: 479ms\n",
      "881:\tlearn: 0.0383152\ttotal: 3.55s\tremaining: 474ms\n",
      "882:\tlearn: 0.0383040\ttotal: 3.55s\tremaining: 470ms\n",
      "883:\tlearn: 0.0382335\ttotal: 3.55s\tremaining: 466ms\n",
      "884:\tlearn: 0.0381689\ttotal: 3.56s\tremaining: 462ms\n",
      "885:\tlearn: 0.0381368\ttotal: 3.56s\tremaining: 458ms\n",
      "886:\tlearn: 0.0380875\ttotal: 3.56s\tremaining: 454ms\n",
      "887:\tlearn: 0.0380603\ttotal: 3.57s\tremaining: 450ms\n",
      "888:\tlearn: 0.0380329\ttotal: 3.57s\tremaining: 446ms\n",
      "889:\tlearn: 0.0380105\ttotal: 3.57s\tremaining: 442ms\n",
      "890:\tlearn: 0.0379871\ttotal: 3.58s\tremaining: 438ms\n",
      "891:\tlearn: 0.0379461\ttotal: 3.58s\tremaining: 434ms\n",
      "892:\tlearn: 0.0379336\ttotal: 3.58s\tremaining: 430ms\n",
      "893:\tlearn: 0.0379208\ttotal: 3.59s\tremaining: 426ms\n",
      "894:\tlearn: 0.0378589\ttotal: 3.59s\tremaining: 422ms\n",
      "895:\tlearn: 0.0377938\ttotal: 3.6s\tremaining: 417ms\n",
      "896:\tlearn: 0.0377563\ttotal: 3.6s\tremaining: 413ms\n",
      "897:\tlearn: 0.0377147\ttotal: 3.6s\tremaining: 409ms\n",
      "898:\tlearn: 0.0377024\ttotal: 3.61s\tremaining: 405ms\n",
      "899:\tlearn: 0.0376864\ttotal: 3.61s\tremaining: 401ms\n",
      "900:\tlearn: 0.0376596\ttotal: 3.61s\tremaining: 397ms\n",
      "901:\tlearn: 0.0376172\ttotal: 3.62s\tremaining: 393ms\n",
      "902:\tlearn: 0.0375972\ttotal: 3.62s\tremaining: 389ms\n",
      "903:\tlearn: 0.0375082\ttotal: 3.62s\tremaining: 385ms\n",
      "904:\tlearn: 0.0374904\ttotal: 3.63s\tremaining: 381ms\n",
      "905:\tlearn: 0.0374706\ttotal: 3.63s\tremaining: 377ms\n",
      "906:\tlearn: 0.0374369\ttotal: 3.63s\tremaining: 373ms\n",
      "907:\tlearn: 0.0373875\ttotal: 3.64s\tremaining: 369ms\n",
      "908:\tlearn: 0.0373301\ttotal: 3.64s\tremaining: 365ms\n",
      "909:\tlearn: 0.0372638\ttotal: 3.65s\tremaining: 361ms\n",
      "910:\tlearn: 0.0372183\ttotal: 3.65s\tremaining: 357ms\n",
      "911:\tlearn: 0.0371290\ttotal: 3.65s\tremaining: 353ms\n",
      "912:\tlearn: 0.0370701\ttotal: 3.66s\tremaining: 349ms\n",
      "913:\tlearn: 0.0370249\ttotal: 3.66s\tremaining: 345ms\n",
      "914:\tlearn: 0.0370075\ttotal: 3.67s\tremaining: 341ms\n",
      "915:\tlearn: 0.0369611\ttotal: 3.67s\tremaining: 337ms\n",
      "916:\tlearn: 0.0369507\ttotal: 3.67s\tremaining: 333ms\n",
      "917:\tlearn: 0.0368854\ttotal: 3.68s\tremaining: 329ms\n",
      "918:\tlearn: 0.0367988\ttotal: 3.68s\tremaining: 324ms\n",
      "919:\tlearn: 0.0367779\ttotal: 3.69s\tremaining: 320ms\n",
      "920:\tlearn: 0.0367676\ttotal: 3.69s\tremaining: 316ms\n",
      "921:\tlearn: 0.0367575\ttotal: 3.69s\tremaining: 312ms\n",
      "922:\tlearn: 0.0367338\ttotal: 3.7s\tremaining: 308ms\n",
      "923:\tlearn: 0.0366585\ttotal: 3.7s\tremaining: 304ms\n",
      "924:\tlearn: 0.0366137\ttotal: 3.7s\tremaining: 300ms\n",
      "925:\tlearn: 0.0365904\ttotal: 3.71s\tremaining: 296ms\n",
      "926:\tlearn: 0.0365046\ttotal: 3.71s\tremaining: 292ms\n",
      "927:\tlearn: 0.0364613\ttotal: 3.71s\tremaining: 288ms\n",
      "928:\tlearn: 0.0364513\ttotal: 3.72s\tremaining: 284ms\n",
      "929:\tlearn: 0.0364400\ttotal: 3.72s\tremaining: 280ms\n",
      "930:\tlearn: 0.0364199\ttotal: 3.73s\tremaining: 276ms\n",
      "931:\tlearn: 0.0363955\ttotal: 3.73s\tremaining: 272ms\n",
      "932:\tlearn: 0.0363287\ttotal: 3.73s\tremaining: 268ms\n",
      "933:\tlearn: 0.0363084\ttotal: 3.74s\tremaining: 264ms\n",
      "934:\tlearn: 0.0362906\ttotal: 3.74s\tremaining: 260ms\n",
      "935:\tlearn: 0.0362783\ttotal: 3.74s\tremaining: 256ms\n",
      "936:\tlearn: 0.0362577\ttotal: 3.75s\tremaining: 252ms\n",
      "937:\tlearn: 0.0362147\ttotal: 3.75s\tremaining: 248ms\n",
      "938:\tlearn: 0.0361821\ttotal: 3.75s\tremaining: 244ms\n",
      "939:\tlearn: 0.0361200\ttotal: 3.76s\tremaining: 240ms\n",
      "940:\tlearn: 0.0360894\ttotal: 3.76s\tremaining: 236ms\n",
      "941:\tlearn: 0.0360696\ttotal: 3.77s\tremaining: 232ms\n",
      "942:\tlearn: 0.0360501\ttotal: 3.77s\tremaining: 228ms\n",
      "943:\tlearn: 0.0360032\ttotal: 3.77s\tremaining: 224ms\n",
      "944:\tlearn: 0.0359580\ttotal: 3.77s\tremaining: 220ms\n",
      "945:\tlearn: 0.0359388\ttotal: 3.78s\tremaining: 216ms\n",
      "946:\tlearn: 0.0359293\ttotal: 3.78s\tremaining: 212ms\n",
      "947:\tlearn: 0.0359199\ttotal: 3.79s\tremaining: 208ms\n",
      "948:\tlearn: 0.0359009\ttotal: 3.79s\tremaining: 204ms\n",
      "949:\tlearn: 0.0358401\ttotal: 3.79s\tremaining: 200ms\n",
      "950:\tlearn: 0.0358209\ttotal: 3.8s\tremaining: 196ms\n",
      "951:\tlearn: 0.0357810\ttotal: 3.8s\tremaining: 192ms\n",
      "952:\tlearn: 0.0357352\ttotal: 3.81s\tremaining: 188ms\n",
      "953:\tlearn: 0.0356949\ttotal: 3.81s\tremaining: 184ms\n",
      "954:\tlearn: 0.0356843\ttotal: 3.81s\tremaining: 180ms\n",
      "955:\tlearn: 0.0356752\ttotal: 3.82s\tremaining: 176ms\n",
      "956:\tlearn: 0.0355972\ttotal: 3.82s\tremaining: 172ms\n",
      "957:\tlearn: 0.0355752\ttotal: 3.83s\tremaining: 168ms\n",
      "958:\tlearn: 0.0355584\ttotal: 3.83s\tremaining: 164ms\n",
      "959:\tlearn: 0.0355494\ttotal: 3.83s\tremaining: 160ms\n",
      "960:\tlearn: 0.0355378\ttotal: 3.84s\tremaining: 156ms\n",
      "961:\tlearn: 0.0354777\ttotal: 3.84s\tremaining: 152ms\n",
      "962:\tlearn: 0.0354315\ttotal: 3.84s\tremaining: 148ms\n",
      "963:\tlearn: 0.0353723\ttotal: 3.85s\tremaining: 144ms\n",
      "964:\tlearn: 0.0353330\ttotal: 3.85s\tremaining: 140ms\n",
      "965:\tlearn: 0.0352498\ttotal: 3.85s\tremaining: 136ms\n",
      "966:\tlearn: 0.0352383\ttotal: 3.86s\tremaining: 132ms\n",
      "967:\tlearn: 0.0351943\ttotal: 3.86s\tremaining: 128ms\n",
      "968:\tlearn: 0.0351754\ttotal: 3.87s\tremaining: 124ms\n",
      "969:\tlearn: 0.0351571\ttotal: 3.87s\tremaining: 120ms\n",
      "970:\tlearn: 0.0351388\ttotal: 3.88s\tremaining: 116ms\n",
      "971:\tlearn: 0.0350945\ttotal: 3.88s\tremaining: 112ms\n",
      "972:\tlearn: 0.0350436\ttotal: 3.88s\tremaining: 108ms\n",
      "973:\tlearn: 0.0350255\ttotal: 3.89s\tremaining: 104ms\n",
      "974:\tlearn: 0.0349838\ttotal: 3.89s\tremaining: 99.8ms\n",
      "975:\tlearn: 0.0349441\ttotal: 3.9s\tremaining: 95.8ms\n",
      "976:\tlearn: 0.0349134\ttotal: 3.9s\tremaining: 91.8ms\n",
      "977:\tlearn: 0.0348979\ttotal: 3.9s\tremaining: 87.8ms\n",
      "978:\tlearn: 0.0348799\ttotal: 3.91s\tremaining: 83.8ms\n",
      "979:\tlearn: 0.0348494\ttotal: 3.91s\tremaining: 79.8ms\n",
      "980:\tlearn: 0.0348407\ttotal: 3.92s\tremaining: 75.9ms\n",
      "981:\tlearn: 0.0348070\ttotal: 3.92s\tremaining: 71.9ms\n",
      "982:\tlearn: 0.0347564\ttotal: 3.93s\tremaining: 67.9ms\n",
      "983:\tlearn: 0.0347189\ttotal: 3.93s\tremaining: 63.9ms\n",
      "984:\tlearn: 0.0346994\ttotal: 3.93s\tremaining: 59.9ms\n",
      "985:\tlearn: 0.0346785\ttotal: 3.94s\tremaining: 55.9ms\n",
      "986:\tlearn: 0.0346609\ttotal: 3.94s\tremaining: 51.9ms\n",
      "987:\tlearn: 0.0346501\ttotal: 3.94s\tremaining: 47.9ms\n",
      "988:\tlearn: 0.0346016\ttotal: 3.95s\tremaining: 43.9ms\n",
      "989:\tlearn: 0.0345592\ttotal: 3.95s\tremaining: 39.9ms\n",
      "990:\tlearn: 0.0345296\ttotal: 3.96s\tremaining: 35.9ms\n",
      "991:\tlearn: 0.0344739\ttotal: 3.96s\tremaining: 31.9ms\n",
      "992:\tlearn: 0.0344441\ttotal: 3.96s\tremaining: 27.9ms\n",
      "993:\tlearn: 0.0344062\ttotal: 3.97s\tremaining: 23.9ms\n",
      "994:\tlearn: 0.0343767\ttotal: 3.97s\tremaining: 20ms\n",
      "995:\tlearn: 0.0343640\ttotal: 3.97s\tremaining: 16ms\n",
      "996:\tlearn: 0.0343275\ttotal: 3.98s\tremaining: 12ms\n",
      "997:\tlearn: 0.0342691\ttotal: 3.98s\tremaining: 7.98ms\n",
      "998:\tlearn: 0.0342508\ttotal: 3.98s\tremaining: 3.99ms\n",
      "999:\tlearn: 0.0342328\ttotal: 3.99s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013276\n",
      "0:\tlearn: 0.6682213\ttotal: 6.78ms\tremaining: 6.78s\n",
      "1:\tlearn: 0.6425727\ttotal: 11ms\tremaining: 5.5s\n",
      "2:\tlearn: 0.6201333\ttotal: 15.4ms\tremaining: 5.12s\n",
      "3:\tlearn: 0.5964613\ttotal: 20.2ms\tremaining: 5.04s\n",
      "4:\tlearn: 0.5744830\ttotal: 24.4ms\tremaining: 4.85s\n",
      "5:\tlearn: 0.5531827\ttotal: 28.5ms\tremaining: 4.72s\n",
      "6:\tlearn: 0.5341614\ttotal: 34.5ms\tremaining: 4.9s\n",
      "7:\tlearn: 0.5166779\ttotal: 38.8ms\tremaining: 4.82s\n",
      "8:\tlearn: 0.4976639\ttotal: 43.2ms\tremaining: 4.76s\n",
      "9:\tlearn: 0.4808986\ttotal: 47.5ms\tremaining: 4.7s\n",
      "10:\tlearn: 0.4649693\ttotal: 52.2ms\tremaining: 4.69s\n",
      "11:\tlearn: 0.4500715\ttotal: 56.3ms\tremaining: 4.63s\n",
      "12:\tlearn: 0.4348467\ttotal: 60.6ms\tremaining: 4.6s\n",
      "13:\tlearn: 0.4204162\ttotal: 66.7ms\tremaining: 4.69s\n",
      "14:\tlearn: 0.4081438\ttotal: 70.8ms\tremaining: 4.65s\n",
      "15:\tlearn: 0.3956356\ttotal: 74.8ms\tremaining: 4.6s\n",
      "16:\tlearn: 0.3831185\ttotal: 79.7ms\tremaining: 4.61s\n",
      "17:\tlearn: 0.3709154\ttotal: 84.5ms\tremaining: 4.61s\n",
      "18:\tlearn: 0.3602205\ttotal: 88.7ms\tremaining: 4.58s\n",
      "19:\tlearn: 0.3504145\ttotal: 93.7ms\tremaining: 4.59s\n",
      "20:\tlearn: 0.3410964\ttotal: 99.5ms\tremaining: 4.64s\n",
      "21:\tlearn: 0.3312065\ttotal: 104ms\tremaining: 4.61s\n",
      "22:\tlearn: 0.3221205\ttotal: 109ms\tremaining: 4.61s\n",
      "23:\tlearn: 0.3143506\ttotal: 114ms\tremaining: 4.63s\n",
      "24:\tlearn: 0.3063586\ttotal: 118ms\tremaining: 4.59s\n",
      "25:\tlearn: 0.3003081\ttotal: 122ms\tremaining: 4.57s\n",
      "26:\tlearn: 0.2927392\ttotal: 127ms\tremaining: 4.56s\n",
      "27:\tlearn: 0.2861850\ttotal: 132ms\tremaining: 4.57s\n",
      "28:\tlearn: 0.2787189\ttotal: 136ms\tremaining: 4.54s\n",
      "29:\tlearn: 0.2721519\ttotal: 140ms\tremaining: 4.52s\n",
      "30:\tlearn: 0.2658355\ttotal: 144ms\tremaining: 4.5s\n",
      "31:\tlearn: 0.2599404\ttotal: 148ms\tremaining: 4.47s\n",
      "32:\tlearn: 0.2545069\ttotal: 152ms\tremaining: 4.45s\n",
      "33:\tlearn: 0.2495002\ttotal: 156ms\tremaining: 4.43s\n",
      "34:\tlearn: 0.2456188\ttotal: 160ms\tremaining: 4.41s\n",
      "35:\tlearn: 0.2403045\ttotal: 164ms\tremaining: 4.38s\n",
      "36:\tlearn: 0.2358956\ttotal: 168ms\tremaining: 4.36s\n",
      "37:\tlearn: 0.2314399\ttotal: 172ms\tremaining: 4.35s\n",
      "38:\tlearn: 0.2272798\ttotal: 176ms\tremaining: 4.34s\n",
      "39:\tlearn: 0.2229537\ttotal: 180ms\tremaining: 4.32s\n",
      "40:\tlearn: 0.2186205\ttotal: 184ms\tremaining: 4.3s\n",
      "41:\tlearn: 0.2149583\ttotal: 189ms\tremaining: 4.31s\n",
      "42:\tlearn: 0.2120182\ttotal: 193ms\tremaining: 4.3s\n",
      "43:\tlearn: 0.2091219\ttotal: 197ms\tremaining: 4.28s\n",
      "44:\tlearn: 0.2056702\ttotal: 201ms\tremaining: 4.27s\n",
      "45:\tlearn: 0.2026522\ttotal: 205ms\tremaining: 4.25s\n",
      "46:\tlearn: 0.1998888\ttotal: 209ms\tremaining: 4.23s\n",
      "47:\tlearn: 0.1964025\ttotal: 213ms\tremaining: 4.23s\n",
      "48:\tlearn: 0.1938497\ttotal: 219ms\tremaining: 4.25s\n",
      "49:\tlearn: 0.1908817\ttotal: 225ms\tremaining: 4.27s\n",
      "50:\tlearn: 0.1881758\ttotal: 229ms\tremaining: 4.26s\n",
      "51:\tlearn: 0.1859525\ttotal: 234ms\tremaining: 4.27s\n",
      "52:\tlearn: 0.1835437\ttotal: 238ms\tremaining: 4.26s\n",
      "53:\tlearn: 0.1816925\ttotal: 242ms\tremaining: 4.24s\n",
      "54:\tlearn: 0.1796035\ttotal: 246ms\tremaining: 4.23s\n",
      "55:\tlearn: 0.1772525\ttotal: 252ms\tremaining: 4.25s\n",
      "56:\tlearn: 0.1749499\ttotal: 257ms\tremaining: 4.25s\n",
      "57:\tlearn: 0.1733914\ttotal: 261ms\tremaining: 4.24s\n",
      "58:\tlearn: 0.1716210\ttotal: 265ms\tremaining: 4.23s\n",
      "59:\tlearn: 0.1698168\ttotal: 270ms\tremaining: 4.23s\n",
      "60:\tlearn: 0.1682340\ttotal: 274ms\tremaining: 4.22s\n",
      "61:\tlearn: 0.1663611\ttotal: 278ms\tremaining: 4.21s\n",
      "62:\tlearn: 0.1645486\ttotal: 283ms\tremaining: 4.21s\n",
      "63:\tlearn: 0.1629213\ttotal: 287ms\tremaining: 4.2s\n",
      "64:\tlearn: 0.1615170\ttotal: 292ms\tremaining: 4.2s\n",
      "65:\tlearn: 0.1598812\ttotal: 297ms\tremaining: 4.2s\n",
      "66:\tlearn: 0.1583828\ttotal: 302ms\tremaining: 4.2s\n",
      "67:\tlearn: 0.1568733\ttotal: 305ms\tremaining: 4.19s\n",
      "68:\tlearn: 0.1554080\ttotal: 310ms\tremaining: 4.18s\n",
      "69:\tlearn: 0.1537147\ttotal: 314ms\tremaining: 4.17s\n",
      "70:\tlearn: 0.1522290\ttotal: 318ms\tremaining: 4.16s\n",
      "71:\tlearn: 0.1509350\ttotal: 322ms\tremaining: 4.15s\n",
      "72:\tlearn: 0.1497127\ttotal: 327ms\tremaining: 4.15s\n",
      "73:\tlearn: 0.1481462\ttotal: 331ms\tremaining: 4.14s\n",
      "74:\tlearn: 0.1469043\ttotal: 336ms\tremaining: 4.14s\n",
      "75:\tlearn: 0.1456750\ttotal: 341ms\tremaining: 4.14s\n",
      "76:\tlearn: 0.1444651\ttotal: 347ms\tremaining: 4.16s\n",
      "77:\tlearn: 0.1432169\ttotal: 351ms\tremaining: 4.15s\n",
      "78:\tlearn: 0.1420612\ttotal: 355ms\tremaining: 4.14s\n",
      "79:\tlearn: 0.1410739\ttotal: 360ms\tremaining: 4.14s\n",
      "80:\tlearn: 0.1399145\ttotal: 365ms\tremaining: 4.13s\n",
      "81:\tlearn: 0.1391597\ttotal: 369ms\tremaining: 4.13s\n",
      "82:\tlearn: 0.1383855\ttotal: 373ms\tremaining: 4.12s\n",
      "83:\tlearn: 0.1374795\ttotal: 377ms\tremaining: 4.11s\n",
      "84:\tlearn: 0.1367623\ttotal: 381ms\tremaining: 4.1s\n",
      "85:\tlearn: 0.1355687\ttotal: 385ms\tremaining: 4.09s\n",
      "86:\tlearn: 0.1345622\ttotal: 390ms\tremaining: 4.09s\n",
      "87:\tlearn: 0.1335375\ttotal: 394ms\tremaining: 4.08s\n",
      "88:\tlearn: 0.1328124\ttotal: 398ms\tremaining: 4.07s\n",
      "89:\tlearn: 0.1319636\ttotal: 404ms\tremaining: 4.08s\n",
      "90:\tlearn: 0.1312735\ttotal: 408ms\tremaining: 4.08s\n",
      "91:\tlearn: 0.1304800\ttotal: 412ms\tremaining: 4.07s\n",
      "92:\tlearn: 0.1295371\ttotal: 416ms\tremaining: 4.06s\n",
      "93:\tlearn: 0.1288138\ttotal: 421ms\tremaining: 4.05s\n",
      "94:\tlearn: 0.1281144\ttotal: 425ms\tremaining: 4.05s\n",
      "95:\tlearn: 0.1274900\ttotal: 430ms\tremaining: 4.05s\n",
      "96:\tlearn: 0.1269267\ttotal: 436ms\tremaining: 4.06s\n",
      "97:\tlearn: 0.1263271\ttotal: 440ms\tremaining: 4.05s\n",
      "98:\tlearn: 0.1257396\ttotal: 444ms\tremaining: 4.04s\n",
      "99:\tlearn: 0.1249750\ttotal: 448ms\tremaining: 4.04s\n",
      "100:\tlearn: 0.1242625\ttotal: 453ms\tremaining: 4.03s\n",
      "101:\tlearn: 0.1235964\ttotal: 457ms\tremaining: 4.02s\n",
      "102:\tlearn: 0.1229007\ttotal: 461ms\tremaining: 4.01s\n",
      "103:\tlearn: 0.1222826\ttotal: 465ms\tremaining: 4.01s\n",
      "104:\tlearn: 0.1215401\ttotal: 470ms\tremaining: 4.01s\n",
      "105:\tlearn: 0.1208948\ttotal: 474ms\tremaining: 4s\n",
      "106:\tlearn: 0.1201401\ttotal: 479ms\tremaining: 3.99s\n",
      "107:\tlearn: 0.1196594\ttotal: 483ms\tremaining: 3.99s\n",
      "108:\tlearn: 0.1191814\ttotal: 488ms\tremaining: 3.99s\n",
      "109:\tlearn: 0.1186631\ttotal: 492ms\tremaining: 3.98s\n",
      "110:\tlearn: 0.1181467\ttotal: 497ms\tremaining: 3.98s\n",
      "111:\tlearn: 0.1176220\ttotal: 501ms\tremaining: 3.97s\n",
      "112:\tlearn: 0.1170791\ttotal: 505ms\tremaining: 3.96s\n",
      "113:\tlearn: 0.1166633\ttotal: 509ms\tremaining: 3.95s\n",
      "114:\tlearn: 0.1161626\ttotal: 513ms\tremaining: 3.95s\n",
      "115:\tlearn: 0.1156829\ttotal: 518ms\tremaining: 3.95s\n",
      "116:\tlearn: 0.1151659\ttotal: 522ms\tremaining: 3.94s\n",
      "117:\tlearn: 0.1145621\ttotal: 526ms\tremaining: 3.93s\n",
      "118:\tlearn: 0.1140956\ttotal: 532ms\tremaining: 3.93s\n",
      "119:\tlearn: 0.1136654\ttotal: 536ms\tremaining: 3.93s\n",
      "120:\tlearn: 0.1130604\ttotal: 540ms\tremaining: 3.92s\n",
      "121:\tlearn: 0.1125741\ttotal: 545ms\tremaining: 3.92s\n",
      "122:\tlearn: 0.1120524\ttotal: 549ms\tremaining: 3.91s\n",
      "123:\tlearn: 0.1115425\ttotal: 553ms\tremaining: 3.9s\n",
      "124:\tlearn: 0.1110742\ttotal: 557ms\tremaining: 3.9s\n",
      "125:\tlearn: 0.1106693\ttotal: 562ms\tremaining: 3.9s\n",
      "126:\tlearn: 0.1101015\ttotal: 566ms\tremaining: 3.89s\n",
      "127:\tlearn: 0.1096103\ttotal: 571ms\tremaining: 3.89s\n",
      "128:\tlearn: 0.1092362\ttotal: 575ms\tremaining: 3.88s\n",
      "129:\tlearn: 0.1088464\ttotal: 580ms\tremaining: 3.88s\n",
      "130:\tlearn: 0.1084815\ttotal: 583ms\tremaining: 3.87s\n",
      "131:\tlearn: 0.1080144\ttotal: 587ms\tremaining: 3.86s\n",
      "132:\tlearn: 0.1076932\ttotal: 591ms\tremaining: 3.85s\n",
      "133:\tlearn: 0.1073280\ttotal: 595ms\tremaining: 3.85s\n",
      "134:\tlearn: 0.1070455\ttotal: 599ms\tremaining: 3.84s\n",
      "135:\tlearn: 0.1067137\ttotal: 603ms\tremaining: 3.83s\n",
      "136:\tlearn: 0.1063498\ttotal: 607ms\tremaining: 3.83s\n",
      "137:\tlearn: 0.1059305\ttotal: 612ms\tremaining: 3.82s\n",
      "138:\tlearn: 0.1056344\ttotal: 616ms\tremaining: 3.81s\n",
      "139:\tlearn: 0.1052826\ttotal: 621ms\tremaining: 3.81s\n",
      "140:\tlearn: 0.1048921\ttotal: 626ms\tremaining: 3.81s\n",
      "141:\tlearn: 0.1046724\ttotal: 630ms\tremaining: 3.81s\n",
      "142:\tlearn: 0.1043552\ttotal: 637ms\tremaining: 3.82s\n",
      "143:\tlearn: 0.1041793\ttotal: 641ms\tremaining: 3.81s\n",
      "144:\tlearn: 0.1038450\ttotal: 645ms\tremaining: 3.81s\n",
      "145:\tlearn: 0.1034527\ttotal: 650ms\tremaining: 3.8s\n",
      "146:\tlearn: 0.1031762\ttotal: 655ms\tremaining: 3.8s\n",
      "147:\tlearn: 0.1028382\ttotal: 659ms\tremaining: 3.79s\n",
      "148:\tlearn: 0.1025940\ttotal: 662ms\tremaining: 3.78s\n",
      "149:\tlearn: 0.1023230\ttotal: 667ms\tremaining: 3.78s\n",
      "150:\tlearn: 0.1020440\ttotal: 672ms\tremaining: 3.78s\n",
      "151:\tlearn: 0.1017304\ttotal: 676ms\tremaining: 3.77s\n",
      "152:\tlearn: 0.1014561\ttotal: 680ms\tremaining: 3.76s\n",
      "153:\tlearn: 0.1010082\ttotal: 685ms\tremaining: 3.76s\n",
      "154:\tlearn: 0.1007225\ttotal: 689ms\tremaining: 3.76s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "155:\tlearn: 0.1004951\ttotal: 694ms\tremaining: 3.75s\n",
      "156:\tlearn: 0.1002149\ttotal: 698ms\tremaining: 3.75s\n",
      "157:\tlearn: 0.1000510\ttotal: 703ms\tremaining: 3.75s\n",
      "158:\tlearn: 0.0997637\ttotal: 707ms\tremaining: 3.74s\n",
      "159:\tlearn: 0.0994549\ttotal: 712ms\tremaining: 3.74s\n",
      "160:\tlearn: 0.0991790\ttotal: 716ms\tremaining: 3.73s\n",
      "161:\tlearn: 0.0989176\ttotal: 720ms\tremaining: 3.72s\n",
      "162:\tlearn: 0.0985682\ttotal: 724ms\tremaining: 3.72s\n",
      "163:\tlearn: 0.0984050\ttotal: 729ms\tremaining: 3.72s\n",
      "164:\tlearn: 0.0980816\ttotal: 734ms\tremaining: 3.71s\n",
      "165:\tlearn: 0.0977481\ttotal: 738ms\tremaining: 3.71s\n",
      "166:\tlearn: 0.0973884\ttotal: 742ms\tremaining: 3.7s\n",
      "167:\tlearn: 0.0971969\ttotal: 747ms\tremaining: 3.7s\n",
      "168:\tlearn: 0.0969692\ttotal: 751ms\tremaining: 3.69s\n",
      "169:\tlearn: 0.0966895\ttotal: 755ms\tremaining: 3.69s\n",
      "170:\tlearn: 0.0963334\ttotal: 759ms\tremaining: 3.68s\n",
      "171:\tlearn: 0.0960278\ttotal: 764ms\tremaining: 3.68s\n",
      "172:\tlearn: 0.0958025\ttotal: 768ms\tremaining: 3.67s\n",
      "173:\tlearn: 0.0955858\ttotal: 773ms\tremaining: 3.67s\n",
      "174:\tlearn: 0.0954156\ttotal: 777ms\tremaining: 3.67s\n",
      "175:\tlearn: 0.0952932\ttotal: 782ms\tremaining: 3.66s\n",
      "176:\tlearn: 0.0950149\ttotal: 786ms\tremaining: 3.65s\n",
      "177:\tlearn: 0.0947000\ttotal: 791ms\tremaining: 3.65s\n",
      "178:\tlearn: 0.0945417\ttotal: 796ms\tremaining: 3.65s\n",
      "179:\tlearn: 0.0943597\ttotal: 800ms\tremaining: 3.64s\n",
      "180:\tlearn: 0.0941271\ttotal: 804ms\tremaining: 3.64s\n",
      "181:\tlearn: 0.0936571\ttotal: 809ms\tremaining: 3.63s\n",
      "182:\tlearn: 0.0934471\ttotal: 813ms\tremaining: 3.63s\n",
      "183:\tlearn: 0.0932297\ttotal: 817ms\tremaining: 3.62s\n",
      "184:\tlearn: 0.0929627\ttotal: 822ms\tremaining: 3.62s\n",
      "185:\tlearn: 0.0928569\ttotal: 826ms\tremaining: 3.62s\n",
      "186:\tlearn: 0.0925239\ttotal: 830ms\tremaining: 3.61s\n",
      "187:\tlearn: 0.0922869\ttotal: 835ms\tremaining: 3.6s\n",
      "188:\tlearn: 0.0920898\ttotal: 840ms\tremaining: 3.6s\n",
      "189:\tlearn: 0.0917992\ttotal: 844ms\tremaining: 3.6s\n",
      "190:\tlearn: 0.0915515\ttotal: 849ms\tremaining: 3.59s\n",
      "191:\tlearn: 0.0912485\ttotal: 854ms\tremaining: 3.59s\n",
      "192:\tlearn: 0.0908791\ttotal: 859ms\tremaining: 3.59s\n",
      "193:\tlearn: 0.0907512\ttotal: 863ms\tremaining: 3.59s\n",
      "194:\tlearn: 0.0904889\ttotal: 869ms\tremaining: 3.59s\n",
      "195:\tlearn: 0.0903020\ttotal: 875ms\tremaining: 3.59s\n",
      "196:\tlearn: 0.0901199\ttotal: 881ms\tremaining: 3.59s\n",
      "197:\tlearn: 0.0898455\ttotal: 885ms\tremaining: 3.58s\n",
      "198:\tlearn: 0.0896554\ttotal: 889ms\tremaining: 3.58s\n",
      "199:\tlearn: 0.0894384\ttotal: 894ms\tremaining: 3.58s\n",
      "200:\tlearn: 0.0893305\ttotal: 900ms\tremaining: 3.58s\n",
      "201:\tlearn: 0.0891266\ttotal: 905ms\tremaining: 3.58s\n",
      "202:\tlearn: 0.0889345\ttotal: 910ms\tremaining: 3.57s\n",
      "203:\tlearn: 0.0886315\ttotal: 914ms\tremaining: 3.57s\n",
      "204:\tlearn: 0.0885090\ttotal: 919ms\tremaining: 3.56s\n",
      "205:\tlearn: 0.0882945\ttotal: 923ms\tremaining: 3.56s\n",
      "206:\tlearn: 0.0881110\ttotal: 928ms\tremaining: 3.56s\n",
      "207:\tlearn: 0.0878587\ttotal: 933ms\tremaining: 3.55s\n",
      "208:\tlearn: 0.0876667\ttotal: 937ms\tremaining: 3.55s\n",
      "209:\tlearn: 0.0875049\ttotal: 942ms\tremaining: 3.54s\n",
      "210:\tlearn: 0.0873239\ttotal: 946ms\tremaining: 3.54s\n",
      "211:\tlearn: 0.0870640\ttotal: 951ms\tremaining: 3.53s\n",
      "212:\tlearn: 0.0867847\ttotal: 955ms\tremaining: 3.53s\n",
      "213:\tlearn: 0.0866214\ttotal: 959ms\tremaining: 3.52s\n",
      "214:\tlearn: 0.0864424\ttotal: 963ms\tremaining: 3.52s\n",
      "215:\tlearn: 0.0863419\ttotal: 967ms\tremaining: 3.51s\n",
      "216:\tlearn: 0.0860476\ttotal: 971ms\tremaining: 3.5s\n",
      "217:\tlearn: 0.0858814\ttotal: 975ms\tremaining: 3.5s\n",
      "218:\tlearn: 0.0856449\ttotal: 979ms\tremaining: 3.49s\n",
      "219:\tlearn: 0.0854521\ttotal: 983ms\tremaining: 3.48s\n",
      "220:\tlearn: 0.0852860\ttotal: 987ms\tremaining: 3.48s\n",
      "221:\tlearn: 0.0851520\ttotal: 991ms\tremaining: 3.47s\n",
      "222:\tlearn: 0.0849851\ttotal: 995ms\tremaining: 3.47s\n",
      "223:\tlearn: 0.0846811\ttotal: 999ms\tremaining: 3.46s\n",
      "224:\tlearn: 0.0846049\ttotal: 1s\tremaining: 3.45s\n",
      "225:\tlearn: 0.0843972\ttotal: 1.01s\tremaining: 3.45s\n",
      "226:\tlearn: 0.0842880\ttotal: 1.01s\tremaining: 3.44s\n",
      "227:\tlearn: 0.0840765\ttotal: 1.01s\tremaining: 3.44s\n",
      "228:\tlearn: 0.0839177\ttotal: 1.02s\tremaining: 3.43s\n",
      "229:\tlearn: 0.0836734\ttotal: 1.02s\tremaining: 3.43s\n",
      "230:\tlearn: 0.0834695\ttotal: 1.03s\tremaining: 3.42s\n",
      "231:\tlearn: 0.0833503\ttotal: 1.03s\tremaining: 3.42s\n",
      "232:\tlearn: 0.0832627\ttotal: 1.04s\tremaining: 3.41s\n",
      "233:\tlearn: 0.0831002\ttotal: 1.04s\tremaining: 3.41s\n",
      "234:\tlearn: 0.0829333\ttotal: 1.04s\tremaining: 3.4s\n",
      "235:\tlearn: 0.0827769\ttotal: 1.05s\tremaining: 3.4s\n",
      "236:\tlearn: 0.0826212\ttotal: 1.05s\tremaining: 3.4s\n",
      "237:\tlearn: 0.0823612\ttotal: 1.06s\tremaining: 3.39s\n",
      "238:\tlearn: 0.0821308\ttotal: 1.06s\tremaining: 3.39s\n",
      "239:\tlearn: 0.0819308\ttotal: 1.07s\tremaining: 3.38s\n",
      "240:\tlearn: 0.0817388\ttotal: 1.07s\tremaining: 3.38s\n",
      "241:\tlearn: 0.0815358\ttotal: 1.07s\tremaining: 3.37s\n",
      "242:\tlearn: 0.0813648\ttotal: 1.08s\tremaining: 3.36s\n",
      "243:\tlearn: 0.0811440\ttotal: 1.08s\tremaining: 3.36s\n",
      "244:\tlearn: 0.0809358\ttotal: 1.09s\tremaining: 3.36s\n",
      "245:\tlearn: 0.0807421\ttotal: 1.09s\tremaining: 3.35s\n",
      "246:\tlearn: 0.0805350\ttotal: 1.1s\tremaining: 3.35s\n",
      "247:\tlearn: 0.0803938\ttotal: 1.1s\tremaining: 3.34s\n",
      "248:\tlearn: 0.0802040\ttotal: 1.11s\tremaining: 3.34s\n",
      "249:\tlearn: 0.0801084\ttotal: 1.11s\tremaining: 3.33s\n",
      "250:\tlearn: 0.0799730\ttotal: 1.12s\tremaining: 3.33s\n",
      "251:\tlearn: 0.0798275\ttotal: 1.12s\tremaining: 3.33s\n",
      "252:\tlearn: 0.0796881\ttotal: 1.13s\tremaining: 3.33s\n",
      "253:\tlearn: 0.0795137\ttotal: 1.13s\tremaining: 3.33s\n",
      "254:\tlearn: 0.0794024\ttotal: 1.14s\tremaining: 3.32s\n",
      "255:\tlearn: 0.0792774\ttotal: 1.14s\tremaining: 3.32s\n",
      "256:\tlearn: 0.0791457\ttotal: 1.15s\tremaining: 3.32s\n",
      "257:\tlearn: 0.0790257\ttotal: 1.15s\tremaining: 3.32s\n",
      "258:\tlearn: 0.0788401\ttotal: 1.16s\tremaining: 3.31s\n",
      "259:\tlearn: 0.0787205\ttotal: 1.16s\tremaining: 3.31s\n",
      "260:\tlearn: 0.0784828\ttotal: 1.17s\tremaining: 3.31s\n",
      "261:\tlearn: 0.0783605\ttotal: 1.17s\tremaining: 3.3s\n",
      "262:\tlearn: 0.0782183\ttotal: 1.18s\tremaining: 3.29s\n",
      "263:\tlearn: 0.0780986\ttotal: 1.18s\tremaining: 3.29s\n",
      "264:\tlearn: 0.0780081\ttotal: 1.19s\tremaining: 3.29s\n",
      "265:\tlearn: 0.0778324\ttotal: 1.19s\tremaining: 3.28s\n",
      "266:\tlearn: 0.0777552\ttotal: 1.19s\tremaining: 3.28s\n",
      "267:\tlearn: 0.0776147\ttotal: 1.2s\tremaining: 3.27s\n",
      "268:\tlearn: 0.0774691\ttotal: 1.2s\tremaining: 3.27s\n",
      "269:\tlearn: 0.0773325\ttotal: 1.21s\tremaining: 3.26s\n",
      "270:\tlearn: 0.0771463\ttotal: 1.21s\tremaining: 3.26s\n",
      "271:\tlearn: 0.0769935\ttotal: 1.22s\tremaining: 3.26s\n",
      "272:\tlearn: 0.0767951\ttotal: 1.22s\tremaining: 3.25s\n",
      "273:\tlearn: 0.0765074\ttotal: 1.23s\tremaining: 3.25s\n",
      "274:\tlearn: 0.0763776\ttotal: 1.23s\tremaining: 3.24s\n",
      "275:\tlearn: 0.0763243\ttotal: 1.23s\tremaining: 3.24s\n",
      "276:\tlearn: 0.0762631\ttotal: 1.24s\tremaining: 3.23s\n",
      "277:\tlearn: 0.0760893\ttotal: 1.24s\tremaining: 3.23s\n",
      "278:\tlearn: 0.0759718\ttotal: 1.25s\tremaining: 3.23s\n",
      "279:\tlearn: 0.0758609\ttotal: 1.26s\tremaining: 3.23s\n",
      "280:\tlearn: 0.0756788\ttotal: 1.26s\tremaining: 3.23s\n",
      "281:\tlearn: 0.0755422\ttotal: 1.26s\tremaining: 3.22s\n",
      "282:\tlearn: 0.0753112\ttotal: 1.27s\tremaining: 3.22s\n",
      "283:\tlearn: 0.0751755\ttotal: 1.27s\tremaining: 3.22s\n",
      "284:\tlearn: 0.0749897\ttotal: 1.28s\tremaining: 3.21s\n",
      "285:\tlearn: 0.0748790\ttotal: 1.28s\tremaining: 3.21s\n",
      "286:\tlearn: 0.0747051\ttotal: 1.29s\tremaining: 3.21s\n",
      "287:\tlearn: 0.0746457\ttotal: 1.29s\tremaining: 3.2s\n",
      "288:\tlearn: 0.0745222\ttotal: 1.3s\tremaining: 3.19s\n",
      "289:\tlearn: 0.0744320\ttotal: 1.3s\tremaining: 3.19s\n",
      "290:\tlearn: 0.0743208\ttotal: 1.31s\tremaining: 3.19s\n",
      "291:\tlearn: 0.0742091\ttotal: 1.31s\tremaining: 3.18s\n",
      "292:\tlearn: 0.0740579\ttotal: 1.32s\tremaining: 3.19s\n",
      "293:\tlearn: 0.0739114\ttotal: 1.33s\tremaining: 3.19s\n",
      "294:\tlearn: 0.0737165\ttotal: 1.33s\tremaining: 3.18s\n",
      "295:\tlearn: 0.0735923\ttotal: 1.34s\tremaining: 3.18s\n",
      "296:\tlearn: 0.0735031\ttotal: 1.34s\tremaining: 3.18s\n",
      "297:\tlearn: 0.0734078\ttotal: 1.35s\tremaining: 3.18s\n",
      "298:\tlearn: 0.0733407\ttotal: 1.36s\tremaining: 3.18s\n",
      "299:\tlearn: 0.0731026\ttotal: 1.36s\tremaining: 3.18s\n",
      "300:\tlearn: 0.0728353\ttotal: 1.37s\tremaining: 3.18s\n",
      "301:\tlearn: 0.0727321\ttotal: 1.37s\tremaining: 3.18s\n",
      "302:\tlearn: 0.0726177\ttotal: 1.38s\tremaining: 3.17s\n",
      "303:\tlearn: 0.0724652\ttotal: 1.38s\tremaining: 3.17s\n",
      "304:\tlearn: 0.0724223\ttotal: 1.39s\tremaining: 3.17s\n",
      "305:\tlearn: 0.0722521\ttotal: 1.39s\tremaining: 3.16s\n",
      "306:\tlearn: 0.0720458\ttotal: 1.4s\tremaining: 3.16s\n",
      "307:\tlearn: 0.0719997\ttotal: 1.4s\tremaining: 3.15s\n",
      "308:\tlearn: 0.0719476\ttotal: 1.41s\tremaining: 3.15s\n",
      "309:\tlearn: 0.0717932\ttotal: 1.41s\tremaining: 3.14s\n",
      "310:\tlearn: 0.0716086\ttotal: 1.42s\tremaining: 3.14s\n",
      "311:\tlearn: 0.0714467\ttotal: 1.42s\tremaining: 3.14s\n",
      "312:\tlearn: 0.0712743\ttotal: 1.43s\tremaining: 3.14s\n",
      "313:\tlearn: 0.0711469\ttotal: 1.43s\tremaining: 3.13s\n",
      "314:\tlearn: 0.0709920\ttotal: 1.44s\tremaining: 3.13s\n",
      "315:\tlearn: 0.0709046\ttotal: 1.44s\tremaining: 3.12s\n",
      "316:\tlearn: 0.0707668\ttotal: 1.45s\tremaining: 3.12s\n",
      "317:\tlearn: 0.0705993\ttotal: 1.45s\tremaining: 3.11s\n",
      "318:\tlearn: 0.0704117\ttotal: 1.45s\tremaining: 3.11s\n",
      "319:\tlearn: 0.0703248\ttotal: 1.46s\tremaining: 3.1s\n",
      "320:\tlearn: 0.0702141\ttotal: 1.46s\tremaining: 3.09s\n",
      "321:\tlearn: 0.0701479\ttotal: 1.47s\tremaining: 3.09s\n",
      "322:\tlearn: 0.0700894\ttotal: 1.47s\tremaining: 3.08s\n",
      "323:\tlearn: 0.0699620\ttotal: 1.47s\tremaining: 3.08s\n",
      "324:\tlearn: 0.0698920\ttotal: 1.48s\tremaining: 3.07s\n",
      "325:\tlearn: 0.0697924\ttotal: 1.48s\tremaining: 3.06s\n",
      "326:\tlearn: 0.0696823\ttotal: 1.49s\tremaining: 3.06s\n",
      "327:\tlearn: 0.0695436\ttotal: 1.49s\tremaining: 3.05s\n",
      "328:\tlearn: 0.0693863\ttotal: 1.49s\tremaining: 3.04s\n",
      "329:\tlearn: 0.0692968\ttotal: 1.5s\tremaining: 3.04s\n",
      "330:\tlearn: 0.0691843\ttotal: 1.5s\tremaining: 3.03s\n",
      "331:\tlearn: 0.0690478\ttotal: 1.5s\tremaining: 3.03s\n",
      "332:\tlearn: 0.0689459\ttotal: 1.51s\tremaining: 3.02s\n",
      "333:\tlearn: 0.0688369\ttotal: 1.51s\tremaining: 3.02s\n",
      "334:\tlearn: 0.0686687\ttotal: 1.52s\tremaining: 3.01s\n",
      "335:\tlearn: 0.0685865\ttotal: 1.52s\tremaining: 3s\n",
      "336:\tlearn: 0.0684800\ttotal: 1.52s\tremaining: 3s\n",
      "337:\tlearn: 0.0683329\ttotal: 1.53s\tremaining: 2.99s\n",
      "338:\tlearn: 0.0683000\ttotal: 1.53s\tremaining: 2.98s\n",
      "339:\tlearn: 0.0682327\ttotal: 1.53s\tremaining: 2.98s\n",
      "340:\tlearn: 0.0681299\ttotal: 1.54s\tremaining: 2.97s\n",
      "341:\tlearn: 0.0680053\ttotal: 1.54s\tremaining: 2.97s\n",
      "342:\tlearn: 0.0679131\ttotal: 1.55s\tremaining: 2.96s\n",
      "343:\tlearn: 0.0677654\ttotal: 1.55s\tremaining: 2.96s\n",
      "344:\tlearn: 0.0676320\ttotal: 1.55s\tremaining: 2.95s\n",
      "345:\tlearn: 0.0675152\ttotal: 1.56s\tremaining: 2.94s\n",
      "346:\tlearn: 0.0674480\ttotal: 1.56s\tremaining: 2.94s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "347:\tlearn: 0.0673949\ttotal: 1.56s\tremaining: 2.93s\n",
      "348:\tlearn: 0.0672813\ttotal: 1.57s\tremaining: 2.93s\n",
      "349:\tlearn: 0.0672022\ttotal: 1.57s\tremaining: 2.92s\n",
      "350:\tlearn: 0.0671036\ttotal: 1.58s\tremaining: 2.92s\n",
      "351:\tlearn: 0.0669933\ttotal: 1.58s\tremaining: 2.91s\n",
      "352:\tlearn: 0.0668857\ttotal: 1.59s\tremaining: 2.91s\n",
      "353:\tlearn: 0.0667738\ttotal: 1.59s\tremaining: 2.9s\n",
      "354:\tlearn: 0.0666684\ttotal: 1.59s\tremaining: 2.9s\n",
      "355:\tlearn: 0.0664741\ttotal: 1.6s\tremaining: 2.89s\n",
      "356:\tlearn: 0.0663315\ttotal: 1.6s\tremaining: 2.89s\n",
      "357:\tlearn: 0.0662392\ttotal: 1.61s\tremaining: 2.88s\n",
      "358:\tlearn: 0.0661575\ttotal: 1.61s\tremaining: 2.88s\n",
      "359:\tlearn: 0.0660062\ttotal: 1.61s\tremaining: 2.87s\n",
      "360:\tlearn: 0.0658889\ttotal: 1.62s\tremaining: 2.86s\n",
      "361:\tlearn: 0.0658053\ttotal: 1.62s\tremaining: 2.86s\n",
      "362:\tlearn: 0.0657178\ttotal: 1.63s\tremaining: 2.85s\n",
      "363:\tlearn: 0.0655790\ttotal: 1.63s\tremaining: 2.85s\n",
      "364:\tlearn: 0.0654218\ttotal: 1.63s\tremaining: 2.84s\n",
      "365:\tlearn: 0.0653022\ttotal: 1.64s\tremaining: 2.83s\n",
      "366:\tlearn: 0.0652235\ttotal: 1.64s\tremaining: 2.83s\n",
      "367:\tlearn: 0.0651330\ttotal: 1.64s\tremaining: 2.82s\n",
      "368:\tlearn: 0.0650492\ttotal: 1.65s\tremaining: 2.82s\n",
      "369:\tlearn: 0.0649469\ttotal: 1.65s\tremaining: 2.81s\n",
      "370:\tlearn: 0.0648260\ttotal: 1.66s\tremaining: 2.81s\n",
      "371:\tlearn: 0.0647236\ttotal: 1.66s\tremaining: 2.8s\n",
      "372:\tlearn: 0.0646301\ttotal: 1.66s\tremaining: 2.79s\n",
      "373:\tlearn: 0.0644597\ttotal: 1.67s\tremaining: 2.79s\n",
      "374:\tlearn: 0.0643173\ttotal: 1.67s\tremaining: 2.78s\n",
      "375:\tlearn: 0.0642032\ttotal: 1.67s\tremaining: 2.78s\n",
      "376:\tlearn: 0.0641205\ttotal: 1.68s\tremaining: 2.77s\n",
      "377:\tlearn: 0.0639864\ttotal: 1.68s\tremaining: 2.77s\n",
      "378:\tlearn: 0.0639183\ttotal: 1.69s\tremaining: 2.76s\n",
      "379:\tlearn: 0.0638213\ttotal: 1.69s\tremaining: 2.76s\n",
      "380:\tlearn: 0.0637044\ttotal: 1.69s\tremaining: 2.75s\n",
      "381:\tlearn: 0.0635810\ttotal: 1.7s\tremaining: 2.75s\n",
      "382:\tlearn: 0.0634128\ttotal: 1.7s\tremaining: 2.74s\n",
      "383:\tlearn: 0.0633353\ttotal: 1.7s\tremaining: 2.73s\n",
      "384:\tlearn: 0.0632015\ttotal: 1.71s\tremaining: 2.73s\n",
      "385:\tlearn: 0.0631031\ttotal: 1.71s\tremaining: 2.72s\n",
      "386:\tlearn: 0.0630304\ttotal: 1.72s\tremaining: 2.72s\n",
      "387:\tlearn: 0.0628560\ttotal: 1.72s\tremaining: 2.71s\n",
      "388:\tlearn: 0.0627496\ttotal: 1.72s\tremaining: 2.71s\n",
      "389:\tlearn: 0.0626196\ttotal: 1.73s\tremaining: 2.7s\n",
      "390:\tlearn: 0.0624819\ttotal: 1.73s\tremaining: 2.69s\n",
      "391:\tlearn: 0.0624107\ttotal: 1.73s\tremaining: 2.69s\n",
      "392:\tlearn: 0.0622590\ttotal: 1.74s\tremaining: 2.68s\n",
      "393:\tlearn: 0.0621860\ttotal: 1.74s\tremaining: 2.68s\n",
      "394:\tlearn: 0.0620296\ttotal: 1.75s\tremaining: 2.67s\n",
      "395:\tlearn: 0.0619283\ttotal: 1.75s\tremaining: 2.67s\n",
      "396:\tlearn: 0.0618732\ttotal: 1.75s\tremaining: 2.67s\n",
      "397:\tlearn: 0.0617953\ttotal: 1.76s\tremaining: 2.66s\n",
      "398:\tlearn: 0.0616864\ttotal: 1.76s\tremaining: 2.65s\n",
      "399:\tlearn: 0.0616065\ttotal: 1.76s\tremaining: 2.65s\n",
      "400:\tlearn: 0.0615033\ttotal: 1.77s\tremaining: 2.65s\n",
      "401:\tlearn: 0.0613918\ttotal: 1.77s\tremaining: 2.64s\n",
      "402:\tlearn: 0.0612860\ttotal: 1.78s\tremaining: 2.63s\n",
      "403:\tlearn: 0.0612094\ttotal: 1.78s\tremaining: 2.63s\n",
      "404:\tlearn: 0.0611096\ttotal: 1.78s\tremaining: 2.62s\n",
      "405:\tlearn: 0.0610369\ttotal: 1.79s\tremaining: 2.62s\n",
      "406:\tlearn: 0.0609865\ttotal: 1.79s\tremaining: 2.61s\n",
      "407:\tlearn: 0.0608534\ttotal: 1.8s\tremaining: 2.61s\n",
      "408:\tlearn: 0.0607750\ttotal: 1.8s\tremaining: 2.6s\n",
      "409:\tlearn: 0.0607130\ttotal: 1.81s\tremaining: 2.6s\n",
      "410:\tlearn: 0.0606008\ttotal: 1.81s\tremaining: 2.59s\n",
      "411:\tlearn: 0.0605364\ttotal: 1.81s\tremaining: 2.59s\n",
      "412:\tlearn: 0.0604520\ttotal: 1.82s\tremaining: 2.58s\n",
      "413:\tlearn: 0.0603361\ttotal: 1.82s\tremaining: 2.58s\n",
      "414:\tlearn: 0.0602368\ttotal: 1.82s\tremaining: 2.57s\n",
      "415:\tlearn: 0.0601257\ttotal: 1.83s\tremaining: 2.57s\n",
      "416:\tlearn: 0.0600333\ttotal: 1.83s\tremaining: 2.56s\n",
      "417:\tlearn: 0.0599643\ttotal: 1.84s\tremaining: 2.56s\n",
      "418:\tlearn: 0.0598778\ttotal: 1.84s\tremaining: 2.55s\n",
      "419:\tlearn: 0.0597761\ttotal: 1.84s\tremaining: 2.55s\n",
      "420:\tlearn: 0.0597543\ttotal: 1.85s\tremaining: 2.54s\n",
      "421:\tlearn: 0.0596598\ttotal: 1.85s\tremaining: 2.54s\n",
      "422:\tlearn: 0.0595812\ttotal: 1.86s\tremaining: 2.53s\n",
      "423:\tlearn: 0.0594778\ttotal: 1.86s\tremaining: 2.53s\n",
      "424:\tlearn: 0.0594263\ttotal: 1.86s\tremaining: 2.52s\n",
      "425:\tlearn: 0.0593519\ttotal: 1.87s\tremaining: 2.52s\n",
      "426:\tlearn: 0.0592411\ttotal: 1.87s\tremaining: 2.51s\n",
      "427:\tlearn: 0.0592067\ttotal: 1.88s\tremaining: 2.51s\n",
      "428:\tlearn: 0.0591468\ttotal: 1.88s\tremaining: 2.5s\n",
      "429:\tlearn: 0.0590500\ttotal: 1.89s\tremaining: 2.5s\n",
      "430:\tlearn: 0.0589508\ttotal: 1.89s\tremaining: 2.5s\n",
      "431:\tlearn: 0.0588808\ttotal: 1.89s\tremaining: 2.49s\n",
      "432:\tlearn: 0.0588325\ttotal: 1.9s\tremaining: 2.49s\n",
      "433:\tlearn: 0.0587771\ttotal: 1.9s\tremaining: 2.48s\n",
      "434:\tlearn: 0.0586637\ttotal: 1.91s\tremaining: 2.48s\n",
      "435:\tlearn: 0.0585318\ttotal: 1.91s\tremaining: 2.47s\n",
      "436:\tlearn: 0.0584871\ttotal: 1.92s\tremaining: 2.47s\n",
      "437:\tlearn: 0.0584314\ttotal: 1.92s\tremaining: 2.46s\n",
      "438:\tlearn: 0.0583141\ttotal: 1.92s\tremaining: 2.46s\n",
      "439:\tlearn: 0.0582345\ttotal: 1.93s\tremaining: 2.46s\n",
      "440:\tlearn: 0.0581880\ttotal: 1.93s\tremaining: 2.45s\n",
      "441:\tlearn: 0.0580695\ttotal: 1.94s\tremaining: 2.45s\n",
      "442:\tlearn: 0.0580321\ttotal: 1.94s\tremaining: 2.44s\n",
      "443:\tlearn: 0.0579288\ttotal: 1.95s\tremaining: 2.44s\n",
      "444:\tlearn: 0.0577333\ttotal: 1.95s\tremaining: 2.43s\n",
      "445:\tlearn: 0.0576225\ttotal: 1.95s\tremaining: 2.43s\n",
      "446:\tlearn: 0.0575225\ttotal: 1.96s\tremaining: 2.42s\n",
      "447:\tlearn: 0.0574351\ttotal: 1.96s\tremaining: 2.42s\n",
      "448:\tlearn: 0.0573225\ttotal: 1.97s\tremaining: 2.41s\n",
      "449:\tlearn: 0.0572801\ttotal: 1.97s\tremaining: 2.41s\n",
      "450:\tlearn: 0.0572102\ttotal: 1.97s\tremaining: 2.4s\n",
      "451:\tlearn: 0.0571871\ttotal: 1.98s\tremaining: 2.4s\n",
      "452:\tlearn: 0.0571249\ttotal: 1.98s\tremaining: 2.39s\n",
      "453:\tlearn: 0.0570688\ttotal: 1.98s\tremaining: 2.39s\n",
      "454:\tlearn: 0.0569827\ttotal: 1.99s\tremaining: 2.38s\n",
      "455:\tlearn: 0.0569126\ttotal: 1.99s\tremaining: 2.38s\n",
      "456:\tlearn: 0.0568427\ttotal: 2s\tremaining: 2.37s\n",
      "457:\tlearn: 0.0567571\ttotal: 2s\tremaining: 2.37s\n",
      "458:\tlearn: 0.0567133\ttotal: 2.01s\tremaining: 2.36s\n",
      "459:\tlearn: 0.0566104\ttotal: 2.01s\tremaining: 2.36s\n",
      "460:\tlearn: 0.0565297\ttotal: 2.02s\tremaining: 2.36s\n",
      "461:\tlearn: 0.0564210\ttotal: 2.02s\tremaining: 2.35s\n",
      "462:\tlearn: 0.0563301\ttotal: 2.02s\tremaining: 2.35s\n",
      "463:\tlearn: 0.0562315\ttotal: 2.03s\tremaining: 2.34s\n",
      "464:\tlearn: 0.0561457\ttotal: 2.03s\tremaining: 2.34s\n",
      "465:\tlearn: 0.0560773\ttotal: 2.03s\tremaining: 2.33s\n",
      "466:\tlearn: 0.0559987\ttotal: 2.04s\tremaining: 2.33s\n",
      "467:\tlearn: 0.0559568\ttotal: 2.04s\tremaining: 2.32s\n",
      "468:\tlearn: 0.0558609\ttotal: 2.05s\tremaining: 2.32s\n",
      "469:\tlearn: 0.0557852\ttotal: 2.05s\tremaining: 2.31s\n",
      "470:\tlearn: 0.0557026\ttotal: 2.05s\tremaining: 2.31s\n",
      "471:\tlearn: 0.0556146\ttotal: 2.06s\tremaining: 2.3s\n",
      "472:\tlearn: 0.0555221\ttotal: 2.06s\tremaining: 2.3s\n",
      "473:\tlearn: 0.0554884\ttotal: 2.06s\tremaining: 2.29s\n",
      "474:\tlearn: 0.0554647\ttotal: 2.07s\tremaining: 2.29s\n",
      "475:\tlearn: 0.0553719\ttotal: 2.07s\tremaining: 2.28s\n",
      "476:\tlearn: 0.0552704\ttotal: 2.08s\tremaining: 2.28s\n",
      "477:\tlearn: 0.0551921\ttotal: 2.08s\tremaining: 2.27s\n",
      "478:\tlearn: 0.0551451\ttotal: 2.08s\tremaining: 2.27s\n",
      "479:\tlearn: 0.0550178\ttotal: 2.09s\tremaining: 2.26s\n",
      "480:\tlearn: 0.0549117\ttotal: 2.09s\tremaining: 2.26s\n",
      "481:\tlearn: 0.0548497\ttotal: 2.1s\tremaining: 2.25s\n",
      "482:\tlearn: 0.0547101\ttotal: 2.1s\tremaining: 2.25s\n",
      "483:\tlearn: 0.0546260\ttotal: 2.11s\tremaining: 2.25s\n",
      "484:\tlearn: 0.0545432\ttotal: 2.11s\tremaining: 2.24s\n",
      "485:\tlearn: 0.0544228\ttotal: 2.12s\tremaining: 2.24s\n",
      "486:\tlearn: 0.0543420\ttotal: 2.12s\tremaining: 2.23s\n",
      "487:\tlearn: 0.0543137\ttotal: 2.12s\tremaining: 2.23s\n",
      "488:\tlearn: 0.0542906\ttotal: 2.13s\tremaining: 2.22s\n",
      "489:\tlearn: 0.0542337\ttotal: 2.13s\tremaining: 2.22s\n",
      "490:\tlearn: 0.0542082\ttotal: 2.13s\tremaining: 2.21s\n",
      "491:\tlearn: 0.0541425\ttotal: 2.14s\tremaining: 2.21s\n",
      "492:\tlearn: 0.0541183\ttotal: 2.14s\tremaining: 2.2s\n",
      "493:\tlearn: 0.0540845\ttotal: 2.15s\tremaining: 2.2s\n",
      "494:\tlearn: 0.0540317\ttotal: 2.15s\tremaining: 2.19s\n",
      "495:\tlearn: 0.0539243\ttotal: 2.15s\tremaining: 2.19s\n",
      "496:\tlearn: 0.0538862\ttotal: 2.16s\tremaining: 2.19s\n",
      "497:\tlearn: 0.0538299\ttotal: 2.16s\tremaining: 2.18s\n",
      "498:\tlearn: 0.0537768\ttotal: 2.17s\tremaining: 2.17s\n",
      "499:\tlearn: 0.0537069\ttotal: 2.17s\tremaining: 2.17s\n",
      "500:\tlearn: 0.0535992\ttotal: 2.17s\tremaining: 2.17s\n",
      "501:\tlearn: 0.0535273\ttotal: 2.18s\tremaining: 2.16s\n",
      "502:\tlearn: 0.0534598\ttotal: 2.18s\tremaining: 2.16s\n",
      "503:\tlearn: 0.0533804\ttotal: 2.19s\tremaining: 2.15s\n",
      "504:\tlearn: 0.0533079\ttotal: 2.19s\tremaining: 2.15s\n",
      "505:\tlearn: 0.0532352\ttotal: 2.19s\tremaining: 2.14s\n",
      "506:\tlearn: 0.0531960\ttotal: 2.2s\tremaining: 2.14s\n",
      "507:\tlearn: 0.0531391\ttotal: 2.2s\tremaining: 2.13s\n",
      "508:\tlearn: 0.0530786\ttotal: 2.21s\tremaining: 2.13s\n",
      "509:\tlearn: 0.0530455\ttotal: 2.21s\tremaining: 2.12s\n",
      "510:\tlearn: 0.0529624\ttotal: 2.21s\tremaining: 2.12s\n",
      "511:\tlearn: 0.0528838\ttotal: 2.22s\tremaining: 2.11s\n",
      "512:\tlearn: 0.0528302\ttotal: 2.22s\tremaining: 2.11s\n",
      "513:\tlearn: 0.0527848\ttotal: 2.23s\tremaining: 2.1s\n",
      "514:\tlearn: 0.0527434\ttotal: 2.23s\tremaining: 2.1s\n",
      "515:\tlearn: 0.0527112\ttotal: 2.23s\tremaining: 2.09s\n",
      "516:\tlearn: 0.0526422\ttotal: 2.24s\tremaining: 2.09s\n",
      "517:\tlearn: 0.0525572\ttotal: 2.24s\tremaining: 2.08s\n",
      "518:\tlearn: 0.0524649\ttotal: 2.24s\tremaining: 2.08s\n",
      "519:\tlearn: 0.0523919\ttotal: 2.25s\tremaining: 2.08s\n",
      "520:\tlearn: 0.0523252\ttotal: 2.25s\tremaining: 2.07s\n",
      "521:\tlearn: 0.0522514\ttotal: 2.26s\tremaining: 2.07s\n",
      "522:\tlearn: 0.0521545\ttotal: 2.26s\tremaining: 2.06s\n",
      "523:\tlearn: 0.0521113\ttotal: 2.26s\tremaining: 2.06s\n",
      "524:\tlearn: 0.0520490\ttotal: 2.27s\tremaining: 2.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "525:\tlearn: 0.0519890\ttotal: 2.27s\tremaining: 2.05s\n",
      "526:\tlearn: 0.0519395\ttotal: 2.28s\tremaining: 2.04s\n",
      "527:\tlearn: 0.0518600\ttotal: 2.28s\tremaining: 2.04s\n",
      "528:\tlearn: 0.0518101\ttotal: 2.29s\tremaining: 2.04s\n",
      "529:\tlearn: 0.0517807\ttotal: 2.29s\tremaining: 2.03s\n",
      "530:\tlearn: 0.0517237\ttotal: 2.29s\tremaining: 2.03s\n",
      "531:\tlearn: 0.0516377\ttotal: 2.3s\tremaining: 2.02s\n",
      "532:\tlearn: 0.0515690\ttotal: 2.3s\tremaining: 2.02s\n",
      "533:\tlearn: 0.0515386\ttotal: 2.31s\tremaining: 2.01s\n",
      "534:\tlearn: 0.0514587\ttotal: 2.31s\tremaining: 2.01s\n",
      "535:\tlearn: 0.0513935\ttotal: 2.31s\tremaining: 2s\n",
      "536:\tlearn: 0.0513236\ttotal: 2.32s\tremaining: 2s\n",
      "537:\tlearn: 0.0512898\ttotal: 2.32s\tremaining: 2s\n",
      "538:\tlearn: 0.0512487\ttotal: 2.33s\tremaining: 1.99s\n",
      "539:\tlearn: 0.0511907\ttotal: 2.33s\tremaining: 1.99s\n",
      "540:\tlearn: 0.0511582\ttotal: 2.33s\tremaining: 1.98s\n",
      "541:\tlearn: 0.0511026\ttotal: 2.34s\tremaining: 1.98s\n",
      "542:\tlearn: 0.0510397\ttotal: 2.34s\tremaining: 1.97s\n",
      "543:\tlearn: 0.0509213\ttotal: 2.35s\tremaining: 1.97s\n",
      "544:\tlearn: 0.0508411\ttotal: 2.35s\tremaining: 1.96s\n",
      "545:\tlearn: 0.0507653\ttotal: 2.35s\tremaining: 1.96s\n",
      "546:\tlearn: 0.0506977\ttotal: 2.36s\tremaining: 1.95s\n",
      "547:\tlearn: 0.0506022\ttotal: 2.36s\tremaining: 1.95s\n",
      "548:\tlearn: 0.0505615\ttotal: 2.37s\tremaining: 1.94s\n",
      "549:\tlearn: 0.0504565\ttotal: 2.37s\tremaining: 1.94s\n",
      "550:\tlearn: 0.0503710\ttotal: 2.37s\tremaining: 1.93s\n",
      "551:\tlearn: 0.0503286\ttotal: 2.38s\tremaining: 1.93s\n",
      "552:\tlearn: 0.0502901\ttotal: 2.38s\tremaining: 1.93s\n",
      "553:\tlearn: 0.0502321\ttotal: 2.39s\tremaining: 1.92s\n",
      "554:\tlearn: 0.0501958\ttotal: 2.39s\tremaining: 1.92s\n",
      "555:\tlearn: 0.0501081\ttotal: 2.39s\tremaining: 1.91s\n",
      "556:\tlearn: 0.0500749\ttotal: 2.4s\tremaining: 1.91s\n",
      "557:\tlearn: 0.0500519\ttotal: 2.4s\tremaining: 1.9s\n",
      "558:\tlearn: 0.0500285\ttotal: 2.4s\tremaining: 1.9s\n",
      "559:\tlearn: 0.0499818\ttotal: 2.41s\tremaining: 1.89s\n",
      "560:\tlearn: 0.0499427\ttotal: 2.41s\tremaining: 1.89s\n",
      "561:\tlearn: 0.0499138\ttotal: 2.42s\tremaining: 1.88s\n",
      "562:\tlearn: 0.0498736\ttotal: 2.42s\tremaining: 1.88s\n",
      "563:\tlearn: 0.0498487\ttotal: 2.42s\tremaining: 1.87s\n",
      "564:\tlearn: 0.0498018\ttotal: 2.43s\tremaining: 1.87s\n",
      "565:\tlearn: 0.0497621\ttotal: 2.43s\tremaining: 1.86s\n",
      "566:\tlearn: 0.0497326\ttotal: 2.44s\tremaining: 1.86s\n",
      "567:\tlearn: 0.0496994\ttotal: 2.44s\tremaining: 1.86s\n",
      "568:\tlearn: 0.0495752\ttotal: 2.44s\tremaining: 1.85s\n",
      "569:\tlearn: 0.0495078\ttotal: 2.45s\tremaining: 1.85s\n",
      "570:\tlearn: 0.0493932\ttotal: 2.45s\tremaining: 1.84s\n",
      "571:\tlearn: 0.0492936\ttotal: 2.46s\tremaining: 1.84s\n",
      "572:\tlearn: 0.0492642\ttotal: 2.46s\tremaining: 1.83s\n",
      "573:\tlearn: 0.0492242\ttotal: 2.47s\tremaining: 1.83s\n",
      "574:\tlearn: 0.0491665\ttotal: 2.47s\tremaining: 1.83s\n",
      "575:\tlearn: 0.0491276\ttotal: 2.48s\tremaining: 1.82s\n",
      "576:\tlearn: 0.0490251\ttotal: 2.48s\tremaining: 1.82s\n",
      "577:\tlearn: 0.0489659\ttotal: 2.48s\tremaining: 1.81s\n",
      "578:\tlearn: 0.0489521\ttotal: 2.49s\tremaining: 1.81s\n",
      "579:\tlearn: 0.0488967\ttotal: 2.49s\tremaining: 1.8s\n",
      "580:\tlearn: 0.0488697\ttotal: 2.5s\tremaining: 1.8s\n",
      "581:\tlearn: 0.0488325\ttotal: 2.5s\tremaining: 1.79s\n",
      "582:\tlearn: 0.0487427\ttotal: 2.5s\tremaining: 1.79s\n",
      "583:\tlearn: 0.0486067\ttotal: 2.51s\tremaining: 1.79s\n",
      "584:\tlearn: 0.0485521\ttotal: 2.51s\tremaining: 1.78s\n",
      "585:\tlearn: 0.0484964\ttotal: 2.52s\tremaining: 1.78s\n",
      "586:\tlearn: 0.0484541\ttotal: 2.52s\tremaining: 1.77s\n",
      "587:\tlearn: 0.0483919\ttotal: 2.52s\tremaining: 1.77s\n",
      "588:\tlearn: 0.0483040\ttotal: 2.53s\tremaining: 1.76s\n",
      "589:\tlearn: 0.0482342\ttotal: 2.53s\tremaining: 1.76s\n",
      "590:\tlearn: 0.0481886\ttotal: 2.54s\tremaining: 1.75s\n",
      "591:\tlearn: 0.0481340\ttotal: 2.54s\tremaining: 1.75s\n",
      "592:\tlearn: 0.0480900\ttotal: 2.54s\tremaining: 1.75s\n",
      "593:\tlearn: 0.0480286\ttotal: 2.55s\tremaining: 1.74s\n",
      "594:\tlearn: 0.0479858\ttotal: 2.55s\tremaining: 1.74s\n",
      "595:\tlearn: 0.0479550\ttotal: 2.56s\tremaining: 1.73s\n",
      "596:\tlearn: 0.0479178\ttotal: 2.56s\tremaining: 1.73s\n",
      "597:\tlearn: 0.0478554\ttotal: 2.56s\tremaining: 1.72s\n",
      "598:\tlearn: 0.0478142\ttotal: 2.57s\tremaining: 1.72s\n",
      "599:\tlearn: 0.0477763\ttotal: 2.57s\tremaining: 1.71s\n",
      "600:\tlearn: 0.0477282\ttotal: 2.57s\tremaining: 1.71s\n",
      "601:\tlearn: 0.0476768\ttotal: 2.58s\tremaining: 1.7s\n",
      "602:\tlearn: 0.0476220\ttotal: 2.58s\tremaining: 1.7s\n",
      "603:\tlearn: 0.0475712\ttotal: 2.59s\tremaining: 1.7s\n",
      "604:\tlearn: 0.0474800\ttotal: 2.59s\tremaining: 1.69s\n",
      "605:\tlearn: 0.0474358\ttotal: 2.59s\tremaining: 1.69s\n",
      "606:\tlearn: 0.0473903\ttotal: 2.6s\tremaining: 1.68s\n",
      "607:\tlearn: 0.0473405\ttotal: 2.6s\tremaining: 1.68s\n",
      "608:\tlearn: 0.0473089\ttotal: 2.6s\tremaining: 1.67s\n",
      "609:\tlearn: 0.0472498\ttotal: 2.61s\tremaining: 1.67s\n",
      "610:\tlearn: 0.0472063\ttotal: 2.61s\tremaining: 1.66s\n",
      "611:\tlearn: 0.0471659\ttotal: 2.62s\tremaining: 1.66s\n",
      "612:\tlearn: 0.0471370\ttotal: 2.62s\tremaining: 1.65s\n",
      "613:\tlearn: 0.0471054\ttotal: 2.62s\tremaining: 1.65s\n",
      "614:\tlearn: 0.0470095\ttotal: 2.63s\tremaining: 1.65s\n",
      "615:\tlearn: 0.0469486\ttotal: 2.63s\tremaining: 1.64s\n",
      "616:\tlearn: 0.0469224\ttotal: 2.64s\tremaining: 1.64s\n",
      "617:\tlearn: 0.0468540\ttotal: 2.64s\tremaining: 1.63s\n",
      "618:\tlearn: 0.0468347\ttotal: 2.65s\tremaining: 1.63s\n",
      "619:\tlearn: 0.0468112\ttotal: 2.65s\tremaining: 1.62s\n",
      "620:\tlearn: 0.0467512\ttotal: 2.65s\tremaining: 1.62s\n",
      "621:\tlearn: 0.0467054\ttotal: 2.66s\tremaining: 1.61s\n",
      "622:\tlearn: 0.0466911\ttotal: 2.66s\tremaining: 1.61s\n",
      "623:\tlearn: 0.0465651\ttotal: 2.67s\tremaining: 1.61s\n",
      "624:\tlearn: 0.0465427\ttotal: 2.67s\tremaining: 1.6s\n",
      "625:\tlearn: 0.0464979\ttotal: 2.67s\tremaining: 1.6s\n",
      "626:\tlearn: 0.0464601\ttotal: 2.68s\tremaining: 1.59s\n",
      "627:\tlearn: 0.0464327\ttotal: 2.68s\tremaining: 1.59s\n",
      "628:\tlearn: 0.0463728\ttotal: 2.69s\tremaining: 1.58s\n",
      "629:\tlearn: 0.0463296\ttotal: 2.69s\tremaining: 1.58s\n",
      "630:\tlearn: 0.0462895\ttotal: 2.7s\tremaining: 1.58s\n",
      "631:\tlearn: 0.0462514\ttotal: 2.7s\tremaining: 1.57s\n",
      "632:\tlearn: 0.0462066\ttotal: 2.7s\tremaining: 1.57s\n",
      "633:\tlearn: 0.0461493\ttotal: 2.71s\tremaining: 1.56s\n",
      "634:\tlearn: 0.0461082\ttotal: 2.71s\tremaining: 1.56s\n",
      "635:\tlearn: 0.0460721\ttotal: 2.72s\tremaining: 1.55s\n",
      "636:\tlearn: 0.0460111\ttotal: 2.72s\tremaining: 1.55s\n",
      "637:\tlearn: 0.0459633\ttotal: 2.72s\tremaining: 1.55s\n",
      "638:\tlearn: 0.0459161\ttotal: 2.73s\tremaining: 1.54s\n",
      "639:\tlearn: 0.0458875\ttotal: 2.73s\tremaining: 1.54s\n",
      "640:\tlearn: 0.0458303\ttotal: 2.74s\tremaining: 1.53s\n",
      "641:\tlearn: 0.0458000\ttotal: 2.74s\tremaining: 1.53s\n",
      "642:\tlearn: 0.0457258\ttotal: 2.75s\tremaining: 1.52s\n",
      "643:\tlearn: 0.0456931\ttotal: 2.75s\tremaining: 1.52s\n",
      "644:\tlearn: 0.0456675\ttotal: 2.75s\tremaining: 1.51s\n",
      "645:\tlearn: 0.0456444\ttotal: 2.76s\tremaining: 1.51s\n",
      "646:\tlearn: 0.0456160\ttotal: 2.76s\tremaining: 1.51s\n",
      "647:\tlearn: 0.0455840\ttotal: 2.76s\tremaining: 1.5s\n",
      "648:\tlearn: 0.0455576\ttotal: 2.77s\tremaining: 1.5s\n",
      "649:\tlearn: 0.0455023\ttotal: 2.77s\tremaining: 1.49s\n",
      "650:\tlearn: 0.0454548\ttotal: 2.78s\tremaining: 1.49s\n",
      "651:\tlearn: 0.0454157\ttotal: 2.78s\tremaining: 1.48s\n",
      "652:\tlearn: 0.0453743\ttotal: 2.78s\tremaining: 1.48s\n",
      "653:\tlearn: 0.0453136\ttotal: 2.79s\tremaining: 1.48s\n",
      "654:\tlearn: 0.0452766\ttotal: 2.79s\tremaining: 1.47s\n",
      "655:\tlearn: 0.0451963\ttotal: 2.8s\tremaining: 1.47s\n",
      "656:\tlearn: 0.0450861\ttotal: 2.8s\tremaining: 1.46s\n",
      "657:\tlearn: 0.0450588\ttotal: 2.8s\tremaining: 1.46s\n",
      "658:\tlearn: 0.0450244\ttotal: 2.81s\tremaining: 1.45s\n",
      "659:\tlearn: 0.0449658\ttotal: 2.81s\tremaining: 1.45s\n",
      "660:\tlearn: 0.0449231\ttotal: 2.82s\tremaining: 1.44s\n",
      "661:\tlearn: 0.0448808\ttotal: 2.82s\tremaining: 1.44s\n",
      "662:\tlearn: 0.0447849\ttotal: 2.82s\tremaining: 1.44s\n",
      "663:\tlearn: 0.0447468\ttotal: 2.83s\tremaining: 1.43s\n",
      "664:\tlearn: 0.0447224\ttotal: 2.83s\tremaining: 1.43s\n",
      "665:\tlearn: 0.0446759\ttotal: 2.84s\tremaining: 1.42s\n",
      "666:\tlearn: 0.0446368\ttotal: 2.84s\tremaining: 1.42s\n",
      "667:\tlearn: 0.0446033\ttotal: 2.84s\tremaining: 1.41s\n",
      "668:\tlearn: 0.0444828\ttotal: 2.85s\tremaining: 1.41s\n",
      "669:\tlearn: 0.0444432\ttotal: 2.85s\tremaining: 1.4s\n",
      "670:\tlearn: 0.0443903\ttotal: 2.85s\tremaining: 1.4s\n",
      "671:\tlearn: 0.0443529\ttotal: 2.86s\tremaining: 1.4s\n",
      "672:\tlearn: 0.0442976\ttotal: 2.86s\tremaining: 1.39s\n",
      "673:\tlearn: 0.0442569\ttotal: 2.87s\tremaining: 1.39s\n",
      "674:\tlearn: 0.0441767\ttotal: 2.87s\tremaining: 1.38s\n",
      "675:\tlearn: 0.0441399\ttotal: 2.87s\tremaining: 1.38s\n",
      "676:\tlearn: 0.0440518\ttotal: 2.88s\tremaining: 1.37s\n",
      "677:\tlearn: 0.0440226\ttotal: 2.88s\tremaining: 1.37s\n",
      "678:\tlearn: 0.0439583\ttotal: 2.89s\tremaining: 1.36s\n",
      "679:\tlearn: 0.0439040\ttotal: 2.89s\tremaining: 1.36s\n",
      "680:\tlearn: 0.0438620\ttotal: 2.9s\tremaining: 1.36s\n",
      "681:\tlearn: 0.0437591\ttotal: 2.9s\tremaining: 1.35s\n",
      "682:\tlearn: 0.0437236\ttotal: 2.9s\tremaining: 1.35s\n",
      "683:\tlearn: 0.0436645\ttotal: 2.91s\tremaining: 1.34s\n",
      "684:\tlearn: 0.0435862\ttotal: 2.91s\tremaining: 1.34s\n",
      "685:\tlearn: 0.0435403\ttotal: 2.92s\tremaining: 1.33s\n",
      "686:\tlearn: 0.0434939\ttotal: 2.92s\tremaining: 1.33s\n",
      "687:\tlearn: 0.0434551\ttotal: 2.93s\tremaining: 1.33s\n",
      "688:\tlearn: 0.0434239\ttotal: 2.93s\tremaining: 1.32s\n",
      "689:\tlearn: 0.0433866\ttotal: 2.94s\tremaining: 1.32s\n",
      "690:\tlearn: 0.0433562\ttotal: 2.94s\tremaining: 1.31s\n",
      "691:\tlearn: 0.0433192\ttotal: 2.94s\tremaining: 1.31s\n",
      "692:\tlearn: 0.0432578\ttotal: 2.95s\tremaining: 1.31s\n",
      "693:\tlearn: 0.0432168\ttotal: 2.95s\tremaining: 1.3s\n",
      "694:\tlearn: 0.0431875\ttotal: 2.96s\tremaining: 1.3s\n",
      "695:\tlearn: 0.0431360\ttotal: 2.96s\tremaining: 1.29s\n",
      "696:\tlearn: 0.0431008\ttotal: 2.96s\tremaining: 1.29s\n",
      "697:\tlearn: 0.0430801\ttotal: 2.97s\tremaining: 1.28s\n",
      "698:\tlearn: 0.0430072\ttotal: 2.97s\tremaining: 1.28s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "699:\tlearn: 0.0429729\ttotal: 2.98s\tremaining: 1.27s\n",
      "700:\tlearn: 0.0428988\ttotal: 2.98s\tremaining: 1.27s\n",
      "701:\tlearn: 0.0428656\ttotal: 2.98s\tremaining: 1.27s\n",
      "702:\tlearn: 0.0428324\ttotal: 2.99s\tremaining: 1.26s\n",
      "703:\tlearn: 0.0427821\ttotal: 2.99s\tremaining: 1.26s\n",
      "704:\tlearn: 0.0427490\ttotal: 3s\tremaining: 1.25s\n",
      "705:\tlearn: 0.0426782\ttotal: 3s\tremaining: 1.25s\n",
      "706:\tlearn: 0.0426503\ttotal: 3s\tremaining: 1.25s\n",
      "707:\tlearn: 0.0426062\ttotal: 3.01s\tremaining: 1.24s\n",
      "708:\tlearn: 0.0425312\ttotal: 3.01s\tremaining: 1.24s\n",
      "709:\tlearn: 0.0424908\ttotal: 3.02s\tremaining: 1.23s\n",
      "710:\tlearn: 0.0424659\ttotal: 3.02s\tremaining: 1.23s\n",
      "711:\tlearn: 0.0424332\ttotal: 3.02s\tremaining: 1.22s\n",
      "712:\tlearn: 0.0423677\ttotal: 3.03s\tremaining: 1.22s\n",
      "713:\tlearn: 0.0422882\ttotal: 3.03s\tremaining: 1.22s\n",
      "714:\tlearn: 0.0422637\ttotal: 3.04s\tremaining: 1.21s\n",
      "715:\tlearn: 0.0421725\ttotal: 3.04s\tremaining: 1.21s\n",
      "716:\tlearn: 0.0421495\ttotal: 3.04s\tremaining: 1.2s\n",
      "717:\tlearn: 0.0421233\ttotal: 3.05s\tremaining: 1.2s\n",
      "718:\tlearn: 0.0420835\ttotal: 3.06s\tremaining: 1.19s\n",
      "719:\tlearn: 0.0420204\ttotal: 3.06s\tremaining: 1.19s\n",
      "720:\tlearn: 0.0419978\ttotal: 3.06s\tremaining: 1.19s\n",
      "721:\tlearn: 0.0419673\ttotal: 3.07s\tremaining: 1.18s\n",
      "722:\tlearn: 0.0419399\ttotal: 3.07s\tremaining: 1.18s\n",
      "723:\tlearn: 0.0418635\ttotal: 3.07s\tremaining: 1.17s\n",
      "724:\tlearn: 0.0417707\ttotal: 3.08s\tremaining: 1.17s\n",
      "725:\tlearn: 0.0417374\ttotal: 3.08s\tremaining: 1.16s\n",
      "726:\tlearn: 0.0417147\ttotal: 3.09s\tremaining: 1.16s\n",
      "727:\tlearn: 0.0416811\ttotal: 3.09s\tremaining: 1.15s\n",
      "728:\tlearn: 0.0416116\ttotal: 3.09s\tremaining: 1.15s\n",
      "729:\tlearn: 0.0415465\ttotal: 3.1s\tremaining: 1.15s\n",
      "730:\tlearn: 0.0415240\ttotal: 3.1s\tremaining: 1.14s\n",
      "731:\tlearn: 0.0415000\ttotal: 3.1s\tremaining: 1.14s\n",
      "732:\tlearn: 0.0414408\ttotal: 3.11s\tremaining: 1.13s\n",
      "733:\tlearn: 0.0414174\ttotal: 3.11s\tremaining: 1.13s\n",
      "734:\tlearn: 0.0413556\ttotal: 3.12s\tremaining: 1.12s\n",
      "735:\tlearn: 0.0413020\ttotal: 3.12s\tremaining: 1.12s\n",
      "736:\tlearn: 0.0412735\ttotal: 3.13s\tremaining: 1.11s\n",
      "737:\tlearn: 0.0412336\ttotal: 3.13s\tremaining: 1.11s\n",
      "738:\tlearn: 0.0411680\ttotal: 3.13s\tremaining: 1.11s\n",
      "739:\tlearn: 0.0411094\ttotal: 3.14s\tremaining: 1.1s\n",
      "740:\tlearn: 0.0410651\ttotal: 3.14s\tremaining: 1.1s\n",
      "741:\tlearn: 0.0410114\ttotal: 3.14s\tremaining: 1.09s\n",
      "742:\tlearn: 0.0409452\ttotal: 3.15s\tremaining: 1.09s\n",
      "743:\tlearn: 0.0409142\ttotal: 3.15s\tremaining: 1.08s\n",
      "744:\tlearn: 0.0408705\ttotal: 3.16s\tremaining: 1.08s\n",
      "745:\tlearn: 0.0408364\ttotal: 3.16s\tremaining: 1.08s\n",
      "746:\tlearn: 0.0408072\ttotal: 3.17s\tremaining: 1.07s\n",
      "747:\tlearn: 0.0407752\ttotal: 3.17s\tremaining: 1.07s\n",
      "748:\tlearn: 0.0407128\ttotal: 3.17s\tremaining: 1.06s\n",
      "749:\tlearn: 0.0406898\ttotal: 3.18s\tremaining: 1.06s\n",
      "750:\tlearn: 0.0406607\ttotal: 3.18s\tremaining: 1.05s\n",
      "751:\tlearn: 0.0406195\ttotal: 3.19s\tremaining: 1.05s\n",
      "752:\tlearn: 0.0405678\ttotal: 3.19s\tremaining: 1.05s\n",
      "753:\tlearn: 0.0405151\ttotal: 3.19s\tremaining: 1.04s\n",
      "754:\tlearn: 0.0404570\ttotal: 3.2s\tremaining: 1.04s\n",
      "755:\tlearn: 0.0404323\ttotal: 3.2s\tremaining: 1.03s\n",
      "756:\tlearn: 0.0403714\ttotal: 3.21s\tremaining: 1.03s\n",
      "757:\tlearn: 0.0403400\ttotal: 3.21s\tremaining: 1.02s\n",
      "758:\tlearn: 0.0402765\ttotal: 3.21s\tremaining: 1.02s\n",
      "759:\tlearn: 0.0402309\ttotal: 3.22s\tremaining: 1.01s\n",
      "760:\tlearn: 0.0402183\ttotal: 3.22s\tremaining: 1.01s\n",
      "761:\tlearn: 0.0401699\ttotal: 3.22s\tremaining: 1.01s\n",
      "762:\tlearn: 0.0401157\ttotal: 3.23s\tremaining: 1s\n",
      "763:\tlearn: 0.0400572\ttotal: 3.23s\tremaining: 998ms\n",
      "764:\tlearn: 0.0400207\ttotal: 3.23s\tremaining: 994ms\n",
      "765:\tlearn: 0.0399971\ttotal: 3.24s\tremaining: 989ms\n",
      "766:\tlearn: 0.0399701\ttotal: 3.24s\tremaining: 985ms\n",
      "767:\tlearn: 0.0399359\ttotal: 3.25s\tremaining: 981ms\n",
      "768:\tlearn: 0.0399078\ttotal: 3.25s\tremaining: 976ms\n",
      "769:\tlearn: 0.0398862\ttotal: 3.25s\tremaining: 972ms\n",
      "770:\tlearn: 0.0398506\ttotal: 3.26s\tremaining: 968ms\n",
      "771:\tlearn: 0.0398312\ttotal: 3.26s\tremaining: 963ms\n",
      "772:\tlearn: 0.0397817\ttotal: 3.27s\tremaining: 959ms\n",
      "773:\tlearn: 0.0396974\ttotal: 3.27s\tremaining: 954ms\n",
      "774:\tlearn: 0.0396612\ttotal: 3.27s\tremaining: 950ms\n",
      "775:\tlearn: 0.0396137\ttotal: 3.28s\tremaining: 946ms\n",
      "776:\tlearn: 0.0395249\ttotal: 3.28s\tremaining: 941ms\n",
      "777:\tlearn: 0.0394893\ttotal: 3.28s\tremaining: 937ms\n",
      "778:\tlearn: 0.0394559\ttotal: 3.29s\tremaining: 933ms\n",
      "779:\tlearn: 0.0394407\ttotal: 3.29s\tremaining: 928ms\n",
      "780:\tlearn: 0.0393884\ttotal: 3.29s\tremaining: 924ms\n",
      "781:\tlearn: 0.0393673\ttotal: 3.3s\tremaining: 920ms\n",
      "782:\tlearn: 0.0393174\ttotal: 3.3s\tremaining: 915ms\n",
      "783:\tlearn: 0.0392633\ttotal: 3.31s\tremaining: 911ms\n",
      "784:\tlearn: 0.0391737\ttotal: 3.31s\tremaining: 907ms\n",
      "785:\tlearn: 0.0391167\ttotal: 3.31s\tremaining: 902ms\n",
      "786:\tlearn: 0.0390585\ttotal: 3.32s\tremaining: 898ms\n",
      "787:\tlearn: 0.0390377\ttotal: 3.32s\tremaining: 894ms\n",
      "788:\tlearn: 0.0389861\ttotal: 3.33s\tremaining: 890ms\n",
      "789:\tlearn: 0.0389399\ttotal: 3.33s\tremaining: 885ms\n",
      "790:\tlearn: 0.0389070\ttotal: 3.33s\tremaining: 881ms\n",
      "791:\tlearn: 0.0388432\ttotal: 3.34s\tremaining: 877ms\n",
      "792:\tlearn: 0.0388232\ttotal: 3.34s\tremaining: 873ms\n",
      "793:\tlearn: 0.0387605\ttotal: 3.35s\tremaining: 869ms\n",
      "794:\tlearn: 0.0387072\ttotal: 3.35s\tremaining: 865ms\n",
      "795:\tlearn: 0.0386753\ttotal: 3.36s\tremaining: 860ms\n",
      "796:\tlearn: 0.0386378\ttotal: 3.36s\tremaining: 856ms\n",
      "797:\tlearn: 0.0386118\ttotal: 3.36s\tremaining: 852ms\n",
      "798:\tlearn: 0.0385617\ttotal: 3.37s\tremaining: 848ms\n",
      "799:\tlearn: 0.0385424\ttotal: 3.37s\tremaining: 843ms\n",
      "800:\tlearn: 0.0385209\ttotal: 3.38s\tremaining: 839ms\n",
      "801:\tlearn: 0.0385036\ttotal: 3.38s\tremaining: 835ms\n",
      "802:\tlearn: 0.0384647\ttotal: 3.38s\tremaining: 831ms\n",
      "803:\tlearn: 0.0384160\ttotal: 3.39s\tremaining: 826ms\n",
      "804:\tlearn: 0.0383697\ttotal: 3.39s\tremaining: 822ms\n",
      "805:\tlearn: 0.0383502\ttotal: 3.4s\tremaining: 818ms\n",
      "806:\tlearn: 0.0383271\ttotal: 3.4s\tremaining: 813ms\n",
      "807:\tlearn: 0.0383013\ttotal: 3.4s\tremaining: 809ms\n",
      "808:\tlearn: 0.0382818\ttotal: 3.41s\tremaining: 805ms\n",
      "809:\tlearn: 0.0382382\ttotal: 3.41s\tremaining: 801ms\n",
      "810:\tlearn: 0.0381660\ttotal: 3.42s\tremaining: 796ms\n",
      "811:\tlearn: 0.0381116\ttotal: 3.42s\tremaining: 792ms\n",
      "812:\tlearn: 0.0380713\ttotal: 3.42s\tremaining: 788ms\n",
      "813:\tlearn: 0.0380507\ttotal: 3.43s\tremaining: 783ms\n",
      "814:\tlearn: 0.0379832\ttotal: 3.43s\tremaining: 779ms\n",
      "815:\tlearn: 0.0379539\ttotal: 3.44s\tremaining: 775ms\n",
      "816:\tlearn: 0.0379331\ttotal: 3.44s\tremaining: 771ms\n",
      "817:\tlearn: 0.0379150\ttotal: 3.44s\tremaining: 766ms\n",
      "818:\tlearn: 0.0378708\ttotal: 3.45s\tremaining: 762ms\n",
      "819:\tlearn: 0.0378355\ttotal: 3.45s\tremaining: 758ms\n",
      "820:\tlearn: 0.0378239\ttotal: 3.46s\tremaining: 754ms\n",
      "821:\tlearn: 0.0377574\ttotal: 3.46s\tremaining: 749ms\n",
      "822:\tlearn: 0.0377368\ttotal: 3.46s\tremaining: 745ms\n",
      "823:\tlearn: 0.0377104\ttotal: 3.47s\tremaining: 741ms\n",
      "824:\tlearn: 0.0376889\ttotal: 3.47s\tremaining: 736ms\n",
      "825:\tlearn: 0.0376187\ttotal: 3.48s\tremaining: 732ms\n",
      "826:\tlearn: 0.0376014\ttotal: 3.48s\tremaining: 728ms\n",
      "827:\tlearn: 0.0375601\ttotal: 3.48s\tremaining: 724ms\n",
      "828:\tlearn: 0.0375083\ttotal: 3.49s\tremaining: 719ms\n",
      "829:\tlearn: 0.0374408\ttotal: 3.49s\tremaining: 715ms\n",
      "830:\tlearn: 0.0374021\ttotal: 3.5s\tremaining: 711ms\n",
      "831:\tlearn: 0.0373675\ttotal: 3.5s\tremaining: 707ms\n",
      "832:\tlearn: 0.0373480\ttotal: 3.5s\tremaining: 703ms\n",
      "833:\tlearn: 0.0373294\ttotal: 3.51s\tremaining: 698ms\n",
      "834:\tlearn: 0.0373095\ttotal: 3.51s\tremaining: 694ms\n",
      "835:\tlearn: 0.0372911\ttotal: 3.52s\tremaining: 690ms\n",
      "836:\tlearn: 0.0372695\ttotal: 3.52s\tremaining: 686ms\n",
      "837:\tlearn: 0.0372331\ttotal: 3.53s\tremaining: 682ms\n",
      "838:\tlearn: 0.0372159\ttotal: 3.53s\tremaining: 677ms\n",
      "839:\tlearn: 0.0371855\ttotal: 3.53s\tremaining: 673ms\n",
      "840:\tlearn: 0.0371390\ttotal: 3.54s\tremaining: 669ms\n",
      "841:\tlearn: 0.0370968\ttotal: 3.54s\tremaining: 665ms\n",
      "842:\tlearn: 0.0370647\ttotal: 3.55s\tremaining: 661ms\n",
      "843:\tlearn: 0.0370329\ttotal: 3.55s\tremaining: 656ms\n",
      "844:\tlearn: 0.0370136\ttotal: 3.56s\tremaining: 652ms\n",
      "845:\tlearn: 0.0369984\ttotal: 3.56s\tremaining: 648ms\n",
      "846:\tlearn: 0.0369818\ttotal: 3.56s\tremaining: 644ms\n",
      "847:\tlearn: 0.0369546\ttotal: 3.57s\tremaining: 639ms\n",
      "848:\tlearn: 0.0369353\ttotal: 3.57s\tremaining: 635ms\n",
      "849:\tlearn: 0.0369176\ttotal: 3.58s\tremaining: 631ms\n",
      "850:\tlearn: 0.0369012\ttotal: 3.58s\tremaining: 627ms\n",
      "851:\tlearn: 0.0368642\ttotal: 3.58s\tremaining: 622ms\n",
      "852:\tlearn: 0.0368413\ttotal: 3.59s\tremaining: 618ms\n",
      "853:\tlearn: 0.0368224\ttotal: 3.59s\tremaining: 614ms\n",
      "854:\tlearn: 0.0368031\ttotal: 3.59s\tremaining: 610ms\n",
      "855:\tlearn: 0.0367842\ttotal: 3.6s\tremaining: 605ms\n",
      "856:\tlearn: 0.0367658\ttotal: 3.6s\tremaining: 601ms\n",
      "857:\tlearn: 0.0367383\ttotal: 3.61s\tremaining: 597ms\n",
      "858:\tlearn: 0.0367195\ttotal: 3.61s\tremaining: 593ms\n",
      "859:\tlearn: 0.0367051\ttotal: 3.61s\tremaining: 588ms\n",
      "860:\tlearn: 0.0366588\ttotal: 3.62s\tremaining: 584ms\n",
      "861:\tlearn: 0.0366372\ttotal: 3.62s\tremaining: 580ms\n",
      "862:\tlearn: 0.0366267\ttotal: 3.63s\tremaining: 576ms\n",
      "863:\tlearn: 0.0366079\ttotal: 3.63s\tremaining: 572ms\n",
      "864:\tlearn: 0.0365839\ttotal: 3.63s\tremaining: 567ms\n",
      "865:\tlearn: 0.0365445\ttotal: 3.64s\tremaining: 563ms\n",
      "866:\tlearn: 0.0365038\ttotal: 3.64s\tremaining: 559ms\n",
      "867:\tlearn: 0.0364811\ttotal: 3.65s\tremaining: 555ms\n",
      "868:\tlearn: 0.0364560\ttotal: 3.65s\tremaining: 551ms\n",
      "869:\tlearn: 0.0364386\ttotal: 3.66s\tremaining: 546ms\n",
      "870:\tlearn: 0.0364040\ttotal: 3.66s\tremaining: 542ms\n",
      "871:\tlearn: 0.0363866\ttotal: 3.66s\tremaining: 538ms\n",
      "872:\tlearn: 0.0363726\ttotal: 3.67s\tremaining: 534ms\n",
      "873:\tlearn: 0.0363549\ttotal: 3.67s\tremaining: 529ms\n",
      "874:\tlearn: 0.0363346\ttotal: 3.68s\tremaining: 525ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875:\tlearn: 0.0363095\ttotal: 3.68s\tremaining: 521ms\n",
      "876:\tlearn: 0.0362592\ttotal: 3.69s\tremaining: 517ms\n",
      "877:\tlearn: 0.0362431\ttotal: 3.69s\tremaining: 513ms\n",
      "878:\tlearn: 0.0361956\ttotal: 3.69s\tremaining: 509ms\n",
      "879:\tlearn: 0.0361510\ttotal: 3.7s\tremaining: 504ms\n",
      "880:\tlearn: 0.0361294\ttotal: 3.7s\tremaining: 500ms\n",
      "881:\tlearn: 0.0361082\ttotal: 3.71s\tremaining: 496ms\n",
      "882:\tlearn: 0.0360591\ttotal: 3.71s\tremaining: 492ms\n",
      "883:\tlearn: 0.0360419\ttotal: 3.71s\tremaining: 488ms\n",
      "884:\tlearn: 0.0360127\ttotal: 3.72s\tremaining: 483ms\n",
      "885:\tlearn: 0.0359543\ttotal: 3.72s\tremaining: 479ms\n",
      "886:\tlearn: 0.0359343\ttotal: 3.73s\tremaining: 475ms\n",
      "887:\tlearn: 0.0359131\ttotal: 3.73s\tremaining: 471ms\n",
      "888:\tlearn: 0.0358695\ttotal: 3.74s\tremaining: 467ms\n",
      "889:\tlearn: 0.0358525\ttotal: 3.74s\tremaining: 462ms\n",
      "890:\tlearn: 0.0358328\ttotal: 3.75s\tremaining: 458ms\n",
      "891:\tlearn: 0.0358143\ttotal: 3.75s\tremaining: 454ms\n",
      "892:\tlearn: 0.0357657\ttotal: 3.75s\tremaining: 450ms\n",
      "893:\tlearn: 0.0357179\ttotal: 3.76s\tremaining: 446ms\n",
      "894:\tlearn: 0.0356711\ttotal: 3.76s\tremaining: 441ms\n",
      "895:\tlearn: 0.0356327\ttotal: 3.77s\tremaining: 437ms\n",
      "896:\tlearn: 0.0355938\ttotal: 3.77s\tremaining: 433ms\n",
      "897:\tlearn: 0.0355484\ttotal: 3.77s\tremaining: 429ms\n",
      "898:\tlearn: 0.0355184\ttotal: 3.78s\tremaining: 425ms\n",
      "899:\tlearn: 0.0354758\ttotal: 3.78s\tremaining: 421ms\n",
      "900:\tlearn: 0.0354043\ttotal: 3.79s\tremaining: 416ms\n",
      "901:\tlearn: 0.0353722\ttotal: 3.79s\tremaining: 412ms\n",
      "902:\tlearn: 0.0353144\ttotal: 3.8s\tremaining: 408ms\n",
      "903:\tlearn: 0.0352836\ttotal: 3.8s\tremaining: 404ms\n",
      "904:\tlearn: 0.0352644\ttotal: 3.8s\tremaining: 399ms\n",
      "905:\tlearn: 0.0352475\ttotal: 3.81s\tremaining: 395ms\n",
      "906:\tlearn: 0.0352136\ttotal: 3.81s\tremaining: 391ms\n",
      "907:\tlearn: 0.0351678\ttotal: 3.82s\tremaining: 387ms\n",
      "908:\tlearn: 0.0351512\ttotal: 3.82s\tremaining: 382ms\n",
      "909:\tlearn: 0.0351103\ttotal: 3.82s\tremaining: 378ms\n",
      "910:\tlearn: 0.0350871\ttotal: 3.83s\tremaining: 374ms\n",
      "911:\tlearn: 0.0350675\ttotal: 3.83s\tremaining: 370ms\n",
      "912:\tlearn: 0.0350473\ttotal: 3.84s\tremaining: 366ms\n",
      "913:\tlearn: 0.0350336\ttotal: 3.84s\tremaining: 361ms\n",
      "914:\tlearn: 0.0350130\ttotal: 3.84s\tremaining: 357ms\n",
      "915:\tlearn: 0.0349980\ttotal: 3.85s\tremaining: 353ms\n",
      "916:\tlearn: 0.0349664\ttotal: 3.85s\tremaining: 349ms\n",
      "917:\tlearn: 0.0349354\ttotal: 3.86s\tremaining: 344ms\n",
      "918:\tlearn: 0.0349226\ttotal: 3.86s\tremaining: 340ms\n",
      "919:\tlearn: 0.0348840\ttotal: 3.86s\tremaining: 336ms\n",
      "920:\tlearn: 0.0348714\ttotal: 3.87s\tremaining: 332ms\n",
      "921:\tlearn: 0.0348295\ttotal: 3.87s\tremaining: 328ms\n",
      "922:\tlearn: 0.0347891\ttotal: 3.88s\tremaining: 323ms\n",
      "923:\tlearn: 0.0347645\ttotal: 3.88s\tremaining: 319ms\n",
      "924:\tlearn: 0.0347438\ttotal: 3.88s\tremaining: 315ms\n",
      "925:\tlearn: 0.0346961\ttotal: 3.89s\tremaining: 311ms\n",
      "926:\tlearn: 0.0346721\ttotal: 3.89s\tremaining: 307ms\n",
      "927:\tlearn: 0.0346329\ttotal: 3.9s\tremaining: 302ms\n",
      "928:\tlearn: 0.0345978\ttotal: 3.9s\tremaining: 298ms\n",
      "929:\tlearn: 0.0345322\ttotal: 3.91s\tremaining: 294ms\n",
      "930:\tlearn: 0.0345146\ttotal: 3.91s\tremaining: 290ms\n",
      "931:\tlearn: 0.0344993\ttotal: 3.92s\tremaining: 286ms\n",
      "932:\tlearn: 0.0344843\ttotal: 3.92s\tremaining: 281ms\n",
      "933:\tlearn: 0.0344617\ttotal: 3.92s\tremaining: 277ms\n",
      "934:\tlearn: 0.0344429\ttotal: 3.93s\tremaining: 273ms\n",
      "935:\tlearn: 0.0344094\ttotal: 3.93s\tremaining: 269ms\n",
      "936:\tlearn: 0.0343953\ttotal: 3.94s\tremaining: 265ms\n",
      "937:\tlearn: 0.0343728\ttotal: 3.94s\tremaining: 261ms\n",
      "938:\tlearn: 0.0343340\ttotal: 3.95s\tremaining: 256ms\n",
      "939:\tlearn: 0.0343174\ttotal: 3.95s\tremaining: 252ms\n",
      "940:\tlearn: 0.0342782\ttotal: 3.96s\tremaining: 248ms\n",
      "941:\tlearn: 0.0342420\ttotal: 3.96s\tremaining: 244ms\n",
      "942:\tlearn: 0.0342095\ttotal: 3.97s\tremaining: 240ms\n",
      "943:\tlearn: 0.0341808\ttotal: 3.97s\tremaining: 236ms\n",
      "944:\tlearn: 0.0341300\ttotal: 3.97s\tremaining: 231ms\n",
      "945:\tlearn: 0.0341100\ttotal: 3.98s\tremaining: 227ms\n",
      "946:\tlearn: 0.0340782\ttotal: 3.98s\tremaining: 223ms\n",
      "947:\tlearn: 0.0340610\ttotal: 3.99s\tremaining: 219ms\n",
      "948:\tlearn: 0.0340424\ttotal: 3.99s\tremaining: 215ms\n",
      "949:\tlearn: 0.0339949\ttotal: 4s\tremaining: 210ms\n",
      "950:\tlearn: 0.0339683\ttotal: 4s\tremaining: 206ms\n",
      "951:\tlearn: 0.0339472\ttotal: 4s\tremaining: 202ms\n",
      "952:\tlearn: 0.0339303\ttotal: 4.01s\tremaining: 198ms\n",
      "953:\tlearn: 0.0339143\ttotal: 4.01s\tremaining: 193ms\n",
      "954:\tlearn: 0.0338981\ttotal: 4.01s\tremaining: 189ms\n",
      "955:\tlearn: 0.0338706\ttotal: 4.02s\tremaining: 185ms\n",
      "956:\tlearn: 0.0338544\ttotal: 4.02s\tremaining: 181ms\n",
      "957:\tlearn: 0.0338430\ttotal: 4.03s\tremaining: 177ms\n",
      "958:\tlearn: 0.0338270\ttotal: 4.03s\tremaining: 172ms\n",
      "959:\tlearn: 0.0337960\ttotal: 4.04s\tremaining: 168ms\n",
      "960:\tlearn: 0.0337259\ttotal: 4.04s\tremaining: 164ms\n",
      "961:\tlearn: 0.0336867\ttotal: 4.04s\tremaining: 160ms\n",
      "962:\tlearn: 0.0336501\ttotal: 4.05s\tremaining: 156ms\n",
      "963:\tlearn: 0.0336351\ttotal: 4.05s\tremaining: 151ms\n",
      "964:\tlearn: 0.0336027\ttotal: 4.06s\tremaining: 147ms\n",
      "965:\tlearn: 0.0335735\ttotal: 4.06s\tremaining: 143ms\n",
      "966:\tlearn: 0.0335317\ttotal: 4.07s\tremaining: 139ms\n",
      "967:\tlearn: 0.0334954\ttotal: 4.07s\tremaining: 135ms\n",
      "968:\tlearn: 0.0334490\ttotal: 4.07s\tremaining: 130ms\n",
      "969:\tlearn: 0.0334219\ttotal: 4.08s\tremaining: 126ms\n",
      "970:\tlearn: 0.0334079\ttotal: 4.08s\tremaining: 122ms\n",
      "971:\tlearn: 0.0333780\ttotal: 4.08s\tremaining: 118ms\n",
      "972:\tlearn: 0.0333481\ttotal: 4.09s\tremaining: 113ms\n",
      "973:\tlearn: 0.0333333\ttotal: 4.09s\tremaining: 109ms\n",
      "974:\tlearn: 0.0332970\ttotal: 4.1s\tremaining: 105ms\n",
      "975:\tlearn: 0.0332576\ttotal: 4.1s\tremaining: 101ms\n",
      "976:\tlearn: 0.0332223\ttotal: 4.1s\tremaining: 96.6ms\n",
      "977:\tlearn: 0.0331940\ttotal: 4.11s\tremaining: 92.4ms\n",
      "978:\tlearn: 0.0331657\ttotal: 4.11s\tremaining: 88.2ms\n",
      "979:\tlearn: 0.0331381\ttotal: 4.12s\tremaining: 84ms\n",
      "980:\tlearn: 0.0331228\ttotal: 4.12s\tremaining: 79.8ms\n",
      "981:\tlearn: 0.0331071\ttotal: 4.13s\tremaining: 75.6ms\n",
      "982:\tlearn: 0.0330685\ttotal: 4.13s\tremaining: 71.4ms\n",
      "983:\tlearn: 0.0330565\ttotal: 4.13s\tremaining: 67.2ms\n",
      "984:\tlearn: 0.0329960\ttotal: 4.14s\tremaining: 63ms\n",
      "985:\tlearn: 0.0329792\ttotal: 4.14s\tremaining: 58.8ms\n",
      "986:\tlearn: 0.0329601\ttotal: 4.14s\tremaining: 54.6ms\n",
      "987:\tlearn: 0.0329467\ttotal: 4.15s\tremaining: 50.4ms\n",
      "988:\tlearn: 0.0329349\ttotal: 4.15s\tremaining: 46.2ms\n",
      "989:\tlearn: 0.0329072\ttotal: 4.16s\tremaining: 42ms\n",
      "990:\tlearn: 0.0328885\ttotal: 4.16s\tremaining: 37.8ms\n",
      "991:\tlearn: 0.0328745\ttotal: 4.17s\tremaining: 33.6ms\n",
      "992:\tlearn: 0.0328474\ttotal: 4.17s\tremaining: 29.4ms\n",
      "993:\tlearn: 0.0328256\ttotal: 4.17s\tremaining: 25.2ms\n",
      "994:\tlearn: 0.0328116\ttotal: 4.18s\tremaining: 21ms\n",
      "995:\tlearn: 0.0327736\ttotal: 4.18s\tremaining: 16.8ms\n",
      "996:\tlearn: 0.0327390\ttotal: 4.18s\tremaining: 12.6ms\n",
      "997:\tlearn: 0.0327191\ttotal: 4.19s\tremaining: 8.39ms\n",
      "998:\tlearn: 0.0326855\ttotal: 4.19s\tremaining: 4.2ms\n",
      "999:\tlearn: 0.0326681\ttotal: 4.2s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:09] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013276\n",
      "0:\tlearn: 0.6678452\ttotal: 4.86ms\tremaining: 4.86s\n",
      "1:\tlearn: 0.6443257\ttotal: 8.63ms\tremaining: 4.3s\n",
      "2:\tlearn: 0.6200072\ttotal: 12.4ms\tremaining: 4.12s\n",
      "3:\tlearn: 0.5977488\ttotal: 15.9ms\tremaining: 3.96s\n",
      "4:\tlearn: 0.5755904\ttotal: 19.6ms\tremaining: 3.9s\n",
      "5:\tlearn: 0.5598102\ttotal: 23ms\tremaining: 3.81s\n",
      "6:\tlearn: 0.5398914\ttotal: 26.7ms\tremaining: 3.79s\n",
      "7:\tlearn: 0.5228764\ttotal: 30.6ms\tremaining: 3.79s\n",
      "8:\tlearn: 0.5076528\ttotal: 35.4ms\tremaining: 3.9s\n",
      "9:\tlearn: 0.4905056\ttotal: 39.6ms\tremaining: 3.92s\n",
      "10:\tlearn: 0.4748955\ttotal: 43.3ms\tremaining: 3.89s\n",
      "11:\tlearn: 0.4589653\ttotal: 47.7ms\tremaining: 3.93s\n",
      "12:\tlearn: 0.4439314\ttotal: 52.4ms\tremaining: 3.98s\n",
      "13:\tlearn: 0.4294930\ttotal: 56.6ms\tremaining: 3.98s\n",
      "14:\tlearn: 0.4160493\ttotal: 60.4ms\tremaining: 3.97s\n",
      "15:\tlearn: 0.4025838\ttotal: 65.1ms\tremaining: 4s\n",
      "16:\tlearn: 0.3919773\ttotal: 69.7ms\tremaining: 4.03s\n",
      "17:\tlearn: 0.3795450\ttotal: 73.6ms\tremaining: 4.01s\n",
      "18:\tlearn: 0.3682808\ttotal: 77.9ms\tremaining: 4.02s\n",
      "19:\tlearn: 0.3581858\ttotal: 82.2ms\tremaining: 4.03s\n",
      "20:\tlearn: 0.3487535\ttotal: 85.9ms\tremaining: 4s\n",
      "21:\tlearn: 0.3414740\ttotal: 90ms\tremaining: 4s\n",
      "22:\tlearn: 0.3323218\ttotal: 94.2ms\tremaining: 4s\n",
      "23:\tlearn: 0.3249813\ttotal: 99.1ms\tremaining: 4.03s\n",
      "24:\tlearn: 0.3167072\ttotal: 103ms\tremaining: 4.02s\n",
      "25:\tlearn: 0.3087670\ttotal: 107ms\tremaining: 4s\n",
      "26:\tlearn: 0.3022660\ttotal: 110ms\tremaining: 3.98s\n",
      "27:\tlearn: 0.2945563\ttotal: 114ms\tremaining: 3.96s\n",
      "28:\tlearn: 0.2876962\ttotal: 118ms\tremaining: 3.94s\n",
      "29:\tlearn: 0.2813190\ttotal: 121ms\tremaining: 3.92s\n",
      "30:\tlearn: 0.2750407\ttotal: 125ms\tremaining: 3.9s\n",
      "31:\tlearn: 0.2682069\ttotal: 128ms\tremaining: 3.87s\n",
      "32:\tlearn: 0.2623752\ttotal: 131ms\tremaining: 3.85s\n",
      "33:\tlearn: 0.2570749\ttotal: 135ms\tremaining: 3.85s\n",
      "34:\tlearn: 0.2524092\ttotal: 139ms\tremaining: 3.83s\n",
      "35:\tlearn: 0.2470980\ttotal: 143ms\tremaining: 3.82s\n",
      "36:\tlearn: 0.2422058\ttotal: 146ms\tremaining: 3.8s\n",
      "37:\tlearn: 0.2377174\ttotal: 150ms\tremaining: 3.79s\n",
      "38:\tlearn: 0.2333830\ttotal: 153ms\tremaining: 3.78s\n",
      "39:\tlearn: 0.2286120\ttotal: 157ms\tremaining: 3.76s\n",
      "40:\tlearn: 0.2249846\ttotal: 160ms\tremaining: 3.75s\n",
      "41:\tlearn: 0.2210748\ttotal: 165ms\tremaining: 3.75s\n",
      "42:\tlearn: 0.2169972\ttotal: 168ms\tremaining: 3.75s\n",
      "43:\tlearn: 0.2131211\ttotal: 172ms\tremaining: 3.74s\n",
      "44:\tlearn: 0.2093656\ttotal: 176ms\tremaining: 3.73s\n",
      "45:\tlearn: 0.2061195\ttotal: 180ms\tremaining: 3.73s\n",
      "46:\tlearn: 0.2025773\ttotal: 184ms\tremaining: 3.73s\n",
      "47:\tlearn: 0.1992541\ttotal: 188ms\tremaining: 3.72s\n",
      "48:\tlearn: 0.1969806\ttotal: 192ms\tremaining: 3.72s\n",
      "49:\tlearn: 0.1936715\ttotal: 196ms\tremaining: 3.72s\n",
      "50:\tlearn: 0.1910700\ttotal: 199ms\tremaining: 3.71s\n",
      "51:\tlearn: 0.1881987\ttotal: 203ms\tremaining: 3.71s\n",
      "52:\tlearn: 0.1857205\ttotal: 207ms\tremaining: 3.7s\n",
      "53:\tlearn: 0.1828433\ttotal: 211ms\tremaining: 3.69s\n",
      "54:\tlearn: 0.1804873\ttotal: 214ms\tremaining: 3.68s\n",
      "55:\tlearn: 0.1776186\ttotal: 218ms\tremaining: 3.67s\n",
      "56:\tlearn: 0.1752688\ttotal: 221ms\tremaining: 3.66s\n",
      "57:\tlearn: 0.1731583\ttotal: 225ms\tremaining: 3.65s\n",
      "58:\tlearn: 0.1713695\ttotal: 229ms\tremaining: 3.65s\n",
      "59:\tlearn: 0.1691346\ttotal: 232ms\tremaining: 3.64s\n",
      "60:\tlearn: 0.1674294\ttotal: 237ms\tremaining: 3.64s\n",
      "61:\tlearn: 0.1653910\ttotal: 240ms\tremaining: 3.63s\n",
      "62:\tlearn: 0.1633646\ttotal: 244ms\tremaining: 3.62s\n",
      "63:\tlearn: 0.1618545\ttotal: 247ms\tremaining: 3.62s\n",
      "64:\tlearn: 0.1601208\ttotal: 251ms\tremaining: 3.61s\n",
      "65:\tlearn: 0.1587506\ttotal: 255ms\tremaining: 3.6s\n",
      "66:\tlearn: 0.1573147\ttotal: 259ms\tremaining: 3.6s\n",
      "67:\tlearn: 0.1559645\ttotal: 262ms\tremaining: 3.59s\n",
      "68:\tlearn: 0.1545533\ttotal: 266ms\tremaining: 3.59s\n",
      "69:\tlearn: 0.1530382\ttotal: 270ms\tremaining: 3.58s\n",
      "70:\tlearn: 0.1515818\ttotal: 274ms\tremaining: 3.58s\n",
      "71:\tlearn: 0.1500905\ttotal: 277ms\tremaining: 3.57s\n",
      "72:\tlearn: 0.1487953\ttotal: 281ms\tremaining: 3.57s\n",
      "73:\tlearn: 0.1475639\ttotal: 285ms\tremaining: 3.56s\n",
      "74:\tlearn: 0.1462343\ttotal: 289ms\tremaining: 3.56s\n",
      "75:\tlearn: 0.1450562\ttotal: 292ms\tremaining: 3.56s\n",
      "76:\tlearn: 0.1441216\ttotal: 296ms\tremaining: 3.55s\n",
      "77:\tlearn: 0.1430689\ttotal: 299ms\tremaining: 3.54s\n",
      "78:\tlearn: 0.1418939\ttotal: 303ms\tremaining: 3.54s\n",
      "79:\tlearn: 0.1407599\ttotal: 307ms\tremaining: 3.53s\n",
      "80:\tlearn: 0.1397932\ttotal: 311ms\tremaining: 3.52s\n",
      "81:\tlearn: 0.1387270\ttotal: 314ms\tremaining: 3.52s\n",
      "82:\tlearn: 0.1377188\ttotal: 318ms\tremaining: 3.51s\n",
      "83:\tlearn: 0.1370576\ttotal: 322ms\tremaining: 3.51s\n",
      "84:\tlearn: 0.1363555\ttotal: 326ms\tremaining: 3.51s\n",
      "85:\tlearn: 0.1353678\ttotal: 329ms\tremaining: 3.5s\n",
      "86:\tlearn: 0.1345280\ttotal: 333ms\tremaining: 3.49s\n",
      "87:\tlearn: 0.1337378\ttotal: 337ms\tremaining: 3.49s\n",
      "88:\tlearn: 0.1328631\ttotal: 341ms\tremaining: 3.48s\n",
      "89:\tlearn: 0.1319238\ttotal: 344ms\tremaining: 3.48s\n",
      "90:\tlearn: 0.1311591\ttotal: 348ms\tremaining: 3.48s\n",
      "91:\tlearn: 0.1306596\ttotal: 353ms\tremaining: 3.48s\n",
      "92:\tlearn: 0.1299244\ttotal: 357ms\tremaining: 3.48s\n",
      "93:\tlearn: 0.1290914\ttotal: 361ms\tremaining: 3.48s\n",
      "94:\tlearn: 0.1284237\ttotal: 365ms\tremaining: 3.47s\n",
      "95:\tlearn: 0.1276581\ttotal: 368ms\tremaining: 3.47s\n",
      "96:\tlearn: 0.1269934\ttotal: 372ms\tremaining: 3.46s\n",
      "97:\tlearn: 0.1262116\ttotal: 376ms\tremaining: 3.46s\n",
      "98:\tlearn: 0.1254391\ttotal: 379ms\tremaining: 3.45s\n",
      "99:\tlearn: 0.1248777\ttotal: 384ms\tremaining: 3.45s\n",
      "100:\tlearn: 0.1242504\ttotal: 387ms\tremaining: 3.45s\n",
      "101:\tlearn: 0.1233903\ttotal: 391ms\tremaining: 3.44s\n",
      "102:\tlearn: 0.1226634\ttotal: 395ms\tremaining: 3.44s\n",
      "103:\tlearn: 0.1221349\ttotal: 398ms\tremaining: 3.43s\n",
      "104:\tlearn: 0.1216894\ttotal: 403ms\tremaining: 3.43s\n",
      "105:\tlearn: 0.1211387\ttotal: 407ms\tremaining: 3.43s\n",
      "106:\tlearn: 0.1204689\ttotal: 411ms\tremaining: 3.43s\n",
      "107:\tlearn: 0.1197216\ttotal: 415ms\tremaining: 3.43s\n",
      "108:\tlearn: 0.1189800\ttotal: 419ms\tremaining: 3.42s\n",
      "109:\tlearn: 0.1182740\ttotal: 422ms\tremaining: 3.42s\n",
      "110:\tlearn: 0.1178272\ttotal: 426ms\tremaining: 3.41s\n",
      "111:\tlearn: 0.1175102\ttotal: 430ms\tremaining: 3.41s\n",
      "112:\tlearn: 0.1171472\ttotal: 433ms\tremaining: 3.4s\n",
      "113:\tlearn: 0.1166358\ttotal: 437ms\tremaining: 3.39s\n",
      "114:\tlearn: 0.1160181\ttotal: 440ms\tremaining: 3.39s\n",
      "115:\tlearn: 0.1155459\ttotal: 444ms\tremaining: 3.38s\n",
      "116:\tlearn: 0.1151933\ttotal: 448ms\tremaining: 3.38s\n",
      "117:\tlearn: 0.1148374\ttotal: 451ms\tremaining: 3.37s\n",
      "118:\tlearn: 0.1143344\ttotal: 454ms\tremaining: 3.36s\n",
      "119:\tlearn: 0.1138335\ttotal: 458ms\tremaining: 3.36s\n",
      "120:\tlearn: 0.1133810\ttotal: 461ms\tremaining: 3.35s\n",
      "121:\tlearn: 0.1128691\ttotal: 465ms\tremaining: 3.34s\n",
      "122:\tlearn: 0.1124482\ttotal: 468ms\tremaining: 3.34s\n",
      "123:\tlearn: 0.1118959\ttotal: 472ms\tremaining: 3.33s\n",
      "124:\tlearn: 0.1116221\ttotal: 476ms\tremaining: 3.33s\n",
      "125:\tlearn: 0.1112068\ttotal: 479ms\tremaining: 3.32s\n",
      "126:\tlearn: 0.1108624\ttotal: 482ms\tremaining: 3.32s\n",
      "127:\tlearn: 0.1104682\ttotal: 486ms\tremaining: 3.31s\n",
      "128:\tlearn: 0.1100491\ttotal: 490ms\tremaining: 3.31s\n",
      "129:\tlearn: 0.1095444\ttotal: 493ms\tremaining: 3.3s\n",
      "130:\tlearn: 0.1090781\ttotal: 497ms\tremaining: 3.29s\n",
      "131:\tlearn: 0.1087950\ttotal: 500ms\tremaining: 3.29s\n",
      "132:\tlearn: 0.1083818\ttotal: 504ms\tremaining: 3.28s\n",
      "133:\tlearn: 0.1079243\ttotal: 507ms\tremaining: 3.28s\n",
      "134:\tlearn: 0.1075499\ttotal: 511ms\tremaining: 3.27s\n",
      "135:\tlearn: 0.1071744\ttotal: 514ms\tremaining: 3.27s\n",
      "136:\tlearn: 0.1068014\ttotal: 518ms\tremaining: 3.26s\n",
      "137:\tlearn: 0.1064361\ttotal: 521ms\tremaining: 3.26s\n",
      "138:\tlearn: 0.1061144\ttotal: 525ms\tremaining: 3.25s\n",
      "139:\tlearn: 0.1059274\ttotal: 529ms\tremaining: 3.25s\n",
      "140:\tlearn: 0.1056610\ttotal: 533ms\tremaining: 3.24s\n",
      "141:\tlearn: 0.1050784\ttotal: 537ms\tremaining: 3.24s\n",
      "142:\tlearn: 0.1046854\ttotal: 540ms\tremaining: 3.24s\n",
      "143:\tlearn: 0.1043576\ttotal: 544ms\tremaining: 3.23s\n",
      "144:\tlearn: 0.1040392\ttotal: 548ms\tremaining: 3.23s\n",
      "145:\tlearn: 0.1037095\ttotal: 552ms\tremaining: 3.23s\n",
      "146:\tlearn: 0.1033972\ttotal: 555ms\tremaining: 3.22s\n",
      "147:\tlearn: 0.1031723\ttotal: 559ms\tremaining: 3.21s\n",
      "148:\tlearn: 0.1029415\ttotal: 562ms\tremaining: 3.21s\n",
      "149:\tlearn: 0.1026558\ttotal: 566ms\tremaining: 3.21s\n",
      "150:\tlearn: 0.1023588\ttotal: 570ms\tremaining: 3.2s\n",
      "151:\tlearn: 0.1020356\ttotal: 575ms\tremaining: 3.21s\n",
      "152:\tlearn: 0.1017584\ttotal: 579ms\tremaining: 3.21s\n",
      "153:\tlearn: 0.1014837\ttotal: 583ms\tremaining: 3.2s\n",
      "154:\tlearn: 0.1012716\ttotal: 587ms\tremaining: 3.2s\n",
      "155:\tlearn: 0.1010075\ttotal: 591ms\tremaining: 3.19s\n",
      "156:\tlearn: 0.1007256\ttotal: 594ms\tremaining: 3.19s\n",
      "157:\tlearn: 0.1004506\ttotal: 598ms\tremaining: 3.19s\n",
      "158:\tlearn: 0.1000973\ttotal: 602ms\tremaining: 3.19s\n",
      "159:\tlearn: 0.0998169\ttotal: 605ms\tremaining: 3.18s\n",
      "160:\tlearn: 0.0995688\ttotal: 609ms\tremaining: 3.17s\n",
      "161:\tlearn: 0.0993388\ttotal: 612ms\tremaining: 3.17s\n",
      "162:\tlearn: 0.0991166\ttotal: 616ms\tremaining: 3.16s\n",
      "163:\tlearn: 0.0989479\ttotal: 620ms\tremaining: 3.16s\n",
      "164:\tlearn: 0.0985325\ttotal: 624ms\tremaining: 3.16s\n",
      "165:\tlearn: 0.0983238\ttotal: 627ms\tremaining: 3.15s\n",
      "166:\tlearn: 0.0980123\ttotal: 631ms\tremaining: 3.15s\n",
      "167:\tlearn: 0.0977228\ttotal: 635ms\tremaining: 3.14s\n",
      "168:\tlearn: 0.0974374\ttotal: 639ms\tremaining: 3.14s\n",
      "169:\tlearn: 0.0972146\ttotal: 643ms\tremaining: 3.14s\n",
      "170:\tlearn: 0.0969230\ttotal: 647ms\tremaining: 3.13s\n",
      "171:\tlearn: 0.0965832\ttotal: 651ms\tremaining: 3.13s\n",
      "172:\tlearn: 0.0963673\ttotal: 655ms\tremaining: 3.13s\n",
      "173:\tlearn: 0.0961515\ttotal: 659ms\tremaining: 3.13s\n",
      "174:\tlearn: 0.0959011\ttotal: 664ms\tremaining: 3.13s\n",
      "175:\tlearn: 0.0956106\ttotal: 668ms\tremaining: 3.13s\n",
      "176:\tlearn: 0.0954542\ttotal: 672ms\tremaining: 3.12s\n",
      "177:\tlearn: 0.0951907\ttotal: 675ms\tremaining: 3.12s\n",
      "178:\tlearn: 0.0948810\ttotal: 680ms\tremaining: 3.12s\n",
      "179:\tlearn: 0.0946962\ttotal: 683ms\tremaining: 3.11s\n",
      "180:\tlearn: 0.0944038\ttotal: 688ms\tremaining: 3.11s\n",
      "181:\tlearn: 0.0941252\ttotal: 691ms\tremaining: 3.11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182:\tlearn: 0.0937490\ttotal: 696ms\tremaining: 3.1s\n",
      "183:\tlearn: 0.0934514\ttotal: 700ms\tremaining: 3.1s\n",
      "184:\tlearn: 0.0931633\ttotal: 704ms\tremaining: 3.1s\n",
      "185:\tlearn: 0.0929137\ttotal: 708ms\tremaining: 3.1s\n",
      "186:\tlearn: 0.0925646\ttotal: 712ms\tremaining: 3.09s\n",
      "187:\tlearn: 0.0924197\ttotal: 716ms\tremaining: 3.09s\n",
      "188:\tlearn: 0.0922700\ttotal: 719ms\tremaining: 3.09s\n",
      "189:\tlearn: 0.0920150\ttotal: 724ms\tremaining: 3.09s\n",
      "190:\tlearn: 0.0918465\ttotal: 728ms\tremaining: 3.08s\n",
      "191:\tlearn: 0.0915185\ttotal: 732ms\tremaining: 3.08s\n",
      "192:\tlearn: 0.0913262\ttotal: 735ms\tremaining: 3.08s\n",
      "193:\tlearn: 0.0910962\ttotal: 739ms\tremaining: 3.07s\n",
      "194:\tlearn: 0.0907886\ttotal: 742ms\tremaining: 3.06s\n",
      "195:\tlearn: 0.0906149\ttotal: 746ms\tremaining: 3.06s\n",
      "196:\tlearn: 0.0903544\ttotal: 749ms\tremaining: 3.05s\n",
      "197:\tlearn: 0.0901716\ttotal: 753ms\tremaining: 3.05s\n",
      "198:\tlearn: 0.0899297\ttotal: 756ms\tremaining: 3.04s\n",
      "199:\tlearn: 0.0897165\ttotal: 759ms\tremaining: 3.04s\n",
      "200:\tlearn: 0.0895187\ttotal: 763ms\tremaining: 3.03s\n",
      "201:\tlearn: 0.0893606\ttotal: 766ms\tremaining: 3.03s\n",
      "202:\tlearn: 0.0890586\ttotal: 770ms\tremaining: 3.02s\n",
      "203:\tlearn: 0.0888964\ttotal: 773ms\tremaining: 3.02s\n",
      "204:\tlearn: 0.0887694\ttotal: 776ms\tremaining: 3.01s\n",
      "205:\tlearn: 0.0886299\ttotal: 780ms\tremaining: 3.01s\n",
      "206:\tlearn: 0.0884438\ttotal: 784ms\tremaining: 3s\n",
      "207:\tlearn: 0.0883044\ttotal: 787ms\tremaining: 3s\n",
      "208:\tlearn: 0.0880345\ttotal: 791ms\tremaining: 2.99s\n",
      "209:\tlearn: 0.0879008\ttotal: 794ms\tremaining: 2.99s\n",
      "210:\tlearn: 0.0876619\ttotal: 797ms\tremaining: 2.98s\n",
      "211:\tlearn: 0.0875228\ttotal: 801ms\tremaining: 2.98s\n",
      "212:\tlearn: 0.0872838\ttotal: 804ms\tremaining: 2.97s\n",
      "213:\tlearn: 0.0870324\ttotal: 808ms\tremaining: 2.97s\n",
      "214:\tlearn: 0.0868213\ttotal: 811ms\tremaining: 2.96s\n",
      "215:\tlearn: 0.0865361\ttotal: 815ms\tremaining: 2.96s\n",
      "216:\tlearn: 0.0863564\ttotal: 818ms\tremaining: 2.95s\n",
      "217:\tlearn: 0.0862478\ttotal: 822ms\tremaining: 2.95s\n",
      "218:\tlearn: 0.0860545\ttotal: 825ms\tremaining: 2.94s\n",
      "219:\tlearn: 0.0859109\ttotal: 829ms\tremaining: 2.94s\n",
      "220:\tlearn: 0.0857376\ttotal: 832ms\tremaining: 2.93s\n",
      "221:\tlearn: 0.0855243\ttotal: 836ms\tremaining: 2.93s\n",
      "222:\tlearn: 0.0853151\ttotal: 840ms\tremaining: 2.92s\n",
      "223:\tlearn: 0.0851586\ttotal: 843ms\tremaining: 2.92s\n",
      "224:\tlearn: 0.0850290\ttotal: 846ms\tremaining: 2.92s\n",
      "225:\tlearn: 0.0847392\ttotal: 850ms\tremaining: 2.91s\n",
      "226:\tlearn: 0.0845069\ttotal: 854ms\tremaining: 2.91s\n",
      "227:\tlearn: 0.0844186\ttotal: 857ms\tremaining: 2.9s\n",
      "228:\tlearn: 0.0841761\ttotal: 860ms\tremaining: 2.9s\n",
      "229:\tlearn: 0.0838913\ttotal: 864ms\tremaining: 2.89s\n",
      "230:\tlearn: 0.0836926\ttotal: 867ms\tremaining: 2.89s\n",
      "231:\tlearn: 0.0835989\ttotal: 871ms\tremaining: 2.88s\n",
      "232:\tlearn: 0.0833623\ttotal: 876ms\tremaining: 2.88s\n",
      "233:\tlearn: 0.0831116\ttotal: 880ms\tremaining: 2.88s\n",
      "234:\tlearn: 0.0829301\ttotal: 883ms\tremaining: 2.88s\n",
      "235:\tlearn: 0.0827155\ttotal: 887ms\tremaining: 2.87s\n",
      "236:\tlearn: 0.0825247\ttotal: 891ms\tremaining: 2.87s\n",
      "237:\tlearn: 0.0823926\ttotal: 894ms\tremaining: 2.86s\n",
      "238:\tlearn: 0.0822581\ttotal: 898ms\tremaining: 2.86s\n",
      "239:\tlearn: 0.0820545\ttotal: 901ms\tremaining: 2.85s\n",
      "240:\tlearn: 0.0819880\ttotal: 905ms\tremaining: 2.85s\n",
      "241:\tlearn: 0.0818560\ttotal: 908ms\tremaining: 2.84s\n",
      "242:\tlearn: 0.0816446\ttotal: 912ms\tremaining: 2.84s\n",
      "243:\tlearn: 0.0814993\ttotal: 915ms\tremaining: 2.83s\n",
      "244:\tlearn: 0.0813613\ttotal: 919ms\tremaining: 2.83s\n",
      "245:\tlearn: 0.0810975\ttotal: 922ms\tremaining: 2.83s\n",
      "246:\tlearn: 0.0809506\ttotal: 926ms\tremaining: 2.82s\n",
      "247:\tlearn: 0.0808553\ttotal: 929ms\tremaining: 2.82s\n",
      "248:\tlearn: 0.0806710\ttotal: 933ms\tremaining: 2.81s\n",
      "249:\tlearn: 0.0805368\ttotal: 937ms\tremaining: 2.81s\n",
      "250:\tlearn: 0.0804313\ttotal: 941ms\tremaining: 2.81s\n",
      "251:\tlearn: 0.0802619\ttotal: 945ms\tremaining: 2.8s\n",
      "252:\tlearn: 0.0801595\ttotal: 948ms\tremaining: 2.8s\n",
      "253:\tlearn: 0.0799653\ttotal: 952ms\tremaining: 2.79s\n",
      "254:\tlearn: 0.0798693\ttotal: 955ms\tremaining: 2.79s\n",
      "255:\tlearn: 0.0797572\ttotal: 958ms\tremaining: 2.79s\n",
      "256:\tlearn: 0.0796126\ttotal: 962ms\tremaining: 2.78s\n",
      "257:\tlearn: 0.0794691\ttotal: 965ms\tremaining: 2.78s\n",
      "258:\tlearn: 0.0793981\ttotal: 969ms\tremaining: 2.77s\n",
      "259:\tlearn: 0.0792573\ttotal: 973ms\tremaining: 2.77s\n",
      "260:\tlearn: 0.0790943\ttotal: 976ms\tremaining: 2.76s\n",
      "261:\tlearn: 0.0789418\ttotal: 980ms\tremaining: 2.76s\n",
      "262:\tlearn: 0.0787224\ttotal: 984ms\tremaining: 2.76s\n",
      "263:\tlearn: 0.0785615\ttotal: 987ms\tremaining: 2.75s\n",
      "264:\tlearn: 0.0783581\ttotal: 991ms\tremaining: 2.75s\n",
      "265:\tlearn: 0.0782324\ttotal: 994ms\tremaining: 2.74s\n",
      "266:\tlearn: 0.0781573\ttotal: 998ms\tremaining: 2.74s\n",
      "267:\tlearn: 0.0780009\ttotal: 1s\tremaining: 2.73s\n",
      "268:\tlearn: 0.0778677\ttotal: 1s\tremaining: 2.73s\n",
      "269:\tlearn: 0.0777002\ttotal: 1.01s\tremaining: 2.73s\n",
      "270:\tlearn: 0.0776322\ttotal: 1.01s\tremaining: 2.72s\n",
      "271:\tlearn: 0.0774517\ttotal: 1.01s\tremaining: 2.72s\n",
      "272:\tlearn: 0.0773388\ttotal: 1.02s\tremaining: 2.71s\n",
      "273:\tlearn: 0.0772282\ttotal: 1.02s\tremaining: 2.71s\n",
      "274:\tlearn: 0.0769985\ttotal: 1.02s\tremaining: 2.7s\n",
      "275:\tlearn: 0.0768854\ttotal: 1.03s\tremaining: 2.7s\n",
      "276:\tlearn: 0.0766902\ttotal: 1.03s\tremaining: 2.69s\n",
      "277:\tlearn: 0.0765505\ttotal: 1.04s\tremaining: 2.69s\n",
      "278:\tlearn: 0.0763637\ttotal: 1.04s\tremaining: 2.69s\n",
      "279:\tlearn: 0.0762908\ttotal: 1.04s\tremaining: 2.68s\n",
      "280:\tlearn: 0.0761558\ttotal: 1.05s\tremaining: 2.68s\n",
      "281:\tlearn: 0.0760616\ttotal: 1.05s\tremaining: 2.68s\n",
      "282:\tlearn: 0.0758920\ttotal: 1.05s\tremaining: 2.67s\n",
      "283:\tlearn: 0.0757716\ttotal: 1.06s\tremaining: 2.67s\n",
      "284:\tlearn: 0.0756513\ttotal: 1.06s\tremaining: 2.67s\n",
      "285:\tlearn: 0.0755194\ttotal: 1.07s\tremaining: 2.66s\n",
      "286:\tlearn: 0.0754191\ttotal: 1.07s\tremaining: 2.66s\n",
      "287:\tlearn: 0.0752503\ttotal: 1.07s\tremaining: 2.65s\n",
      "288:\tlearn: 0.0751032\ttotal: 1.08s\tremaining: 2.65s\n",
      "289:\tlearn: 0.0749888\ttotal: 1.08s\tremaining: 2.65s\n",
      "290:\tlearn: 0.0748447\ttotal: 1.08s\tremaining: 2.64s\n",
      "291:\tlearn: 0.0746815\ttotal: 1.09s\tremaining: 2.64s\n",
      "292:\tlearn: 0.0745699\ttotal: 1.09s\tremaining: 2.63s\n",
      "293:\tlearn: 0.0744566\ttotal: 1.09s\tremaining: 2.63s\n",
      "294:\tlearn: 0.0743252\ttotal: 1.1s\tremaining: 2.63s\n",
      "295:\tlearn: 0.0742158\ttotal: 1.1s\tremaining: 2.62s\n",
      "296:\tlearn: 0.0740612\ttotal: 1.11s\tremaining: 2.62s\n",
      "297:\tlearn: 0.0740176\ttotal: 1.11s\tremaining: 2.61s\n",
      "298:\tlearn: 0.0739048\ttotal: 1.11s\tremaining: 2.61s\n",
      "299:\tlearn: 0.0738137\ttotal: 1.12s\tremaining: 2.61s\n",
      "300:\tlearn: 0.0736376\ttotal: 1.12s\tremaining: 2.6s\n",
      "301:\tlearn: 0.0734758\ttotal: 1.12s\tremaining: 2.6s\n",
      "302:\tlearn: 0.0733159\ttotal: 1.13s\tremaining: 2.59s\n",
      "303:\tlearn: 0.0731954\ttotal: 1.13s\tremaining: 2.59s\n",
      "304:\tlearn: 0.0731308\ttotal: 1.13s\tremaining: 2.58s\n",
      "305:\tlearn: 0.0729574\ttotal: 1.14s\tremaining: 2.58s\n",
      "306:\tlearn: 0.0728591\ttotal: 1.14s\tremaining: 2.58s\n",
      "307:\tlearn: 0.0727367\ttotal: 1.14s\tremaining: 2.57s\n",
      "308:\tlearn: 0.0725575\ttotal: 1.15s\tremaining: 2.57s\n",
      "309:\tlearn: 0.0724517\ttotal: 1.15s\tremaining: 2.56s\n",
      "310:\tlearn: 0.0723526\ttotal: 1.16s\tremaining: 2.56s\n",
      "311:\tlearn: 0.0722229\ttotal: 1.16s\tremaining: 2.56s\n",
      "312:\tlearn: 0.0721358\ttotal: 1.16s\tremaining: 2.55s\n",
      "313:\tlearn: 0.0720320\ttotal: 1.17s\tremaining: 2.55s\n",
      "314:\tlearn: 0.0719095\ttotal: 1.17s\tremaining: 2.54s\n",
      "315:\tlearn: 0.0718105\ttotal: 1.17s\tremaining: 2.54s\n",
      "316:\tlearn: 0.0717474\ttotal: 1.18s\tremaining: 2.54s\n",
      "317:\tlearn: 0.0715976\ttotal: 1.18s\tremaining: 2.53s\n",
      "318:\tlearn: 0.0714783\ttotal: 1.18s\tremaining: 2.53s\n",
      "319:\tlearn: 0.0713552\ttotal: 1.19s\tremaining: 2.52s\n",
      "320:\tlearn: 0.0712510\ttotal: 1.19s\tremaining: 2.52s\n",
      "321:\tlearn: 0.0711878\ttotal: 1.19s\tremaining: 2.51s\n",
      "322:\tlearn: 0.0710554\ttotal: 1.2s\tremaining: 2.51s\n",
      "323:\tlearn: 0.0708950\ttotal: 1.2s\tremaining: 2.5s\n",
      "324:\tlearn: 0.0707215\ttotal: 1.2s\tremaining: 2.5s\n",
      "325:\tlearn: 0.0706039\ttotal: 1.21s\tremaining: 2.5s\n",
      "326:\tlearn: 0.0705211\ttotal: 1.21s\tremaining: 2.49s\n",
      "327:\tlearn: 0.0703700\ttotal: 1.21s\tremaining: 2.49s\n",
      "328:\tlearn: 0.0702679\ttotal: 1.22s\tremaining: 2.48s\n",
      "329:\tlearn: 0.0701643\ttotal: 1.22s\tremaining: 2.48s\n",
      "330:\tlearn: 0.0699994\ttotal: 1.23s\tremaining: 2.48s\n",
      "331:\tlearn: 0.0699014\ttotal: 1.23s\tremaining: 2.48s\n",
      "332:\tlearn: 0.0698408\ttotal: 1.23s\tremaining: 2.47s\n",
      "333:\tlearn: 0.0697203\ttotal: 1.24s\tremaining: 2.47s\n",
      "334:\tlearn: 0.0695453\ttotal: 1.24s\tremaining: 2.46s\n",
      "335:\tlearn: 0.0694437\ttotal: 1.25s\tremaining: 2.46s\n",
      "336:\tlearn: 0.0693688\ttotal: 1.25s\tremaining: 2.46s\n",
      "337:\tlearn: 0.0692898\ttotal: 1.25s\tremaining: 2.46s\n",
      "338:\tlearn: 0.0691892\ttotal: 1.26s\tremaining: 2.45s\n",
      "339:\tlearn: 0.0690862\ttotal: 1.26s\tremaining: 2.45s\n",
      "340:\tlearn: 0.0689800\ttotal: 1.26s\tremaining: 2.44s\n",
      "341:\tlearn: 0.0688541\ttotal: 1.27s\tremaining: 2.44s\n",
      "342:\tlearn: 0.0687442\ttotal: 1.27s\tremaining: 2.44s\n",
      "343:\tlearn: 0.0685769\ttotal: 1.28s\tremaining: 2.43s\n",
      "344:\tlearn: 0.0685102\ttotal: 1.28s\tremaining: 2.43s\n",
      "345:\tlearn: 0.0684481\ttotal: 1.28s\tremaining: 2.43s\n",
      "346:\tlearn: 0.0683367\ttotal: 1.29s\tremaining: 2.42s\n",
      "347:\tlearn: 0.0681634\ttotal: 1.29s\tremaining: 2.42s\n",
      "348:\tlearn: 0.0680147\ttotal: 1.29s\tremaining: 2.41s\n",
      "349:\tlearn: 0.0679371\ttotal: 1.3s\tremaining: 2.41s\n",
      "350:\tlearn: 0.0678277\ttotal: 1.3s\tremaining: 2.4s\n",
      "351:\tlearn: 0.0677091\ttotal: 1.3s\tremaining: 2.4s\n",
      "352:\tlearn: 0.0675597\ttotal: 1.31s\tremaining: 2.4s\n",
      "353:\tlearn: 0.0674783\ttotal: 1.31s\tremaining: 2.39s\n",
      "354:\tlearn: 0.0674312\ttotal: 1.31s\tremaining: 2.39s\n",
      "355:\tlearn: 0.0673352\ttotal: 1.32s\tremaining: 2.38s\n",
      "356:\tlearn: 0.0672755\ttotal: 1.32s\tremaining: 2.38s\n",
      "357:\tlearn: 0.0672166\ttotal: 1.33s\tremaining: 2.38s\n",
      "358:\tlearn: 0.0671792\ttotal: 1.33s\tremaining: 2.37s\n",
      "359:\tlearn: 0.0671268\ttotal: 1.33s\tremaining: 2.37s\n",
      "360:\tlearn: 0.0669963\ttotal: 1.34s\tremaining: 2.37s\n",
      "361:\tlearn: 0.0669557\ttotal: 1.34s\tremaining: 2.36s\n",
      "362:\tlearn: 0.0668788\ttotal: 1.34s\tremaining: 2.36s\n",
      "363:\tlearn: 0.0667923\ttotal: 1.35s\tremaining: 2.35s\n",
      "364:\tlearn: 0.0667014\ttotal: 1.35s\tremaining: 2.35s\n",
      "365:\tlearn: 0.0666696\ttotal: 1.35s\tremaining: 2.35s\n",
      "366:\tlearn: 0.0665225\ttotal: 1.36s\tremaining: 2.34s\n",
      "367:\tlearn: 0.0664405\ttotal: 1.36s\tremaining: 2.34s\n",
      "368:\tlearn: 0.0663239\ttotal: 1.36s\tremaining: 2.33s\n",
      "369:\tlearn: 0.0662432\ttotal: 1.37s\tremaining: 2.33s\n",
      "370:\tlearn: 0.0660794\ttotal: 1.37s\tremaining: 2.33s\n",
      "371:\tlearn: 0.0659413\ttotal: 1.38s\tremaining: 2.32s\n",
      "372:\tlearn: 0.0657664\ttotal: 1.38s\tremaining: 2.32s\n",
      "373:\tlearn: 0.0656615\ttotal: 1.38s\tremaining: 2.31s\n",
      "374:\tlearn: 0.0655182\ttotal: 1.39s\tremaining: 2.31s\n",
      "375:\tlearn: 0.0654310\ttotal: 1.39s\tremaining: 2.31s\n",
      "376:\tlearn: 0.0653574\ttotal: 1.39s\tremaining: 2.3s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "377:\tlearn: 0.0652915\ttotal: 1.4s\tremaining: 2.3s\n",
      "378:\tlearn: 0.0652545\ttotal: 1.4s\tremaining: 2.29s\n",
      "379:\tlearn: 0.0651874\ttotal: 1.4s\tremaining: 2.29s\n",
      "380:\tlearn: 0.0650982\ttotal: 1.41s\tremaining: 2.29s\n",
      "381:\tlearn: 0.0649758\ttotal: 1.41s\tremaining: 2.28s\n",
      "382:\tlearn: 0.0648499\ttotal: 1.42s\tremaining: 2.28s\n",
      "383:\tlearn: 0.0647307\ttotal: 1.42s\tremaining: 2.28s\n",
      "384:\tlearn: 0.0646809\ttotal: 1.42s\tremaining: 2.27s\n",
      "385:\tlearn: 0.0646283\ttotal: 1.43s\tremaining: 2.27s\n",
      "386:\tlearn: 0.0644734\ttotal: 1.43s\tremaining: 2.27s\n",
      "387:\tlearn: 0.0643652\ttotal: 1.43s\tremaining: 2.26s\n",
      "388:\tlearn: 0.0642345\ttotal: 1.44s\tremaining: 2.26s\n",
      "389:\tlearn: 0.0641669\ttotal: 1.44s\tremaining: 2.25s\n",
      "390:\tlearn: 0.0640926\ttotal: 1.45s\tremaining: 2.25s\n",
      "391:\tlearn: 0.0639773\ttotal: 1.45s\tremaining: 2.25s\n",
      "392:\tlearn: 0.0639082\ttotal: 1.45s\tremaining: 2.24s\n",
      "393:\tlearn: 0.0638507\ttotal: 1.46s\tremaining: 2.24s\n",
      "394:\tlearn: 0.0637837\ttotal: 1.46s\tremaining: 2.24s\n",
      "395:\tlearn: 0.0637031\ttotal: 1.46s\tremaining: 2.23s\n",
      "396:\tlearn: 0.0636456\ttotal: 1.47s\tremaining: 2.23s\n",
      "397:\tlearn: 0.0635711\ttotal: 1.47s\tremaining: 2.22s\n",
      "398:\tlearn: 0.0634837\ttotal: 1.47s\tremaining: 2.22s\n",
      "399:\tlearn: 0.0633989\ttotal: 1.48s\tremaining: 2.22s\n",
      "400:\tlearn: 0.0633410\ttotal: 1.48s\tremaining: 2.21s\n",
      "401:\tlearn: 0.0633112\ttotal: 1.49s\tremaining: 2.21s\n",
      "402:\tlearn: 0.0631758\ttotal: 1.49s\tremaining: 2.21s\n",
      "403:\tlearn: 0.0631196\ttotal: 1.49s\tremaining: 2.2s\n",
      "404:\tlearn: 0.0630275\ttotal: 1.5s\tremaining: 2.2s\n",
      "405:\tlearn: 0.0629429\ttotal: 1.5s\tremaining: 2.19s\n",
      "406:\tlearn: 0.0628421\ttotal: 1.5s\tremaining: 2.19s\n",
      "407:\tlearn: 0.0627461\ttotal: 1.51s\tremaining: 2.19s\n",
      "408:\tlearn: 0.0627023\ttotal: 1.51s\tremaining: 2.18s\n",
      "409:\tlearn: 0.0625998\ttotal: 1.51s\tremaining: 2.18s\n",
      "410:\tlearn: 0.0624777\ttotal: 1.52s\tremaining: 2.17s\n",
      "411:\tlearn: 0.0623796\ttotal: 1.52s\tremaining: 2.17s\n",
      "412:\tlearn: 0.0622598\ttotal: 1.52s\tremaining: 2.17s\n",
      "413:\tlearn: 0.0621695\ttotal: 1.53s\tremaining: 2.16s\n",
      "414:\tlearn: 0.0621349\ttotal: 1.53s\tremaining: 2.16s\n",
      "415:\tlearn: 0.0620335\ttotal: 1.54s\tremaining: 2.16s\n",
      "416:\tlearn: 0.0619373\ttotal: 1.54s\tremaining: 2.15s\n",
      "417:\tlearn: 0.0617722\ttotal: 1.54s\tremaining: 2.15s\n",
      "418:\tlearn: 0.0617285\ttotal: 1.55s\tremaining: 2.15s\n",
      "419:\tlearn: 0.0616505\ttotal: 1.55s\tremaining: 2.14s\n",
      "420:\tlearn: 0.0615387\ttotal: 1.55s\tremaining: 2.14s\n",
      "421:\tlearn: 0.0615133\ttotal: 1.56s\tremaining: 2.13s\n",
      "422:\tlearn: 0.0613736\ttotal: 1.56s\tremaining: 2.13s\n",
      "423:\tlearn: 0.0612907\ttotal: 1.56s\tremaining: 2.13s\n",
      "424:\tlearn: 0.0612016\ttotal: 1.57s\tremaining: 2.12s\n",
      "425:\tlearn: 0.0610948\ttotal: 1.57s\tremaining: 2.12s\n",
      "426:\tlearn: 0.0609926\ttotal: 1.58s\tremaining: 2.12s\n",
      "427:\tlearn: 0.0609263\ttotal: 1.58s\tremaining: 2.11s\n",
      "428:\tlearn: 0.0608022\ttotal: 1.58s\tremaining: 2.11s\n",
      "429:\tlearn: 0.0607007\ttotal: 1.59s\tremaining: 2.11s\n",
      "430:\tlearn: 0.0606565\ttotal: 1.59s\tremaining: 2.1s\n",
      "431:\tlearn: 0.0605670\ttotal: 1.6s\tremaining: 2.1s\n",
      "432:\tlearn: 0.0604747\ttotal: 1.6s\tremaining: 2.1s\n",
      "433:\tlearn: 0.0604287\ttotal: 1.6s\tremaining: 2.09s\n",
      "434:\tlearn: 0.0603766\ttotal: 1.61s\tremaining: 2.09s\n",
      "435:\tlearn: 0.0603406\ttotal: 1.61s\tremaining: 2.08s\n",
      "436:\tlearn: 0.0602457\ttotal: 1.61s\tremaining: 2.08s\n",
      "437:\tlearn: 0.0602158\ttotal: 1.62s\tremaining: 2.08s\n",
      "438:\tlearn: 0.0601644\ttotal: 1.62s\tremaining: 2.07s\n",
      "439:\tlearn: 0.0600754\ttotal: 1.63s\tremaining: 2.07s\n",
      "440:\tlearn: 0.0599611\ttotal: 1.63s\tremaining: 2.06s\n",
      "441:\tlearn: 0.0598807\ttotal: 1.63s\tremaining: 2.06s\n",
      "442:\tlearn: 0.0598294\ttotal: 1.64s\tremaining: 2.06s\n",
      "443:\tlearn: 0.0597459\ttotal: 1.64s\tremaining: 2.05s\n",
      "444:\tlearn: 0.0596648\ttotal: 1.64s\tremaining: 2.05s\n",
      "445:\tlearn: 0.0595602\ttotal: 1.65s\tremaining: 2.05s\n",
      "446:\tlearn: 0.0594820\ttotal: 1.65s\tremaining: 2.04s\n",
      "447:\tlearn: 0.0593648\ttotal: 1.66s\tremaining: 2.04s\n",
      "448:\tlearn: 0.0592622\ttotal: 1.66s\tremaining: 2.04s\n",
      "449:\tlearn: 0.0591151\ttotal: 1.66s\tremaining: 2.03s\n",
      "450:\tlearn: 0.0590386\ttotal: 1.67s\tremaining: 2.03s\n",
      "451:\tlearn: 0.0589968\ttotal: 1.67s\tremaining: 2.03s\n",
      "452:\tlearn: 0.0589601\ttotal: 1.68s\tremaining: 2.02s\n",
      "453:\tlearn: 0.0589079\ttotal: 1.68s\tremaining: 2.02s\n",
      "454:\tlearn: 0.0588596\ttotal: 1.68s\tremaining: 2.02s\n",
      "455:\tlearn: 0.0587995\ttotal: 1.69s\tremaining: 2.01s\n",
      "456:\tlearn: 0.0587270\ttotal: 1.69s\tremaining: 2.01s\n",
      "457:\tlearn: 0.0586702\ttotal: 1.7s\tremaining: 2.01s\n",
      "458:\tlearn: 0.0586112\ttotal: 1.7s\tremaining: 2s\n",
      "459:\tlearn: 0.0585544\ttotal: 1.7s\tremaining: 2s\n",
      "460:\tlearn: 0.0585063\ttotal: 1.71s\tremaining: 2s\n",
      "461:\tlearn: 0.0583990\ttotal: 1.71s\tremaining: 1.99s\n",
      "462:\tlearn: 0.0583194\ttotal: 1.71s\tremaining: 1.99s\n",
      "463:\tlearn: 0.0582404\ttotal: 1.72s\tremaining: 1.99s\n",
      "464:\tlearn: 0.0581998\ttotal: 1.72s\tremaining: 1.98s\n",
      "465:\tlearn: 0.0581246\ttotal: 1.73s\tremaining: 1.98s\n",
      "466:\tlearn: 0.0580173\ttotal: 1.73s\tremaining: 1.97s\n",
      "467:\tlearn: 0.0579903\ttotal: 1.73s\tremaining: 1.97s\n",
      "468:\tlearn: 0.0579078\ttotal: 1.74s\tremaining: 1.97s\n",
      "469:\tlearn: 0.0578833\ttotal: 1.74s\tremaining: 1.96s\n",
      "470:\tlearn: 0.0578317\ttotal: 1.74s\tremaining: 1.96s\n",
      "471:\tlearn: 0.0577793\ttotal: 1.75s\tremaining: 1.96s\n",
      "472:\tlearn: 0.0576802\ttotal: 1.75s\tremaining: 1.95s\n",
      "473:\tlearn: 0.0576184\ttotal: 1.75s\tremaining: 1.95s\n",
      "474:\tlearn: 0.0575178\ttotal: 1.76s\tremaining: 1.94s\n",
      "475:\tlearn: 0.0574400\ttotal: 1.76s\tremaining: 1.94s\n",
      "476:\tlearn: 0.0573811\ttotal: 1.77s\tremaining: 1.94s\n",
      "477:\tlearn: 0.0573008\ttotal: 1.77s\tremaining: 1.93s\n",
      "478:\tlearn: 0.0572501\ttotal: 1.77s\tremaining: 1.93s\n",
      "479:\tlearn: 0.0572211\ttotal: 1.78s\tremaining: 1.93s\n",
      "480:\tlearn: 0.0571133\ttotal: 1.78s\tremaining: 1.92s\n",
      "481:\tlearn: 0.0570495\ttotal: 1.78s\tremaining: 1.92s\n",
      "482:\tlearn: 0.0570019\ttotal: 1.79s\tremaining: 1.91s\n",
      "483:\tlearn: 0.0568945\ttotal: 1.79s\tremaining: 1.91s\n",
      "484:\tlearn: 0.0568867\ttotal: 1.79s\tremaining: 1.9s\n",
      "485:\tlearn: 0.0568191\ttotal: 1.8s\tremaining: 1.9s\n",
      "486:\tlearn: 0.0567083\ttotal: 1.8s\tremaining: 1.9s\n",
      "487:\tlearn: 0.0566558\ttotal: 1.8s\tremaining: 1.89s\n",
      "488:\tlearn: 0.0565793\ttotal: 1.81s\tremaining: 1.89s\n",
      "489:\tlearn: 0.0565172\ttotal: 1.81s\tremaining: 1.88s\n",
      "490:\tlearn: 0.0564770\ttotal: 1.81s\tremaining: 1.88s\n",
      "491:\tlearn: 0.0564377\ttotal: 1.82s\tremaining: 1.88s\n",
      "492:\tlearn: 0.0563915\ttotal: 1.82s\tremaining: 1.87s\n",
      "493:\tlearn: 0.0562916\ttotal: 1.82s\tremaining: 1.87s\n",
      "494:\tlearn: 0.0561804\ttotal: 1.83s\tremaining: 1.86s\n",
      "495:\tlearn: 0.0561074\ttotal: 1.83s\tremaining: 1.86s\n",
      "496:\tlearn: 0.0560238\ttotal: 1.83s\tremaining: 1.86s\n",
      "497:\tlearn: 0.0560090\ttotal: 1.84s\tremaining: 1.85s\n",
      "498:\tlearn: 0.0559151\ttotal: 1.84s\tremaining: 1.85s\n",
      "499:\tlearn: 0.0558463\ttotal: 1.84s\tremaining: 1.84s\n",
      "500:\tlearn: 0.0557213\ttotal: 1.85s\tremaining: 1.84s\n",
      "501:\tlearn: 0.0556696\ttotal: 1.85s\tremaining: 1.84s\n",
      "502:\tlearn: 0.0555717\ttotal: 1.85s\tremaining: 1.83s\n",
      "503:\tlearn: 0.0554945\ttotal: 1.86s\tremaining: 1.83s\n",
      "504:\tlearn: 0.0554522\ttotal: 1.86s\tremaining: 1.82s\n",
      "505:\tlearn: 0.0554132\ttotal: 1.87s\tremaining: 1.82s\n",
      "506:\tlearn: 0.0553018\ttotal: 1.87s\tremaining: 1.82s\n",
      "507:\tlearn: 0.0552018\ttotal: 1.87s\tremaining: 1.81s\n",
      "508:\tlearn: 0.0551067\ttotal: 1.88s\tremaining: 1.81s\n",
      "509:\tlearn: 0.0550672\ttotal: 1.88s\tremaining: 1.81s\n",
      "510:\tlearn: 0.0550013\ttotal: 1.88s\tremaining: 1.8s\n",
      "511:\tlearn: 0.0549217\ttotal: 1.89s\tremaining: 1.8s\n",
      "512:\tlearn: 0.0548655\ttotal: 1.89s\tremaining: 1.79s\n",
      "513:\tlearn: 0.0548029\ttotal: 1.9s\tremaining: 1.79s\n",
      "514:\tlearn: 0.0547346\ttotal: 1.9s\tremaining: 1.79s\n",
      "515:\tlearn: 0.0546692\ttotal: 1.9s\tremaining: 1.78s\n",
      "516:\tlearn: 0.0545950\ttotal: 1.91s\tremaining: 1.78s\n",
      "517:\tlearn: 0.0544829\ttotal: 1.91s\tremaining: 1.78s\n",
      "518:\tlearn: 0.0544603\ttotal: 1.91s\tremaining: 1.77s\n",
      "519:\tlearn: 0.0544383\ttotal: 1.92s\tremaining: 1.77s\n",
      "520:\tlearn: 0.0544018\ttotal: 1.92s\tremaining: 1.77s\n",
      "521:\tlearn: 0.0543271\ttotal: 1.93s\tremaining: 1.76s\n",
      "522:\tlearn: 0.0542716\ttotal: 1.93s\tremaining: 1.76s\n",
      "523:\tlearn: 0.0541852\ttotal: 1.93s\tremaining: 1.75s\n",
      "524:\tlearn: 0.0541510\ttotal: 1.94s\tremaining: 1.75s\n",
      "525:\tlearn: 0.0541302\ttotal: 1.94s\tremaining: 1.75s\n",
      "526:\tlearn: 0.0540082\ttotal: 1.94s\tremaining: 1.75s\n",
      "527:\tlearn: 0.0539447\ttotal: 1.95s\tremaining: 1.74s\n",
      "528:\tlearn: 0.0538458\ttotal: 1.95s\tremaining: 1.74s\n",
      "529:\tlearn: 0.0537106\ttotal: 1.96s\tremaining: 1.73s\n",
      "530:\tlearn: 0.0535845\ttotal: 1.96s\tremaining: 1.73s\n",
      "531:\tlearn: 0.0535268\ttotal: 1.96s\tremaining: 1.73s\n",
      "532:\tlearn: 0.0534826\ttotal: 1.97s\tremaining: 1.72s\n",
      "533:\tlearn: 0.0534580\ttotal: 1.97s\tremaining: 1.72s\n",
      "534:\tlearn: 0.0534004\ttotal: 1.97s\tremaining: 1.72s\n",
      "535:\tlearn: 0.0533109\ttotal: 1.98s\tremaining: 1.71s\n",
      "536:\tlearn: 0.0532763\ttotal: 1.98s\tremaining: 1.71s\n",
      "537:\tlearn: 0.0531987\ttotal: 1.98s\tremaining: 1.7s\n",
      "538:\tlearn: 0.0531265\ttotal: 1.99s\tremaining: 1.7s\n",
      "539:\tlearn: 0.0530753\ttotal: 1.99s\tremaining: 1.7s\n",
      "540:\tlearn: 0.0530295\ttotal: 1.99s\tremaining: 1.69s\n",
      "541:\tlearn: 0.0529787\ttotal: 2s\tremaining: 1.69s\n",
      "542:\tlearn: 0.0528425\ttotal: 2s\tremaining: 1.68s\n",
      "543:\tlearn: 0.0527787\ttotal: 2s\tremaining: 1.68s\n",
      "544:\tlearn: 0.0526957\ttotal: 2.01s\tremaining: 1.68s\n",
      "545:\tlearn: 0.0526635\ttotal: 2.01s\tremaining: 1.67s\n",
      "546:\tlearn: 0.0526267\ttotal: 2.01s\tremaining: 1.67s\n",
      "547:\tlearn: 0.0525818\ttotal: 2.02s\tremaining: 1.66s\n",
      "548:\tlearn: 0.0525113\ttotal: 2.02s\tremaining: 1.66s\n",
      "549:\tlearn: 0.0524425\ttotal: 2.02s\tremaining: 1.66s\n",
      "550:\tlearn: 0.0523856\ttotal: 2.03s\tremaining: 1.65s\n",
      "551:\tlearn: 0.0522355\ttotal: 2.03s\tremaining: 1.65s\n",
      "552:\tlearn: 0.0521805\ttotal: 2.04s\tremaining: 1.65s\n",
      "553:\tlearn: 0.0520645\ttotal: 2.04s\tremaining: 1.64s\n",
      "554:\tlearn: 0.0519568\ttotal: 2.04s\tremaining: 1.64s\n",
      "555:\tlearn: 0.0518874\ttotal: 2.05s\tremaining: 1.63s\n",
      "556:\tlearn: 0.0518319\ttotal: 2.05s\tremaining: 1.63s\n",
      "557:\tlearn: 0.0517999\ttotal: 2.05s\tremaining: 1.63s\n",
      "558:\tlearn: 0.0517699\ttotal: 2.06s\tremaining: 1.62s\n",
      "559:\tlearn: 0.0516972\ttotal: 2.06s\tremaining: 1.62s\n",
      "560:\tlearn: 0.0516299\ttotal: 2.06s\tremaining: 1.61s\n",
      "561:\tlearn: 0.0515176\ttotal: 2.07s\tremaining: 1.61s\n",
      "562:\tlearn: 0.0514318\ttotal: 2.07s\tremaining: 1.61s\n",
      "563:\tlearn: 0.0513971\ttotal: 2.07s\tremaining: 1.6s\n",
      "564:\tlearn: 0.0513667\ttotal: 2.08s\tremaining: 1.6s\n",
      "565:\tlearn: 0.0513236\ttotal: 2.08s\tremaining: 1.59s\n",
      "566:\tlearn: 0.0512704\ttotal: 2.08s\tremaining: 1.59s\n",
      "567:\tlearn: 0.0512092\ttotal: 2.09s\tremaining: 1.59s\n",
      "568:\tlearn: 0.0511776\ttotal: 2.09s\tremaining: 1.58s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "569:\tlearn: 0.0511466\ttotal: 2.1s\tremaining: 1.58s\n",
      "570:\tlearn: 0.0510639\ttotal: 2.1s\tremaining: 1.58s\n",
      "571:\tlearn: 0.0510008\ttotal: 2.11s\tremaining: 1.58s\n",
      "572:\tlearn: 0.0509555\ttotal: 2.11s\tremaining: 1.57s\n",
      "573:\tlearn: 0.0508951\ttotal: 2.12s\tremaining: 1.57s\n",
      "574:\tlearn: 0.0508395\ttotal: 2.12s\tremaining: 1.57s\n",
      "575:\tlearn: 0.0507942\ttotal: 2.12s\tremaining: 1.56s\n",
      "576:\tlearn: 0.0507500\ttotal: 2.13s\tremaining: 1.56s\n",
      "577:\tlearn: 0.0507195\ttotal: 2.13s\tremaining: 1.55s\n",
      "578:\tlearn: 0.0506852\ttotal: 2.13s\tremaining: 1.55s\n",
      "579:\tlearn: 0.0506072\ttotal: 2.14s\tremaining: 1.55s\n",
      "580:\tlearn: 0.0505391\ttotal: 2.14s\tremaining: 1.54s\n",
      "581:\tlearn: 0.0504911\ttotal: 2.14s\tremaining: 1.54s\n",
      "582:\tlearn: 0.0504388\ttotal: 2.15s\tremaining: 1.54s\n",
      "583:\tlearn: 0.0503800\ttotal: 2.15s\tremaining: 1.53s\n",
      "584:\tlearn: 0.0503007\ttotal: 2.15s\tremaining: 1.53s\n",
      "585:\tlearn: 0.0502663\ttotal: 2.16s\tremaining: 1.52s\n",
      "586:\tlearn: 0.0501797\ttotal: 2.16s\tremaining: 1.52s\n",
      "587:\tlearn: 0.0501476\ttotal: 2.17s\tremaining: 1.52s\n",
      "588:\tlearn: 0.0500928\ttotal: 2.17s\tremaining: 1.51s\n",
      "589:\tlearn: 0.0500697\ttotal: 2.17s\tremaining: 1.51s\n",
      "590:\tlearn: 0.0500362\ttotal: 2.18s\tremaining: 1.51s\n",
      "591:\tlearn: 0.0499970\ttotal: 2.18s\tremaining: 1.5s\n",
      "592:\tlearn: 0.0499159\ttotal: 2.18s\tremaining: 1.5s\n",
      "593:\tlearn: 0.0498721\ttotal: 2.19s\tremaining: 1.49s\n",
      "594:\tlearn: 0.0497892\ttotal: 2.19s\tremaining: 1.49s\n",
      "595:\tlearn: 0.0497313\ttotal: 2.19s\tremaining: 1.49s\n",
      "596:\tlearn: 0.0496849\ttotal: 2.2s\tremaining: 1.48s\n",
      "597:\tlearn: 0.0496535\ttotal: 2.2s\tremaining: 1.48s\n",
      "598:\tlearn: 0.0496007\ttotal: 2.21s\tremaining: 1.48s\n",
      "599:\tlearn: 0.0495541\ttotal: 2.21s\tremaining: 1.47s\n",
      "600:\tlearn: 0.0495148\ttotal: 2.21s\tremaining: 1.47s\n",
      "601:\tlearn: 0.0494751\ttotal: 2.21s\tremaining: 1.46s\n",
      "602:\tlearn: 0.0494059\ttotal: 2.22s\tremaining: 1.46s\n",
      "603:\tlearn: 0.0493406\ttotal: 2.22s\tremaining: 1.46s\n",
      "604:\tlearn: 0.0492573\ttotal: 2.23s\tremaining: 1.45s\n",
      "605:\tlearn: 0.0492193\ttotal: 2.23s\tremaining: 1.45s\n",
      "606:\tlearn: 0.0491906\ttotal: 2.23s\tremaining: 1.45s\n",
      "607:\tlearn: 0.0491429\ttotal: 2.24s\tremaining: 1.44s\n",
      "608:\tlearn: 0.0491057\ttotal: 2.24s\tremaining: 1.44s\n",
      "609:\tlearn: 0.0490390\ttotal: 2.24s\tremaining: 1.43s\n",
      "610:\tlearn: 0.0490031\ttotal: 2.25s\tremaining: 1.43s\n",
      "611:\tlearn: 0.0489547\ttotal: 2.25s\tremaining: 1.43s\n",
      "612:\tlearn: 0.0489208\ttotal: 2.25s\tremaining: 1.42s\n",
      "613:\tlearn: 0.0488563\ttotal: 2.26s\tremaining: 1.42s\n",
      "614:\tlearn: 0.0487944\ttotal: 2.26s\tremaining: 1.42s\n",
      "615:\tlearn: 0.0487355\ttotal: 2.26s\tremaining: 1.41s\n",
      "616:\tlearn: 0.0486735\ttotal: 2.27s\tremaining: 1.41s\n",
      "617:\tlearn: 0.0486512\ttotal: 2.27s\tremaining: 1.4s\n",
      "618:\tlearn: 0.0486068\ttotal: 2.28s\tremaining: 1.4s\n",
      "619:\tlearn: 0.0485522\ttotal: 2.28s\tremaining: 1.4s\n",
      "620:\tlearn: 0.0485193\ttotal: 2.28s\tremaining: 1.39s\n",
      "621:\tlearn: 0.0484701\ttotal: 2.29s\tremaining: 1.39s\n",
      "622:\tlearn: 0.0484270\ttotal: 2.29s\tremaining: 1.39s\n",
      "623:\tlearn: 0.0483644\ttotal: 2.3s\tremaining: 1.38s\n",
      "624:\tlearn: 0.0483261\ttotal: 2.3s\tremaining: 1.38s\n",
      "625:\tlearn: 0.0482494\ttotal: 2.3s\tremaining: 1.38s\n",
      "626:\tlearn: 0.0482288\ttotal: 2.31s\tremaining: 1.37s\n",
      "627:\tlearn: 0.0481799\ttotal: 2.31s\tremaining: 1.37s\n",
      "628:\tlearn: 0.0481481\ttotal: 2.31s\tremaining: 1.36s\n",
      "629:\tlearn: 0.0481331\ttotal: 2.32s\tremaining: 1.36s\n",
      "630:\tlearn: 0.0480809\ttotal: 2.32s\tremaining: 1.36s\n",
      "631:\tlearn: 0.0480208\ttotal: 2.32s\tremaining: 1.35s\n",
      "632:\tlearn: 0.0479847\ttotal: 2.33s\tremaining: 1.35s\n",
      "633:\tlearn: 0.0479539\ttotal: 2.33s\tremaining: 1.34s\n",
      "634:\tlearn: 0.0479122\ttotal: 2.33s\tremaining: 1.34s\n",
      "635:\tlearn: 0.0479028\ttotal: 2.34s\tremaining: 1.34s\n",
      "636:\tlearn: 0.0478476\ttotal: 2.34s\tremaining: 1.33s\n",
      "637:\tlearn: 0.0478136\ttotal: 2.34s\tremaining: 1.33s\n",
      "638:\tlearn: 0.0477947\ttotal: 2.35s\tremaining: 1.33s\n",
      "639:\tlearn: 0.0477155\ttotal: 2.35s\tremaining: 1.32s\n",
      "640:\tlearn: 0.0476788\ttotal: 2.35s\tremaining: 1.32s\n",
      "641:\tlearn: 0.0476362\ttotal: 2.36s\tremaining: 1.31s\n",
      "642:\tlearn: 0.0475818\ttotal: 2.36s\tremaining: 1.31s\n",
      "643:\tlearn: 0.0475426\ttotal: 2.37s\tremaining: 1.31s\n",
      "644:\tlearn: 0.0475006\ttotal: 2.37s\tremaining: 1.3s\n",
      "645:\tlearn: 0.0474625\ttotal: 2.37s\tremaining: 1.3s\n",
      "646:\tlearn: 0.0473715\ttotal: 2.38s\tremaining: 1.29s\n",
      "647:\tlearn: 0.0473345\ttotal: 2.38s\tremaining: 1.29s\n",
      "648:\tlearn: 0.0473048\ttotal: 2.38s\tremaining: 1.29s\n",
      "649:\tlearn: 0.0472742\ttotal: 2.38s\tremaining: 1.28s\n",
      "650:\tlearn: 0.0472232\ttotal: 2.39s\tremaining: 1.28s\n",
      "651:\tlearn: 0.0471830\ttotal: 2.39s\tremaining: 1.28s\n",
      "652:\tlearn: 0.0471019\ttotal: 2.4s\tremaining: 1.27s\n",
      "653:\tlearn: 0.0470391\ttotal: 2.4s\tremaining: 1.27s\n",
      "654:\tlearn: 0.0470193\ttotal: 2.4s\tremaining: 1.26s\n",
      "655:\tlearn: 0.0469288\ttotal: 2.41s\tremaining: 1.26s\n",
      "656:\tlearn: 0.0468962\ttotal: 2.41s\tremaining: 1.26s\n",
      "657:\tlearn: 0.0468366\ttotal: 2.41s\tremaining: 1.25s\n",
      "658:\tlearn: 0.0467867\ttotal: 2.42s\tremaining: 1.25s\n",
      "659:\tlearn: 0.0467390\ttotal: 2.42s\tremaining: 1.25s\n",
      "660:\tlearn: 0.0466926\ttotal: 2.42s\tremaining: 1.24s\n",
      "661:\tlearn: 0.0466637\ttotal: 2.43s\tremaining: 1.24s\n",
      "662:\tlearn: 0.0466249\ttotal: 2.43s\tremaining: 1.24s\n",
      "663:\tlearn: 0.0465798\ttotal: 2.43s\tremaining: 1.23s\n",
      "664:\tlearn: 0.0465212\ttotal: 2.44s\tremaining: 1.23s\n",
      "665:\tlearn: 0.0465012\ttotal: 2.44s\tremaining: 1.22s\n",
      "666:\tlearn: 0.0464398\ttotal: 2.44s\tremaining: 1.22s\n",
      "667:\tlearn: 0.0464192\ttotal: 2.45s\tremaining: 1.22s\n",
      "668:\tlearn: 0.0463527\ttotal: 2.45s\tremaining: 1.21s\n",
      "669:\tlearn: 0.0462892\ttotal: 2.46s\tremaining: 1.21s\n",
      "670:\tlearn: 0.0462388\ttotal: 2.46s\tremaining: 1.21s\n",
      "671:\tlearn: 0.0462162\ttotal: 2.46s\tremaining: 1.2s\n",
      "672:\tlearn: 0.0461663\ttotal: 2.47s\tremaining: 1.2s\n",
      "673:\tlearn: 0.0461299\ttotal: 2.47s\tremaining: 1.2s\n",
      "674:\tlearn: 0.0460292\ttotal: 2.48s\tremaining: 1.19s\n",
      "675:\tlearn: 0.0459915\ttotal: 2.48s\tremaining: 1.19s\n",
      "676:\tlearn: 0.0459740\ttotal: 2.48s\tremaining: 1.18s\n",
      "677:\tlearn: 0.0459060\ttotal: 2.49s\tremaining: 1.18s\n",
      "678:\tlearn: 0.0458442\ttotal: 2.49s\tremaining: 1.18s\n",
      "679:\tlearn: 0.0458236\ttotal: 2.49s\tremaining: 1.17s\n",
      "680:\tlearn: 0.0457862\ttotal: 2.5s\tremaining: 1.17s\n",
      "681:\tlearn: 0.0457631\ttotal: 2.5s\tremaining: 1.17s\n",
      "682:\tlearn: 0.0457280\ttotal: 2.5s\tremaining: 1.16s\n",
      "683:\tlearn: 0.0457122\ttotal: 2.51s\tremaining: 1.16s\n",
      "684:\tlearn: 0.0456755\ttotal: 2.51s\tremaining: 1.16s\n",
      "685:\tlearn: 0.0456249\ttotal: 2.52s\tremaining: 1.15s\n",
      "686:\tlearn: 0.0455669\ttotal: 2.52s\tremaining: 1.15s\n",
      "687:\tlearn: 0.0455332\ttotal: 2.52s\tremaining: 1.14s\n",
      "688:\tlearn: 0.0455096\ttotal: 2.53s\tremaining: 1.14s\n",
      "689:\tlearn: 0.0454815\ttotal: 2.53s\tremaining: 1.14s\n",
      "690:\tlearn: 0.0453748\ttotal: 2.53s\tremaining: 1.13s\n",
      "691:\tlearn: 0.0453157\ttotal: 2.54s\tremaining: 1.13s\n",
      "692:\tlearn: 0.0453017\ttotal: 2.54s\tremaining: 1.13s\n",
      "693:\tlearn: 0.0452683\ttotal: 2.54s\tremaining: 1.12s\n",
      "694:\tlearn: 0.0452364\ttotal: 2.55s\tremaining: 1.12s\n",
      "695:\tlearn: 0.0452123\ttotal: 2.55s\tremaining: 1.11s\n",
      "696:\tlearn: 0.0451652\ttotal: 2.56s\tremaining: 1.11s\n",
      "697:\tlearn: 0.0451196\ttotal: 2.56s\tremaining: 1.11s\n",
      "698:\tlearn: 0.0450762\ttotal: 2.56s\tremaining: 1.1s\n",
      "699:\tlearn: 0.0450560\ttotal: 2.57s\tremaining: 1.1s\n",
      "700:\tlearn: 0.0450361\ttotal: 2.57s\tremaining: 1.1s\n",
      "701:\tlearn: 0.0450067\ttotal: 2.57s\tremaining: 1.09s\n",
      "702:\tlearn: 0.0449761\ttotal: 2.58s\tremaining: 1.09s\n",
      "703:\tlearn: 0.0449070\ttotal: 2.58s\tremaining: 1.08s\n",
      "704:\tlearn: 0.0448856\ttotal: 2.58s\tremaining: 1.08s\n",
      "705:\tlearn: 0.0448296\ttotal: 2.59s\tremaining: 1.08s\n",
      "706:\tlearn: 0.0448174\ttotal: 2.59s\tremaining: 1.07s\n",
      "707:\tlearn: 0.0448031\ttotal: 2.59s\tremaining: 1.07s\n",
      "708:\tlearn: 0.0447798\ttotal: 2.6s\tremaining: 1.07s\n",
      "709:\tlearn: 0.0447343\ttotal: 2.6s\tremaining: 1.06s\n",
      "710:\tlearn: 0.0446724\ttotal: 2.6s\tremaining: 1.06s\n",
      "711:\tlearn: 0.0446404\ttotal: 2.61s\tremaining: 1.05s\n",
      "712:\tlearn: 0.0445519\ttotal: 2.61s\tremaining: 1.05s\n",
      "713:\tlearn: 0.0445067\ttotal: 2.61s\tremaining: 1.05s\n",
      "714:\tlearn: 0.0444784\ttotal: 2.62s\tremaining: 1.04s\n",
      "715:\tlearn: 0.0444208\ttotal: 2.62s\tremaining: 1.04s\n",
      "716:\tlearn: 0.0443887\ttotal: 2.62s\tremaining: 1.03s\n",
      "717:\tlearn: 0.0443583\ttotal: 2.63s\tremaining: 1.03s\n",
      "718:\tlearn: 0.0443167\ttotal: 2.63s\tremaining: 1.03s\n",
      "719:\tlearn: 0.0442894\ttotal: 2.64s\tremaining: 1.02s\n",
      "720:\tlearn: 0.0442715\ttotal: 2.64s\tremaining: 1.02s\n",
      "721:\tlearn: 0.0442135\ttotal: 2.64s\tremaining: 1.02s\n",
      "722:\tlearn: 0.0441763\ttotal: 2.65s\tremaining: 1.01s\n",
      "723:\tlearn: 0.0441622\ttotal: 2.65s\tremaining: 1.01s\n",
      "724:\tlearn: 0.0441071\ttotal: 2.65s\tremaining: 1.01s\n",
      "725:\tlearn: 0.0440778\ttotal: 2.66s\tremaining: 1s\n",
      "726:\tlearn: 0.0439920\ttotal: 2.66s\tremaining: 1000ms\n",
      "727:\tlearn: 0.0439269\ttotal: 2.67s\tremaining: 996ms\n",
      "728:\tlearn: 0.0439048\ttotal: 2.67s\tremaining: 993ms\n",
      "729:\tlearn: 0.0438808\ttotal: 2.67s\tremaining: 989ms\n",
      "730:\tlearn: 0.0438291\ttotal: 2.68s\tremaining: 986ms\n",
      "731:\tlearn: 0.0438074\ttotal: 2.68s\tremaining: 982ms\n",
      "732:\tlearn: 0.0437100\ttotal: 2.69s\tremaining: 979ms\n",
      "733:\tlearn: 0.0436794\ttotal: 2.69s\tremaining: 975ms\n",
      "734:\tlearn: 0.0436495\ttotal: 2.69s\tremaining: 972ms\n",
      "735:\tlearn: 0.0436175\ttotal: 2.7s\tremaining: 968ms\n",
      "736:\tlearn: 0.0435858\ttotal: 2.7s\tremaining: 965ms\n",
      "737:\tlearn: 0.0435269\ttotal: 2.71s\tremaining: 961ms\n",
      "738:\tlearn: 0.0434965\ttotal: 2.71s\tremaining: 957ms\n",
      "739:\tlearn: 0.0434100\ttotal: 2.71s\tremaining: 954ms\n",
      "740:\tlearn: 0.0433608\ttotal: 2.72s\tremaining: 950ms\n",
      "741:\tlearn: 0.0433244\ttotal: 2.72s\tremaining: 947ms\n",
      "742:\tlearn: 0.0432359\ttotal: 2.73s\tremaining: 943ms\n",
      "743:\tlearn: 0.0432057\ttotal: 2.73s\tremaining: 940ms\n",
      "744:\tlearn: 0.0431720\ttotal: 2.73s\tremaining: 936ms\n",
      "745:\tlearn: 0.0430837\ttotal: 2.74s\tremaining: 932ms\n",
      "746:\tlearn: 0.0430465\ttotal: 2.74s\tremaining: 928ms\n",
      "747:\tlearn: 0.0430109\ttotal: 2.74s\tremaining: 925ms\n",
      "748:\tlearn: 0.0429592\ttotal: 2.75s\tremaining: 921ms\n",
      "749:\tlearn: 0.0429385\ttotal: 2.75s\tremaining: 917ms\n",
      "750:\tlearn: 0.0428999\ttotal: 2.75s\tremaining: 914ms\n",
      "751:\tlearn: 0.0428008\ttotal: 2.76s\tremaining: 910ms\n",
      "752:\tlearn: 0.0427849\ttotal: 2.76s\tremaining: 906ms\n",
      "753:\tlearn: 0.0427473\ttotal: 2.77s\tremaining: 902ms\n",
      "754:\tlearn: 0.0426842\ttotal: 2.77s\tremaining: 899ms\n",
      "755:\tlearn: 0.0426387\ttotal: 2.77s\tremaining: 895ms\n",
      "756:\tlearn: 0.0426078\ttotal: 2.78s\tremaining: 891ms\n",
      "757:\tlearn: 0.0425777\ttotal: 2.78s\tremaining: 887ms\n",
      "758:\tlearn: 0.0425462\ttotal: 2.78s\tremaining: 884ms\n",
      "759:\tlearn: 0.0424531\ttotal: 2.79s\tremaining: 880ms\n",
      "760:\tlearn: 0.0424092\ttotal: 2.79s\tremaining: 876ms\n",
      "761:\tlearn: 0.0423551\ttotal: 2.79s\tremaining: 872ms\n",
      "762:\tlearn: 0.0422781\ttotal: 2.8s\tremaining: 869ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "763:\tlearn: 0.0422255\ttotal: 2.8s\tremaining: 865ms\n",
      "764:\tlearn: 0.0421456\ttotal: 2.8s\tremaining: 862ms\n",
      "765:\tlearn: 0.0421160\ttotal: 2.81s\tremaining: 858ms\n",
      "766:\tlearn: 0.0420804\ttotal: 2.81s\tremaining: 854ms\n",
      "767:\tlearn: 0.0420533\ttotal: 2.82s\tremaining: 851ms\n",
      "768:\tlearn: 0.0420049\ttotal: 2.82s\tremaining: 847ms\n",
      "769:\tlearn: 0.0419279\ttotal: 2.82s\tremaining: 844ms\n",
      "770:\tlearn: 0.0418673\ttotal: 2.83s\tremaining: 840ms\n",
      "771:\tlearn: 0.0418408\ttotal: 2.83s\tremaining: 837ms\n",
      "772:\tlearn: 0.0417953\ttotal: 2.84s\tremaining: 833ms\n",
      "773:\tlearn: 0.0417688\ttotal: 2.84s\tremaining: 829ms\n",
      "774:\tlearn: 0.0417196\ttotal: 2.84s\tremaining: 826ms\n",
      "775:\tlearn: 0.0416626\ttotal: 2.85s\tremaining: 822ms\n",
      "776:\tlearn: 0.0416038\ttotal: 2.85s\tremaining: 819ms\n",
      "777:\tlearn: 0.0415637\ttotal: 2.85s\tremaining: 815ms\n",
      "778:\tlearn: 0.0415121\ttotal: 2.86s\tremaining: 811ms\n",
      "779:\tlearn: 0.0414831\ttotal: 2.86s\tremaining: 808ms\n",
      "780:\tlearn: 0.0414435\ttotal: 2.87s\tremaining: 804ms\n",
      "781:\tlearn: 0.0414139\ttotal: 2.87s\tremaining: 800ms\n",
      "782:\tlearn: 0.0413916\ttotal: 2.87s\tremaining: 797ms\n",
      "783:\tlearn: 0.0413616\ttotal: 2.88s\tremaining: 793ms\n",
      "784:\tlearn: 0.0413184\ttotal: 2.88s\tremaining: 789ms\n",
      "785:\tlearn: 0.0412800\ttotal: 2.88s\tremaining: 786ms\n",
      "786:\tlearn: 0.0412300\ttotal: 2.89s\tremaining: 782ms\n",
      "787:\tlearn: 0.0411436\ttotal: 2.89s\tremaining: 778ms\n",
      "788:\tlearn: 0.0411136\ttotal: 2.9s\tremaining: 775ms\n",
      "789:\tlearn: 0.0410826\ttotal: 2.9s\tremaining: 771ms\n",
      "790:\tlearn: 0.0410461\ttotal: 2.9s\tremaining: 767ms\n",
      "791:\tlearn: 0.0410181\ttotal: 2.91s\tremaining: 764ms\n",
      "792:\tlearn: 0.0409862\ttotal: 2.91s\tremaining: 760ms\n",
      "793:\tlearn: 0.0409372\ttotal: 2.92s\tremaining: 756ms\n",
      "794:\tlearn: 0.0408928\ttotal: 2.92s\tremaining: 753ms\n",
      "795:\tlearn: 0.0408323\ttotal: 2.92s\tremaining: 749ms\n",
      "796:\tlearn: 0.0408017\ttotal: 2.93s\tremaining: 745ms\n",
      "797:\tlearn: 0.0407736\ttotal: 2.93s\tremaining: 742ms\n",
      "798:\tlearn: 0.0406873\ttotal: 2.93s\tremaining: 738ms\n",
      "799:\tlearn: 0.0406573\ttotal: 2.94s\tremaining: 735ms\n",
      "800:\tlearn: 0.0405812\ttotal: 2.94s\tremaining: 731ms\n",
      "801:\tlearn: 0.0404950\ttotal: 2.94s\tremaining: 727ms\n",
      "802:\tlearn: 0.0404418\ttotal: 2.95s\tremaining: 724ms\n",
      "803:\tlearn: 0.0403985\ttotal: 2.95s\tremaining: 720ms\n",
      "804:\tlearn: 0.0403214\ttotal: 2.96s\tremaining: 716ms\n",
      "805:\tlearn: 0.0403003\ttotal: 2.96s\tremaining: 712ms\n",
      "806:\tlearn: 0.0402725\ttotal: 2.96s\tremaining: 709ms\n",
      "807:\tlearn: 0.0402228\ttotal: 2.97s\tremaining: 705ms\n",
      "808:\tlearn: 0.0401487\ttotal: 2.97s\tremaining: 701ms\n",
      "809:\tlearn: 0.0401213\ttotal: 2.97s\tremaining: 698ms\n",
      "810:\tlearn: 0.0400950\ttotal: 2.98s\tremaining: 694ms\n",
      "811:\tlearn: 0.0400234\ttotal: 2.98s\tremaining: 690ms\n",
      "812:\tlearn: 0.0399727\ttotal: 2.98s\tremaining: 687ms\n",
      "813:\tlearn: 0.0399488\ttotal: 2.99s\tremaining: 683ms\n",
      "814:\tlearn: 0.0399198\ttotal: 2.99s\tremaining: 679ms\n",
      "815:\tlearn: 0.0398930\ttotal: 3s\tremaining: 676ms\n",
      "816:\tlearn: 0.0398234\ttotal: 3s\tremaining: 672ms\n",
      "817:\tlearn: 0.0397544\ttotal: 3s\tremaining: 668ms\n",
      "818:\tlearn: 0.0397281\ttotal: 3.01s\tremaining: 665ms\n",
      "819:\tlearn: 0.0397072\ttotal: 3.01s\tremaining: 661ms\n",
      "820:\tlearn: 0.0396254\ttotal: 3.01s\tremaining: 657ms\n",
      "821:\tlearn: 0.0395852\ttotal: 3.02s\tremaining: 654ms\n",
      "822:\tlearn: 0.0395481\ttotal: 3.02s\tremaining: 650ms\n",
      "823:\tlearn: 0.0395271\ttotal: 3.02s\tremaining: 646ms\n",
      "824:\tlearn: 0.0394876\ttotal: 3.03s\tremaining: 642ms\n",
      "825:\tlearn: 0.0394625\ttotal: 3.03s\tremaining: 639ms\n",
      "826:\tlearn: 0.0394352\ttotal: 3.04s\tremaining: 635ms\n",
      "827:\tlearn: 0.0394133\ttotal: 3.04s\tremaining: 631ms\n",
      "828:\tlearn: 0.0393613\ttotal: 3.04s\tremaining: 628ms\n",
      "829:\tlearn: 0.0393292\ttotal: 3.04s\tremaining: 624ms\n",
      "830:\tlearn: 0.0392605\ttotal: 3.05s\tremaining: 620ms\n",
      "831:\tlearn: 0.0391911\ttotal: 3.05s\tremaining: 616ms\n",
      "832:\tlearn: 0.0391656\ttotal: 3.06s\tremaining: 613ms\n",
      "833:\tlearn: 0.0391258\ttotal: 3.06s\tremaining: 609ms\n",
      "834:\tlearn: 0.0390614\ttotal: 3.06s\tremaining: 605ms\n",
      "835:\tlearn: 0.0390125\ttotal: 3.07s\tremaining: 602ms\n",
      "836:\tlearn: 0.0389788\ttotal: 3.07s\tremaining: 598ms\n",
      "837:\tlearn: 0.0389312\ttotal: 3.07s\tremaining: 594ms\n",
      "838:\tlearn: 0.0388494\ttotal: 3.08s\tremaining: 590ms\n",
      "839:\tlearn: 0.0388247\ttotal: 3.08s\tremaining: 587ms\n",
      "840:\tlearn: 0.0387441\ttotal: 3.08s\tremaining: 583ms\n",
      "841:\tlearn: 0.0387229\ttotal: 3.09s\tremaining: 579ms\n",
      "842:\tlearn: 0.0386953\ttotal: 3.09s\tremaining: 576ms\n",
      "843:\tlearn: 0.0386676\ttotal: 3.09s\tremaining: 572ms\n",
      "844:\tlearn: 0.0386354\ttotal: 3.1s\tremaining: 568ms\n",
      "845:\tlearn: 0.0386153\ttotal: 3.1s\tremaining: 565ms\n",
      "846:\tlearn: 0.0385739\ttotal: 3.1s\tremaining: 561ms\n",
      "847:\tlearn: 0.0385345\ttotal: 3.11s\tremaining: 557ms\n",
      "848:\tlearn: 0.0384972\ttotal: 3.11s\tremaining: 554ms\n",
      "849:\tlearn: 0.0384767\ttotal: 3.12s\tremaining: 550ms\n",
      "850:\tlearn: 0.0384114\ttotal: 3.12s\tremaining: 546ms\n",
      "851:\tlearn: 0.0383492\ttotal: 3.12s\tremaining: 543ms\n",
      "852:\tlearn: 0.0383271\ttotal: 3.13s\tremaining: 539ms\n",
      "853:\tlearn: 0.0382641\ttotal: 3.13s\tremaining: 535ms\n",
      "854:\tlearn: 0.0382443\ttotal: 3.13s\tremaining: 532ms\n",
      "855:\tlearn: 0.0382037\ttotal: 3.14s\tremaining: 528ms\n",
      "856:\tlearn: 0.0381497\ttotal: 3.14s\tremaining: 524ms\n",
      "857:\tlearn: 0.0381161\ttotal: 3.15s\tremaining: 521ms\n",
      "858:\tlearn: 0.0380949\ttotal: 3.15s\tremaining: 517ms\n",
      "859:\tlearn: 0.0380712\ttotal: 3.15s\tremaining: 513ms\n",
      "860:\tlearn: 0.0380303\ttotal: 3.16s\tremaining: 510ms\n",
      "861:\tlearn: 0.0380112\ttotal: 3.16s\tremaining: 506ms\n",
      "862:\tlearn: 0.0379619\ttotal: 3.17s\tremaining: 502ms\n",
      "863:\tlearn: 0.0379347\ttotal: 3.17s\tremaining: 499ms\n",
      "864:\tlearn: 0.0378700\ttotal: 3.17s\tremaining: 495ms\n",
      "865:\tlearn: 0.0378578\ttotal: 3.18s\tremaining: 492ms\n",
      "866:\tlearn: 0.0377967\ttotal: 3.18s\tremaining: 488ms\n",
      "867:\tlearn: 0.0377776\ttotal: 3.18s\tremaining: 484ms\n",
      "868:\tlearn: 0.0377515\ttotal: 3.19s\tremaining: 481ms\n",
      "869:\tlearn: 0.0376737\ttotal: 3.19s\tremaining: 477ms\n",
      "870:\tlearn: 0.0376384\ttotal: 3.19s\tremaining: 473ms\n",
      "871:\tlearn: 0.0375884\ttotal: 3.2s\tremaining: 470ms\n",
      "872:\tlearn: 0.0375604\ttotal: 3.2s\tremaining: 466ms\n",
      "873:\tlearn: 0.0374960\ttotal: 3.21s\tremaining: 462ms\n",
      "874:\tlearn: 0.0374556\ttotal: 3.21s\tremaining: 458ms\n",
      "875:\tlearn: 0.0374330\ttotal: 3.21s\tremaining: 455ms\n",
      "876:\tlearn: 0.0373983\ttotal: 3.22s\tremaining: 451ms\n",
      "877:\tlearn: 0.0373236\ttotal: 3.22s\tremaining: 447ms\n",
      "878:\tlearn: 0.0372957\ttotal: 3.22s\tremaining: 444ms\n",
      "879:\tlearn: 0.0372731\ttotal: 3.23s\tremaining: 440ms\n",
      "880:\tlearn: 0.0372614\ttotal: 3.23s\tremaining: 436ms\n",
      "881:\tlearn: 0.0372152\ttotal: 3.23s\tremaining: 433ms\n",
      "882:\tlearn: 0.0371933\ttotal: 3.24s\tremaining: 429ms\n",
      "883:\tlearn: 0.0371670\ttotal: 3.24s\tremaining: 425ms\n",
      "884:\tlearn: 0.0371472\ttotal: 3.24s\tremaining: 422ms\n",
      "885:\tlearn: 0.0370898\ttotal: 3.25s\tremaining: 418ms\n",
      "886:\tlearn: 0.0370754\ttotal: 3.25s\tremaining: 414ms\n",
      "887:\tlearn: 0.0370559\ttotal: 3.25s\tremaining: 410ms\n",
      "888:\tlearn: 0.0369977\ttotal: 3.26s\tremaining: 407ms\n",
      "889:\tlearn: 0.0369480\ttotal: 3.26s\tremaining: 403ms\n",
      "890:\tlearn: 0.0369071\ttotal: 3.26s\tremaining: 399ms\n",
      "891:\tlearn: 0.0368898\ttotal: 3.27s\tremaining: 396ms\n",
      "892:\tlearn: 0.0368286\ttotal: 3.27s\tremaining: 392ms\n",
      "893:\tlearn: 0.0367565\ttotal: 3.27s\tremaining: 388ms\n",
      "894:\tlearn: 0.0367307\ttotal: 3.28s\tremaining: 385ms\n",
      "895:\tlearn: 0.0366750\ttotal: 3.28s\tremaining: 381ms\n",
      "896:\tlearn: 0.0366580\ttotal: 3.29s\tremaining: 377ms\n",
      "897:\tlearn: 0.0366214\ttotal: 3.29s\tremaining: 374ms\n",
      "898:\tlearn: 0.0366041\ttotal: 3.29s\tremaining: 370ms\n",
      "899:\tlearn: 0.0365682\ttotal: 3.3s\tremaining: 366ms\n",
      "900:\tlearn: 0.0365142\ttotal: 3.3s\tremaining: 363ms\n",
      "901:\tlearn: 0.0364679\ttotal: 3.3s\tremaining: 359ms\n",
      "902:\tlearn: 0.0364515\ttotal: 3.31s\tremaining: 355ms\n",
      "903:\tlearn: 0.0363844\ttotal: 3.31s\tremaining: 352ms\n",
      "904:\tlearn: 0.0363425\ttotal: 3.31s\tremaining: 348ms\n",
      "905:\tlearn: 0.0363071\ttotal: 3.32s\tremaining: 344ms\n",
      "906:\tlearn: 0.0362839\ttotal: 3.32s\tremaining: 341ms\n",
      "907:\tlearn: 0.0362510\ttotal: 3.33s\tremaining: 337ms\n",
      "908:\tlearn: 0.0362195\ttotal: 3.33s\tremaining: 333ms\n",
      "909:\tlearn: 0.0361545\ttotal: 3.33s\tremaining: 330ms\n",
      "910:\tlearn: 0.0361189\ttotal: 3.34s\tremaining: 326ms\n",
      "911:\tlearn: 0.0361023\ttotal: 3.34s\tremaining: 322ms\n",
      "912:\tlearn: 0.0360664\ttotal: 3.35s\tremaining: 319ms\n",
      "913:\tlearn: 0.0360502\ttotal: 3.35s\tremaining: 315ms\n",
      "914:\tlearn: 0.0360371\ttotal: 3.35s\tremaining: 311ms\n",
      "915:\tlearn: 0.0360009\ttotal: 3.36s\tremaining: 308ms\n",
      "916:\tlearn: 0.0359754\ttotal: 3.36s\tremaining: 304ms\n",
      "917:\tlearn: 0.0359159\ttotal: 3.36s\tremaining: 300ms\n",
      "918:\tlearn: 0.0358674\ttotal: 3.37s\tremaining: 297ms\n",
      "919:\tlearn: 0.0358315\ttotal: 3.37s\tremaining: 293ms\n",
      "920:\tlearn: 0.0358162\ttotal: 3.37s\tremaining: 289ms\n",
      "921:\tlearn: 0.0357674\ttotal: 3.38s\tremaining: 286ms\n",
      "922:\tlearn: 0.0357131\ttotal: 3.38s\tremaining: 282ms\n",
      "923:\tlearn: 0.0356754\ttotal: 3.38s\tremaining: 278ms\n",
      "924:\tlearn: 0.0356605\ttotal: 3.39s\tremaining: 275ms\n",
      "925:\tlearn: 0.0356095\ttotal: 3.39s\tremaining: 271ms\n",
      "926:\tlearn: 0.0355948\ttotal: 3.4s\tremaining: 267ms\n",
      "927:\tlearn: 0.0355515\ttotal: 3.4s\tremaining: 264ms\n",
      "928:\tlearn: 0.0355370\ttotal: 3.4s\tremaining: 260ms\n",
      "929:\tlearn: 0.0354910\ttotal: 3.41s\tremaining: 256ms\n",
      "930:\tlearn: 0.0354754\ttotal: 3.41s\tremaining: 253ms\n",
      "931:\tlearn: 0.0354442\ttotal: 3.42s\tremaining: 249ms\n",
      "932:\tlearn: 0.0353938\ttotal: 3.42s\tremaining: 246ms\n",
      "933:\tlearn: 0.0353489\ttotal: 3.42s\tremaining: 242ms\n",
      "934:\tlearn: 0.0353147\ttotal: 3.43s\tremaining: 238ms\n",
      "935:\tlearn: 0.0352672\ttotal: 3.43s\tremaining: 235ms\n",
      "936:\tlearn: 0.0352186\ttotal: 3.43s\tremaining: 231ms\n",
      "937:\tlearn: 0.0351750\ttotal: 3.44s\tremaining: 227ms\n",
      "938:\tlearn: 0.0351505\ttotal: 3.44s\tremaining: 224ms\n",
      "939:\tlearn: 0.0351028\ttotal: 3.44s\tremaining: 220ms\n",
      "940:\tlearn: 0.0350666\ttotal: 3.45s\tremaining: 216ms\n",
      "941:\tlearn: 0.0350520\ttotal: 3.45s\tremaining: 213ms\n",
      "942:\tlearn: 0.0350034\ttotal: 3.46s\tremaining: 209ms\n",
      "943:\tlearn: 0.0349915\ttotal: 3.46s\tremaining: 205ms\n",
      "944:\tlearn: 0.0349288\ttotal: 3.46s\tremaining: 202ms\n",
      "945:\tlearn: 0.0348985\ttotal: 3.47s\tremaining: 198ms\n",
      "946:\tlearn: 0.0348483\ttotal: 3.47s\tremaining: 194ms\n",
      "947:\tlearn: 0.0348043\ttotal: 3.47s\tremaining: 191ms\n",
      "948:\tlearn: 0.0347791\ttotal: 3.48s\tremaining: 187ms\n",
      "949:\tlearn: 0.0347398\ttotal: 3.48s\tremaining: 183ms\n",
      "950:\tlearn: 0.0346997\ttotal: 3.48s\tremaining: 180ms\n",
      "951:\tlearn: 0.0346855\ttotal: 3.49s\tremaining: 176ms\n",
      "952:\tlearn: 0.0346497\ttotal: 3.49s\tremaining: 172ms\n",
      "953:\tlearn: 0.0346086\ttotal: 3.5s\tremaining: 169ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "954:\tlearn: 0.0345595\ttotal: 3.5s\tremaining: 165ms\n",
      "955:\tlearn: 0.0345350\ttotal: 3.5s\tremaining: 161ms\n",
      "956:\tlearn: 0.0345002\ttotal: 3.51s\tremaining: 158ms\n",
      "957:\tlearn: 0.0344711\ttotal: 3.51s\tremaining: 154ms\n",
      "958:\tlearn: 0.0344303\ttotal: 3.52s\tremaining: 150ms\n",
      "959:\tlearn: 0.0343962\ttotal: 3.52s\tremaining: 147ms\n",
      "960:\tlearn: 0.0343496\ttotal: 3.52s\tremaining: 143ms\n",
      "961:\tlearn: 0.0343382\ttotal: 3.53s\tremaining: 139ms\n",
      "962:\tlearn: 0.0343048\ttotal: 3.53s\tremaining: 136ms\n",
      "963:\tlearn: 0.0342764\ttotal: 3.53s\tremaining: 132ms\n",
      "964:\tlearn: 0.0342423\ttotal: 3.54s\tremaining: 128ms\n",
      "965:\tlearn: 0.0342181\ttotal: 3.54s\tremaining: 125ms\n",
      "966:\tlearn: 0.0341884\ttotal: 3.54s\tremaining: 121ms\n",
      "967:\tlearn: 0.0341563\ttotal: 3.55s\tremaining: 117ms\n",
      "968:\tlearn: 0.0341314\ttotal: 3.55s\tremaining: 114ms\n",
      "969:\tlearn: 0.0340991\ttotal: 3.56s\tremaining: 110ms\n",
      "970:\tlearn: 0.0340750\ttotal: 3.56s\tremaining: 106ms\n",
      "971:\tlearn: 0.0340507\ttotal: 3.56s\tremaining: 103ms\n",
      "972:\tlearn: 0.0340337\ttotal: 3.57s\tremaining: 99ms\n",
      "973:\tlearn: 0.0340091\ttotal: 3.57s\tremaining: 95.3ms\n",
      "974:\tlearn: 0.0339849\ttotal: 3.57s\tremaining: 91.6ms\n",
      "975:\tlearn: 0.0339534\ttotal: 3.58s\tremaining: 88ms\n",
      "976:\tlearn: 0.0339281\ttotal: 3.58s\tremaining: 84.3ms\n",
      "977:\tlearn: 0.0339080\ttotal: 3.58s\tremaining: 80.6ms\n",
      "978:\tlearn: 0.0338770\ttotal: 3.59s\tremaining: 76.9ms\n",
      "979:\tlearn: 0.0338496\ttotal: 3.59s\tremaining: 73.3ms\n",
      "980:\tlearn: 0.0338252\ttotal: 3.59s\tremaining: 69.6ms\n",
      "981:\tlearn: 0.0337984\ttotal: 3.6s\tremaining: 65.9ms\n",
      "982:\tlearn: 0.0337552\ttotal: 3.6s\tremaining: 62.3ms\n",
      "983:\tlearn: 0.0337200\ttotal: 3.6s\tremaining: 58.6ms\n",
      "984:\tlearn: 0.0336958\ttotal: 3.61s\tremaining: 55ms\n",
      "985:\tlearn: 0.0336482\ttotal: 3.61s\tremaining: 51.3ms\n",
      "986:\tlearn: 0.0336209\ttotal: 3.62s\tremaining: 47.6ms\n",
      "987:\tlearn: 0.0336015\ttotal: 3.62s\tremaining: 44ms\n",
      "988:\tlearn: 0.0335747\ttotal: 3.62s\tremaining: 40.3ms\n",
      "989:\tlearn: 0.0335297\ttotal: 3.63s\tremaining: 36.6ms\n",
      "990:\tlearn: 0.0334847\ttotal: 3.63s\tremaining: 33ms\n",
      "991:\tlearn: 0.0334522\ttotal: 3.63s\tremaining: 29.3ms\n",
      "992:\tlearn: 0.0334260\ttotal: 3.63s\tremaining: 25.6ms\n",
      "993:\tlearn: 0.0334035\ttotal: 3.64s\tremaining: 22ms\n",
      "994:\tlearn: 0.0333756\ttotal: 3.64s\tremaining: 18.3ms\n",
      "995:\tlearn: 0.0333446\ttotal: 3.65s\tremaining: 14.6ms\n",
      "996:\tlearn: 0.0333128\ttotal: 3.65s\tremaining: 11ms\n",
      "997:\tlearn: 0.0332856\ttotal: 3.65s\tremaining: 7.32ms\n",
      "998:\tlearn: 0.0332552\ttotal: 3.66s\tremaining: 3.66ms\n",
      "999:\tlearn: 0.0332139\ttotal: 3.66s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:15] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013279\n",
      "0:\tlearn: 0.6669673\ttotal: 4.04ms\tremaining: 4.04s\n",
      "1:\tlearn: 0.6445058\ttotal: 8.01ms\tremaining: 4s\n",
      "2:\tlearn: 0.6204390\ttotal: 11.6ms\tremaining: 3.85s\n",
      "3:\tlearn: 0.5973865\ttotal: 15.2ms\tremaining: 3.79s\n",
      "4:\tlearn: 0.5742131\ttotal: 19.3ms\tremaining: 3.84s\n",
      "5:\tlearn: 0.5588506\ttotal: 23ms\tremaining: 3.81s\n",
      "6:\tlearn: 0.5376912\ttotal: 26.7ms\tremaining: 3.79s\n",
      "7:\tlearn: 0.5202290\ttotal: 32.1ms\tremaining: 3.98s\n",
      "8:\tlearn: 0.5044324\ttotal: 36.2ms\tremaining: 3.98s\n",
      "9:\tlearn: 0.4873071\ttotal: 40.2ms\tremaining: 3.98s\n",
      "10:\tlearn: 0.4711316\ttotal: 44.3ms\tremaining: 3.98s\n",
      "11:\tlearn: 0.4553270\ttotal: 48.2ms\tremaining: 3.97s\n",
      "12:\tlearn: 0.4401684\ttotal: 52.4ms\tremaining: 3.98s\n",
      "13:\tlearn: 0.4262022\ttotal: 56.3ms\tremaining: 3.96s\n",
      "14:\tlearn: 0.4125393\ttotal: 60.2ms\tremaining: 3.96s\n",
      "15:\tlearn: 0.3987303\ttotal: 64.8ms\tremaining: 3.98s\n",
      "16:\tlearn: 0.3872307\ttotal: 68.6ms\tremaining: 3.96s\n",
      "17:\tlearn: 0.3771578\ttotal: 72.1ms\tremaining: 3.93s\n",
      "18:\tlearn: 0.3661077\ttotal: 75.7ms\tremaining: 3.91s\n",
      "19:\tlearn: 0.3552475\ttotal: 79.6ms\tremaining: 3.9s\n",
      "20:\tlearn: 0.3456931\ttotal: 83.5ms\tremaining: 3.89s\n",
      "21:\tlearn: 0.3381612\ttotal: 87.5ms\tremaining: 3.89s\n",
      "22:\tlearn: 0.3282549\ttotal: 91.1ms\tremaining: 3.87s\n",
      "23:\tlearn: 0.3213965\ttotal: 95.1ms\tremaining: 3.87s\n",
      "24:\tlearn: 0.3129718\ttotal: 98.9ms\tremaining: 3.86s\n",
      "25:\tlearn: 0.3049326\ttotal: 103ms\tremaining: 3.85s\n",
      "26:\tlearn: 0.2981933\ttotal: 106ms\tremaining: 3.83s\n",
      "27:\tlearn: 0.2904250\ttotal: 110ms\tremaining: 3.81s\n",
      "28:\tlearn: 0.2839020\ttotal: 113ms\tremaining: 3.79s\n",
      "29:\tlearn: 0.2773872\ttotal: 117ms\tremaining: 3.8s\n",
      "30:\tlearn: 0.2711752\ttotal: 121ms\tremaining: 3.78s\n",
      "31:\tlearn: 0.2654074\ttotal: 125ms\tremaining: 3.78s\n",
      "32:\tlearn: 0.2595027\ttotal: 128ms\tremaining: 3.76s\n",
      "33:\tlearn: 0.2539010\ttotal: 132ms\tremaining: 3.75s\n",
      "34:\tlearn: 0.2480979\ttotal: 136ms\tremaining: 3.74s\n",
      "35:\tlearn: 0.2433912\ttotal: 139ms\tremaining: 3.72s\n",
      "36:\tlearn: 0.2383245\ttotal: 143ms\tremaining: 3.71s\n",
      "37:\tlearn: 0.2333791\ttotal: 147ms\tremaining: 3.71s\n",
      "38:\tlearn: 0.2291946\ttotal: 150ms\tremaining: 3.7s\n",
      "39:\tlearn: 0.2255741\ttotal: 154ms\tremaining: 3.69s\n",
      "40:\tlearn: 0.2219824\ttotal: 158ms\tremaining: 3.69s\n",
      "41:\tlearn: 0.2175045\ttotal: 162ms\tremaining: 3.69s\n",
      "42:\tlearn: 0.2132867\ttotal: 165ms\tremaining: 3.68s\n",
      "43:\tlearn: 0.2095623\ttotal: 169ms\tremaining: 3.67s\n",
      "44:\tlearn: 0.2065812\ttotal: 172ms\tremaining: 3.66s\n",
      "45:\tlearn: 0.2028442\ttotal: 176ms\tremaining: 3.65s\n",
      "46:\tlearn: 0.1992707\ttotal: 180ms\tremaining: 3.65s\n",
      "47:\tlearn: 0.1961224\ttotal: 184ms\tremaining: 3.65s\n",
      "48:\tlearn: 0.1930951\ttotal: 188ms\tremaining: 3.65s\n",
      "49:\tlearn: 0.1901332\ttotal: 192ms\tremaining: 3.66s\n",
      "50:\tlearn: 0.1870633\ttotal: 197ms\tremaining: 3.66s\n",
      "51:\tlearn: 0.1846710\ttotal: 200ms\tremaining: 3.65s\n",
      "52:\tlearn: 0.1820899\ttotal: 204ms\tremaining: 3.64s\n",
      "53:\tlearn: 0.1792841\ttotal: 207ms\tremaining: 3.63s\n",
      "54:\tlearn: 0.1773237\ttotal: 211ms\tremaining: 3.63s\n",
      "55:\tlearn: 0.1750012\ttotal: 215ms\tremaining: 3.63s\n",
      "56:\tlearn: 0.1728299\ttotal: 219ms\tremaining: 3.63s\n",
      "57:\tlearn: 0.1706338\ttotal: 223ms\tremaining: 3.62s\n",
      "58:\tlearn: 0.1689238\ttotal: 227ms\tremaining: 3.61s\n",
      "59:\tlearn: 0.1669347\ttotal: 230ms\tremaining: 3.61s\n",
      "60:\tlearn: 0.1649481\ttotal: 234ms\tremaining: 3.6s\n",
      "61:\tlearn: 0.1628324\ttotal: 238ms\tremaining: 3.59s\n",
      "62:\tlearn: 0.1609563\ttotal: 241ms\tremaining: 3.59s\n",
      "63:\tlearn: 0.1595001\ttotal: 245ms\tremaining: 3.58s\n",
      "64:\tlearn: 0.1575083\ttotal: 249ms\tremaining: 3.58s\n",
      "65:\tlearn: 0.1557403\ttotal: 253ms\tremaining: 3.58s\n",
      "66:\tlearn: 0.1544794\ttotal: 256ms\tremaining: 3.57s\n",
      "67:\tlearn: 0.1529843\ttotal: 260ms\tremaining: 3.56s\n",
      "68:\tlearn: 0.1513654\ttotal: 264ms\tremaining: 3.56s\n",
      "69:\tlearn: 0.1500060\ttotal: 267ms\tremaining: 3.55s\n",
      "70:\tlearn: 0.1489192\ttotal: 271ms\tremaining: 3.54s\n",
      "71:\tlearn: 0.1473304\ttotal: 274ms\tremaining: 3.53s\n",
      "72:\tlearn: 0.1460970\ttotal: 278ms\tremaining: 3.53s\n",
      "73:\tlearn: 0.1450855\ttotal: 282ms\tremaining: 3.53s\n",
      "74:\tlearn: 0.1439488\ttotal: 286ms\tremaining: 3.53s\n",
      "75:\tlearn: 0.1424578\ttotal: 290ms\tremaining: 3.53s\n",
      "76:\tlearn: 0.1415480\ttotal: 294ms\tremaining: 3.52s\n",
      "77:\tlearn: 0.1401740\ttotal: 297ms\tremaining: 3.52s\n",
      "78:\tlearn: 0.1390101\ttotal: 301ms\tremaining: 3.51s\n",
      "79:\tlearn: 0.1378497\ttotal: 304ms\tremaining: 3.5s\n",
      "80:\tlearn: 0.1368738\ttotal: 309ms\tremaining: 3.5s\n",
      "81:\tlearn: 0.1358592\ttotal: 313ms\tremaining: 3.51s\n",
      "82:\tlearn: 0.1346982\ttotal: 317ms\tremaining: 3.51s\n",
      "83:\tlearn: 0.1339277\ttotal: 321ms\tremaining: 3.5s\n",
      "84:\tlearn: 0.1328789\ttotal: 325ms\tremaining: 3.5s\n",
      "85:\tlearn: 0.1320653\ttotal: 329ms\tremaining: 3.49s\n",
      "86:\tlearn: 0.1312493\ttotal: 332ms\tremaining: 3.49s\n",
      "87:\tlearn: 0.1303163\ttotal: 336ms\tremaining: 3.48s\n",
      "88:\tlearn: 0.1293955\ttotal: 340ms\tremaining: 3.48s\n",
      "89:\tlearn: 0.1285140\ttotal: 344ms\tremaining: 3.48s\n",
      "90:\tlearn: 0.1275373\ttotal: 348ms\tremaining: 3.47s\n",
      "91:\tlearn: 0.1268271\ttotal: 351ms\tremaining: 3.47s\n",
      "92:\tlearn: 0.1261195\ttotal: 355ms\tremaining: 3.46s\n",
      "93:\tlearn: 0.1254650\ttotal: 359ms\tremaining: 3.46s\n",
      "94:\tlearn: 0.1247830\ttotal: 363ms\tremaining: 3.46s\n",
      "95:\tlearn: 0.1240823\ttotal: 367ms\tremaining: 3.46s\n",
      "96:\tlearn: 0.1233889\ttotal: 371ms\tremaining: 3.46s\n",
      "97:\tlearn: 0.1227117\ttotal: 375ms\tremaining: 3.45s\n",
      "98:\tlearn: 0.1221868\ttotal: 379ms\tremaining: 3.45s\n",
      "99:\tlearn: 0.1216559\ttotal: 383ms\tremaining: 3.44s\n",
      "100:\tlearn: 0.1209507\ttotal: 387ms\tremaining: 3.45s\n",
      "101:\tlearn: 0.1201477\ttotal: 392ms\tremaining: 3.45s\n",
      "102:\tlearn: 0.1194512\ttotal: 395ms\tremaining: 3.44s\n",
      "103:\tlearn: 0.1187759\ttotal: 400ms\tremaining: 3.44s\n",
      "104:\tlearn: 0.1184847\ttotal: 403ms\tremaining: 3.44s\n",
      "105:\tlearn: 0.1179699\ttotal: 408ms\tremaining: 3.44s\n",
      "106:\tlearn: 0.1173273\ttotal: 412ms\tremaining: 3.44s\n",
      "107:\tlearn: 0.1168050\ttotal: 416ms\tremaining: 3.44s\n",
      "108:\tlearn: 0.1164045\ttotal: 419ms\tremaining: 3.43s\n",
      "109:\tlearn: 0.1159480\ttotal: 423ms\tremaining: 3.42s\n",
      "110:\tlearn: 0.1153524\ttotal: 426ms\tremaining: 3.42s\n",
      "111:\tlearn: 0.1149801\ttotal: 431ms\tremaining: 3.41s\n",
      "112:\tlearn: 0.1145535\ttotal: 434ms\tremaining: 3.41s\n",
      "113:\tlearn: 0.1140472\ttotal: 438ms\tremaining: 3.4s\n",
      "114:\tlearn: 0.1136213\ttotal: 441ms\tremaining: 3.4s\n",
      "115:\tlearn: 0.1130998\ttotal: 445ms\tremaining: 3.39s\n",
      "116:\tlearn: 0.1128061\ttotal: 449ms\tremaining: 3.39s\n",
      "117:\tlearn: 0.1123110\ttotal: 452ms\tremaining: 3.38s\n",
      "118:\tlearn: 0.1118771\ttotal: 456ms\tremaining: 3.38s\n",
      "119:\tlearn: 0.1113320\ttotal: 460ms\tremaining: 3.37s\n",
      "120:\tlearn: 0.1108260\ttotal: 463ms\tremaining: 3.37s\n",
      "121:\tlearn: 0.1104350\ttotal: 467ms\tremaining: 3.36s\n",
      "122:\tlearn: 0.1099737\ttotal: 470ms\tremaining: 3.35s\n",
      "123:\tlearn: 0.1095775\ttotal: 474ms\tremaining: 3.35s\n",
      "124:\tlearn: 0.1090935\ttotal: 478ms\tremaining: 3.34s\n",
      "125:\tlearn: 0.1086831\ttotal: 481ms\tremaining: 3.34s\n",
      "126:\tlearn: 0.1082241\ttotal: 484ms\tremaining: 3.33s\n",
      "127:\tlearn: 0.1078319\ttotal: 488ms\tremaining: 3.33s\n",
      "128:\tlearn: 0.1074238\ttotal: 492ms\tremaining: 3.32s\n",
      "129:\tlearn: 0.1070279\ttotal: 495ms\tremaining: 3.31s\n",
      "130:\tlearn: 0.1067005\ttotal: 499ms\tremaining: 3.31s\n",
      "131:\tlearn: 0.1062287\ttotal: 502ms\tremaining: 3.3s\n",
      "132:\tlearn: 0.1058143\ttotal: 506ms\tremaining: 3.3s\n",
      "133:\tlearn: 0.1054723\ttotal: 509ms\tremaining: 3.29s\n",
      "134:\tlearn: 0.1050884\ttotal: 513ms\tremaining: 3.29s\n",
      "135:\tlearn: 0.1045260\ttotal: 516ms\tremaining: 3.28s\n",
      "136:\tlearn: 0.1042035\ttotal: 520ms\tremaining: 3.27s\n",
      "137:\tlearn: 0.1039357\ttotal: 524ms\tremaining: 3.27s\n",
      "138:\tlearn: 0.1036217\ttotal: 527ms\tremaining: 3.26s\n",
      "139:\tlearn: 0.1032663\ttotal: 531ms\tremaining: 3.26s\n",
      "140:\tlearn: 0.1028888\ttotal: 535ms\tremaining: 3.26s\n",
      "141:\tlearn: 0.1024158\ttotal: 539ms\tremaining: 3.25s\n",
      "142:\tlearn: 0.1019827\ttotal: 542ms\tremaining: 3.25s\n",
      "143:\tlearn: 0.1015812\ttotal: 546ms\tremaining: 3.25s\n",
      "144:\tlearn: 0.1013474\ttotal: 550ms\tremaining: 3.24s\n",
      "145:\tlearn: 0.1010349\ttotal: 554ms\tremaining: 3.24s\n",
      "146:\tlearn: 0.1006836\ttotal: 558ms\tremaining: 3.24s\n",
      "147:\tlearn: 0.1004447\ttotal: 561ms\tremaining: 3.23s\n",
      "148:\tlearn: 0.1002540\ttotal: 565ms\tremaining: 3.23s\n",
      "149:\tlearn: 0.0998673\ttotal: 569ms\tremaining: 3.22s\n",
      "150:\tlearn: 0.0994502\ttotal: 572ms\tremaining: 3.22s\n",
      "151:\tlearn: 0.0991668\ttotal: 576ms\tremaining: 3.21s\n",
      "152:\tlearn: 0.0988353\ttotal: 579ms\tremaining: 3.21s\n",
      "153:\tlearn: 0.0985704\ttotal: 583ms\tremaining: 3.2s\n",
      "154:\tlearn: 0.0983122\ttotal: 586ms\tremaining: 3.19s\n",
      "155:\tlearn: 0.0980793\ttotal: 589ms\tremaining: 3.19s\n",
      "156:\tlearn: 0.0977412\ttotal: 593ms\tremaining: 3.18s\n",
      "157:\tlearn: 0.0974957\ttotal: 597ms\tremaining: 3.18s\n",
      "158:\tlearn: 0.0972596\ttotal: 601ms\tremaining: 3.18s\n",
      "159:\tlearn: 0.0969769\ttotal: 605ms\tremaining: 3.17s\n",
      "160:\tlearn: 0.0966997\ttotal: 608ms\tremaining: 3.17s\n",
      "161:\tlearn: 0.0963427\ttotal: 611ms\tremaining: 3.16s\n",
      "162:\tlearn: 0.0961685\ttotal: 615ms\tremaining: 3.16s\n",
      "163:\tlearn: 0.0958467\ttotal: 619ms\tremaining: 3.15s\n",
      "164:\tlearn: 0.0955991\ttotal: 623ms\tremaining: 3.15s\n",
      "165:\tlearn: 0.0953242\ttotal: 627ms\tremaining: 3.15s\n",
      "166:\tlearn: 0.0950831\ttotal: 631ms\tremaining: 3.15s\n",
      "167:\tlearn: 0.0948626\ttotal: 635ms\tremaining: 3.15s\n",
      "168:\tlearn: 0.0946288\ttotal: 639ms\tremaining: 3.14s\n",
      "169:\tlearn: 0.0943525\ttotal: 643ms\tremaining: 3.14s\n",
      "170:\tlearn: 0.0940930\ttotal: 647ms\tremaining: 3.14s\n",
      "171:\tlearn: 0.0939227\ttotal: 651ms\tremaining: 3.13s\n",
      "172:\tlearn: 0.0936205\ttotal: 655ms\tremaining: 3.13s\n",
      "173:\tlearn: 0.0933537\ttotal: 659ms\tremaining: 3.13s\n",
      "174:\tlearn: 0.0931307\ttotal: 663ms\tremaining: 3.13s\n",
      "175:\tlearn: 0.0928851\ttotal: 667ms\tremaining: 3.12s\n",
      "176:\tlearn: 0.0927600\ttotal: 670ms\tremaining: 3.12s\n",
      "177:\tlearn: 0.0925558\ttotal: 674ms\tremaining: 3.11s\n",
      "178:\tlearn: 0.0923076\ttotal: 678ms\tremaining: 3.11s\n",
      "179:\tlearn: 0.0920866\ttotal: 682ms\tremaining: 3.1s\n",
      "180:\tlearn: 0.0918733\ttotal: 686ms\tremaining: 3.1s\n",
      "181:\tlearn: 0.0916309\ttotal: 690ms\tremaining: 3.1s\n",
      "182:\tlearn: 0.0914414\ttotal: 694ms\tremaining: 3.1s\n",
      "183:\tlearn: 0.0912841\ttotal: 698ms\tremaining: 3.1s\n",
      "184:\tlearn: 0.0910800\ttotal: 702ms\tremaining: 3.09s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "185:\tlearn: 0.0908256\ttotal: 706ms\tremaining: 3.09s\n",
      "186:\tlearn: 0.0905611\ttotal: 711ms\tremaining: 3.09s\n",
      "187:\tlearn: 0.0903014\ttotal: 715ms\tremaining: 3.09s\n",
      "188:\tlearn: 0.0901702\ttotal: 719ms\tremaining: 3.09s\n",
      "189:\tlearn: 0.0899287\ttotal: 723ms\tremaining: 3.08s\n",
      "190:\tlearn: 0.0896983\ttotal: 727ms\tremaining: 3.08s\n",
      "191:\tlearn: 0.0894794\ttotal: 730ms\tremaining: 3.07s\n",
      "192:\tlearn: 0.0892551\ttotal: 734ms\tremaining: 3.07s\n",
      "193:\tlearn: 0.0891420\ttotal: 739ms\tremaining: 3.07s\n",
      "194:\tlearn: 0.0888457\ttotal: 744ms\tremaining: 3.07s\n",
      "195:\tlearn: 0.0886663\ttotal: 748ms\tremaining: 3.07s\n",
      "196:\tlearn: 0.0884832\ttotal: 752ms\tremaining: 3.06s\n",
      "197:\tlearn: 0.0883439\ttotal: 755ms\tremaining: 3.06s\n",
      "198:\tlearn: 0.0881904\ttotal: 759ms\tremaining: 3.05s\n",
      "199:\tlearn: 0.0880205\ttotal: 762ms\tremaining: 3.05s\n",
      "200:\tlearn: 0.0877544\ttotal: 766ms\tremaining: 3.04s\n",
      "201:\tlearn: 0.0874685\ttotal: 770ms\tremaining: 3.04s\n",
      "202:\tlearn: 0.0873254\ttotal: 773ms\tremaining: 3.04s\n",
      "203:\tlearn: 0.0871263\ttotal: 777ms\tremaining: 3.03s\n",
      "204:\tlearn: 0.0869233\ttotal: 781ms\tremaining: 3.03s\n",
      "205:\tlearn: 0.0865941\ttotal: 784ms\tremaining: 3.02s\n",
      "206:\tlearn: 0.0863703\ttotal: 788ms\tremaining: 3.02s\n",
      "207:\tlearn: 0.0862374\ttotal: 791ms\tremaining: 3.01s\n",
      "208:\tlearn: 0.0860211\ttotal: 795ms\tremaining: 3.01s\n",
      "209:\tlearn: 0.0858009\ttotal: 799ms\tremaining: 3s\n",
      "210:\tlearn: 0.0856088\ttotal: 802ms\tremaining: 3s\n",
      "211:\tlearn: 0.0854621\ttotal: 806ms\tremaining: 2.99s\n",
      "212:\tlearn: 0.0852107\ttotal: 810ms\tremaining: 2.99s\n",
      "213:\tlearn: 0.0850254\ttotal: 813ms\tremaining: 2.99s\n",
      "214:\tlearn: 0.0847402\ttotal: 817ms\tremaining: 2.98s\n",
      "215:\tlearn: 0.0845615\ttotal: 821ms\tremaining: 2.98s\n",
      "216:\tlearn: 0.0843867\ttotal: 824ms\tremaining: 2.97s\n",
      "217:\tlearn: 0.0842574\ttotal: 827ms\tremaining: 2.97s\n",
      "218:\tlearn: 0.0839863\ttotal: 831ms\tremaining: 2.96s\n",
      "219:\tlearn: 0.0838041\ttotal: 835ms\tremaining: 2.96s\n",
      "220:\tlearn: 0.0836119\ttotal: 838ms\tremaining: 2.95s\n",
      "221:\tlearn: 0.0834104\ttotal: 842ms\tremaining: 2.95s\n",
      "222:\tlearn: 0.0831860\ttotal: 845ms\tremaining: 2.94s\n",
      "223:\tlearn: 0.0830130\ttotal: 849ms\tremaining: 2.94s\n",
      "224:\tlearn: 0.0828823\ttotal: 853ms\tremaining: 2.94s\n",
      "225:\tlearn: 0.0827060\ttotal: 856ms\tremaining: 2.93s\n",
      "226:\tlearn: 0.0824916\ttotal: 860ms\tremaining: 2.93s\n",
      "227:\tlearn: 0.0823584\ttotal: 863ms\tremaining: 2.92s\n",
      "228:\tlearn: 0.0822649\ttotal: 867ms\tremaining: 2.92s\n",
      "229:\tlearn: 0.0820753\ttotal: 870ms\tremaining: 2.91s\n",
      "230:\tlearn: 0.0819043\ttotal: 874ms\tremaining: 2.91s\n",
      "231:\tlearn: 0.0817777\ttotal: 878ms\tremaining: 2.91s\n",
      "232:\tlearn: 0.0814709\ttotal: 882ms\tremaining: 2.9s\n",
      "233:\tlearn: 0.0812335\ttotal: 885ms\tremaining: 2.9s\n",
      "234:\tlearn: 0.0810638\ttotal: 889ms\tremaining: 2.9s\n",
      "235:\tlearn: 0.0808182\ttotal: 894ms\tremaining: 2.89s\n",
      "236:\tlearn: 0.0806809\ttotal: 898ms\tremaining: 2.89s\n",
      "237:\tlearn: 0.0805357\ttotal: 901ms\tremaining: 2.89s\n",
      "238:\tlearn: 0.0804303\ttotal: 905ms\tremaining: 2.88s\n",
      "239:\tlearn: 0.0802998\ttotal: 909ms\tremaining: 2.88s\n",
      "240:\tlearn: 0.0801829\ttotal: 913ms\tremaining: 2.87s\n",
      "241:\tlearn: 0.0800082\ttotal: 916ms\tremaining: 2.87s\n",
      "242:\tlearn: 0.0798355\ttotal: 919ms\tremaining: 2.86s\n",
      "243:\tlearn: 0.0796570\ttotal: 923ms\tremaining: 2.86s\n",
      "244:\tlearn: 0.0795151\ttotal: 927ms\tremaining: 2.85s\n",
      "245:\tlearn: 0.0794035\ttotal: 931ms\tremaining: 2.85s\n",
      "246:\tlearn: 0.0792085\ttotal: 935ms\tremaining: 2.85s\n",
      "247:\tlearn: 0.0790819\ttotal: 939ms\tremaining: 2.85s\n",
      "248:\tlearn: 0.0789535\ttotal: 942ms\tremaining: 2.84s\n",
      "249:\tlearn: 0.0787578\ttotal: 946ms\tremaining: 2.84s\n",
      "250:\tlearn: 0.0786680\ttotal: 949ms\tremaining: 2.83s\n",
      "251:\tlearn: 0.0785570\ttotal: 953ms\tremaining: 2.83s\n",
      "252:\tlearn: 0.0784360\ttotal: 957ms\tremaining: 2.82s\n",
      "253:\tlearn: 0.0783108\ttotal: 960ms\tremaining: 2.82s\n",
      "254:\tlearn: 0.0782230\ttotal: 964ms\tremaining: 2.82s\n",
      "255:\tlearn: 0.0781345\ttotal: 968ms\tremaining: 2.81s\n",
      "256:\tlearn: 0.0779466\ttotal: 971ms\tremaining: 2.81s\n",
      "257:\tlearn: 0.0778420\ttotal: 975ms\tremaining: 2.8s\n",
      "258:\tlearn: 0.0777072\ttotal: 978ms\tremaining: 2.8s\n",
      "259:\tlearn: 0.0775402\ttotal: 982ms\tremaining: 2.79s\n",
      "260:\tlearn: 0.0773835\ttotal: 986ms\tremaining: 2.79s\n",
      "261:\tlearn: 0.0772719\ttotal: 989ms\tremaining: 2.79s\n",
      "262:\tlearn: 0.0771144\ttotal: 993ms\tremaining: 2.78s\n",
      "263:\tlearn: 0.0769649\ttotal: 997ms\tremaining: 2.78s\n",
      "264:\tlearn: 0.0769006\ttotal: 1s\tremaining: 2.77s\n",
      "265:\tlearn: 0.0767623\ttotal: 1s\tremaining: 2.77s\n",
      "266:\tlearn: 0.0766676\ttotal: 1.01s\tremaining: 2.77s\n",
      "267:\tlearn: 0.0764616\ttotal: 1.01s\tremaining: 2.76s\n",
      "268:\tlearn: 0.0763389\ttotal: 1.01s\tremaining: 2.76s\n",
      "269:\tlearn: 0.0762390\ttotal: 1.02s\tremaining: 2.76s\n",
      "270:\tlearn: 0.0761442\ttotal: 1.02s\tremaining: 2.75s\n",
      "271:\tlearn: 0.0759812\ttotal: 1.03s\tremaining: 2.75s\n",
      "272:\tlearn: 0.0759425\ttotal: 1.04s\tremaining: 2.77s\n",
      "273:\tlearn: 0.0757748\ttotal: 1.04s\tremaining: 2.77s\n",
      "274:\tlearn: 0.0756562\ttotal: 1.05s\tremaining: 2.77s\n",
      "275:\tlearn: 0.0756077\ttotal: 1.06s\tremaining: 2.78s\n",
      "276:\tlearn: 0.0755200\ttotal: 1.06s\tremaining: 2.78s\n",
      "277:\tlearn: 0.0754021\ttotal: 1.07s\tremaining: 2.77s\n",
      "278:\tlearn: 0.0752966\ttotal: 1.07s\tremaining: 2.77s\n",
      "279:\tlearn: 0.0751636\ttotal: 1.08s\tremaining: 2.77s\n",
      "280:\tlearn: 0.0749969\ttotal: 1.08s\tremaining: 2.77s\n",
      "281:\tlearn: 0.0748798\ttotal: 1.09s\tremaining: 2.77s\n",
      "282:\tlearn: 0.0748171\ttotal: 1.09s\tremaining: 2.77s\n",
      "283:\tlearn: 0.0746904\ttotal: 1.1s\tremaining: 2.78s\n",
      "284:\tlearn: 0.0746251\ttotal: 1.11s\tremaining: 2.79s\n",
      "285:\tlearn: 0.0744780\ttotal: 1.12s\tremaining: 2.8s\n",
      "286:\tlearn: 0.0743640\ttotal: 1.13s\tremaining: 2.8s\n",
      "287:\tlearn: 0.0743128\ttotal: 1.13s\tremaining: 2.8s\n",
      "288:\tlearn: 0.0741908\ttotal: 1.14s\tremaining: 2.79s\n",
      "289:\tlearn: 0.0740229\ttotal: 1.14s\tremaining: 2.79s\n",
      "290:\tlearn: 0.0738949\ttotal: 1.15s\tremaining: 2.79s\n",
      "291:\tlearn: 0.0737762\ttotal: 1.15s\tremaining: 2.79s\n",
      "292:\tlearn: 0.0736250\ttotal: 1.16s\tremaining: 2.8s\n",
      "293:\tlearn: 0.0734357\ttotal: 1.16s\tremaining: 2.79s\n",
      "294:\tlearn: 0.0732913\ttotal: 1.17s\tremaining: 2.79s\n",
      "295:\tlearn: 0.0731830\ttotal: 1.17s\tremaining: 2.79s\n",
      "296:\tlearn: 0.0730679\ttotal: 1.18s\tremaining: 2.78s\n",
      "297:\tlearn: 0.0728707\ttotal: 1.18s\tremaining: 2.78s\n",
      "298:\tlearn: 0.0727345\ttotal: 1.18s\tremaining: 2.78s\n",
      "299:\tlearn: 0.0726120\ttotal: 1.19s\tremaining: 2.77s\n",
      "300:\tlearn: 0.0724721\ttotal: 1.19s\tremaining: 2.77s\n",
      "301:\tlearn: 0.0723784\ttotal: 1.2s\tremaining: 2.76s\n",
      "302:\tlearn: 0.0722266\ttotal: 1.2s\tremaining: 2.76s\n",
      "303:\tlearn: 0.0720633\ttotal: 1.2s\tremaining: 2.75s\n",
      "304:\tlearn: 0.0719639\ttotal: 1.21s\tremaining: 2.75s\n",
      "305:\tlearn: 0.0717855\ttotal: 1.21s\tremaining: 2.74s\n",
      "306:\tlearn: 0.0716569\ttotal: 1.21s\tremaining: 2.74s\n",
      "307:\tlearn: 0.0714872\ttotal: 1.22s\tremaining: 2.73s\n",
      "308:\tlearn: 0.0713570\ttotal: 1.22s\tremaining: 2.73s\n",
      "309:\tlearn: 0.0712624\ttotal: 1.23s\tremaining: 2.73s\n",
      "310:\tlearn: 0.0711450\ttotal: 1.23s\tremaining: 2.72s\n",
      "311:\tlearn: 0.0710476\ttotal: 1.23s\tremaining: 2.72s\n",
      "312:\tlearn: 0.0710018\ttotal: 1.24s\tremaining: 2.71s\n",
      "313:\tlearn: 0.0709262\ttotal: 1.24s\tremaining: 2.71s\n",
      "314:\tlearn: 0.0707507\ttotal: 1.24s\tremaining: 2.71s\n",
      "315:\tlearn: 0.0706348\ttotal: 1.25s\tremaining: 2.7s\n",
      "316:\tlearn: 0.0704901\ttotal: 1.25s\tremaining: 2.7s\n",
      "317:\tlearn: 0.0703154\ttotal: 1.25s\tremaining: 2.69s\n",
      "318:\tlearn: 0.0702050\ttotal: 1.26s\tremaining: 2.69s\n",
      "319:\tlearn: 0.0701074\ttotal: 1.26s\tremaining: 2.68s\n",
      "320:\tlearn: 0.0699531\ttotal: 1.27s\tremaining: 2.68s\n",
      "321:\tlearn: 0.0698349\ttotal: 1.27s\tremaining: 2.67s\n",
      "322:\tlearn: 0.0696771\ttotal: 1.27s\tremaining: 2.67s\n",
      "323:\tlearn: 0.0696000\ttotal: 1.28s\tremaining: 2.67s\n",
      "324:\tlearn: 0.0694770\ttotal: 1.28s\tremaining: 2.66s\n",
      "325:\tlearn: 0.0693768\ttotal: 1.28s\tremaining: 2.66s\n",
      "326:\tlearn: 0.0693063\ttotal: 1.29s\tremaining: 2.65s\n",
      "327:\tlearn: 0.0692585\ttotal: 1.29s\tremaining: 2.65s\n",
      "328:\tlearn: 0.0691706\ttotal: 1.3s\tremaining: 2.64s\n",
      "329:\tlearn: 0.0690581\ttotal: 1.3s\tremaining: 2.64s\n",
      "330:\tlearn: 0.0689186\ttotal: 1.3s\tremaining: 2.63s\n",
      "331:\tlearn: 0.0688391\ttotal: 1.31s\tremaining: 2.63s\n",
      "332:\tlearn: 0.0687513\ttotal: 1.31s\tremaining: 2.63s\n",
      "333:\tlearn: 0.0686795\ttotal: 1.31s\tremaining: 2.62s\n",
      "334:\tlearn: 0.0686672\ttotal: 1.32s\tremaining: 2.62s\n",
      "335:\tlearn: 0.0685199\ttotal: 1.32s\tremaining: 2.61s\n",
      "336:\tlearn: 0.0684749\ttotal: 1.32s\tremaining: 2.61s\n",
      "337:\tlearn: 0.0684131\ttotal: 1.33s\tremaining: 2.6s\n",
      "338:\tlearn: 0.0683487\ttotal: 1.33s\tremaining: 2.6s\n",
      "339:\tlearn: 0.0682116\ttotal: 1.33s\tremaining: 2.59s\n",
      "340:\tlearn: 0.0679924\ttotal: 1.34s\tremaining: 2.59s\n",
      "341:\tlearn: 0.0678095\ttotal: 1.34s\tremaining: 2.58s\n",
      "342:\tlearn: 0.0676658\ttotal: 1.35s\tremaining: 2.58s\n",
      "343:\tlearn: 0.0675299\ttotal: 1.35s\tremaining: 2.58s\n",
      "344:\tlearn: 0.0674017\ttotal: 1.35s\tremaining: 2.57s\n",
      "345:\tlearn: 0.0673512\ttotal: 1.36s\tremaining: 2.57s\n",
      "346:\tlearn: 0.0672054\ttotal: 1.36s\tremaining: 2.56s\n",
      "347:\tlearn: 0.0670618\ttotal: 1.37s\tremaining: 2.56s\n",
      "348:\tlearn: 0.0669900\ttotal: 1.37s\tremaining: 2.56s\n",
      "349:\tlearn: 0.0669058\ttotal: 1.37s\tremaining: 2.55s\n",
      "350:\tlearn: 0.0667940\ttotal: 1.38s\tremaining: 2.55s\n",
      "351:\tlearn: 0.0667442\ttotal: 1.38s\tremaining: 2.54s\n",
      "352:\tlearn: 0.0666437\ttotal: 1.38s\tremaining: 2.54s\n",
      "353:\tlearn: 0.0665814\ttotal: 1.39s\tremaining: 2.53s\n",
      "354:\tlearn: 0.0664740\ttotal: 1.39s\tremaining: 2.53s\n",
      "355:\tlearn: 0.0663100\ttotal: 1.4s\tremaining: 2.52s\n",
      "356:\tlearn: 0.0662121\ttotal: 1.4s\tremaining: 2.52s\n",
      "357:\tlearn: 0.0660685\ttotal: 1.4s\tremaining: 2.52s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "358:\tlearn: 0.0660248\ttotal: 1.41s\tremaining: 2.52s\n",
      "359:\tlearn: 0.0659074\ttotal: 1.41s\tremaining: 2.51s\n",
      "360:\tlearn: 0.0657538\ttotal: 1.42s\tremaining: 2.51s\n",
      "361:\tlearn: 0.0656323\ttotal: 1.42s\tremaining: 2.5s\n",
      "362:\tlearn: 0.0654958\ttotal: 1.43s\tremaining: 2.5s\n",
      "363:\tlearn: 0.0653975\ttotal: 1.43s\tremaining: 2.5s\n",
      "364:\tlearn: 0.0652579\ttotal: 1.43s\tremaining: 2.49s\n",
      "365:\tlearn: 0.0651791\ttotal: 1.44s\tremaining: 2.49s\n",
      "366:\tlearn: 0.0650757\ttotal: 1.44s\tremaining: 2.48s\n",
      "367:\tlearn: 0.0649691\ttotal: 1.45s\tremaining: 2.48s\n",
      "368:\tlearn: 0.0648371\ttotal: 1.45s\tremaining: 2.48s\n",
      "369:\tlearn: 0.0647023\ttotal: 1.45s\tremaining: 2.47s\n",
      "370:\tlearn: 0.0646643\ttotal: 1.46s\tremaining: 2.47s\n",
      "371:\tlearn: 0.0645739\ttotal: 1.46s\tremaining: 2.47s\n",
      "372:\tlearn: 0.0644209\ttotal: 1.46s\tremaining: 2.46s\n",
      "373:\tlearn: 0.0643200\ttotal: 1.47s\tremaining: 2.46s\n",
      "374:\tlearn: 0.0642313\ttotal: 1.47s\tremaining: 2.46s\n",
      "375:\tlearn: 0.0641246\ttotal: 1.48s\tremaining: 2.45s\n",
      "376:\tlearn: 0.0640131\ttotal: 1.48s\tremaining: 2.45s\n",
      "377:\tlearn: 0.0639163\ttotal: 1.48s\tremaining: 2.44s\n",
      "378:\tlearn: 0.0637865\ttotal: 1.49s\tremaining: 2.44s\n",
      "379:\tlearn: 0.0636593\ttotal: 1.49s\tremaining: 2.43s\n",
      "380:\tlearn: 0.0635896\ttotal: 1.5s\tremaining: 2.43s\n",
      "381:\tlearn: 0.0635271\ttotal: 1.5s\tremaining: 2.43s\n",
      "382:\tlearn: 0.0634692\ttotal: 1.5s\tremaining: 2.42s\n",
      "383:\tlearn: 0.0633267\ttotal: 1.51s\tremaining: 2.42s\n",
      "384:\tlearn: 0.0631891\ttotal: 1.51s\tremaining: 2.42s\n",
      "385:\tlearn: 0.0631356\ttotal: 1.51s\tremaining: 2.41s\n",
      "386:\tlearn: 0.0630351\ttotal: 1.52s\tremaining: 2.41s\n",
      "387:\tlearn: 0.0629463\ttotal: 1.52s\tremaining: 2.4s\n",
      "388:\tlearn: 0.0628844\ttotal: 1.53s\tremaining: 2.4s\n",
      "389:\tlearn: 0.0627823\ttotal: 1.53s\tremaining: 2.39s\n",
      "390:\tlearn: 0.0626703\ttotal: 1.53s\tremaining: 2.39s\n",
      "391:\tlearn: 0.0626264\ttotal: 1.54s\tremaining: 2.38s\n",
      "392:\tlearn: 0.0625518\ttotal: 1.54s\tremaining: 2.38s\n",
      "393:\tlearn: 0.0624619\ttotal: 1.54s\tremaining: 2.38s\n",
      "394:\tlearn: 0.0623661\ttotal: 1.55s\tremaining: 2.37s\n",
      "395:\tlearn: 0.0622492\ttotal: 1.55s\tremaining: 2.37s\n",
      "396:\tlearn: 0.0621630\ttotal: 1.56s\tremaining: 2.36s\n",
      "397:\tlearn: 0.0621121\ttotal: 1.56s\tremaining: 2.36s\n",
      "398:\tlearn: 0.0620080\ttotal: 1.56s\tremaining: 2.35s\n",
      "399:\tlearn: 0.0618896\ttotal: 1.57s\tremaining: 2.35s\n",
      "400:\tlearn: 0.0618095\ttotal: 1.57s\tremaining: 2.35s\n",
      "401:\tlearn: 0.0617395\ttotal: 1.57s\tremaining: 2.34s\n",
      "402:\tlearn: 0.0615813\ttotal: 1.58s\tremaining: 2.34s\n",
      "403:\tlearn: 0.0615274\ttotal: 1.58s\tremaining: 2.34s\n",
      "404:\tlearn: 0.0613784\ttotal: 1.59s\tremaining: 2.33s\n",
      "405:\tlearn: 0.0611991\ttotal: 1.59s\tremaining: 2.33s\n",
      "406:\tlearn: 0.0611012\ttotal: 1.6s\tremaining: 2.33s\n",
      "407:\tlearn: 0.0609696\ttotal: 1.6s\tremaining: 2.32s\n",
      "408:\tlearn: 0.0608481\ttotal: 1.6s\tremaining: 2.32s\n",
      "409:\tlearn: 0.0607952\ttotal: 1.61s\tremaining: 2.31s\n",
      "410:\tlearn: 0.0607545\ttotal: 1.61s\tremaining: 2.31s\n",
      "411:\tlearn: 0.0606312\ttotal: 1.61s\tremaining: 2.31s\n",
      "412:\tlearn: 0.0605031\ttotal: 1.62s\tremaining: 2.3s\n",
      "413:\tlearn: 0.0604427\ttotal: 1.62s\tremaining: 2.3s\n",
      "414:\tlearn: 0.0603483\ttotal: 1.63s\tremaining: 2.29s\n",
      "415:\tlearn: 0.0603188\ttotal: 1.63s\tremaining: 2.29s\n",
      "416:\tlearn: 0.0602243\ttotal: 1.64s\tremaining: 2.29s\n",
      "417:\tlearn: 0.0601383\ttotal: 1.64s\tremaining: 2.28s\n",
      "418:\tlearn: 0.0600513\ttotal: 1.64s\tremaining: 2.28s\n",
      "419:\tlearn: 0.0599585\ttotal: 1.65s\tremaining: 2.27s\n",
      "420:\tlearn: 0.0599360\ttotal: 1.65s\tremaining: 2.27s\n",
      "421:\tlearn: 0.0598433\ttotal: 1.65s\tremaining: 2.27s\n",
      "422:\tlearn: 0.0597304\ttotal: 1.66s\tremaining: 2.26s\n",
      "423:\tlearn: 0.0596875\ttotal: 1.66s\tremaining: 2.26s\n",
      "424:\tlearn: 0.0596460\ttotal: 1.67s\tremaining: 2.25s\n",
      "425:\tlearn: 0.0596335\ttotal: 1.67s\tremaining: 2.25s\n",
      "426:\tlearn: 0.0595635\ttotal: 1.67s\tremaining: 2.24s\n",
      "427:\tlearn: 0.0594715\ttotal: 1.68s\tremaining: 2.24s\n",
      "428:\tlearn: 0.0594303\ttotal: 1.68s\tremaining: 2.23s\n",
      "429:\tlearn: 0.0593554\ttotal: 1.68s\tremaining: 2.23s\n",
      "430:\tlearn: 0.0592726\ttotal: 1.69s\tremaining: 2.23s\n",
      "431:\tlearn: 0.0592032\ttotal: 1.69s\tremaining: 2.22s\n",
      "432:\tlearn: 0.0590973\ttotal: 1.69s\tremaining: 2.22s\n",
      "433:\tlearn: 0.0590449\ttotal: 1.7s\tremaining: 2.21s\n",
      "434:\tlearn: 0.0589421\ttotal: 1.7s\tremaining: 2.21s\n",
      "435:\tlearn: 0.0588932\ttotal: 1.7s\tremaining: 2.2s\n",
      "436:\tlearn: 0.0587997\ttotal: 1.71s\tremaining: 2.2s\n",
      "437:\tlearn: 0.0587369\ttotal: 1.71s\tremaining: 2.2s\n",
      "438:\tlearn: 0.0587018\ttotal: 1.72s\tremaining: 2.19s\n",
      "439:\tlearn: 0.0585541\ttotal: 1.72s\tremaining: 2.19s\n",
      "440:\tlearn: 0.0584712\ttotal: 1.72s\tremaining: 2.18s\n",
      "441:\tlearn: 0.0583156\ttotal: 1.73s\tremaining: 2.18s\n",
      "442:\tlearn: 0.0582424\ttotal: 1.73s\tremaining: 2.17s\n",
      "443:\tlearn: 0.0581471\ttotal: 1.73s\tremaining: 2.17s\n",
      "444:\tlearn: 0.0580848\ttotal: 1.74s\tremaining: 2.17s\n",
      "445:\tlearn: 0.0579856\ttotal: 1.74s\tremaining: 2.16s\n",
      "446:\tlearn: 0.0579162\ttotal: 1.74s\tremaining: 2.16s\n",
      "447:\tlearn: 0.0578237\ttotal: 1.75s\tremaining: 2.15s\n",
      "448:\tlearn: 0.0577030\ttotal: 1.75s\tremaining: 2.15s\n",
      "449:\tlearn: 0.0576125\ttotal: 1.76s\tremaining: 2.15s\n",
      "450:\tlearn: 0.0574646\ttotal: 1.76s\tremaining: 2.14s\n",
      "451:\tlearn: 0.0573815\ttotal: 1.76s\tremaining: 2.14s\n",
      "452:\tlearn: 0.0573222\ttotal: 1.77s\tremaining: 2.13s\n",
      "453:\tlearn: 0.0571687\ttotal: 1.77s\tremaining: 2.13s\n",
      "454:\tlearn: 0.0570782\ttotal: 1.78s\tremaining: 2.13s\n",
      "455:\tlearn: 0.0570536\ttotal: 1.78s\tremaining: 2.12s\n",
      "456:\tlearn: 0.0569587\ttotal: 1.78s\tremaining: 2.12s\n",
      "457:\tlearn: 0.0569145\ttotal: 1.79s\tremaining: 2.12s\n",
      "458:\tlearn: 0.0568147\ttotal: 1.79s\tremaining: 2.11s\n",
      "459:\tlearn: 0.0567255\ttotal: 1.79s\tremaining: 2.11s\n",
      "460:\tlearn: 0.0566937\ttotal: 1.8s\tremaining: 2.1s\n",
      "461:\tlearn: 0.0566451\ttotal: 1.8s\tremaining: 2.1s\n",
      "462:\tlearn: 0.0565584\ttotal: 1.81s\tremaining: 2.1s\n",
      "463:\tlearn: 0.0564780\ttotal: 1.81s\tremaining: 2.09s\n",
      "464:\tlearn: 0.0564027\ttotal: 1.81s\tremaining: 2.09s\n",
      "465:\tlearn: 0.0563245\ttotal: 1.82s\tremaining: 2.08s\n",
      "466:\tlearn: 0.0562511\ttotal: 1.82s\tremaining: 2.08s\n",
      "467:\tlearn: 0.0561624\ttotal: 1.82s\tremaining: 2.07s\n",
      "468:\tlearn: 0.0560432\ttotal: 1.83s\tremaining: 2.07s\n",
      "469:\tlearn: 0.0559836\ttotal: 1.83s\tremaining: 2.07s\n",
      "470:\tlearn: 0.0559432\ttotal: 1.84s\tremaining: 2.06s\n",
      "471:\tlearn: 0.0558784\ttotal: 1.84s\tremaining: 2.06s\n",
      "472:\tlearn: 0.0558238\ttotal: 1.84s\tremaining: 2.05s\n",
      "473:\tlearn: 0.0558021\ttotal: 1.85s\tremaining: 2.05s\n",
      "474:\tlearn: 0.0556349\ttotal: 1.85s\tremaining: 2.04s\n",
      "475:\tlearn: 0.0555563\ttotal: 1.85s\tremaining: 2.04s\n",
      "476:\tlearn: 0.0554746\ttotal: 1.86s\tremaining: 2.04s\n",
      "477:\tlearn: 0.0554415\ttotal: 1.86s\tremaining: 2.03s\n",
      "478:\tlearn: 0.0553151\ttotal: 1.86s\tremaining: 2.03s\n",
      "479:\tlearn: 0.0552875\ttotal: 1.87s\tremaining: 2.02s\n",
      "480:\tlearn: 0.0552028\ttotal: 1.87s\tremaining: 2.02s\n",
      "481:\tlearn: 0.0551397\ttotal: 1.88s\tremaining: 2.02s\n",
      "482:\tlearn: 0.0550195\ttotal: 1.88s\tremaining: 2.01s\n",
      "483:\tlearn: 0.0549599\ttotal: 1.88s\tremaining: 2.01s\n",
      "484:\tlearn: 0.0549122\ttotal: 1.89s\tremaining: 2s\n",
      "485:\tlearn: 0.0547879\ttotal: 1.89s\tremaining: 2s\n",
      "486:\tlearn: 0.0547380\ttotal: 1.89s\tremaining: 1.99s\n",
      "487:\tlearn: 0.0546311\ttotal: 1.9s\tremaining: 1.99s\n",
      "488:\tlearn: 0.0545463\ttotal: 1.9s\tremaining: 1.99s\n",
      "489:\tlearn: 0.0544470\ttotal: 1.9s\tremaining: 1.98s\n",
      "490:\tlearn: 0.0543869\ttotal: 1.91s\tremaining: 1.98s\n",
      "491:\tlearn: 0.0542932\ttotal: 1.91s\tremaining: 1.97s\n",
      "492:\tlearn: 0.0542270\ttotal: 1.91s\tremaining: 1.97s\n",
      "493:\tlearn: 0.0541343\ttotal: 1.92s\tremaining: 1.96s\n",
      "494:\tlearn: 0.0540819\ttotal: 1.92s\tremaining: 1.96s\n",
      "495:\tlearn: 0.0539706\ttotal: 1.93s\tremaining: 1.96s\n",
      "496:\tlearn: 0.0539009\ttotal: 1.93s\tremaining: 1.95s\n",
      "497:\tlearn: 0.0538361\ttotal: 1.93s\tremaining: 1.95s\n",
      "498:\tlearn: 0.0538124\ttotal: 1.94s\tremaining: 1.95s\n",
      "499:\tlearn: 0.0537633\ttotal: 1.94s\tremaining: 1.94s\n",
      "500:\tlearn: 0.0536619\ttotal: 1.95s\tremaining: 1.94s\n",
      "501:\tlearn: 0.0536376\ttotal: 1.95s\tremaining: 1.93s\n",
      "502:\tlearn: 0.0534893\ttotal: 1.95s\tremaining: 1.93s\n",
      "503:\tlearn: 0.0534302\ttotal: 1.96s\tremaining: 1.93s\n",
      "504:\tlearn: 0.0533030\ttotal: 1.96s\tremaining: 1.92s\n",
      "505:\tlearn: 0.0532084\ttotal: 1.96s\tremaining: 1.92s\n",
      "506:\tlearn: 0.0531435\ttotal: 1.97s\tremaining: 1.91s\n",
      "507:\tlearn: 0.0530603\ttotal: 1.97s\tremaining: 1.91s\n",
      "508:\tlearn: 0.0529593\ttotal: 1.97s\tremaining: 1.9s\n",
      "509:\tlearn: 0.0529390\ttotal: 1.98s\tremaining: 1.9s\n",
      "510:\tlearn: 0.0528591\ttotal: 1.98s\tremaining: 1.9s\n",
      "511:\tlearn: 0.0527887\ttotal: 1.99s\tremaining: 1.89s\n",
      "512:\tlearn: 0.0527589\ttotal: 1.99s\tremaining: 1.89s\n",
      "513:\tlearn: 0.0526897\ttotal: 1.99s\tremaining: 1.88s\n",
      "514:\tlearn: 0.0526258\ttotal: 2s\tremaining: 1.88s\n",
      "515:\tlearn: 0.0525870\ttotal: 2s\tremaining: 1.88s\n",
      "516:\tlearn: 0.0525507\ttotal: 2s\tremaining: 1.87s\n",
      "517:\tlearn: 0.0525020\ttotal: 2.01s\tremaining: 1.87s\n",
      "518:\tlearn: 0.0524527\ttotal: 2.01s\tremaining: 1.86s\n",
      "519:\tlearn: 0.0523916\ttotal: 2.01s\tremaining: 1.86s\n",
      "520:\tlearn: 0.0523513\ttotal: 2.02s\tremaining: 1.85s\n",
      "521:\tlearn: 0.0523174\ttotal: 2.02s\tremaining: 1.85s\n",
      "522:\tlearn: 0.0523075\ttotal: 2.02s\tremaining: 1.85s\n",
      "523:\tlearn: 0.0521901\ttotal: 2.03s\tremaining: 1.84s\n",
      "524:\tlearn: 0.0521149\ttotal: 2.03s\tremaining: 1.84s\n",
      "525:\tlearn: 0.0520223\ttotal: 2.03s\tremaining: 1.83s\n",
      "526:\tlearn: 0.0519414\ttotal: 2.04s\tremaining: 1.83s\n",
      "527:\tlearn: 0.0518873\ttotal: 2.04s\tremaining: 1.82s\n",
      "528:\tlearn: 0.0518480\ttotal: 2.04s\tremaining: 1.82s\n",
      "529:\tlearn: 0.0518068\ttotal: 2.05s\tremaining: 1.82s\n",
      "530:\tlearn: 0.0517683\ttotal: 2.05s\tremaining: 1.81s\n",
      "531:\tlearn: 0.0517188\ttotal: 2.06s\tremaining: 1.81s\n",
      "532:\tlearn: 0.0516830\ttotal: 2.06s\tremaining: 1.8s\n",
      "533:\tlearn: 0.0516519\ttotal: 2.06s\tremaining: 1.8s\n",
      "534:\tlearn: 0.0516147\ttotal: 2.07s\tremaining: 1.8s\n",
      "535:\tlearn: 0.0515582\ttotal: 2.07s\tremaining: 1.79s\n",
      "536:\tlearn: 0.0515078\ttotal: 2.07s\tremaining: 1.79s\n",
      "537:\tlearn: 0.0514374\ttotal: 2.08s\tremaining: 1.78s\n",
      "538:\tlearn: 0.0513124\ttotal: 2.08s\tremaining: 1.78s\n",
      "539:\tlearn: 0.0512692\ttotal: 2.08s\tremaining: 1.78s\n",
      "540:\tlearn: 0.0512286\ttotal: 2.09s\tremaining: 1.77s\n",
      "541:\tlearn: 0.0511693\ttotal: 2.09s\tremaining: 1.77s\n",
      "542:\tlearn: 0.0511358\ttotal: 2.1s\tremaining: 1.76s\n",
      "543:\tlearn: 0.0510927\ttotal: 2.1s\tremaining: 1.76s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "544:\tlearn: 0.0510238\ttotal: 2.1s\tremaining: 1.76s\n",
      "545:\tlearn: 0.0509766\ttotal: 2.11s\tremaining: 1.75s\n",
      "546:\tlearn: 0.0509394\ttotal: 2.11s\tremaining: 1.75s\n",
      "547:\tlearn: 0.0509085\ttotal: 2.12s\tremaining: 1.75s\n",
      "548:\tlearn: 0.0508582\ttotal: 2.12s\tremaining: 1.74s\n",
      "549:\tlearn: 0.0507802\ttotal: 2.13s\tremaining: 1.74s\n",
      "550:\tlearn: 0.0507371\ttotal: 2.13s\tremaining: 1.73s\n",
      "551:\tlearn: 0.0506983\ttotal: 2.13s\tremaining: 1.73s\n",
      "552:\tlearn: 0.0505754\ttotal: 2.14s\tremaining: 1.73s\n",
      "553:\tlearn: 0.0504904\ttotal: 2.14s\tremaining: 1.72s\n",
      "554:\tlearn: 0.0504586\ttotal: 2.14s\tremaining: 1.72s\n",
      "555:\tlearn: 0.0503965\ttotal: 2.15s\tremaining: 1.72s\n",
      "556:\tlearn: 0.0503710\ttotal: 2.15s\tremaining: 1.71s\n",
      "557:\tlearn: 0.0503248\ttotal: 2.16s\tremaining: 1.71s\n",
      "558:\tlearn: 0.0502763\ttotal: 2.16s\tremaining: 1.71s\n",
      "559:\tlearn: 0.0502228\ttotal: 2.17s\tremaining: 1.7s\n",
      "560:\tlearn: 0.0501597\ttotal: 2.17s\tremaining: 1.7s\n",
      "561:\tlearn: 0.0501122\ttotal: 2.17s\tremaining: 1.69s\n",
      "562:\tlearn: 0.0500479\ttotal: 2.18s\tremaining: 1.69s\n",
      "563:\tlearn: 0.0499382\ttotal: 2.18s\tremaining: 1.69s\n",
      "564:\tlearn: 0.0499089\ttotal: 2.18s\tremaining: 1.68s\n",
      "565:\tlearn: 0.0498352\ttotal: 2.19s\tremaining: 1.68s\n",
      "566:\tlearn: 0.0498017\ttotal: 2.19s\tremaining: 1.67s\n",
      "567:\tlearn: 0.0497736\ttotal: 2.19s\tremaining: 1.67s\n",
      "568:\tlearn: 0.0497442\ttotal: 2.2s\tremaining: 1.67s\n",
      "569:\tlearn: 0.0496825\ttotal: 2.2s\tremaining: 1.66s\n",
      "570:\tlearn: 0.0496033\ttotal: 2.21s\tremaining: 1.66s\n",
      "571:\tlearn: 0.0495857\ttotal: 2.21s\tremaining: 1.65s\n",
      "572:\tlearn: 0.0495415\ttotal: 2.21s\tremaining: 1.65s\n",
      "573:\tlearn: 0.0494440\ttotal: 2.22s\tremaining: 1.65s\n",
      "574:\tlearn: 0.0494134\ttotal: 2.22s\tremaining: 1.64s\n",
      "575:\tlearn: 0.0493544\ttotal: 2.22s\tremaining: 1.64s\n",
      "576:\tlearn: 0.0493265\ttotal: 2.23s\tremaining: 1.63s\n",
      "577:\tlearn: 0.0492510\ttotal: 2.23s\tremaining: 1.63s\n",
      "578:\tlearn: 0.0491923\ttotal: 2.23s\tremaining: 1.63s\n",
      "579:\tlearn: 0.0491429\ttotal: 2.24s\tremaining: 1.62s\n",
      "580:\tlearn: 0.0491001\ttotal: 2.24s\tremaining: 1.62s\n",
      "581:\tlearn: 0.0490714\ttotal: 2.25s\tremaining: 1.61s\n",
      "582:\tlearn: 0.0489748\ttotal: 2.25s\tremaining: 1.61s\n",
      "583:\tlearn: 0.0488817\ttotal: 2.26s\tremaining: 1.61s\n",
      "584:\tlearn: 0.0488287\ttotal: 2.26s\tremaining: 1.6s\n",
      "585:\tlearn: 0.0487713\ttotal: 2.26s\tremaining: 1.6s\n",
      "586:\tlearn: 0.0487273\ttotal: 2.27s\tremaining: 1.59s\n",
      "587:\tlearn: 0.0487035\ttotal: 2.27s\tremaining: 1.59s\n",
      "588:\tlearn: 0.0486210\ttotal: 2.27s\tremaining: 1.59s\n",
      "589:\tlearn: 0.0485809\ttotal: 2.28s\tremaining: 1.58s\n",
      "590:\tlearn: 0.0485031\ttotal: 2.28s\tremaining: 1.58s\n",
      "591:\tlearn: 0.0484898\ttotal: 2.29s\tremaining: 1.58s\n",
      "592:\tlearn: 0.0484643\ttotal: 2.29s\tremaining: 1.57s\n",
      "593:\tlearn: 0.0484311\ttotal: 2.29s\tremaining: 1.57s\n",
      "594:\tlearn: 0.0483886\ttotal: 2.3s\tremaining: 1.56s\n",
      "595:\tlearn: 0.0483528\ttotal: 2.3s\tremaining: 1.56s\n",
      "596:\tlearn: 0.0483032\ttotal: 2.31s\tremaining: 1.56s\n",
      "597:\tlearn: 0.0482387\ttotal: 2.31s\tremaining: 1.55s\n",
      "598:\tlearn: 0.0481742\ttotal: 2.31s\tremaining: 1.55s\n",
      "599:\tlearn: 0.0481167\ttotal: 2.32s\tremaining: 1.54s\n",
      "600:\tlearn: 0.0480516\ttotal: 2.32s\tremaining: 1.54s\n",
      "601:\tlearn: 0.0479398\ttotal: 2.33s\tremaining: 1.54s\n",
      "602:\tlearn: 0.0478808\ttotal: 2.33s\tremaining: 1.53s\n",
      "603:\tlearn: 0.0478168\ttotal: 2.33s\tremaining: 1.53s\n",
      "604:\tlearn: 0.0477651\ttotal: 2.34s\tremaining: 1.52s\n",
      "605:\tlearn: 0.0477347\ttotal: 2.34s\tremaining: 1.52s\n",
      "606:\tlearn: 0.0477026\ttotal: 2.34s\tremaining: 1.52s\n",
      "607:\tlearn: 0.0476558\ttotal: 2.35s\tremaining: 1.51s\n",
      "608:\tlearn: 0.0476044\ttotal: 2.35s\tremaining: 1.51s\n",
      "609:\tlearn: 0.0475607\ttotal: 2.35s\tremaining: 1.5s\n",
      "610:\tlearn: 0.0475123\ttotal: 2.36s\tremaining: 1.5s\n",
      "611:\tlearn: 0.0474328\ttotal: 2.36s\tremaining: 1.5s\n",
      "612:\tlearn: 0.0473390\ttotal: 2.37s\tremaining: 1.49s\n",
      "613:\tlearn: 0.0473098\ttotal: 2.37s\tremaining: 1.49s\n",
      "614:\tlearn: 0.0472695\ttotal: 2.37s\tremaining: 1.49s\n",
      "615:\tlearn: 0.0472520\ttotal: 2.38s\tremaining: 1.48s\n",
      "616:\tlearn: 0.0472129\ttotal: 2.38s\tremaining: 1.48s\n",
      "617:\tlearn: 0.0471902\ttotal: 2.38s\tremaining: 1.47s\n",
      "618:\tlearn: 0.0471503\ttotal: 2.39s\tremaining: 1.47s\n",
      "619:\tlearn: 0.0471103\ttotal: 2.39s\tremaining: 1.46s\n",
      "620:\tlearn: 0.0470509\ttotal: 2.39s\tremaining: 1.46s\n",
      "621:\tlearn: 0.0469997\ttotal: 2.4s\tremaining: 1.46s\n",
      "622:\tlearn: 0.0469234\ttotal: 2.4s\tremaining: 1.45s\n",
      "623:\tlearn: 0.0469090\ttotal: 2.4s\tremaining: 1.45s\n",
      "624:\tlearn: 0.0467702\ttotal: 2.41s\tremaining: 1.44s\n",
      "625:\tlearn: 0.0467429\ttotal: 2.41s\tremaining: 1.44s\n",
      "626:\tlearn: 0.0467010\ttotal: 2.42s\tremaining: 1.44s\n",
      "627:\tlearn: 0.0466491\ttotal: 2.42s\tremaining: 1.43s\n",
      "628:\tlearn: 0.0466006\ttotal: 2.42s\tremaining: 1.43s\n",
      "629:\tlearn: 0.0465682\ttotal: 2.42s\tremaining: 1.42s\n",
      "630:\tlearn: 0.0465495\ttotal: 2.43s\tremaining: 1.42s\n",
      "631:\tlearn: 0.0465089\ttotal: 2.43s\tremaining: 1.42s\n",
      "632:\tlearn: 0.0464597\ttotal: 2.44s\tremaining: 1.41s\n",
      "633:\tlearn: 0.0464213\ttotal: 2.44s\tremaining: 1.41s\n",
      "634:\tlearn: 0.0463976\ttotal: 2.44s\tremaining: 1.4s\n",
      "635:\tlearn: 0.0463199\ttotal: 2.45s\tremaining: 1.4s\n",
      "636:\tlearn: 0.0462954\ttotal: 2.45s\tremaining: 1.4s\n",
      "637:\tlearn: 0.0462592\ttotal: 2.45s\tremaining: 1.39s\n",
      "638:\tlearn: 0.0462277\ttotal: 2.46s\tremaining: 1.39s\n",
      "639:\tlearn: 0.0461797\ttotal: 2.46s\tremaining: 1.38s\n",
      "640:\tlearn: 0.0461556\ttotal: 2.46s\tremaining: 1.38s\n",
      "641:\tlearn: 0.0460970\ttotal: 2.47s\tremaining: 1.38s\n",
      "642:\tlearn: 0.0460630\ttotal: 2.47s\tremaining: 1.37s\n",
      "643:\tlearn: 0.0460415\ttotal: 2.48s\tremaining: 1.37s\n",
      "644:\tlearn: 0.0460113\ttotal: 2.48s\tremaining: 1.36s\n",
      "645:\tlearn: 0.0459679\ttotal: 2.48s\tremaining: 1.36s\n",
      "646:\tlearn: 0.0459199\ttotal: 2.49s\tremaining: 1.36s\n",
      "647:\tlearn: 0.0458604\ttotal: 2.49s\tremaining: 1.35s\n",
      "648:\tlearn: 0.0458232\ttotal: 2.49s\tremaining: 1.35s\n",
      "649:\tlearn: 0.0457980\ttotal: 2.5s\tremaining: 1.34s\n",
      "650:\tlearn: 0.0457543\ttotal: 2.5s\tremaining: 1.34s\n",
      "651:\tlearn: 0.0457272\ttotal: 2.51s\tremaining: 1.34s\n",
      "652:\tlearn: 0.0456358\ttotal: 2.51s\tremaining: 1.33s\n",
      "653:\tlearn: 0.0455903\ttotal: 2.51s\tremaining: 1.33s\n",
      "654:\tlearn: 0.0455398\ttotal: 2.52s\tremaining: 1.32s\n",
      "655:\tlearn: 0.0454840\ttotal: 2.52s\tremaining: 1.32s\n",
      "656:\tlearn: 0.0453873\ttotal: 2.52s\tremaining: 1.32s\n",
      "657:\tlearn: 0.0453051\ttotal: 2.53s\tremaining: 1.31s\n",
      "658:\tlearn: 0.0452847\ttotal: 2.53s\tremaining: 1.31s\n",
      "659:\tlearn: 0.0452562\ttotal: 2.54s\tremaining: 1.31s\n",
      "660:\tlearn: 0.0451633\ttotal: 2.54s\tremaining: 1.3s\n",
      "661:\tlearn: 0.0450951\ttotal: 2.54s\tremaining: 1.3s\n",
      "662:\tlearn: 0.0450759\ttotal: 2.54s\tremaining: 1.29s\n",
      "663:\tlearn: 0.0450387\ttotal: 2.55s\tremaining: 1.29s\n",
      "664:\tlearn: 0.0449848\ttotal: 2.55s\tremaining: 1.28s\n",
      "665:\tlearn: 0.0449362\ttotal: 2.56s\tremaining: 1.28s\n",
      "666:\tlearn: 0.0449124\ttotal: 2.56s\tremaining: 1.28s\n",
      "667:\tlearn: 0.0448652\ttotal: 2.56s\tremaining: 1.27s\n",
      "668:\tlearn: 0.0448260\ttotal: 2.57s\tremaining: 1.27s\n",
      "669:\tlearn: 0.0447728\ttotal: 2.57s\tremaining: 1.27s\n",
      "670:\tlearn: 0.0447239\ttotal: 2.57s\tremaining: 1.26s\n",
      "671:\tlearn: 0.0446890\ttotal: 2.58s\tremaining: 1.26s\n",
      "672:\tlearn: 0.0446466\ttotal: 2.58s\tremaining: 1.25s\n",
      "673:\tlearn: 0.0446111\ttotal: 2.59s\tremaining: 1.25s\n",
      "674:\tlearn: 0.0445768\ttotal: 2.59s\tremaining: 1.25s\n",
      "675:\tlearn: 0.0445498\ttotal: 2.59s\tremaining: 1.24s\n",
      "676:\tlearn: 0.0445091\ttotal: 2.6s\tremaining: 1.24s\n",
      "677:\tlearn: 0.0444260\ttotal: 2.6s\tremaining: 1.24s\n",
      "678:\tlearn: 0.0443447\ttotal: 2.6s\tremaining: 1.23s\n",
      "679:\tlearn: 0.0442902\ttotal: 2.61s\tremaining: 1.23s\n",
      "680:\tlearn: 0.0442420\ttotal: 2.61s\tremaining: 1.22s\n",
      "681:\tlearn: 0.0441814\ttotal: 2.61s\tremaining: 1.22s\n",
      "682:\tlearn: 0.0440938\ttotal: 2.62s\tremaining: 1.22s\n",
      "683:\tlearn: 0.0440548\ttotal: 2.62s\tremaining: 1.21s\n",
      "684:\tlearn: 0.0440285\ttotal: 2.63s\tremaining: 1.21s\n",
      "685:\tlearn: 0.0439952\ttotal: 2.63s\tremaining: 1.2s\n",
      "686:\tlearn: 0.0439451\ttotal: 2.63s\tremaining: 1.2s\n",
      "687:\tlearn: 0.0439335\ttotal: 2.64s\tremaining: 1.2s\n",
      "688:\tlearn: 0.0438996\ttotal: 2.64s\tremaining: 1.19s\n",
      "689:\tlearn: 0.0438582\ttotal: 2.64s\tremaining: 1.19s\n",
      "690:\tlearn: 0.0438382\ttotal: 2.65s\tremaining: 1.18s\n",
      "691:\tlearn: 0.0438195\ttotal: 2.65s\tremaining: 1.18s\n",
      "692:\tlearn: 0.0437707\ttotal: 2.66s\tremaining: 1.18s\n",
      "693:\tlearn: 0.0437561\ttotal: 2.66s\tremaining: 1.17s\n",
      "694:\tlearn: 0.0437156\ttotal: 2.66s\tremaining: 1.17s\n",
      "695:\tlearn: 0.0436823\ttotal: 2.67s\tremaining: 1.16s\n",
      "696:\tlearn: 0.0436483\ttotal: 2.67s\tremaining: 1.16s\n",
      "697:\tlearn: 0.0436162\ttotal: 2.67s\tremaining: 1.16s\n",
      "698:\tlearn: 0.0435859\ttotal: 2.68s\tremaining: 1.15s\n",
      "699:\tlearn: 0.0435495\ttotal: 2.68s\tremaining: 1.15s\n",
      "700:\tlearn: 0.0435005\ttotal: 2.68s\tremaining: 1.15s\n",
      "701:\tlearn: 0.0434701\ttotal: 2.69s\tremaining: 1.14s\n",
      "702:\tlearn: 0.0434345\ttotal: 2.69s\tremaining: 1.14s\n",
      "703:\tlearn: 0.0433609\ttotal: 2.69s\tremaining: 1.13s\n",
      "704:\tlearn: 0.0432821\ttotal: 2.7s\tremaining: 1.13s\n",
      "705:\tlearn: 0.0432438\ttotal: 2.7s\tremaining: 1.13s\n",
      "706:\tlearn: 0.0432179\ttotal: 2.71s\tremaining: 1.12s\n",
      "707:\tlearn: 0.0431811\ttotal: 2.71s\tremaining: 1.12s\n",
      "708:\tlearn: 0.0431606\ttotal: 2.71s\tremaining: 1.11s\n",
      "709:\tlearn: 0.0431173\ttotal: 2.72s\tremaining: 1.11s\n",
      "710:\tlearn: 0.0430835\ttotal: 2.72s\tremaining: 1.1s\n",
      "711:\tlearn: 0.0430307\ttotal: 2.72s\tremaining: 1.1s\n",
      "712:\tlearn: 0.0430030\ttotal: 2.73s\tremaining: 1.1s\n",
      "713:\tlearn: 0.0429698\ttotal: 2.73s\tremaining: 1.09s\n",
      "714:\tlearn: 0.0429034\ttotal: 2.73s\tremaining: 1.09s\n",
      "715:\tlearn: 0.0428552\ttotal: 2.74s\tremaining: 1.08s\n",
      "716:\tlearn: 0.0427803\ttotal: 2.74s\tremaining: 1.08s\n",
      "717:\tlearn: 0.0427101\ttotal: 2.74s\tremaining: 1.08s\n",
      "718:\tlearn: 0.0426934\ttotal: 2.75s\tremaining: 1.07s\n",
      "719:\tlearn: 0.0426541\ttotal: 2.75s\tremaining: 1.07s\n",
      "720:\tlearn: 0.0426307\ttotal: 2.75s\tremaining: 1.07s\n",
      "721:\tlearn: 0.0425994\ttotal: 2.76s\tremaining: 1.06s\n",
      "722:\tlearn: 0.0425256\ttotal: 2.76s\tremaining: 1.06s\n",
      "723:\tlearn: 0.0424555\ttotal: 2.77s\tremaining: 1.05s\n",
      "724:\tlearn: 0.0424254\ttotal: 2.77s\tremaining: 1.05s\n",
      "725:\tlearn: 0.0423855\ttotal: 2.77s\tremaining: 1.05s\n",
      "726:\tlearn: 0.0423531\ttotal: 2.78s\tremaining: 1.04s\n",
      "727:\tlearn: 0.0423341\ttotal: 2.78s\tremaining: 1.04s\n",
      "728:\tlearn: 0.0422381\ttotal: 2.78s\tremaining: 1.03s\n",
      "729:\tlearn: 0.0422180\ttotal: 2.79s\tremaining: 1.03s\n",
      "730:\tlearn: 0.0421702\ttotal: 2.79s\tremaining: 1.03s\n",
      "731:\tlearn: 0.0421399\ttotal: 2.79s\tremaining: 1.02s\n",
      "732:\tlearn: 0.0421065\ttotal: 2.8s\tremaining: 1.02s\n",
      "733:\tlearn: 0.0420775\ttotal: 2.8s\tremaining: 1.01s\n",
      "734:\tlearn: 0.0420355\ttotal: 2.81s\tremaining: 1.01s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "735:\tlearn: 0.0420051\ttotal: 2.81s\tremaining: 1.01s\n",
      "736:\tlearn: 0.0419877\ttotal: 2.81s\tremaining: 1s\n",
      "737:\tlearn: 0.0418868\ttotal: 2.82s\tremaining: 1s\n",
      "738:\tlearn: 0.0418353\ttotal: 2.82s\tremaining: 997ms\n",
      "739:\tlearn: 0.0417701\ttotal: 2.83s\tremaining: 993ms\n",
      "740:\tlearn: 0.0417349\ttotal: 2.83s\tremaining: 990ms\n",
      "741:\tlearn: 0.0417072\ttotal: 2.84s\tremaining: 986ms\n",
      "742:\tlearn: 0.0416767\ttotal: 2.84s\tremaining: 982ms\n",
      "743:\tlearn: 0.0416414\ttotal: 2.84s\tremaining: 979ms\n",
      "744:\tlearn: 0.0416123\ttotal: 2.85s\tremaining: 975ms\n",
      "745:\tlearn: 0.0415491\ttotal: 2.85s\tremaining: 971ms\n",
      "746:\tlearn: 0.0415220\ttotal: 2.85s\tremaining: 967ms\n",
      "747:\tlearn: 0.0414977\ttotal: 2.86s\tremaining: 963ms\n",
      "748:\tlearn: 0.0414709\ttotal: 2.86s\tremaining: 959ms\n",
      "749:\tlearn: 0.0414067\ttotal: 2.87s\tremaining: 956ms\n",
      "750:\tlearn: 0.0413745\ttotal: 2.87s\tremaining: 952ms\n",
      "751:\tlearn: 0.0412973\ttotal: 2.87s\tremaining: 948ms\n",
      "752:\tlearn: 0.0412153\ttotal: 2.88s\tremaining: 944ms\n",
      "753:\tlearn: 0.0411910\ttotal: 2.88s\tremaining: 940ms\n",
      "754:\tlearn: 0.0411630\ttotal: 2.88s\tremaining: 936ms\n",
      "755:\tlearn: 0.0410582\ttotal: 2.89s\tremaining: 932ms\n",
      "756:\tlearn: 0.0409952\ttotal: 2.89s\tremaining: 928ms\n",
      "757:\tlearn: 0.0409367\ttotal: 2.9s\tremaining: 924ms\n",
      "758:\tlearn: 0.0408882\ttotal: 2.9s\tremaining: 920ms\n",
      "759:\tlearn: 0.0408233\ttotal: 2.9s\tremaining: 917ms\n",
      "760:\tlearn: 0.0407982\ttotal: 2.91s\tremaining: 913ms\n",
      "761:\tlearn: 0.0407628\ttotal: 2.91s\tremaining: 909ms\n",
      "762:\tlearn: 0.0407264\ttotal: 2.91s\tremaining: 905ms\n",
      "763:\tlearn: 0.0406694\ttotal: 2.92s\tremaining: 901ms\n",
      "764:\tlearn: 0.0406421\ttotal: 2.92s\tremaining: 897ms\n",
      "765:\tlearn: 0.0406076\ttotal: 2.92s\tremaining: 893ms\n",
      "766:\tlearn: 0.0405805\ttotal: 2.93s\tremaining: 889ms\n",
      "767:\tlearn: 0.0405525\ttotal: 2.93s\tremaining: 885ms\n",
      "768:\tlearn: 0.0405206\ttotal: 2.93s\tremaining: 882ms\n",
      "769:\tlearn: 0.0404894\ttotal: 2.94s\tremaining: 878ms\n",
      "770:\tlearn: 0.0404330\ttotal: 2.94s\tremaining: 874ms\n",
      "771:\tlearn: 0.0403703\ttotal: 2.94s\tremaining: 870ms\n",
      "772:\tlearn: 0.0403397\ttotal: 2.95s\tremaining: 866ms\n",
      "773:\tlearn: 0.0402907\ttotal: 2.95s\tremaining: 862ms\n",
      "774:\tlearn: 0.0402362\ttotal: 2.96s\tremaining: 858ms\n",
      "775:\tlearn: 0.0401672\ttotal: 2.96s\tremaining: 855ms\n",
      "776:\tlearn: 0.0401323\ttotal: 2.96s\tremaining: 851ms\n",
      "777:\tlearn: 0.0400772\ttotal: 2.97s\tremaining: 847ms\n",
      "778:\tlearn: 0.0400458\ttotal: 2.97s\tremaining: 843ms\n",
      "779:\tlearn: 0.0400208\ttotal: 2.97s\tremaining: 839ms\n",
      "780:\tlearn: 0.0399107\ttotal: 2.98s\tremaining: 835ms\n",
      "781:\tlearn: 0.0398870\ttotal: 2.98s\tremaining: 831ms\n",
      "782:\tlearn: 0.0398653\ttotal: 2.98s\tremaining: 827ms\n",
      "783:\tlearn: 0.0398389\ttotal: 2.99s\tremaining: 824ms\n",
      "784:\tlearn: 0.0398126\ttotal: 2.99s\tremaining: 820ms\n",
      "785:\tlearn: 0.0397873\ttotal: 3s\tremaining: 816ms\n",
      "786:\tlearn: 0.0397555\ttotal: 3s\tremaining: 812ms\n",
      "787:\tlearn: 0.0396876\ttotal: 3s\tremaining: 809ms\n",
      "788:\tlearn: 0.0396413\ttotal: 3.01s\tremaining: 805ms\n",
      "789:\tlearn: 0.0396180\ttotal: 3.01s\tremaining: 801ms\n",
      "790:\tlearn: 0.0395786\ttotal: 3.02s\tremaining: 797ms\n",
      "791:\tlearn: 0.0395302\ttotal: 3.02s\tremaining: 793ms\n",
      "792:\tlearn: 0.0395063\ttotal: 3.02s\tremaining: 789ms\n",
      "793:\tlearn: 0.0394644\ttotal: 3.03s\tremaining: 785ms\n",
      "794:\tlearn: 0.0394195\ttotal: 3.03s\tremaining: 781ms\n",
      "795:\tlearn: 0.0393747\ttotal: 3.03s\tremaining: 778ms\n",
      "796:\tlearn: 0.0393532\ttotal: 3.04s\tremaining: 774ms\n",
      "797:\tlearn: 0.0393022\ttotal: 3.04s\tremaining: 770ms\n",
      "798:\tlearn: 0.0392775\ttotal: 3.04s\tremaining: 766ms\n",
      "799:\tlearn: 0.0392460\ttotal: 3.05s\tremaining: 762ms\n",
      "800:\tlearn: 0.0392158\ttotal: 3.05s\tremaining: 758ms\n",
      "801:\tlearn: 0.0391841\ttotal: 3.06s\tremaining: 754ms\n",
      "802:\tlearn: 0.0391609\ttotal: 3.06s\tremaining: 750ms\n",
      "803:\tlearn: 0.0391370\ttotal: 3.06s\tremaining: 747ms\n",
      "804:\tlearn: 0.0391091\ttotal: 3.06s\tremaining: 743ms\n",
      "805:\tlearn: 0.0390646\ttotal: 3.07s\tremaining: 739ms\n",
      "806:\tlearn: 0.0390363\ttotal: 3.07s\tremaining: 735ms\n",
      "807:\tlearn: 0.0390081\ttotal: 3.08s\tremaining: 731ms\n",
      "808:\tlearn: 0.0389833\ttotal: 3.08s\tremaining: 727ms\n",
      "809:\tlearn: 0.0389330\ttotal: 3.08s\tremaining: 723ms\n",
      "810:\tlearn: 0.0389108\ttotal: 3.09s\tremaining: 719ms\n",
      "811:\tlearn: 0.0388835\ttotal: 3.09s\tremaining: 716ms\n",
      "812:\tlearn: 0.0388105\ttotal: 3.09s\tremaining: 712ms\n",
      "813:\tlearn: 0.0387870\ttotal: 3.1s\tremaining: 708ms\n",
      "814:\tlearn: 0.0387437\ttotal: 3.1s\tremaining: 704ms\n",
      "815:\tlearn: 0.0386945\ttotal: 3.11s\tremaining: 701ms\n",
      "816:\tlearn: 0.0386139\ttotal: 3.11s\tremaining: 697ms\n",
      "817:\tlearn: 0.0385840\ttotal: 3.11s\tremaining: 693ms\n",
      "818:\tlearn: 0.0385512\ttotal: 3.12s\tremaining: 689ms\n",
      "819:\tlearn: 0.0385296\ttotal: 3.12s\tremaining: 685ms\n",
      "820:\tlearn: 0.0385002\ttotal: 3.13s\tremaining: 682ms\n",
      "821:\tlearn: 0.0384626\ttotal: 3.13s\tremaining: 678ms\n",
      "822:\tlearn: 0.0384346\ttotal: 3.13s\tremaining: 674ms\n",
      "823:\tlearn: 0.0384004\ttotal: 3.14s\tremaining: 670ms\n",
      "824:\tlearn: 0.0383729\ttotal: 3.14s\tremaining: 667ms\n",
      "825:\tlearn: 0.0383516\ttotal: 3.15s\tremaining: 663ms\n",
      "826:\tlearn: 0.0383139\ttotal: 3.15s\tremaining: 659ms\n",
      "827:\tlearn: 0.0382723\ttotal: 3.15s\tremaining: 655ms\n",
      "828:\tlearn: 0.0382237\ttotal: 3.16s\tremaining: 652ms\n",
      "829:\tlearn: 0.0381957\ttotal: 3.16s\tremaining: 648ms\n",
      "830:\tlearn: 0.0381463\ttotal: 3.17s\tremaining: 644ms\n",
      "831:\tlearn: 0.0381057\ttotal: 3.17s\tremaining: 641ms\n",
      "832:\tlearn: 0.0380671\ttotal: 3.18s\tremaining: 637ms\n",
      "833:\tlearn: 0.0380209\ttotal: 3.18s\tremaining: 633ms\n",
      "834:\tlearn: 0.0379946\ttotal: 3.18s\tremaining: 629ms\n",
      "835:\tlearn: 0.0379794\ttotal: 3.19s\tremaining: 626ms\n",
      "836:\tlearn: 0.0379581\ttotal: 3.19s\tremaining: 622ms\n",
      "837:\tlearn: 0.0378936\ttotal: 3.2s\tremaining: 618ms\n",
      "838:\tlearn: 0.0378754\ttotal: 3.2s\tremaining: 614ms\n",
      "839:\tlearn: 0.0378544\ttotal: 3.2s\tremaining: 610ms\n",
      "840:\tlearn: 0.0378245\ttotal: 3.21s\tremaining: 606ms\n",
      "841:\tlearn: 0.0378092\ttotal: 3.21s\tremaining: 603ms\n",
      "842:\tlearn: 0.0377865\ttotal: 3.21s\tremaining: 599ms\n",
      "843:\tlearn: 0.0377501\ttotal: 3.22s\tremaining: 595ms\n",
      "844:\tlearn: 0.0377088\ttotal: 3.22s\tremaining: 591ms\n",
      "845:\tlearn: 0.0376881\ttotal: 3.23s\tremaining: 587ms\n",
      "846:\tlearn: 0.0376718\ttotal: 3.23s\tremaining: 583ms\n",
      "847:\tlearn: 0.0376454\ttotal: 3.23s\tremaining: 579ms\n",
      "848:\tlearn: 0.0376303\ttotal: 3.23s\tremaining: 575ms\n",
      "849:\tlearn: 0.0375857\ttotal: 3.24s\tremaining: 572ms\n",
      "850:\tlearn: 0.0375646\ttotal: 3.24s\tremaining: 568ms\n",
      "851:\tlearn: 0.0375443\ttotal: 3.25s\tremaining: 564ms\n",
      "852:\tlearn: 0.0374966\ttotal: 3.25s\tremaining: 560ms\n",
      "853:\tlearn: 0.0374537\ttotal: 3.25s\tremaining: 556ms\n",
      "854:\tlearn: 0.0374318\ttotal: 3.26s\tremaining: 552ms\n",
      "855:\tlearn: 0.0374059\ttotal: 3.26s\tremaining: 549ms\n",
      "856:\tlearn: 0.0373591\ttotal: 3.26s\tremaining: 545ms\n",
      "857:\tlearn: 0.0373395\ttotal: 3.27s\tremaining: 541ms\n",
      "858:\tlearn: 0.0373183\ttotal: 3.27s\tremaining: 537ms\n",
      "859:\tlearn: 0.0372500\ttotal: 3.28s\tremaining: 533ms\n",
      "860:\tlearn: 0.0371889\ttotal: 3.28s\tremaining: 530ms\n",
      "861:\tlearn: 0.0371598\ttotal: 3.28s\tremaining: 526ms\n",
      "862:\tlearn: 0.0371320\ttotal: 3.29s\tremaining: 522ms\n",
      "863:\tlearn: 0.0370653\ttotal: 3.29s\tremaining: 518ms\n",
      "864:\tlearn: 0.0370459\ttotal: 3.29s\tremaining: 514ms\n",
      "865:\tlearn: 0.0370258\ttotal: 3.3s\tremaining: 510ms\n",
      "866:\tlearn: 0.0369978\ttotal: 3.3s\tremaining: 507ms\n",
      "867:\tlearn: 0.0369789\ttotal: 3.31s\tremaining: 503ms\n",
      "868:\tlearn: 0.0369588\ttotal: 3.31s\tremaining: 499ms\n",
      "869:\tlearn: 0.0369281\ttotal: 3.31s\tremaining: 495ms\n",
      "870:\tlearn: 0.0368825\ttotal: 3.32s\tremaining: 491ms\n",
      "871:\tlearn: 0.0368335\ttotal: 3.32s\tremaining: 487ms\n",
      "872:\tlearn: 0.0368149\ttotal: 3.32s\tremaining: 483ms\n",
      "873:\tlearn: 0.0367809\ttotal: 3.33s\tremaining: 480ms\n",
      "874:\tlearn: 0.0367580\ttotal: 3.33s\tremaining: 476ms\n",
      "875:\tlearn: 0.0367325\ttotal: 3.33s\tremaining: 472ms\n",
      "876:\tlearn: 0.0366880\ttotal: 3.34s\tremaining: 468ms\n",
      "877:\tlearn: 0.0366696\ttotal: 3.34s\tremaining: 464ms\n",
      "878:\tlearn: 0.0366295\ttotal: 3.35s\tremaining: 461ms\n",
      "879:\tlearn: 0.0365533\ttotal: 3.35s\tremaining: 457ms\n",
      "880:\tlearn: 0.0364807\ttotal: 3.35s\tremaining: 453ms\n",
      "881:\tlearn: 0.0364293\ttotal: 3.36s\tremaining: 449ms\n",
      "882:\tlearn: 0.0364040\ttotal: 3.36s\tremaining: 445ms\n",
      "883:\tlearn: 0.0363852\ttotal: 3.37s\tremaining: 442ms\n",
      "884:\tlearn: 0.0363462\ttotal: 3.37s\tremaining: 438ms\n",
      "885:\tlearn: 0.0362908\ttotal: 3.37s\tremaining: 434ms\n",
      "886:\tlearn: 0.0362664\ttotal: 3.38s\tremaining: 430ms\n",
      "887:\tlearn: 0.0362486\ttotal: 3.38s\tremaining: 426ms\n",
      "888:\tlearn: 0.0362197\ttotal: 3.38s\tremaining: 422ms\n",
      "889:\tlearn: 0.0361912\ttotal: 3.39s\tremaining: 419ms\n",
      "890:\tlearn: 0.0361633\ttotal: 3.39s\tremaining: 415ms\n",
      "891:\tlearn: 0.0361142\ttotal: 3.39s\tremaining: 411ms\n",
      "892:\tlearn: 0.0360895\ttotal: 3.4s\tremaining: 407ms\n",
      "893:\tlearn: 0.0360268\ttotal: 3.4s\tremaining: 403ms\n",
      "894:\tlearn: 0.0360093\ttotal: 3.4s\tremaining: 399ms\n",
      "895:\tlearn: 0.0359920\ttotal: 3.41s\tremaining: 396ms\n",
      "896:\tlearn: 0.0359728\ttotal: 3.41s\tremaining: 392ms\n",
      "897:\tlearn: 0.0359454\ttotal: 3.42s\tremaining: 388ms\n",
      "898:\tlearn: 0.0359282\ttotal: 3.42s\tremaining: 384ms\n",
      "899:\tlearn: 0.0359005\ttotal: 3.42s\tremaining: 380ms\n",
      "900:\tlearn: 0.0358835\ttotal: 3.43s\tremaining: 376ms\n",
      "901:\tlearn: 0.0358340\ttotal: 3.43s\tremaining: 373ms\n",
      "902:\tlearn: 0.0357705\ttotal: 3.43s\tremaining: 369ms\n",
      "903:\tlearn: 0.0357346\ttotal: 3.44s\tremaining: 365ms\n",
      "904:\tlearn: 0.0357106\ttotal: 3.44s\tremaining: 361ms\n",
      "905:\tlearn: 0.0356851\ttotal: 3.45s\tremaining: 358ms\n",
      "906:\tlearn: 0.0356555\ttotal: 3.45s\tremaining: 354ms\n",
      "907:\tlearn: 0.0356305\ttotal: 3.46s\tremaining: 350ms\n",
      "908:\tlearn: 0.0356018\ttotal: 3.46s\tremaining: 346ms\n",
      "909:\tlearn: 0.0355731\ttotal: 3.46s\tremaining: 343ms\n",
      "910:\tlearn: 0.0355506\ttotal: 3.47s\tremaining: 339ms\n",
      "911:\tlearn: 0.0354915\ttotal: 3.47s\tremaining: 335ms\n",
      "912:\tlearn: 0.0354749\ttotal: 3.48s\tremaining: 331ms\n",
      "913:\tlearn: 0.0354190\ttotal: 3.48s\tremaining: 327ms\n",
      "914:\tlearn: 0.0353921\ttotal: 3.48s\tremaining: 323ms\n",
      "915:\tlearn: 0.0353320\ttotal: 3.48s\tremaining: 320ms\n",
      "916:\tlearn: 0.0353155\ttotal: 3.49s\tremaining: 316ms\n",
      "917:\tlearn: 0.0352369\ttotal: 3.49s\tremaining: 312ms\n",
      "918:\tlearn: 0.0352135\ttotal: 3.5s\tremaining: 308ms\n",
      "919:\tlearn: 0.0351973\ttotal: 3.5s\tremaining: 304ms\n",
      "920:\tlearn: 0.0351709\ttotal: 3.5s\tremaining: 301ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "921:\tlearn: 0.0351391\ttotal: 3.51s\tremaining: 297ms\n",
      "922:\tlearn: 0.0350982\ttotal: 3.51s\tremaining: 293ms\n",
      "923:\tlearn: 0.0350664\ttotal: 3.52s\tremaining: 289ms\n",
      "924:\tlearn: 0.0350425\ttotal: 3.52s\tremaining: 285ms\n",
      "925:\tlearn: 0.0350265\ttotal: 3.52s\tremaining: 282ms\n",
      "926:\tlearn: 0.0350107\ttotal: 3.53s\tremaining: 278ms\n",
      "927:\tlearn: 0.0349891\ttotal: 3.53s\tremaining: 274ms\n",
      "928:\tlearn: 0.0349612\ttotal: 3.54s\tremaining: 270ms\n",
      "929:\tlearn: 0.0349030\ttotal: 3.54s\tremaining: 267ms\n",
      "930:\tlearn: 0.0348697\ttotal: 3.54s\tremaining: 263ms\n",
      "931:\tlearn: 0.0348114\ttotal: 3.55s\tremaining: 259ms\n",
      "932:\tlearn: 0.0347812\ttotal: 3.55s\tremaining: 255ms\n",
      "933:\tlearn: 0.0347351\ttotal: 3.56s\tremaining: 251ms\n",
      "934:\tlearn: 0.0347195\ttotal: 3.56s\tremaining: 248ms\n",
      "935:\tlearn: 0.0346655\ttotal: 3.56s\tremaining: 244ms\n",
      "936:\tlearn: 0.0346423\ttotal: 3.57s\tremaining: 240ms\n",
      "937:\tlearn: 0.0346036\ttotal: 3.57s\tremaining: 236ms\n",
      "938:\tlearn: 0.0345643\ttotal: 3.58s\tremaining: 232ms\n",
      "939:\tlearn: 0.0345489\ttotal: 3.58s\tremaining: 229ms\n",
      "940:\tlearn: 0.0344931\ttotal: 3.58s\tremaining: 225ms\n",
      "941:\tlearn: 0.0344627\ttotal: 3.59s\tremaining: 221ms\n",
      "942:\tlearn: 0.0344399\ttotal: 3.59s\tremaining: 217ms\n",
      "943:\tlearn: 0.0344257\ttotal: 3.59s\tremaining: 213ms\n",
      "944:\tlearn: 0.0343867\ttotal: 3.6s\tremaining: 209ms\n",
      "945:\tlearn: 0.0343715\ttotal: 3.6s\tremaining: 206ms\n",
      "946:\tlearn: 0.0343465\ttotal: 3.6s\tremaining: 202ms\n",
      "947:\tlearn: 0.0343224\ttotal: 3.61s\tremaining: 198ms\n",
      "948:\tlearn: 0.0343074\ttotal: 3.61s\tremaining: 194ms\n",
      "949:\tlearn: 0.0342837\ttotal: 3.62s\tremaining: 190ms\n",
      "950:\tlearn: 0.0342689\ttotal: 3.62s\tremaining: 187ms\n",
      "951:\tlearn: 0.0342182\ttotal: 3.62s\tremaining: 183ms\n",
      "952:\tlearn: 0.0341522\ttotal: 3.63s\tremaining: 179ms\n",
      "953:\tlearn: 0.0340892\ttotal: 3.63s\tremaining: 175ms\n",
      "954:\tlearn: 0.0340671\ttotal: 3.63s\tremaining: 171ms\n",
      "955:\tlearn: 0.0340512\ttotal: 3.64s\tremaining: 167ms\n",
      "956:\tlearn: 0.0340365\ttotal: 3.64s\tremaining: 164ms\n",
      "957:\tlearn: 0.0340091\ttotal: 3.65s\tremaining: 160ms\n",
      "958:\tlearn: 0.0339715\ttotal: 3.65s\tremaining: 156ms\n",
      "959:\tlearn: 0.0339460\ttotal: 3.65s\tremaining: 152ms\n",
      "960:\tlearn: 0.0339266\ttotal: 3.66s\tremaining: 148ms\n",
      "961:\tlearn: 0.0338896\ttotal: 3.66s\tremaining: 145ms\n",
      "962:\tlearn: 0.0338283\ttotal: 3.66s\tremaining: 141ms\n",
      "963:\tlearn: 0.0337907\ttotal: 3.67s\tremaining: 137ms\n",
      "964:\tlearn: 0.0337691\ttotal: 3.67s\tremaining: 133ms\n",
      "965:\tlearn: 0.0337013\ttotal: 3.67s\tremaining: 129ms\n",
      "966:\tlearn: 0.0336490\ttotal: 3.68s\tremaining: 126ms\n",
      "967:\tlearn: 0.0336346\ttotal: 3.68s\tremaining: 122ms\n",
      "968:\tlearn: 0.0336094\ttotal: 3.69s\tremaining: 118ms\n",
      "969:\tlearn: 0.0335786\ttotal: 3.69s\tremaining: 114ms\n",
      "970:\tlearn: 0.0335598\ttotal: 3.7s\tremaining: 110ms\n",
      "971:\tlearn: 0.0335240\ttotal: 3.7s\tremaining: 107ms\n",
      "972:\tlearn: 0.0335036\ttotal: 3.7s\tremaining: 103ms\n",
      "973:\tlearn: 0.0334793\ttotal: 3.71s\tremaining: 99ms\n",
      "974:\tlearn: 0.0334509\ttotal: 3.71s\tremaining: 95.2ms\n",
      "975:\tlearn: 0.0334252\ttotal: 3.72s\tremaining: 91.4ms\n",
      "976:\tlearn: 0.0334108\ttotal: 3.72s\tremaining: 87.6ms\n",
      "977:\tlearn: 0.0333632\ttotal: 3.72s\tremaining: 83.8ms\n",
      "978:\tlearn: 0.0333485\ttotal: 3.73s\tremaining: 79.9ms\n",
      "979:\tlearn: 0.0333275\ttotal: 3.73s\tremaining: 76.1ms\n",
      "980:\tlearn: 0.0333077\ttotal: 3.73s\tremaining: 72.3ms\n",
      "981:\tlearn: 0.0332934\ttotal: 3.74s\tremaining: 68.5ms\n",
      "982:\tlearn: 0.0332698\ttotal: 3.74s\tremaining: 64.7ms\n",
      "983:\tlearn: 0.0332557\ttotal: 3.75s\tremaining: 60.9ms\n",
      "984:\tlearn: 0.0332010\ttotal: 3.75s\tremaining: 57.1ms\n",
      "985:\tlearn: 0.0331518\ttotal: 3.75s\tremaining: 53.3ms\n",
      "986:\tlearn: 0.0331153\ttotal: 3.76s\tremaining: 49.5ms\n",
      "987:\tlearn: 0.0330963\ttotal: 3.76s\tremaining: 45.7ms\n",
      "988:\tlearn: 0.0330511\ttotal: 3.76s\tremaining: 41.9ms\n",
      "989:\tlearn: 0.0330372\ttotal: 3.77s\tremaining: 38.1ms\n",
      "990:\tlearn: 0.0330185\ttotal: 3.77s\tremaining: 34.3ms\n",
      "991:\tlearn: 0.0329798\ttotal: 3.78s\tremaining: 30.5ms\n",
      "992:\tlearn: 0.0329583\ttotal: 3.78s\tremaining: 26.6ms\n",
      "993:\tlearn: 0.0329370\ttotal: 3.78s\tremaining: 22.8ms\n",
      "994:\tlearn: 0.0329236\ttotal: 3.79s\tremaining: 19ms\n",
      "995:\tlearn: 0.0328896\ttotal: 3.79s\tremaining: 15.2ms\n",
      "996:\tlearn: 0.0328731\ttotal: 3.79s\tremaining: 11.4ms\n",
      "997:\tlearn: 0.0328414\ttotal: 3.8s\tremaining: 7.61ms\n",
      "998:\tlearn: 0.0328232\ttotal: 3.8s\tremaining: 3.81ms\n",
      "999:\tlearn: 0.0327793\ttotal: 3.81s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:21] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013279\n",
      "0:\tlearn: 0.6678101\ttotal: 4.48ms\tremaining: 4.48s\n",
      "1:\tlearn: 0.6433761\ttotal: 8.05ms\tremaining: 4.02s\n",
      "2:\tlearn: 0.6195374\ttotal: 11.5ms\tremaining: 3.83s\n",
      "3:\tlearn: 0.5975412\ttotal: 15.1ms\tremaining: 3.75s\n",
      "4:\tlearn: 0.5754271\ttotal: 18.7ms\tremaining: 3.71s\n",
      "5:\tlearn: 0.5599742\ttotal: 22.6ms\tremaining: 3.74s\n",
      "6:\tlearn: 0.5403275\ttotal: 26.5ms\tremaining: 3.76s\n",
      "7:\tlearn: 0.5224934\ttotal: 30ms\tremaining: 3.72s\n",
      "8:\tlearn: 0.5070426\ttotal: 34.5ms\tremaining: 3.8s\n",
      "9:\tlearn: 0.4899270\ttotal: 38.1ms\tremaining: 3.77s\n",
      "10:\tlearn: 0.4744400\ttotal: 41.8ms\tremaining: 3.76s\n",
      "11:\tlearn: 0.4586295\ttotal: 45.6ms\tremaining: 3.75s\n",
      "12:\tlearn: 0.4436823\ttotal: 49ms\tremaining: 3.72s\n",
      "13:\tlearn: 0.4296991\ttotal: 52.9ms\tremaining: 3.72s\n",
      "14:\tlearn: 0.4163789\ttotal: 57.5ms\tremaining: 3.78s\n",
      "15:\tlearn: 0.4031211\ttotal: 61.3ms\tremaining: 3.77s\n",
      "16:\tlearn: 0.3926136\ttotal: 65.2ms\tremaining: 3.77s\n",
      "17:\tlearn: 0.3810259\ttotal: 68.9ms\tremaining: 3.76s\n",
      "18:\tlearn: 0.3700220\ttotal: 72.7ms\tremaining: 3.75s\n",
      "19:\tlearn: 0.3596299\ttotal: 77ms\tremaining: 3.77s\n",
      "20:\tlearn: 0.3501928\ttotal: 80.9ms\tremaining: 3.77s\n",
      "21:\tlearn: 0.3416457\ttotal: 85ms\tremaining: 3.78s\n",
      "22:\tlearn: 0.3327181\ttotal: 89.1ms\tremaining: 3.78s\n",
      "23:\tlearn: 0.3255988\ttotal: 93.3ms\tremaining: 3.79s\n",
      "24:\tlearn: 0.3173180\ttotal: 97.3ms\tremaining: 3.79s\n",
      "25:\tlearn: 0.3095673\ttotal: 101ms\tremaining: 3.8s\n",
      "26:\tlearn: 0.3029556\ttotal: 105ms\tremaining: 3.79s\n",
      "27:\tlearn: 0.2953449\ttotal: 109ms\tremaining: 3.78s\n",
      "28:\tlearn: 0.2886364\ttotal: 113ms\tremaining: 3.78s\n",
      "29:\tlearn: 0.2821928\ttotal: 117ms\tremaining: 3.79s\n",
      "30:\tlearn: 0.2758531\ttotal: 123ms\tremaining: 3.83s\n",
      "31:\tlearn: 0.2693538\ttotal: 126ms\tremaining: 3.82s\n",
      "32:\tlearn: 0.2632832\ttotal: 130ms\tremaining: 3.81s\n",
      "33:\tlearn: 0.2578813\ttotal: 134ms\tremaining: 3.79s\n",
      "34:\tlearn: 0.2521283\ttotal: 137ms\tremaining: 3.79s\n",
      "35:\tlearn: 0.2470457\ttotal: 141ms\tremaining: 3.77s\n",
      "36:\tlearn: 0.2423068\ttotal: 145ms\tremaining: 3.77s\n",
      "37:\tlearn: 0.2380006\ttotal: 148ms\tremaining: 3.75s\n",
      "38:\tlearn: 0.2337057\ttotal: 152ms\tremaining: 3.75s\n",
      "39:\tlearn: 0.2291871\ttotal: 156ms\tremaining: 3.75s\n",
      "40:\tlearn: 0.2255404\ttotal: 160ms\tremaining: 3.74s\n",
      "41:\tlearn: 0.2215768\ttotal: 164ms\tremaining: 3.74s\n",
      "42:\tlearn: 0.2176782\ttotal: 168ms\tremaining: 3.73s\n",
      "43:\tlearn: 0.2140261\ttotal: 171ms\tremaining: 3.73s\n",
      "44:\tlearn: 0.2107688\ttotal: 176ms\tremaining: 3.73s\n",
      "45:\tlearn: 0.2074706\ttotal: 180ms\tremaining: 3.73s\n",
      "46:\tlearn: 0.2039999\ttotal: 184ms\tremaining: 3.74s\n",
      "47:\tlearn: 0.2007716\ttotal: 189ms\tremaining: 3.76s\n",
      "48:\tlearn: 0.1983563\ttotal: 193ms\tremaining: 3.75s\n",
      "49:\tlearn: 0.1956268\ttotal: 197ms\tremaining: 3.73s\n",
      "50:\tlearn: 0.1930509\ttotal: 201ms\tremaining: 3.73s\n",
      "51:\tlearn: 0.1903672\ttotal: 205ms\tremaining: 3.73s\n",
      "52:\tlearn: 0.1881259\ttotal: 208ms\tremaining: 3.72s\n",
      "53:\tlearn: 0.1859672\ttotal: 212ms\tremaining: 3.72s\n",
      "54:\tlearn: 0.1838439\ttotal: 216ms\tremaining: 3.71s\n",
      "55:\tlearn: 0.1813498\ttotal: 219ms\tremaining: 3.7s\n",
      "56:\tlearn: 0.1791718\ttotal: 223ms\tremaining: 3.68s\n",
      "57:\tlearn: 0.1767812\ttotal: 227ms\tremaining: 3.68s\n",
      "58:\tlearn: 0.1751154\ttotal: 230ms\tremaining: 3.67s\n",
      "59:\tlearn: 0.1731977\ttotal: 234ms\tremaining: 3.67s\n",
      "60:\tlearn: 0.1716555\ttotal: 238ms\tremaining: 3.67s\n",
      "61:\tlearn: 0.1694674\ttotal: 242ms\tremaining: 3.66s\n",
      "62:\tlearn: 0.1680250\ttotal: 246ms\tremaining: 3.66s\n",
      "63:\tlearn: 0.1661782\ttotal: 250ms\tremaining: 3.66s\n",
      "64:\tlearn: 0.1644794\ttotal: 254ms\tremaining: 3.65s\n",
      "65:\tlearn: 0.1629886\ttotal: 258ms\tremaining: 3.65s\n",
      "66:\tlearn: 0.1615328\ttotal: 262ms\tremaining: 3.64s\n",
      "67:\tlearn: 0.1601902\ttotal: 266ms\tremaining: 3.64s\n",
      "68:\tlearn: 0.1586308\ttotal: 270ms\tremaining: 3.64s\n",
      "69:\tlearn: 0.1571098\ttotal: 274ms\tremaining: 3.64s\n",
      "70:\tlearn: 0.1559205\ttotal: 278ms\tremaining: 3.64s\n",
      "71:\tlearn: 0.1543302\ttotal: 282ms\tremaining: 3.63s\n",
      "72:\tlearn: 0.1528417\ttotal: 286ms\tremaining: 3.63s\n",
      "73:\tlearn: 0.1513733\ttotal: 290ms\tremaining: 3.63s\n",
      "74:\tlearn: 0.1500890\ttotal: 294ms\tremaining: 3.62s\n",
      "75:\tlearn: 0.1489730\ttotal: 297ms\tremaining: 3.62s\n",
      "76:\tlearn: 0.1474391\ttotal: 302ms\tremaining: 3.61s\n",
      "77:\tlearn: 0.1460808\ttotal: 305ms\tremaining: 3.61s\n",
      "78:\tlearn: 0.1448166\ttotal: 309ms\tremaining: 3.6s\n",
      "79:\tlearn: 0.1435108\ttotal: 313ms\tremaining: 3.6s\n",
      "80:\tlearn: 0.1424477\ttotal: 317ms\tremaining: 3.59s\n",
      "81:\tlearn: 0.1414661\ttotal: 320ms\tremaining: 3.58s\n",
      "82:\tlearn: 0.1402921\ttotal: 324ms\tremaining: 3.58s\n",
      "83:\tlearn: 0.1393837\ttotal: 328ms\tremaining: 3.57s\n",
      "84:\tlearn: 0.1385545\ttotal: 331ms\tremaining: 3.56s\n",
      "85:\tlearn: 0.1374533\ttotal: 335ms\tremaining: 3.56s\n",
      "86:\tlearn: 0.1364794\ttotal: 338ms\tremaining: 3.55s\n",
      "87:\tlearn: 0.1357174\ttotal: 342ms\tremaining: 3.54s\n",
      "88:\tlearn: 0.1347535\ttotal: 346ms\tremaining: 3.54s\n",
      "89:\tlearn: 0.1339104\ttotal: 349ms\tremaining: 3.53s\n",
      "90:\tlearn: 0.1332374\ttotal: 353ms\tremaining: 3.52s\n",
      "91:\tlearn: 0.1325868\ttotal: 357ms\tremaining: 3.52s\n",
      "92:\tlearn: 0.1316037\ttotal: 361ms\tremaining: 3.52s\n",
      "93:\tlearn: 0.1306205\ttotal: 364ms\tremaining: 3.51s\n",
      "94:\tlearn: 0.1297999\ttotal: 368ms\tremaining: 3.5s\n",
      "95:\tlearn: 0.1290877\ttotal: 372ms\tremaining: 3.5s\n",
      "96:\tlearn: 0.1282907\ttotal: 376ms\tremaining: 3.5s\n",
      "97:\tlearn: 0.1277814\ttotal: 380ms\tremaining: 3.49s\n",
      "98:\tlearn: 0.1269090\ttotal: 383ms\tremaining: 3.49s\n",
      "99:\tlearn: 0.1260994\ttotal: 387ms\tremaining: 3.48s\n",
      "100:\tlearn: 0.1254515\ttotal: 390ms\tremaining: 3.47s\n",
      "101:\tlearn: 0.1244488\ttotal: 394ms\tremaining: 3.46s\n",
      "102:\tlearn: 0.1238343\ttotal: 397ms\tremaining: 3.46s\n",
      "103:\tlearn: 0.1230226\ttotal: 401ms\tremaining: 3.45s\n",
      "104:\tlearn: 0.1224333\ttotal: 405ms\tremaining: 3.45s\n",
      "105:\tlearn: 0.1218476\ttotal: 409ms\tremaining: 3.44s\n",
      "106:\tlearn: 0.1210884\ttotal: 412ms\tremaining: 3.44s\n",
      "107:\tlearn: 0.1204921\ttotal: 415ms\tremaining: 3.43s\n",
      "108:\tlearn: 0.1197717\ttotal: 419ms\tremaining: 3.43s\n",
      "109:\tlearn: 0.1190745\ttotal: 423ms\tremaining: 3.42s\n",
      "110:\tlearn: 0.1184484\ttotal: 427ms\tremaining: 3.42s\n",
      "111:\tlearn: 0.1180701\ttotal: 431ms\tremaining: 3.42s\n",
      "112:\tlearn: 0.1176182\ttotal: 435ms\tremaining: 3.41s\n",
      "113:\tlearn: 0.1170936\ttotal: 439ms\tremaining: 3.41s\n",
      "114:\tlearn: 0.1164048\ttotal: 442ms\tremaining: 3.4s\n",
      "115:\tlearn: 0.1158710\ttotal: 446ms\tremaining: 3.4s\n",
      "116:\tlearn: 0.1152269\ttotal: 450ms\tremaining: 3.39s\n",
      "117:\tlearn: 0.1146872\ttotal: 453ms\tremaining: 3.39s\n",
      "118:\tlearn: 0.1143026\ttotal: 457ms\tremaining: 3.38s\n",
      "119:\tlearn: 0.1136831\ttotal: 461ms\tremaining: 3.38s\n",
      "120:\tlearn: 0.1131967\ttotal: 465ms\tremaining: 3.38s\n",
      "121:\tlearn: 0.1126147\ttotal: 469ms\tremaining: 3.37s\n",
      "122:\tlearn: 0.1123339\ttotal: 472ms\tremaining: 3.37s\n",
      "123:\tlearn: 0.1120063\ttotal: 476ms\tremaining: 3.36s\n",
      "124:\tlearn: 0.1114588\ttotal: 479ms\tremaining: 3.35s\n",
      "125:\tlearn: 0.1109629\ttotal: 483ms\tremaining: 3.35s\n",
      "126:\tlearn: 0.1104748\ttotal: 487ms\tremaining: 3.35s\n",
      "127:\tlearn: 0.1101193\ttotal: 490ms\tremaining: 3.34s\n",
      "128:\tlearn: 0.1095691\ttotal: 494ms\tremaining: 3.34s\n",
      "129:\tlearn: 0.1092951\ttotal: 498ms\tremaining: 3.33s\n",
      "130:\tlearn: 0.1088239\ttotal: 502ms\tremaining: 3.33s\n",
      "131:\tlearn: 0.1083775\ttotal: 506ms\tremaining: 3.33s\n",
      "132:\tlearn: 0.1079767\ttotal: 510ms\tremaining: 3.32s\n",
      "133:\tlearn: 0.1076209\ttotal: 513ms\tremaining: 3.32s\n",
      "134:\tlearn: 0.1072296\ttotal: 517ms\tremaining: 3.31s\n",
      "135:\tlearn: 0.1067814\ttotal: 520ms\tremaining: 3.31s\n",
      "136:\tlearn: 0.1063849\ttotal: 524ms\tremaining: 3.3s\n",
      "137:\tlearn: 0.1060196\ttotal: 528ms\tremaining: 3.3s\n",
      "138:\tlearn: 0.1057544\ttotal: 532ms\tremaining: 3.3s\n",
      "139:\tlearn: 0.1054062\ttotal: 536ms\tremaining: 3.29s\n",
      "140:\tlearn: 0.1051025\ttotal: 540ms\tremaining: 3.29s\n",
      "141:\tlearn: 0.1046886\ttotal: 544ms\tremaining: 3.29s\n",
      "142:\tlearn: 0.1043827\ttotal: 548ms\tremaining: 3.28s\n",
      "143:\tlearn: 0.1038978\ttotal: 552ms\tremaining: 3.28s\n",
      "144:\tlearn: 0.1035159\ttotal: 555ms\tremaining: 3.27s\n",
      "145:\tlearn: 0.1031602\ttotal: 560ms\tremaining: 3.27s\n",
      "146:\tlearn: 0.1029208\ttotal: 564ms\tremaining: 3.27s\n",
      "147:\tlearn: 0.1025127\ttotal: 567ms\tremaining: 3.26s\n",
      "148:\tlearn: 0.1021693\ttotal: 571ms\tremaining: 3.26s\n",
      "149:\tlearn: 0.1019230\ttotal: 574ms\tremaining: 3.25s\n",
      "150:\tlearn: 0.1016921\ttotal: 578ms\tremaining: 3.25s\n",
      "151:\tlearn: 0.1014338\ttotal: 581ms\tremaining: 3.24s\n",
      "152:\tlearn: 0.1010287\ttotal: 585ms\tremaining: 3.23s\n",
      "153:\tlearn: 0.1006894\ttotal: 588ms\tremaining: 3.23s\n",
      "154:\tlearn: 0.1004577\ttotal: 592ms\tremaining: 3.23s\n",
      "155:\tlearn: 0.1002072\ttotal: 596ms\tremaining: 3.22s\n",
      "156:\tlearn: 0.0998992\ttotal: 599ms\tremaining: 3.22s\n",
      "157:\tlearn: 0.0996231\ttotal: 602ms\tremaining: 3.21s\n",
      "158:\tlearn: 0.0994182\ttotal: 606ms\tremaining: 3.21s\n",
      "159:\tlearn: 0.0990660\ttotal: 610ms\tremaining: 3.2s\n",
      "160:\tlearn: 0.0987149\ttotal: 613ms\tremaining: 3.19s\n",
      "161:\tlearn: 0.0984776\ttotal: 617ms\tremaining: 3.19s\n",
      "162:\tlearn: 0.0982746\ttotal: 621ms\tremaining: 3.19s\n",
      "163:\tlearn: 0.0979542\ttotal: 624ms\tremaining: 3.18s\n",
      "164:\tlearn: 0.0976826\ttotal: 628ms\tremaining: 3.18s\n",
      "165:\tlearn: 0.0973896\ttotal: 631ms\tremaining: 3.17s\n",
      "166:\tlearn: 0.0971327\ttotal: 634ms\tremaining: 3.16s\n",
      "167:\tlearn: 0.0967284\ttotal: 638ms\tremaining: 3.16s\n",
      "168:\tlearn: 0.0964021\ttotal: 641ms\tremaining: 3.15s\n",
      "169:\tlearn: 0.0962035\ttotal: 645ms\tremaining: 3.15s\n",
      "170:\tlearn: 0.0959526\ttotal: 648ms\tremaining: 3.14s\n",
      "171:\tlearn: 0.0956692\ttotal: 652ms\tremaining: 3.14s\n",
      "172:\tlearn: 0.0954684\ttotal: 656ms\tremaining: 3.13s\n",
      "173:\tlearn: 0.0952335\ttotal: 659ms\tremaining: 3.13s\n",
      "174:\tlearn: 0.0949116\ttotal: 663ms\tremaining: 3.13s\n",
      "175:\tlearn: 0.0946847\ttotal: 667ms\tremaining: 3.12s\n",
      "176:\tlearn: 0.0945221\ttotal: 670ms\tremaining: 3.12s\n",
      "177:\tlearn: 0.0941072\ttotal: 674ms\tremaining: 3.11s\n",
      "178:\tlearn: 0.0939597\ttotal: 678ms\tremaining: 3.11s\n",
      "179:\tlearn: 0.0937725\ttotal: 681ms\tremaining: 3.1s\n",
      "180:\tlearn: 0.0935535\ttotal: 685ms\tremaining: 3.1s\n",
      "181:\tlearn: 0.0933342\ttotal: 689ms\tremaining: 3.1s\n",
      "182:\tlearn: 0.0930181\ttotal: 692ms\tremaining: 3.09s\n",
      "183:\tlearn: 0.0927681\ttotal: 695ms\tremaining: 3.08s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "184:\tlearn: 0.0924940\ttotal: 699ms\tremaining: 3.08s\n",
      "185:\tlearn: 0.0922060\ttotal: 703ms\tremaining: 3.08s\n",
      "186:\tlearn: 0.0918452\ttotal: 706ms\tremaining: 3.07s\n",
      "187:\tlearn: 0.0916191\ttotal: 710ms\tremaining: 3.07s\n",
      "188:\tlearn: 0.0914581\ttotal: 714ms\tremaining: 3.06s\n",
      "189:\tlearn: 0.0910932\ttotal: 719ms\tremaining: 3.06s\n",
      "190:\tlearn: 0.0908305\ttotal: 722ms\tremaining: 3.06s\n",
      "191:\tlearn: 0.0904908\ttotal: 726ms\tremaining: 3.05s\n",
      "192:\tlearn: 0.0902727\ttotal: 729ms\tremaining: 3.05s\n",
      "193:\tlearn: 0.0900252\ttotal: 733ms\tremaining: 3.04s\n",
      "194:\tlearn: 0.0897710\ttotal: 737ms\tremaining: 3.04s\n",
      "195:\tlearn: 0.0896097\ttotal: 740ms\tremaining: 3.04s\n",
      "196:\tlearn: 0.0894119\ttotal: 744ms\tremaining: 3.03s\n",
      "197:\tlearn: 0.0892890\ttotal: 747ms\tremaining: 3.03s\n",
      "198:\tlearn: 0.0891160\ttotal: 751ms\tremaining: 3.02s\n",
      "199:\tlearn: 0.0888389\ttotal: 754ms\tremaining: 3.02s\n",
      "200:\tlearn: 0.0886608\ttotal: 758ms\tremaining: 3.01s\n",
      "201:\tlearn: 0.0884192\ttotal: 762ms\tremaining: 3.01s\n",
      "202:\tlearn: 0.0881112\ttotal: 765ms\tremaining: 3s\n",
      "203:\tlearn: 0.0879890\ttotal: 769ms\tremaining: 3s\n",
      "204:\tlearn: 0.0878978\ttotal: 772ms\tremaining: 3s\n",
      "205:\tlearn: 0.0876916\ttotal: 776ms\tremaining: 2.99s\n",
      "206:\tlearn: 0.0875354\ttotal: 780ms\tremaining: 2.99s\n",
      "207:\tlearn: 0.0872274\ttotal: 783ms\tremaining: 2.98s\n",
      "208:\tlearn: 0.0869581\ttotal: 787ms\tremaining: 2.98s\n",
      "209:\tlearn: 0.0868401\ttotal: 791ms\tremaining: 2.97s\n",
      "210:\tlearn: 0.0865863\ttotal: 794ms\tremaining: 2.97s\n",
      "211:\tlearn: 0.0864183\ttotal: 798ms\tremaining: 2.96s\n",
      "212:\tlearn: 0.0862045\ttotal: 801ms\tremaining: 2.96s\n",
      "213:\tlearn: 0.0859837\ttotal: 805ms\tremaining: 2.96s\n",
      "214:\tlearn: 0.0858918\ttotal: 809ms\tremaining: 2.95s\n",
      "215:\tlearn: 0.0857177\ttotal: 813ms\tremaining: 2.95s\n",
      "216:\tlearn: 0.0854054\ttotal: 816ms\tremaining: 2.94s\n",
      "217:\tlearn: 0.0852714\ttotal: 820ms\tremaining: 2.94s\n",
      "218:\tlearn: 0.0851220\ttotal: 823ms\tremaining: 2.94s\n",
      "219:\tlearn: 0.0849418\ttotal: 827ms\tremaining: 2.93s\n",
      "220:\tlearn: 0.0847417\ttotal: 830ms\tremaining: 2.93s\n",
      "221:\tlearn: 0.0846119\ttotal: 834ms\tremaining: 2.92s\n",
      "222:\tlearn: 0.0843576\ttotal: 837ms\tremaining: 2.92s\n",
      "223:\tlearn: 0.0841933\ttotal: 842ms\tremaining: 2.92s\n",
      "224:\tlearn: 0.0840495\ttotal: 845ms\tremaining: 2.91s\n",
      "225:\tlearn: 0.0839572\ttotal: 848ms\tremaining: 2.9s\n",
      "226:\tlearn: 0.0837225\ttotal: 852ms\tremaining: 2.9s\n",
      "227:\tlearn: 0.0836477\ttotal: 856ms\tremaining: 2.9s\n",
      "228:\tlearn: 0.0834541\ttotal: 859ms\tremaining: 2.89s\n",
      "229:\tlearn: 0.0831738\ttotal: 862ms\tremaining: 2.89s\n",
      "230:\tlearn: 0.0829571\ttotal: 866ms\tremaining: 2.88s\n",
      "231:\tlearn: 0.0828527\ttotal: 870ms\tremaining: 2.88s\n",
      "232:\tlearn: 0.0826703\ttotal: 874ms\tremaining: 2.88s\n",
      "233:\tlearn: 0.0825396\ttotal: 878ms\tremaining: 2.87s\n",
      "234:\tlearn: 0.0824187\ttotal: 882ms\tremaining: 2.87s\n",
      "235:\tlearn: 0.0822913\ttotal: 886ms\tremaining: 2.87s\n",
      "236:\tlearn: 0.0821444\ttotal: 889ms\tremaining: 2.86s\n",
      "237:\tlearn: 0.0820442\ttotal: 893ms\tremaining: 2.86s\n",
      "238:\tlearn: 0.0818958\ttotal: 896ms\tremaining: 2.85s\n",
      "239:\tlearn: 0.0816793\ttotal: 900ms\tremaining: 2.85s\n",
      "240:\tlearn: 0.0815324\ttotal: 904ms\tremaining: 2.85s\n",
      "241:\tlearn: 0.0814151\ttotal: 908ms\tremaining: 2.84s\n",
      "242:\tlearn: 0.0811972\ttotal: 912ms\tremaining: 2.84s\n",
      "243:\tlearn: 0.0810838\ttotal: 915ms\tremaining: 2.83s\n",
      "244:\tlearn: 0.0809796\ttotal: 919ms\tremaining: 2.83s\n",
      "245:\tlearn: 0.0808594\ttotal: 922ms\tremaining: 2.83s\n",
      "246:\tlearn: 0.0807616\ttotal: 926ms\tremaining: 2.82s\n",
      "247:\tlearn: 0.0806142\ttotal: 929ms\tremaining: 2.82s\n",
      "248:\tlearn: 0.0804588\ttotal: 934ms\tremaining: 2.82s\n",
      "249:\tlearn: 0.0802493\ttotal: 937ms\tremaining: 2.81s\n",
      "250:\tlearn: 0.0800880\ttotal: 941ms\tremaining: 2.81s\n",
      "251:\tlearn: 0.0799869\ttotal: 944ms\tremaining: 2.8s\n",
      "252:\tlearn: 0.0798827\ttotal: 948ms\tremaining: 2.8s\n",
      "253:\tlearn: 0.0797349\ttotal: 951ms\tremaining: 2.79s\n",
      "254:\tlearn: 0.0796462\ttotal: 954ms\tremaining: 2.79s\n",
      "255:\tlearn: 0.0795182\ttotal: 958ms\tremaining: 2.78s\n",
      "256:\tlearn: 0.0793899\ttotal: 962ms\tremaining: 2.78s\n",
      "257:\tlearn: 0.0792334\ttotal: 965ms\tremaining: 2.78s\n",
      "258:\tlearn: 0.0791201\ttotal: 969ms\tremaining: 2.77s\n",
      "259:\tlearn: 0.0789461\ttotal: 973ms\tremaining: 2.77s\n",
      "260:\tlearn: 0.0787118\ttotal: 976ms\tremaining: 2.76s\n",
      "261:\tlearn: 0.0785893\ttotal: 980ms\tremaining: 2.76s\n",
      "262:\tlearn: 0.0784738\ttotal: 983ms\tremaining: 2.75s\n",
      "263:\tlearn: 0.0783729\ttotal: 987ms\tremaining: 2.75s\n",
      "264:\tlearn: 0.0781228\ttotal: 991ms\tremaining: 2.75s\n",
      "265:\tlearn: 0.0780446\ttotal: 994ms\tremaining: 2.74s\n",
      "266:\tlearn: 0.0779349\ttotal: 998ms\tremaining: 2.74s\n",
      "267:\tlearn: 0.0777863\ttotal: 1s\tremaining: 2.73s\n",
      "268:\tlearn: 0.0775790\ttotal: 1s\tremaining: 2.73s\n",
      "269:\tlearn: 0.0774735\ttotal: 1.01s\tremaining: 2.73s\n",
      "270:\tlearn: 0.0774127\ttotal: 1.01s\tremaining: 2.72s\n",
      "271:\tlearn: 0.0772839\ttotal: 1.01s\tremaining: 2.72s\n",
      "272:\tlearn: 0.0770819\ttotal: 1.02s\tremaining: 2.71s\n",
      "273:\tlearn: 0.0769884\ttotal: 1.02s\tremaining: 2.71s\n",
      "274:\tlearn: 0.0768603\ttotal: 1.03s\tremaining: 2.71s\n",
      "275:\tlearn: 0.0767744\ttotal: 1.03s\tremaining: 2.7s\n",
      "276:\tlearn: 0.0766327\ttotal: 1.03s\tremaining: 2.7s\n",
      "277:\tlearn: 0.0765803\ttotal: 1.04s\tremaining: 2.69s\n",
      "278:\tlearn: 0.0764203\ttotal: 1.04s\tremaining: 2.69s\n",
      "279:\tlearn: 0.0762748\ttotal: 1.04s\tremaining: 2.69s\n",
      "280:\tlearn: 0.0761402\ttotal: 1.05s\tremaining: 2.68s\n",
      "281:\tlearn: 0.0760337\ttotal: 1.05s\tremaining: 2.68s\n",
      "282:\tlearn: 0.0758276\ttotal: 1.06s\tremaining: 2.68s\n",
      "283:\tlearn: 0.0756969\ttotal: 1.06s\tremaining: 2.67s\n",
      "284:\tlearn: 0.0755961\ttotal: 1.06s\tremaining: 2.67s\n",
      "285:\tlearn: 0.0754559\ttotal: 1.07s\tremaining: 2.67s\n",
      "286:\tlearn: 0.0753443\ttotal: 1.07s\tremaining: 2.67s\n",
      "287:\tlearn: 0.0752356\ttotal: 1.08s\tremaining: 2.66s\n",
      "288:\tlearn: 0.0750459\ttotal: 1.08s\tremaining: 2.66s\n",
      "289:\tlearn: 0.0749281\ttotal: 1.08s\tremaining: 2.65s\n",
      "290:\tlearn: 0.0747656\ttotal: 1.09s\tremaining: 2.65s\n",
      "291:\tlearn: 0.0746379\ttotal: 1.09s\tremaining: 2.65s\n",
      "292:\tlearn: 0.0744696\ttotal: 1.1s\tremaining: 2.65s\n",
      "293:\tlearn: 0.0744012\ttotal: 1.1s\tremaining: 2.64s\n",
      "294:\tlearn: 0.0742613\ttotal: 1.1s\tremaining: 2.64s\n",
      "295:\tlearn: 0.0741695\ttotal: 1.11s\tremaining: 2.64s\n",
      "296:\tlearn: 0.0739971\ttotal: 1.11s\tremaining: 2.63s\n",
      "297:\tlearn: 0.0738777\ttotal: 1.12s\tremaining: 2.63s\n",
      "298:\tlearn: 0.0737428\ttotal: 1.12s\tremaining: 2.63s\n",
      "299:\tlearn: 0.0736885\ttotal: 1.12s\tremaining: 2.62s\n",
      "300:\tlearn: 0.0735374\ttotal: 1.13s\tremaining: 2.62s\n",
      "301:\tlearn: 0.0734473\ttotal: 1.13s\tremaining: 2.62s\n",
      "302:\tlearn: 0.0732949\ttotal: 1.14s\tremaining: 2.62s\n",
      "303:\tlearn: 0.0732159\ttotal: 1.14s\tremaining: 2.61s\n",
      "304:\tlearn: 0.0730914\ttotal: 1.15s\tremaining: 2.61s\n",
      "305:\tlearn: 0.0729490\ttotal: 1.15s\tremaining: 2.61s\n",
      "306:\tlearn: 0.0728976\ttotal: 1.15s\tremaining: 2.6s\n",
      "307:\tlearn: 0.0727975\ttotal: 1.16s\tremaining: 2.6s\n",
      "308:\tlearn: 0.0726728\ttotal: 1.16s\tremaining: 2.6s\n",
      "309:\tlearn: 0.0726158\ttotal: 1.17s\tremaining: 2.59s\n",
      "310:\tlearn: 0.0724658\ttotal: 1.17s\tremaining: 2.59s\n",
      "311:\tlearn: 0.0723058\ttotal: 1.17s\tremaining: 2.59s\n",
      "312:\tlearn: 0.0722313\ttotal: 1.18s\tremaining: 2.58s\n",
      "313:\tlearn: 0.0720341\ttotal: 1.18s\tremaining: 2.58s\n",
      "314:\tlearn: 0.0718542\ttotal: 1.18s\tremaining: 2.58s\n",
      "315:\tlearn: 0.0717695\ttotal: 1.19s\tremaining: 2.57s\n",
      "316:\tlearn: 0.0716226\ttotal: 1.19s\tremaining: 2.57s\n",
      "317:\tlearn: 0.0715108\ttotal: 1.2s\tremaining: 2.56s\n",
      "318:\tlearn: 0.0714208\ttotal: 1.2s\tremaining: 2.56s\n",
      "319:\tlearn: 0.0712900\ttotal: 1.2s\tremaining: 2.56s\n",
      "320:\tlearn: 0.0711333\ttotal: 1.21s\tremaining: 2.55s\n",
      "321:\tlearn: 0.0709668\ttotal: 1.21s\tremaining: 2.55s\n",
      "322:\tlearn: 0.0708379\ttotal: 1.22s\tremaining: 2.55s\n",
      "323:\tlearn: 0.0707165\ttotal: 1.22s\tremaining: 2.54s\n",
      "324:\tlearn: 0.0706313\ttotal: 1.22s\tremaining: 2.54s\n",
      "325:\tlearn: 0.0705525\ttotal: 1.23s\tremaining: 2.53s\n",
      "326:\tlearn: 0.0704870\ttotal: 1.23s\tremaining: 2.53s\n",
      "327:\tlearn: 0.0703897\ttotal: 1.23s\tremaining: 2.53s\n",
      "328:\tlearn: 0.0702085\ttotal: 1.24s\tremaining: 2.52s\n",
      "329:\tlearn: 0.0701578\ttotal: 1.24s\tremaining: 2.52s\n",
      "330:\tlearn: 0.0700988\ttotal: 1.25s\tremaining: 2.52s\n",
      "331:\tlearn: 0.0700065\ttotal: 1.25s\tremaining: 2.51s\n",
      "332:\tlearn: 0.0699169\ttotal: 1.25s\tremaining: 2.51s\n",
      "333:\tlearn: 0.0698163\ttotal: 1.26s\tremaining: 2.51s\n",
      "334:\tlearn: 0.0697125\ttotal: 1.26s\tremaining: 2.51s\n",
      "335:\tlearn: 0.0695994\ttotal: 1.27s\tremaining: 2.51s\n",
      "336:\tlearn: 0.0695052\ttotal: 1.27s\tremaining: 2.51s\n",
      "337:\tlearn: 0.0694246\ttotal: 1.28s\tremaining: 2.5s\n",
      "338:\tlearn: 0.0692370\ttotal: 1.28s\tremaining: 2.5s\n",
      "339:\tlearn: 0.0691749\ttotal: 1.29s\tremaining: 2.5s\n",
      "340:\tlearn: 0.0690301\ttotal: 1.29s\tremaining: 2.5s\n",
      "341:\tlearn: 0.0688901\ttotal: 1.3s\tremaining: 2.49s\n",
      "342:\tlearn: 0.0687887\ttotal: 1.3s\tremaining: 2.49s\n",
      "343:\tlearn: 0.0686624\ttotal: 1.31s\tremaining: 2.49s\n",
      "344:\tlearn: 0.0685311\ttotal: 1.31s\tremaining: 2.49s\n",
      "345:\tlearn: 0.0684740\ttotal: 1.31s\tremaining: 2.48s\n",
      "346:\tlearn: 0.0684462\ttotal: 1.32s\tremaining: 2.48s\n",
      "347:\tlearn: 0.0683130\ttotal: 1.32s\tremaining: 2.48s\n",
      "348:\tlearn: 0.0681840\ttotal: 1.33s\tremaining: 2.48s\n",
      "349:\tlearn: 0.0681193\ttotal: 1.33s\tremaining: 2.48s\n",
      "350:\tlearn: 0.0680191\ttotal: 1.34s\tremaining: 2.48s\n",
      "351:\tlearn: 0.0679667\ttotal: 1.34s\tremaining: 2.48s\n",
      "352:\tlearn: 0.0679212\ttotal: 1.35s\tremaining: 2.47s\n",
      "353:\tlearn: 0.0678454\ttotal: 1.35s\tremaining: 2.47s\n",
      "354:\tlearn: 0.0677724\ttotal: 1.36s\tremaining: 2.46s\n",
      "355:\tlearn: 0.0676736\ttotal: 1.36s\tremaining: 2.46s\n",
      "356:\tlearn: 0.0674985\ttotal: 1.36s\tremaining: 2.46s\n",
      "357:\tlearn: 0.0674367\ttotal: 1.37s\tremaining: 2.46s\n",
      "358:\tlearn: 0.0673375\ttotal: 1.38s\tremaining: 2.46s\n",
      "359:\tlearn: 0.0672640\ttotal: 1.38s\tremaining: 2.45s\n",
      "360:\tlearn: 0.0672018\ttotal: 1.38s\tremaining: 2.45s\n",
      "361:\tlearn: 0.0670911\ttotal: 1.39s\tremaining: 2.44s\n",
      "362:\tlearn: 0.0669558\ttotal: 1.39s\tremaining: 2.44s\n",
      "363:\tlearn: 0.0668753\ttotal: 1.4s\tremaining: 2.44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364:\tlearn: 0.0667955\ttotal: 1.4s\tremaining: 2.44s\n",
      "365:\tlearn: 0.0666746\ttotal: 1.4s\tremaining: 2.43s\n",
      "366:\tlearn: 0.0665393\ttotal: 1.41s\tremaining: 2.43s\n",
      "367:\tlearn: 0.0664515\ttotal: 1.41s\tremaining: 2.42s\n",
      "368:\tlearn: 0.0663294\ttotal: 1.42s\tremaining: 2.42s\n",
      "369:\tlearn: 0.0661848\ttotal: 1.42s\tremaining: 2.42s\n",
      "370:\tlearn: 0.0660173\ttotal: 1.42s\tremaining: 2.42s\n",
      "371:\tlearn: 0.0658471\ttotal: 1.43s\tremaining: 2.41s\n",
      "372:\tlearn: 0.0657679\ttotal: 1.44s\tremaining: 2.41s\n",
      "373:\tlearn: 0.0657441\ttotal: 1.44s\tremaining: 2.41s\n",
      "374:\tlearn: 0.0656398\ttotal: 1.44s\tremaining: 2.41s\n",
      "375:\tlearn: 0.0655707\ttotal: 1.45s\tremaining: 2.4s\n",
      "376:\tlearn: 0.0654942\ttotal: 1.45s\tremaining: 2.4s\n",
      "377:\tlearn: 0.0654136\ttotal: 1.46s\tremaining: 2.4s\n",
      "378:\tlearn: 0.0653090\ttotal: 1.46s\tremaining: 2.4s\n",
      "379:\tlearn: 0.0652430\ttotal: 1.47s\tremaining: 2.39s\n",
      "380:\tlearn: 0.0651841\ttotal: 1.47s\tremaining: 2.39s\n",
      "381:\tlearn: 0.0651310\ttotal: 1.47s\tremaining: 2.38s\n",
      "382:\tlearn: 0.0650139\ttotal: 1.48s\tremaining: 2.38s\n",
      "383:\tlearn: 0.0648535\ttotal: 1.48s\tremaining: 2.38s\n",
      "384:\tlearn: 0.0647856\ttotal: 1.49s\tremaining: 2.37s\n",
      "385:\tlearn: 0.0645748\ttotal: 1.49s\tremaining: 2.37s\n",
      "386:\tlearn: 0.0644980\ttotal: 1.49s\tremaining: 2.37s\n",
      "387:\tlearn: 0.0644242\ttotal: 1.5s\tremaining: 2.36s\n",
      "388:\tlearn: 0.0642800\ttotal: 1.5s\tremaining: 2.36s\n",
      "389:\tlearn: 0.0641994\ttotal: 1.5s\tremaining: 2.35s\n",
      "390:\tlearn: 0.0641392\ttotal: 1.51s\tremaining: 2.35s\n",
      "391:\tlearn: 0.0640916\ttotal: 1.51s\tremaining: 2.35s\n",
      "392:\tlearn: 0.0639569\ttotal: 1.52s\tremaining: 2.34s\n",
      "393:\tlearn: 0.0638632\ttotal: 1.52s\tremaining: 2.34s\n",
      "394:\tlearn: 0.0637259\ttotal: 1.52s\tremaining: 2.33s\n",
      "395:\tlearn: 0.0636661\ttotal: 1.53s\tremaining: 2.33s\n",
      "396:\tlearn: 0.0635874\ttotal: 1.53s\tremaining: 2.33s\n",
      "397:\tlearn: 0.0635314\ttotal: 1.53s\tremaining: 2.32s\n",
      "398:\tlearn: 0.0634162\ttotal: 1.54s\tremaining: 2.32s\n",
      "399:\tlearn: 0.0632892\ttotal: 1.54s\tremaining: 2.31s\n",
      "400:\tlearn: 0.0631710\ttotal: 1.55s\tremaining: 2.31s\n",
      "401:\tlearn: 0.0630588\ttotal: 1.55s\tremaining: 2.31s\n",
      "402:\tlearn: 0.0629812\ttotal: 1.55s\tremaining: 2.3s\n",
      "403:\tlearn: 0.0629236\ttotal: 1.56s\tremaining: 2.3s\n",
      "404:\tlearn: 0.0627834\ttotal: 1.56s\tremaining: 2.29s\n",
      "405:\tlearn: 0.0626803\ttotal: 1.56s\tremaining: 2.29s\n",
      "406:\tlearn: 0.0625750\ttotal: 1.57s\tremaining: 2.28s\n",
      "407:\tlearn: 0.0624467\ttotal: 1.57s\tremaining: 2.28s\n",
      "408:\tlearn: 0.0623976\ttotal: 1.58s\tremaining: 2.28s\n",
      "409:\tlearn: 0.0623242\ttotal: 1.58s\tremaining: 2.27s\n",
      "410:\tlearn: 0.0622449\ttotal: 1.58s\tremaining: 2.27s\n",
      "411:\tlearn: 0.0621619\ttotal: 1.59s\tremaining: 2.27s\n",
      "412:\tlearn: 0.0621009\ttotal: 1.59s\tremaining: 2.26s\n",
      "413:\tlearn: 0.0619773\ttotal: 1.59s\tremaining: 2.26s\n",
      "414:\tlearn: 0.0619163\ttotal: 1.6s\tremaining: 2.25s\n",
      "415:\tlearn: 0.0618001\ttotal: 1.6s\tremaining: 2.25s\n",
      "416:\tlearn: 0.0617256\ttotal: 1.61s\tremaining: 2.25s\n",
      "417:\tlearn: 0.0616446\ttotal: 1.61s\tremaining: 2.24s\n",
      "418:\tlearn: 0.0615405\ttotal: 1.61s\tremaining: 2.24s\n",
      "419:\tlearn: 0.0614824\ttotal: 1.62s\tremaining: 2.24s\n",
      "420:\tlearn: 0.0614067\ttotal: 1.62s\tremaining: 2.23s\n",
      "421:\tlearn: 0.0613064\ttotal: 1.63s\tremaining: 2.23s\n",
      "422:\tlearn: 0.0611791\ttotal: 1.63s\tremaining: 2.22s\n",
      "423:\tlearn: 0.0609911\ttotal: 1.63s\tremaining: 2.22s\n",
      "424:\tlearn: 0.0609257\ttotal: 1.64s\tremaining: 2.22s\n",
      "425:\tlearn: 0.0607787\ttotal: 1.64s\tremaining: 2.21s\n",
      "426:\tlearn: 0.0607201\ttotal: 1.65s\tremaining: 2.21s\n",
      "427:\tlearn: 0.0606238\ttotal: 1.65s\tremaining: 2.21s\n",
      "428:\tlearn: 0.0605478\ttotal: 1.65s\tremaining: 2.2s\n",
      "429:\tlearn: 0.0605032\ttotal: 1.66s\tremaining: 2.2s\n",
      "430:\tlearn: 0.0604722\ttotal: 1.66s\tremaining: 2.19s\n",
      "431:\tlearn: 0.0603875\ttotal: 1.67s\tremaining: 2.19s\n",
      "432:\tlearn: 0.0603108\ttotal: 1.67s\tremaining: 2.19s\n",
      "433:\tlearn: 0.0602667\ttotal: 1.67s\tremaining: 2.18s\n",
      "434:\tlearn: 0.0601448\ttotal: 1.68s\tremaining: 2.18s\n",
      "435:\tlearn: 0.0600303\ttotal: 1.68s\tremaining: 2.18s\n",
      "436:\tlearn: 0.0599148\ttotal: 1.69s\tremaining: 2.17s\n",
      "437:\tlearn: 0.0598819\ttotal: 1.69s\tremaining: 2.17s\n",
      "438:\tlearn: 0.0598210\ttotal: 1.7s\tremaining: 2.17s\n",
      "439:\tlearn: 0.0597537\ttotal: 1.7s\tremaining: 2.16s\n",
      "440:\tlearn: 0.0596642\ttotal: 1.71s\tremaining: 2.16s\n",
      "441:\tlearn: 0.0596290\ttotal: 1.71s\tremaining: 2.16s\n",
      "442:\tlearn: 0.0595441\ttotal: 1.71s\tremaining: 2.15s\n",
      "443:\tlearn: 0.0594953\ttotal: 1.72s\tremaining: 2.15s\n",
      "444:\tlearn: 0.0594280\ttotal: 1.72s\tremaining: 2.15s\n",
      "445:\tlearn: 0.0593381\ttotal: 1.73s\tremaining: 2.14s\n",
      "446:\tlearn: 0.0592923\ttotal: 1.73s\tremaining: 2.14s\n",
      "447:\tlearn: 0.0592107\ttotal: 1.73s\tremaining: 2.13s\n",
      "448:\tlearn: 0.0591127\ttotal: 1.74s\tremaining: 2.13s\n",
      "449:\tlearn: 0.0590870\ttotal: 1.74s\tremaining: 2.13s\n",
      "450:\tlearn: 0.0590360\ttotal: 1.75s\tremaining: 2.13s\n",
      "451:\tlearn: 0.0589651\ttotal: 1.75s\tremaining: 2.12s\n",
      "452:\tlearn: 0.0588739\ttotal: 1.75s\tremaining: 2.12s\n",
      "453:\tlearn: 0.0587992\ttotal: 1.76s\tremaining: 2.11s\n",
      "454:\tlearn: 0.0587354\ttotal: 1.76s\tremaining: 2.11s\n",
      "455:\tlearn: 0.0586892\ttotal: 1.77s\tremaining: 2.11s\n",
      "456:\tlearn: 0.0585991\ttotal: 1.77s\tremaining: 2.1s\n",
      "457:\tlearn: 0.0585129\ttotal: 1.77s\tremaining: 2.1s\n",
      "458:\tlearn: 0.0584405\ttotal: 1.78s\tremaining: 2.1s\n",
      "459:\tlearn: 0.0583899\ttotal: 1.78s\tremaining: 2.09s\n",
      "460:\tlearn: 0.0583389\ttotal: 1.78s\tremaining: 2.09s\n",
      "461:\tlearn: 0.0582324\ttotal: 1.79s\tremaining: 2.08s\n",
      "462:\tlearn: 0.0581698\ttotal: 1.79s\tremaining: 2.08s\n",
      "463:\tlearn: 0.0580844\ttotal: 1.8s\tremaining: 2.08s\n",
      "464:\tlearn: 0.0580572\ttotal: 1.8s\tremaining: 2.07s\n",
      "465:\tlearn: 0.0580208\ttotal: 1.8s\tremaining: 2.07s\n",
      "466:\tlearn: 0.0579589\ttotal: 1.81s\tremaining: 2.06s\n",
      "467:\tlearn: 0.0578469\ttotal: 1.81s\tremaining: 2.06s\n",
      "468:\tlearn: 0.0577607\ttotal: 1.81s\tremaining: 2.06s\n",
      "469:\tlearn: 0.0576344\ttotal: 1.82s\tremaining: 2.05s\n",
      "470:\tlearn: 0.0575191\ttotal: 1.82s\tremaining: 2.05s\n",
      "471:\tlearn: 0.0574790\ttotal: 1.83s\tremaining: 2.04s\n",
      "472:\tlearn: 0.0573861\ttotal: 1.83s\tremaining: 2.04s\n",
      "473:\tlearn: 0.0573318\ttotal: 1.83s\tremaining: 2.03s\n",
      "474:\tlearn: 0.0572252\ttotal: 1.84s\tremaining: 2.03s\n",
      "475:\tlearn: 0.0571994\ttotal: 1.84s\tremaining: 2.02s\n",
      "476:\tlearn: 0.0571153\ttotal: 1.84s\tremaining: 2.02s\n",
      "477:\tlearn: 0.0570161\ttotal: 1.85s\tremaining: 2.02s\n",
      "478:\tlearn: 0.0569627\ttotal: 1.85s\tremaining: 2.01s\n",
      "479:\tlearn: 0.0568967\ttotal: 1.85s\tremaining: 2.01s\n",
      "480:\tlearn: 0.0568383\ttotal: 1.86s\tremaining: 2s\n",
      "481:\tlearn: 0.0568058\ttotal: 1.86s\tremaining: 2s\n",
      "482:\tlearn: 0.0567453\ttotal: 1.86s\tremaining: 2s\n",
      "483:\tlearn: 0.0566361\ttotal: 1.87s\tremaining: 1.99s\n",
      "484:\tlearn: 0.0565709\ttotal: 1.87s\tremaining: 1.99s\n",
      "485:\tlearn: 0.0564741\ttotal: 1.88s\tremaining: 1.98s\n",
      "486:\tlearn: 0.0564301\ttotal: 1.88s\tremaining: 1.98s\n",
      "487:\tlearn: 0.0563197\ttotal: 1.88s\tremaining: 1.98s\n",
      "488:\tlearn: 0.0562181\ttotal: 1.89s\tremaining: 1.97s\n",
      "489:\tlearn: 0.0561541\ttotal: 1.89s\tremaining: 1.97s\n",
      "490:\tlearn: 0.0560364\ttotal: 1.89s\tremaining: 1.96s\n",
      "491:\tlearn: 0.0560019\ttotal: 1.9s\tremaining: 1.96s\n",
      "492:\tlearn: 0.0559277\ttotal: 1.9s\tremaining: 1.96s\n",
      "493:\tlearn: 0.0558748\ttotal: 1.91s\tremaining: 1.95s\n",
      "494:\tlearn: 0.0558368\ttotal: 1.91s\tremaining: 1.95s\n",
      "495:\tlearn: 0.0557312\ttotal: 1.91s\tremaining: 1.94s\n",
      "496:\tlearn: 0.0556793\ttotal: 1.92s\tremaining: 1.94s\n",
      "497:\tlearn: 0.0556156\ttotal: 1.92s\tremaining: 1.94s\n",
      "498:\tlearn: 0.0555429\ttotal: 1.92s\tremaining: 1.93s\n",
      "499:\tlearn: 0.0554109\ttotal: 1.93s\tremaining: 1.93s\n",
      "500:\tlearn: 0.0553803\ttotal: 1.93s\tremaining: 1.93s\n",
      "501:\tlearn: 0.0552875\ttotal: 1.94s\tremaining: 1.92s\n",
      "502:\tlearn: 0.0552052\ttotal: 1.94s\tremaining: 1.92s\n",
      "503:\tlearn: 0.0551528\ttotal: 1.94s\tremaining: 1.91s\n",
      "504:\tlearn: 0.0550597\ttotal: 1.95s\tremaining: 1.91s\n",
      "505:\tlearn: 0.0549466\ttotal: 1.95s\tremaining: 1.91s\n",
      "506:\tlearn: 0.0548300\ttotal: 1.96s\tremaining: 1.9s\n",
      "507:\tlearn: 0.0547052\ttotal: 1.96s\tremaining: 1.9s\n",
      "508:\tlearn: 0.0546282\ttotal: 1.97s\tremaining: 1.9s\n",
      "509:\tlearn: 0.0545579\ttotal: 1.97s\tremaining: 1.89s\n",
      "510:\tlearn: 0.0544812\ttotal: 1.97s\tremaining: 1.89s\n",
      "511:\tlearn: 0.0544418\ttotal: 1.98s\tremaining: 1.88s\n",
      "512:\tlearn: 0.0544097\ttotal: 1.98s\tremaining: 1.88s\n",
      "513:\tlearn: 0.0543489\ttotal: 1.99s\tremaining: 1.88s\n",
      "514:\tlearn: 0.0542426\ttotal: 1.99s\tremaining: 1.87s\n",
      "515:\tlearn: 0.0542030\ttotal: 1.99s\tremaining: 1.87s\n",
      "516:\tlearn: 0.0541024\ttotal: 2s\tremaining: 1.87s\n",
      "517:\tlearn: 0.0540102\ttotal: 2s\tremaining: 1.86s\n",
      "518:\tlearn: 0.0539914\ttotal: 2.01s\tremaining: 1.86s\n",
      "519:\tlearn: 0.0539445\ttotal: 2.01s\tremaining: 1.85s\n",
      "520:\tlearn: 0.0538899\ttotal: 2.01s\tremaining: 1.85s\n",
      "521:\tlearn: 0.0538335\ttotal: 2.02s\tremaining: 1.85s\n",
      "522:\tlearn: 0.0537752\ttotal: 2.02s\tremaining: 1.84s\n",
      "523:\tlearn: 0.0537216\ttotal: 2.03s\tremaining: 1.84s\n",
      "524:\tlearn: 0.0536565\ttotal: 2.03s\tremaining: 1.84s\n",
      "525:\tlearn: 0.0535611\ttotal: 2.03s\tremaining: 1.83s\n",
      "526:\tlearn: 0.0534944\ttotal: 2.04s\tremaining: 1.83s\n",
      "527:\tlearn: 0.0534661\ttotal: 2.04s\tremaining: 1.82s\n",
      "528:\tlearn: 0.0533497\ttotal: 2.05s\tremaining: 1.82s\n",
      "529:\tlearn: 0.0533180\ttotal: 2.05s\tremaining: 1.82s\n",
      "530:\tlearn: 0.0532701\ttotal: 2.05s\tremaining: 1.81s\n",
      "531:\tlearn: 0.0531954\ttotal: 2.06s\tremaining: 1.81s\n",
      "532:\tlearn: 0.0531596\ttotal: 2.06s\tremaining: 1.81s\n",
      "533:\tlearn: 0.0530859\ttotal: 2.07s\tremaining: 1.8s\n",
      "534:\tlearn: 0.0530261\ttotal: 2.07s\tremaining: 1.8s\n",
      "535:\tlearn: 0.0529154\ttotal: 2.07s\tremaining: 1.79s\n",
      "536:\tlearn: 0.0528478\ttotal: 2.08s\tremaining: 1.79s\n",
      "537:\tlearn: 0.0527892\ttotal: 2.08s\tremaining: 1.79s\n",
      "538:\tlearn: 0.0527401\ttotal: 2.09s\tremaining: 1.78s\n",
      "539:\tlearn: 0.0526892\ttotal: 2.09s\tremaining: 1.78s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "540:\tlearn: 0.0526402\ttotal: 2.1s\tremaining: 1.78s\n",
      "541:\tlearn: 0.0526166\ttotal: 2.1s\tremaining: 1.77s\n",
      "542:\tlearn: 0.0525495\ttotal: 2.1s\tremaining: 1.77s\n",
      "543:\tlearn: 0.0525039\ttotal: 2.11s\tremaining: 1.77s\n",
      "544:\tlearn: 0.0523742\ttotal: 2.11s\tremaining: 1.76s\n",
      "545:\tlearn: 0.0522369\ttotal: 2.12s\tremaining: 1.76s\n",
      "546:\tlearn: 0.0521541\ttotal: 2.12s\tremaining: 1.76s\n",
      "547:\tlearn: 0.0521015\ttotal: 2.13s\tremaining: 1.75s\n",
      "548:\tlearn: 0.0520125\ttotal: 2.13s\tremaining: 1.75s\n",
      "549:\tlearn: 0.0519936\ttotal: 2.13s\tremaining: 1.75s\n",
      "550:\tlearn: 0.0519607\ttotal: 2.14s\tremaining: 1.74s\n",
      "551:\tlearn: 0.0518901\ttotal: 2.14s\tremaining: 1.74s\n",
      "552:\tlearn: 0.0518171\ttotal: 2.15s\tremaining: 1.74s\n",
      "553:\tlearn: 0.0517459\ttotal: 2.15s\tremaining: 1.73s\n",
      "554:\tlearn: 0.0516532\ttotal: 2.15s\tremaining: 1.73s\n",
      "555:\tlearn: 0.0516121\ttotal: 2.16s\tremaining: 1.72s\n",
      "556:\tlearn: 0.0514740\ttotal: 2.16s\tremaining: 1.72s\n",
      "557:\tlearn: 0.0514160\ttotal: 2.17s\tremaining: 1.72s\n",
      "558:\tlearn: 0.0513074\ttotal: 2.17s\tremaining: 1.71s\n",
      "559:\tlearn: 0.0512077\ttotal: 2.17s\tremaining: 1.71s\n",
      "560:\tlearn: 0.0511250\ttotal: 2.18s\tremaining: 1.7s\n",
      "561:\tlearn: 0.0510339\ttotal: 2.18s\tremaining: 1.7s\n",
      "562:\tlearn: 0.0510128\ttotal: 2.18s\tremaining: 1.7s\n",
      "563:\tlearn: 0.0509691\ttotal: 2.19s\tremaining: 1.69s\n",
      "564:\tlearn: 0.0508964\ttotal: 2.19s\tremaining: 1.69s\n",
      "565:\tlearn: 0.0508202\ttotal: 2.2s\tremaining: 1.68s\n",
      "566:\tlearn: 0.0508032\ttotal: 2.2s\tremaining: 1.68s\n",
      "567:\tlearn: 0.0507590\ttotal: 2.2s\tremaining: 1.68s\n",
      "568:\tlearn: 0.0507379\ttotal: 2.21s\tremaining: 1.67s\n",
      "569:\tlearn: 0.0506803\ttotal: 2.21s\tremaining: 1.67s\n",
      "570:\tlearn: 0.0506713\ttotal: 2.21s\tremaining: 1.66s\n",
      "571:\tlearn: 0.0506214\ttotal: 2.22s\tremaining: 1.66s\n",
      "572:\tlearn: 0.0505827\ttotal: 2.22s\tremaining: 1.65s\n",
      "573:\tlearn: 0.0504703\ttotal: 2.22s\tremaining: 1.65s\n",
      "574:\tlearn: 0.0504273\ttotal: 2.23s\tremaining: 1.65s\n",
      "575:\tlearn: 0.0504043\ttotal: 2.23s\tremaining: 1.64s\n",
      "576:\tlearn: 0.0503373\ttotal: 2.24s\tremaining: 1.64s\n",
      "577:\tlearn: 0.0502863\ttotal: 2.24s\tremaining: 1.64s\n",
      "578:\tlearn: 0.0502435\ttotal: 2.24s\tremaining: 1.63s\n",
      "579:\tlearn: 0.0501968\ttotal: 2.25s\tremaining: 1.63s\n",
      "580:\tlearn: 0.0500724\ttotal: 2.25s\tremaining: 1.62s\n",
      "581:\tlearn: 0.0499950\ttotal: 2.25s\tremaining: 1.62s\n",
      "582:\tlearn: 0.0499353\ttotal: 2.26s\tremaining: 1.61s\n",
      "583:\tlearn: 0.0498811\ttotal: 2.26s\tremaining: 1.61s\n",
      "584:\tlearn: 0.0498438\ttotal: 2.27s\tremaining: 1.61s\n",
      "585:\tlearn: 0.0498021\ttotal: 2.27s\tremaining: 1.6s\n",
      "586:\tlearn: 0.0497519\ttotal: 2.28s\tremaining: 1.6s\n",
      "587:\tlearn: 0.0496646\ttotal: 2.28s\tremaining: 1.6s\n",
      "588:\tlearn: 0.0496004\ttotal: 2.28s\tremaining: 1.59s\n",
      "589:\tlearn: 0.0495682\ttotal: 2.29s\tremaining: 1.59s\n",
      "590:\tlearn: 0.0495209\ttotal: 2.29s\tremaining: 1.59s\n",
      "591:\tlearn: 0.0494488\ttotal: 2.3s\tremaining: 1.58s\n",
      "592:\tlearn: 0.0494273\ttotal: 2.3s\tremaining: 1.58s\n",
      "593:\tlearn: 0.0493611\ttotal: 2.31s\tremaining: 1.58s\n",
      "594:\tlearn: 0.0493447\ttotal: 2.31s\tremaining: 1.57s\n",
      "595:\tlearn: 0.0492477\ttotal: 2.31s\tremaining: 1.57s\n",
      "596:\tlearn: 0.0492291\ttotal: 2.32s\tremaining: 1.56s\n",
      "597:\tlearn: 0.0491897\ttotal: 2.32s\tremaining: 1.56s\n",
      "598:\tlearn: 0.0491737\ttotal: 2.33s\tremaining: 1.56s\n",
      "599:\tlearn: 0.0491060\ttotal: 2.33s\tremaining: 1.55s\n",
      "600:\tlearn: 0.0490824\ttotal: 2.33s\tremaining: 1.55s\n",
      "601:\tlearn: 0.0490477\ttotal: 2.34s\tremaining: 1.55s\n",
      "602:\tlearn: 0.0489658\ttotal: 2.34s\tremaining: 1.54s\n",
      "603:\tlearn: 0.0489482\ttotal: 2.35s\tremaining: 1.54s\n",
      "604:\tlearn: 0.0489155\ttotal: 2.35s\tremaining: 1.53s\n",
      "605:\tlearn: 0.0488740\ttotal: 2.35s\tremaining: 1.53s\n",
      "606:\tlearn: 0.0488105\ttotal: 2.36s\tremaining: 1.53s\n",
      "607:\tlearn: 0.0487714\ttotal: 2.36s\tremaining: 1.52s\n",
      "608:\tlearn: 0.0487397\ttotal: 2.37s\tremaining: 1.52s\n",
      "609:\tlearn: 0.0486887\ttotal: 2.37s\tremaining: 1.51s\n",
      "610:\tlearn: 0.0486531\ttotal: 2.38s\tremaining: 1.51s\n",
      "611:\tlearn: 0.0486220\ttotal: 2.38s\tremaining: 1.51s\n",
      "612:\tlearn: 0.0485577\ttotal: 2.38s\tremaining: 1.5s\n",
      "613:\tlearn: 0.0484566\ttotal: 2.39s\tremaining: 1.5s\n",
      "614:\tlearn: 0.0484193\ttotal: 2.39s\tremaining: 1.5s\n",
      "615:\tlearn: 0.0483675\ttotal: 2.4s\tremaining: 1.49s\n",
      "616:\tlearn: 0.0483229\ttotal: 2.4s\tremaining: 1.49s\n",
      "617:\tlearn: 0.0482975\ttotal: 2.4s\tremaining: 1.49s\n",
      "618:\tlearn: 0.0482393\ttotal: 2.41s\tremaining: 1.48s\n",
      "619:\tlearn: 0.0482253\ttotal: 2.41s\tremaining: 1.48s\n",
      "620:\tlearn: 0.0481797\ttotal: 2.42s\tremaining: 1.47s\n",
      "621:\tlearn: 0.0481185\ttotal: 2.42s\tremaining: 1.47s\n",
      "622:\tlearn: 0.0480724\ttotal: 2.42s\tremaining: 1.47s\n",
      "623:\tlearn: 0.0480109\ttotal: 2.43s\tremaining: 1.46s\n",
      "624:\tlearn: 0.0479888\ttotal: 2.43s\tremaining: 1.46s\n",
      "625:\tlearn: 0.0479691\ttotal: 2.44s\tremaining: 1.46s\n",
      "626:\tlearn: 0.0479489\ttotal: 2.44s\tremaining: 1.45s\n",
      "627:\tlearn: 0.0478990\ttotal: 2.45s\tremaining: 1.45s\n",
      "628:\tlearn: 0.0478581\ttotal: 2.45s\tremaining: 1.45s\n",
      "629:\tlearn: 0.0477890\ttotal: 2.46s\tremaining: 1.44s\n",
      "630:\tlearn: 0.0477153\ttotal: 2.46s\tremaining: 1.44s\n",
      "631:\tlearn: 0.0476698\ttotal: 2.47s\tremaining: 1.44s\n",
      "632:\tlearn: 0.0476494\ttotal: 2.47s\tremaining: 1.43s\n",
      "633:\tlearn: 0.0476010\ttotal: 2.48s\tremaining: 1.43s\n",
      "634:\tlearn: 0.0475692\ttotal: 2.48s\tremaining: 1.43s\n",
      "635:\tlearn: 0.0475324\ttotal: 2.48s\tremaining: 1.42s\n",
      "636:\tlearn: 0.0474951\ttotal: 2.49s\tremaining: 1.42s\n",
      "637:\tlearn: 0.0474354\ttotal: 2.49s\tremaining: 1.42s\n",
      "638:\tlearn: 0.0473771\ttotal: 2.5s\tremaining: 1.41s\n",
      "639:\tlearn: 0.0472951\ttotal: 2.5s\tremaining: 1.41s\n",
      "640:\tlearn: 0.0472758\ttotal: 2.51s\tremaining: 1.4s\n",
      "641:\tlearn: 0.0472341\ttotal: 2.51s\tremaining: 1.4s\n",
      "642:\tlearn: 0.0471695\ttotal: 2.52s\tremaining: 1.4s\n",
      "643:\tlearn: 0.0471284\ttotal: 2.52s\tremaining: 1.39s\n",
      "644:\tlearn: 0.0469961\ttotal: 2.52s\tremaining: 1.39s\n",
      "645:\tlearn: 0.0469677\ttotal: 2.53s\tremaining: 1.39s\n",
      "646:\tlearn: 0.0469405\ttotal: 2.53s\tremaining: 1.38s\n",
      "647:\tlearn: 0.0468921\ttotal: 2.54s\tremaining: 1.38s\n",
      "648:\tlearn: 0.0468681\ttotal: 2.54s\tremaining: 1.37s\n",
      "649:\tlearn: 0.0468338\ttotal: 2.54s\tremaining: 1.37s\n",
      "650:\tlearn: 0.0468032\ttotal: 2.55s\tremaining: 1.37s\n",
      "651:\tlearn: 0.0467238\ttotal: 2.55s\tremaining: 1.36s\n",
      "652:\tlearn: 0.0466876\ttotal: 2.56s\tremaining: 1.36s\n",
      "653:\tlearn: 0.0466457\ttotal: 2.56s\tremaining: 1.35s\n",
      "654:\tlearn: 0.0466040\ttotal: 2.56s\tremaining: 1.35s\n",
      "655:\tlearn: 0.0465746\ttotal: 2.57s\tremaining: 1.35s\n",
      "656:\tlearn: 0.0465335\ttotal: 2.57s\tremaining: 1.34s\n",
      "657:\tlearn: 0.0464879\ttotal: 2.58s\tremaining: 1.34s\n",
      "658:\tlearn: 0.0464717\ttotal: 2.58s\tremaining: 1.33s\n",
      "659:\tlearn: 0.0464437\ttotal: 2.58s\tremaining: 1.33s\n",
      "660:\tlearn: 0.0464038\ttotal: 2.59s\tremaining: 1.33s\n",
      "661:\tlearn: 0.0463796\ttotal: 2.59s\tremaining: 1.32s\n",
      "662:\tlearn: 0.0463507\ttotal: 2.6s\tremaining: 1.32s\n",
      "663:\tlearn: 0.0463119\ttotal: 2.6s\tremaining: 1.31s\n",
      "664:\tlearn: 0.0462772\ttotal: 2.6s\tremaining: 1.31s\n",
      "665:\tlearn: 0.0462513\ttotal: 2.61s\tremaining: 1.31s\n",
      "666:\tlearn: 0.0462067\ttotal: 2.61s\tremaining: 1.3s\n",
      "667:\tlearn: 0.0461799\ttotal: 2.62s\tremaining: 1.3s\n",
      "668:\tlearn: 0.0461489\ttotal: 2.62s\tremaining: 1.3s\n",
      "669:\tlearn: 0.0460727\ttotal: 2.63s\tremaining: 1.29s\n",
      "670:\tlearn: 0.0459875\ttotal: 2.63s\tremaining: 1.29s\n",
      "671:\tlearn: 0.0459601\ttotal: 2.64s\tremaining: 1.29s\n",
      "672:\tlearn: 0.0458800\ttotal: 2.64s\tremaining: 1.28s\n",
      "673:\tlearn: 0.0458378\ttotal: 2.65s\tremaining: 1.28s\n",
      "674:\tlearn: 0.0458187\ttotal: 2.65s\tremaining: 1.28s\n",
      "675:\tlearn: 0.0457791\ttotal: 2.66s\tremaining: 1.27s\n",
      "676:\tlearn: 0.0457115\ttotal: 2.66s\tremaining: 1.27s\n",
      "677:\tlearn: 0.0456989\ttotal: 2.67s\tremaining: 1.27s\n",
      "678:\tlearn: 0.0456723\ttotal: 2.67s\tremaining: 1.26s\n",
      "679:\tlearn: 0.0456481\ttotal: 2.68s\tremaining: 1.26s\n",
      "680:\tlearn: 0.0456122\ttotal: 2.68s\tremaining: 1.26s\n",
      "681:\tlearn: 0.0455449\ttotal: 2.69s\tremaining: 1.25s\n",
      "682:\tlearn: 0.0455135\ttotal: 2.69s\tremaining: 1.25s\n",
      "683:\tlearn: 0.0454865\ttotal: 2.7s\tremaining: 1.25s\n",
      "684:\tlearn: 0.0454639\ttotal: 2.7s\tremaining: 1.24s\n",
      "685:\tlearn: 0.0454004\ttotal: 2.71s\tremaining: 1.24s\n",
      "686:\tlearn: 0.0453554\ttotal: 2.71s\tremaining: 1.24s\n",
      "687:\tlearn: 0.0453428\ttotal: 2.72s\tremaining: 1.23s\n",
      "688:\tlearn: 0.0453082\ttotal: 2.72s\tremaining: 1.23s\n",
      "689:\tlearn: 0.0452850\ttotal: 2.73s\tremaining: 1.23s\n",
      "690:\tlearn: 0.0452613\ttotal: 2.73s\tremaining: 1.22s\n",
      "691:\tlearn: 0.0452388\ttotal: 2.74s\tremaining: 1.22s\n",
      "692:\tlearn: 0.0452096\ttotal: 2.74s\tremaining: 1.21s\n",
      "693:\tlearn: 0.0451832\ttotal: 2.75s\tremaining: 1.21s\n",
      "694:\tlearn: 0.0451503\ttotal: 2.75s\tremaining: 1.21s\n",
      "695:\tlearn: 0.0450374\ttotal: 2.75s\tremaining: 1.2s\n",
      "696:\tlearn: 0.0450001\ttotal: 2.76s\tremaining: 1.2s\n",
      "697:\tlearn: 0.0449710\ttotal: 2.76s\tremaining: 1.2s\n",
      "698:\tlearn: 0.0449349\ttotal: 2.77s\tremaining: 1.19s\n",
      "699:\tlearn: 0.0449122\ttotal: 2.77s\tremaining: 1.19s\n",
      "700:\tlearn: 0.0448802\ttotal: 2.77s\tremaining: 1.18s\n",
      "701:\tlearn: 0.0448199\ttotal: 2.78s\tremaining: 1.18s\n",
      "702:\tlearn: 0.0448014\ttotal: 2.78s\tremaining: 1.18s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "703:\tlearn: 0.0447411\ttotal: 2.79s\tremaining: 1.17s\n",
      "704:\tlearn: 0.0447211\ttotal: 2.79s\tremaining: 1.17s\n",
      "705:\tlearn: 0.0446846\ttotal: 2.8s\tremaining: 1.16s\n",
      "706:\tlearn: 0.0446105\ttotal: 2.8s\tremaining: 1.16s\n",
      "707:\tlearn: 0.0445895\ttotal: 2.81s\tremaining: 1.16s\n",
      "708:\tlearn: 0.0444763\ttotal: 2.81s\tremaining: 1.15s\n",
      "709:\tlearn: 0.0444206\ttotal: 2.81s\tremaining: 1.15s\n",
      "710:\tlearn: 0.0443712\ttotal: 2.82s\tremaining: 1.15s\n",
      "711:\tlearn: 0.0443494\ttotal: 2.82s\tremaining: 1.14s\n",
      "712:\tlearn: 0.0442743\ttotal: 2.83s\tremaining: 1.14s\n",
      "713:\tlearn: 0.0442350\ttotal: 2.83s\tremaining: 1.13s\n",
      "714:\tlearn: 0.0441827\ttotal: 2.83s\tremaining: 1.13s\n",
      "715:\tlearn: 0.0441592\ttotal: 2.84s\tremaining: 1.13s\n",
      "716:\tlearn: 0.0440753\ttotal: 2.84s\tremaining: 1.12s\n",
      "717:\tlearn: 0.0440381\ttotal: 2.85s\tremaining: 1.12s\n",
      "718:\tlearn: 0.0440305\ttotal: 2.85s\tremaining: 1.11s\n",
      "719:\tlearn: 0.0439801\ttotal: 2.85s\tremaining: 1.11s\n",
      "720:\tlearn: 0.0439546\ttotal: 2.86s\tremaining: 1.11s\n",
      "721:\tlearn: 0.0439012\ttotal: 2.86s\tremaining: 1.1s\n",
      "722:\tlearn: 0.0438900\ttotal: 2.87s\tremaining: 1.1s\n",
      "723:\tlearn: 0.0438165\ttotal: 2.87s\tremaining: 1.09s\n",
      "724:\tlearn: 0.0437960\ttotal: 2.88s\tremaining: 1.09s\n",
      "725:\tlearn: 0.0437116\ttotal: 2.88s\tremaining: 1.09s\n",
      "726:\tlearn: 0.0436893\ttotal: 2.89s\tremaining: 1.08s\n",
      "727:\tlearn: 0.0436579\ttotal: 2.89s\tremaining: 1.08s\n",
      "728:\tlearn: 0.0435978\ttotal: 2.89s\tremaining: 1.08s\n",
      "729:\tlearn: 0.0435528\ttotal: 2.9s\tremaining: 1.07s\n",
      "730:\tlearn: 0.0435269\ttotal: 2.9s\tremaining: 1.07s\n",
      "731:\tlearn: 0.0434935\ttotal: 2.91s\tremaining: 1.06s\n",
      "732:\tlearn: 0.0434647\ttotal: 2.91s\tremaining: 1.06s\n",
      "733:\tlearn: 0.0433659\ttotal: 2.92s\tremaining: 1.06s\n",
      "734:\tlearn: 0.0433294\ttotal: 2.92s\tremaining: 1.05s\n",
      "735:\tlearn: 0.0433074\ttotal: 2.92s\tremaining: 1.05s\n",
      "736:\tlearn: 0.0432318\ttotal: 2.93s\tremaining: 1.04s\n",
      "737:\tlearn: 0.0431851\ttotal: 2.93s\tremaining: 1.04s\n",
      "738:\tlearn: 0.0431757\ttotal: 2.94s\tremaining: 1.04s\n",
      "739:\tlearn: 0.0431546\ttotal: 2.94s\tremaining: 1.03s\n",
      "740:\tlearn: 0.0430963\ttotal: 2.95s\tremaining: 1.03s\n",
      "741:\tlearn: 0.0430336\ttotal: 2.95s\tremaining: 1.02s\n",
      "742:\tlearn: 0.0430079\ttotal: 2.96s\tremaining: 1.02s\n",
      "743:\tlearn: 0.0429835\ttotal: 2.96s\tremaining: 1.02s\n",
      "744:\tlearn: 0.0429556\ttotal: 2.96s\tremaining: 1.01s\n",
      "745:\tlearn: 0.0429247\ttotal: 2.97s\tremaining: 1.01s\n",
      "746:\tlearn: 0.0429083\ttotal: 2.97s\tremaining: 1.01s\n",
      "747:\tlearn: 0.0428681\ttotal: 2.98s\tremaining: 1s\n",
      "748:\tlearn: 0.0428259\ttotal: 2.98s\tremaining: 999ms\n",
      "749:\tlearn: 0.0428112\ttotal: 2.98s\tremaining: 995ms\n",
      "750:\tlearn: 0.0427739\ttotal: 2.99s\tremaining: 991ms\n",
      "751:\tlearn: 0.0427204\ttotal: 2.99s\tremaining: 987ms\n",
      "752:\tlearn: 0.0426934\ttotal: 3s\tremaining: 983ms\n",
      "753:\tlearn: 0.0426858\ttotal: 3s\tremaining: 979ms\n",
      "754:\tlearn: 0.0426235\ttotal: 3s\tremaining: 975ms\n",
      "755:\tlearn: 0.0425997\ttotal: 3.01s\tremaining: 971ms\n",
      "756:\tlearn: 0.0425791\ttotal: 3.01s\tremaining: 967ms\n",
      "757:\tlearn: 0.0425540\ttotal: 3.02s\tremaining: 963ms\n",
      "758:\tlearn: 0.0425128\ttotal: 3.02s\tremaining: 959ms\n",
      "759:\tlearn: 0.0424918\ttotal: 3.02s\tremaining: 955ms\n",
      "760:\tlearn: 0.0424636\ttotal: 3.03s\tremaining: 951ms\n",
      "761:\tlearn: 0.0423868\ttotal: 3.03s\tremaining: 947ms\n",
      "762:\tlearn: 0.0423359\ttotal: 3.04s\tremaining: 944ms\n",
      "763:\tlearn: 0.0422780\ttotal: 3.04s\tremaining: 940ms\n",
      "764:\tlearn: 0.0422102\ttotal: 3.05s\tremaining: 936ms\n",
      "765:\tlearn: 0.0421656\ttotal: 3.05s\tremaining: 932ms\n",
      "766:\tlearn: 0.0421231\ttotal: 3.06s\tremaining: 929ms\n",
      "767:\tlearn: 0.0421100\ttotal: 3.06s\tremaining: 925ms\n",
      "768:\tlearn: 0.0420833\ttotal: 3.07s\tremaining: 921ms\n",
      "769:\tlearn: 0.0420620\ttotal: 3.07s\tremaining: 917ms\n",
      "770:\tlearn: 0.0419932\ttotal: 3.08s\tremaining: 913ms\n",
      "771:\tlearn: 0.0419468\ttotal: 3.08s\tremaining: 910ms\n",
      "772:\tlearn: 0.0419241\ttotal: 3.08s\tremaining: 906ms\n",
      "773:\tlearn: 0.0418861\ttotal: 3.09s\tremaining: 902ms\n",
      "774:\tlearn: 0.0418125\ttotal: 3.09s\tremaining: 898ms\n",
      "775:\tlearn: 0.0417690\ttotal: 3.1s\tremaining: 894ms\n",
      "776:\tlearn: 0.0416986\ttotal: 3.1s\tremaining: 890ms\n",
      "777:\tlearn: 0.0416731\ttotal: 3.1s\tremaining: 886ms\n",
      "778:\tlearn: 0.0416471\ttotal: 3.11s\tremaining: 882ms\n",
      "779:\tlearn: 0.0416149\ttotal: 3.11s\tremaining: 878ms\n",
      "780:\tlearn: 0.0416040\ttotal: 3.12s\tremaining: 874ms\n",
      "781:\tlearn: 0.0415743\ttotal: 3.12s\tremaining: 870ms\n",
      "782:\tlearn: 0.0415466\ttotal: 3.13s\tremaining: 866ms\n",
      "783:\tlearn: 0.0415080\ttotal: 3.13s\tremaining: 862ms\n",
      "784:\tlearn: 0.0414972\ttotal: 3.13s\tremaining: 858ms\n",
      "785:\tlearn: 0.0414778\ttotal: 3.14s\tremaining: 854ms\n",
      "786:\tlearn: 0.0414602\ttotal: 3.14s\tremaining: 850ms\n",
      "787:\tlearn: 0.0414078\ttotal: 3.15s\tremaining: 846ms\n",
      "788:\tlearn: 0.0413437\ttotal: 3.15s\tremaining: 842ms\n",
      "789:\tlearn: 0.0413200\ttotal: 3.15s\tremaining: 838ms\n",
      "790:\tlearn: 0.0412979\ttotal: 3.16s\tremaining: 834ms\n",
      "791:\tlearn: 0.0412568\ttotal: 3.16s\tremaining: 830ms\n",
      "792:\tlearn: 0.0412147\ttotal: 3.16s\tremaining: 826ms\n",
      "793:\tlearn: 0.0411573\ttotal: 3.17s\tremaining: 822ms\n",
      "794:\tlearn: 0.0411331\ttotal: 3.17s\tremaining: 818ms\n",
      "795:\tlearn: 0.0411255\ttotal: 3.18s\tremaining: 814ms\n",
      "796:\tlearn: 0.0411006\ttotal: 3.18s\tremaining: 810ms\n",
      "797:\tlearn: 0.0410628\ttotal: 3.19s\tremaining: 806ms\n",
      "798:\tlearn: 0.0410369\ttotal: 3.19s\tremaining: 802ms\n",
      "799:\tlearn: 0.0409518\ttotal: 3.19s\tremaining: 798ms\n",
      "800:\tlearn: 0.0408412\ttotal: 3.2s\tremaining: 794ms\n",
      "801:\tlearn: 0.0407850\ttotal: 3.2s\tremaining: 791ms\n",
      "802:\tlearn: 0.0407212\ttotal: 3.21s\tremaining: 787ms\n",
      "803:\tlearn: 0.0406788\ttotal: 3.21s\tremaining: 783ms\n",
      "804:\tlearn: 0.0406544\ttotal: 3.21s\tremaining: 779ms\n",
      "805:\tlearn: 0.0405459\ttotal: 3.22s\tremaining: 775ms\n",
      "806:\tlearn: 0.0404913\ttotal: 3.22s\tremaining: 771ms\n",
      "807:\tlearn: 0.0404745\ttotal: 3.23s\tremaining: 767ms\n",
      "808:\tlearn: 0.0404507\ttotal: 3.23s\tremaining: 763ms\n",
      "809:\tlearn: 0.0404335\ttotal: 3.23s\tremaining: 759ms\n",
      "810:\tlearn: 0.0403960\ttotal: 3.24s\tremaining: 755ms\n",
      "811:\tlearn: 0.0403571\ttotal: 3.24s\tremaining: 751ms\n",
      "812:\tlearn: 0.0403475\ttotal: 3.25s\tremaining: 747ms\n",
      "813:\tlearn: 0.0403314\ttotal: 3.25s\tremaining: 743ms\n",
      "814:\tlearn: 0.0402727\ttotal: 3.25s\tremaining: 739ms\n",
      "815:\tlearn: 0.0401814\ttotal: 3.26s\tremaining: 735ms\n",
      "816:\tlearn: 0.0401551\ttotal: 3.26s\tremaining: 731ms\n",
      "817:\tlearn: 0.0400933\ttotal: 3.27s\tremaining: 727ms\n",
      "818:\tlearn: 0.0400777\ttotal: 3.27s\tremaining: 723ms\n",
      "819:\tlearn: 0.0400403\ttotal: 3.28s\tremaining: 719ms\n",
      "820:\tlearn: 0.0400175\ttotal: 3.28s\tremaining: 716ms\n",
      "821:\tlearn: 0.0399716\ttotal: 3.29s\tremaining: 712ms\n",
      "822:\tlearn: 0.0399546\ttotal: 3.29s\tremaining: 708ms\n",
      "823:\tlearn: 0.0399322\ttotal: 3.29s\tremaining: 704ms\n",
      "824:\tlearn: 0.0399157\ttotal: 3.3s\tremaining: 700ms\n",
      "825:\tlearn: 0.0398824\ttotal: 3.3s\tremaining: 696ms\n",
      "826:\tlearn: 0.0398662\ttotal: 3.31s\tremaining: 692ms\n",
      "827:\tlearn: 0.0397739\ttotal: 3.31s\tremaining: 688ms\n",
      "828:\tlearn: 0.0397501\ttotal: 3.32s\tremaining: 684ms\n",
      "829:\tlearn: 0.0396894\ttotal: 3.32s\tremaining: 680ms\n",
      "830:\tlearn: 0.0395998\ttotal: 3.33s\tremaining: 676ms\n",
      "831:\tlearn: 0.0395608\ttotal: 3.33s\tremaining: 672ms\n",
      "832:\tlearn: 0.0394720\ttotal: 3.33s\tremaining: 668ms\n",
      "833:\tlearn: 0.0394398\ttotal: 3.34s\tremaining: 664ms\n",
      "834:\tlearn: 0.0394212\ttotal: 3.34s\tremaining: 660ms\n",
      "835:\tlearn: 0.0393671\ttotal: 3.35s\tremaining: 656ms\n",
      "836:\tlearn: 0.0393241\ttotal: 3.35s\tremaining: 652ms\n",
      "837:\tlearn: 0.0392894\ttotal: 3.35s\tremaining: 648ms\n",
      "838:\tlearn: 0.0391905\ttotal: 3.36s\tremaining: 645ms\n",
      "839:\tlearn: 0.0391539\ttotal: 3.36s\tremaining: 641ms\n",
      "840:\tlearn: 0.0391309\ttotal: 3.37s\tremaining: 637ms\n",
      "841:\tlearn: 0.0391094\ttotal: 3.37s\tremaining: 632ms\n",
      "842:\tlearn: 0.0390970\ttotal: 3.37s\tremaining: 628ms\n",
      "843:\tlearn: 0.0390575\ttotal: 3.38s\tremaining: 624ms\n",
      "844:\tlearn: 0.0390267\ttotal: 3.38s\tremaining: 620ms\n",
      "845:\tlearn: 0.0390121\ttotal: 3.38s\tremaining: 616ms\n",
      "846:\tlearn: 0.0389647\ttotal: 3.39s\tremaining: 612ms\n",
      "847:\tlearn: 0.0389486\ttotal: 3.39s\tremaining: 608ms\n",
      "848:\tlearn: 0.0389146\ttotal: 3.4s\tremaining: 604ms\n",
      "849:\tlearn: 0.0388821\ttotal: 3.4s\tremaining: 600ms\n",
      "850:\tlearn: 0.0388625\ttotal: 3.4s\tremaining: 596ms\n",
      "851:\tlearn: 0.0388188\ttotal: 3.41s\tremaining: 592ms\n",
      "852:\tlearn: 0.0388013\ttotal: 3.41s\tremaining: 588ms\n",
      "853:\tlearn: 0.0387549\ttotal: 3.42s\tremaining: 584ms\n",
      "854:\tlearn: 0.0387101\ttotal: 3.42s\tremaining: 580ms\n",
      "855:\tlearn: 0.0386889\ttotal: 3.42s\tremaining: 576ms\n",
      "856:\tlearn: 0.0386610\ttotal: 3.43s\tremaining: 572ms\n",
      "857:\tlearn: 0.0386470\ttotal: 3.43s\tremaining: 568ms\n",
      "858:\tlearn: 0.0386253\ttotal: 3.44s\tremaining: 564ms\n",
      "859:\tlearn: 0.0386037\ttotal: 3.44s\tremaining: 560ms\n",
      "860:\tlearn: 0.0385701\ttotal: 3.44s\tremaining: 556ms\n",
      "861:\tlearn: 0.0385291\ttotal: 3.45s\tremaining: 552ms\n",
      "862:\tlearn: 0.0385082\ttotal: 3.45s\tremaining: 548ms\n",
      "863:\tlearn: 0.0384876\ttotal: 3.46s\tremaining: 544ms\n",
      "864:\tlearn: 0.0384632\ttotal: 3.46s\tremaining: 540ms\n",
      "865:\tlearn: 0.0384359\ttotal: 3.47s\tremaining: 536ms\n",
      "866:\tlearn: 0.0383566\ttotal: 3.47s\tremaining: 532ms\n",
      "867:\tlearn: 0.0383274\ttotal: 3.47s\tremaining: 528ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "868:\tlearn: 0.0383139\ttotal: 3.48s\tremaining: 525ms\n",
      "869:\tlearn: 0.0382991\ttotal: 3.48s\tremaining: 521ms\n",
      "870:\tlearn: 0.0382753\ttotal: 3.49s\tremaining: 517ms\n",
      "871:\tlearn: 0.0382205\ttotal: 3.49s\tremaining: 513ms\n",
      "872:\tlearn: 0.0381997\ttotal: 3.5s\tremaining: 509ms\n",
      "873:\tlearn: 0.0381862\ttotal: 3.5s\tremaining: 505ms\n",
      "874:\tlearn: 0.0380957\ttotal: 3.5s\tremaining: 501ms\n",
      "875:\tlearn: 0.0380589\ttotal: 3.51s\tremaining: 497ms\n",
      "876:\tlearn: 0.0380378\ttotal: 3.51s\tremaining: 493ms\n",
      "877:\tlearn: 0.0380136\ttotal: 3.52s\tremaining: 488ms\n",
      "878:\tlearn: 0.0379539\ttotal: 3.52s\tremaining: 484ms\n",
      "879:\tlearn: 0.0379035\ttotal: 3.52s\tremaining: 480ms\n",
      "880:\tlearn: 0.0378557\ttotal: 3.53s\tremaining: 476ms\n",
      "881:\tlearn: 0.0377800\ttotal: 3.53s\tremaining: 472ms\n",
      "882:\tlearn: 0.0377316\ttotal: 3.54s\tremaining: 468ms\n",
      "883:\tlearn: 0.0376863\ttotal: 3.54s\tremaining: 464ms\n",
      "884:\tlearn: 0.0376333\ttotal: 3.54s\tremaining: 460ms\n",
      "885:\tlearn: 0.0375973\ttotal: 3.55s\tremaining: 457ms\n",
      "886:\tlearn: 0.0375776\ttotal: 3.55s\tremaining: 452ms\n",
      "887:\tlearn: 0.0375540\ttotal: 3.56s\tremaining: 448ms\n",
      "888:\tlearn: 0.0374747\ttotal: 3.56s\tremaining: 445ms\n",
      "889:\tlearn: 0.0374571\ttotal: 3.56s\tremaining: 441ms\n",
      "890:\tlearn: 0.0373985\ttotal: 3.57s\tremaining: 437ms\n",
      "891:\tlearn: 0.0373925\ttotal: 3.57s\tremaining: 433ms\n",
      "892:\tlearn: 0.0373521\ttotal: 3.58s\tremaining: 429ms\n",
      "893:\tlearn: 0.0372972\ttotal: 3.58s\tremaining: 425ms\n",
      "894:\tlearn: 0.0372637\ttotal: 3.58s\tremaining: 421ms\n",
      "895:\tlearn: 0.0372292\ttotal: 3.59s\tremaining: 417ms\n",
      "896:\tlearn: 0.0371948\ttotal: 3.59s\tremaining: 413ms\n",
      "897:\tlearn: 0.0371755\ttotal: 3.6s\tremaining: 409ms\n",
      "898:\tlearn: 0.0371241\ttotal: 3.6s\tremaining: 405ms\n",
      "899:\tlearn: 0.0371051\ttotal: 3.6s\tremaining: 401ms\n",
      "900:\tlearn: 0.0370821\ttotal: 3.61s\tremaining: 397ms\n",
      "901:\tlearn: 0.0370456\ttotal: 3.61s\tremaining: 393ms\n",
      "902:\tlearn: 0.0369958\ttotal: 3.62s\tremaining: 389ms\n",
      "903:\tlearn: 0.0369524\ttotal: 3.62s\tremaining: 385ms\n",
      "904:\tlearn: 0.0369151\ttotal: 3.62s\tremaining: 380ms\n",
      "905:\tlearn: 0.0369095\ttotal: 3.63s\tremaining: 376ms\n",
      "906:\tlearn: 0.0368592\ttotal: 3.63s\tremaining: 372ms\n",
      "907:\tlearn: 0.0368141\ttotal: 3.64s\tremaining: 368ms\n",
      "908:\tlearn: 0.0367761\ttotal: 3.64s\tremaining: 364ms\n",
      "909:\tlearn: 0.0367270\ttotal: 3.64s\tremaining: 360ms\n",
      "910:\tlearn: 0.0366769\ttotal: 3.65s\tremaining: 356ms\n",
      "911:\tlearn: 0.0366274\ttotal: 3.65s\tremaining: 352ms\n",
      "912:\tlearn: 0.0365984\ttotal: 3.66s\tremaining: 348ms\n",
      "913:\tlearn: 0.0365499\ttotal: 3.66s\tremaining: 344ms\n",
      "914:\tlearn: 0.0365156\ttotal: 3.67s\tremaining: 341ms\n",
      "915:\tlearn: 0.0364969\ttotal: 3.67s\tremaining: 337ms\n",
      "916:\tlearn: 0.0364794\ttotal: 3.67s\tremaining: 333ms\n",
      "917:\tlearn: 0.0364545\ttotal: 3.68s\tremaining: 329ms\n",
      "918:\tlearn: 0.0364424\ttotal: 3.68s\tremaining: 325ms\n",
      "919:\tlearn: 0.0363637\ttotal: 3.69s\tremaining: 321ms\n",
      "920:\tlearn: 0.0363269\ttotal: 3.69s\tremaining: 317ms\n",
      "921:\tlearn: 0.0362918\ttotal: 3.69s\tremaining: 313ms\n",
      "922:\tlearn: 0.0362747\ttotal: 3.7s\tremaining: 309ms\n",
      "923:\tlearn: 0.0362611\ttotal: 3.7s\tremaining: 305ms\n",
      "924:\tlearn: 0.0362050\ttotal: 3.71s\tremaining: 300ms\n",
      "925:\tlearn: 0.0361558\ttotal: 3.71s\tremaining: 296ms\n",
      "926:\tlearn: 0.0361038\ttotal: 3.71s\tremaining: 293ms\n",
      "927:\tlearn: 0.0360582\ttotal: 3.72s\tremaining: 289ms\n",
      "928:\tlearn: 0.0360153\ttotal: 3.72s\tremaining: 285ms\n",
      "929:\tlearn: 0.0359765\ttotal: 3.73s\tremaining: 281ms\n",
      "930:\tlearn: 0.0359522\ttotal: 3.73s\tremaining: 277ms\n",
      "931:\tlearn: 0.0359123\ttotal: 3.73s\tremaining: 273ms\n",
      "932:\tlearn: 0.0358814\ttotal: 3.74s\tremaining: 269ms\n",
      "933:\tlearn: 0.0358430\ttotal: 3.74s\tremaining: 265ms\n",
      "934:\tlearn: 0.0358020\ttotal: 3.75s\tremaining: 261ms\n",
      "935:\tlearn: 0.0357703\ttotal: 3.75s\tremaining: 257ms\n",
      "936:\tlearn: 0.0357521\ttotal: 3.76s\tremaining: 253ms\n",
      "937:\tlearn: 0.0357044\ttotal: 3.76s\tremaining: 249ms\n",
      "938:\tlearn: 0.0356672\ttotal: 3.76s\tremaining: 245ms\n",
      "939:\tlearn: 0.0356534\ttotal: 3.77s\tremaining: 241ms\n",
      "940:\tlearn: 0.0356234\ttotal: 3.77s\tremaining: 237ms\n",
      "941:\tlearn: 0.0355921\ttotal: 3.78s\tremaining: 233ms\n",
      "942:\tlearn: 0.0355684\ttotal: 3.78s\tremaining: 229ms\n",
      "943:\tlearn: 0.0355131\ttotal: 3.78s\tremaining: 225ms\n",
      "944:\tlearn: 0.0354898\ttotal: 3.79s\tremaining: 221ms\n",
      "945:\tlearn: 0.0354719\ttotal: 3.79s\tremaining: 217ms\n",
      "946:\tlearn: 0.0354408\ttotal: 3.8s\tremaining: 213ms\n",
      "947:\tlearn: 0.0353934\ttotal: 3.8s\tremaining: 209ms\n",
      "948:\tlearn: 0.0353406\ttotal: 3.81s\tremaining: 205ms\n",
      "949:\tlearn: 0.0353230\ttotal: 3.81s\tremaining: 201ms\n",
      "950:\tlearn: 0.0352853\ttotal: 3.81s\tremaining: 197ms\n",
      "951:\tlearn: 0.0352545\ttotal: 3.82s\tremaining: 193ms\n",
      "952:\tlearn: 0.0352155\ttotal: 3.82s\tremaining: 189ms\n",
      "953:\tlearn: 0.0351776\ttotal: 3.83s\tremaining: 185ms\n",
      "954:\tlearn: 0.0351552\ttotal: 3.83s\tremaining: 181ms\n",
      "955:\tlearn: 0.0351176\ttotal: 3.83s\tremaining: 177ms\n",
      "956:\tlearn: 0.0350823\ttotal: 3.84s\tremaining: 172ms\n",
      "957:\tlearn: 0.0350455\ttotal: 3.84s\tremaining: 168ms\n",
      "958:\tlearn: 0.0350366\ttotal: 3.85s\tremaining: 164ms\n",
      "959:\tlearn: 0.0349991\ttotal: 3.85s\tremaining: 160ms\n",
      "960:\tlearn: 0.0349818\ttotal: 3.85s\tremaining: 156ms\n",
      "961:\tlearn: 0.0349360\ttotal: 3.86s\tremaining: 152ms\n",
      "962:\tlearn: 0.0349195\ttotal: 3.86s\tremaining: 148ms\n",
      "963:\tlearn: 0.0348843\ttotal: 3.87s\tremaining: 144ms\n",
      "964:\tlearn: 0.0348567\ttotal: 3.87s\tremaining: 140ms\n",
      "965:\tlearn: 0.0348037\ttotal: 3.87s\tremaining: 136ms\n",
      "966:\tlearn: 0.0347816\ttotal: 3.88s\tremaining: 132ms\n",
      "967:\tlearn: 0.0347514\ttotal: 3.88s\tremaining: 128ms\n",
      "968:\tlearn: 0.0347175\ttotal: 3.88s\tremaining: 124ms\n",
      "969:\tlearn: 0.0346868\ttotal: 3.89s\tremaining: 120ms\n",
      "970:\tlearn: 0.0346574\ttotal: 3.89s\tremaining: 116ms\n",
      "971:\tlearn: 0.0346415\ttotal: 3.9s\tremaining: 112ms\n",
      "972:\tlearn: 0.0346294\ttotal: 3.9s\tremaining: 108ms\n",
      "973:\tlearn: 0.0346124\ttotal: 3.9s\tremaining: 104ms\n",
      "974:\tlearn: 0.0345748\ttotal: 3.91s\tremaining: 100ms\n",
      "975:\tlearn: 0.0345329\ttotal: 3.91s\tremaining: 96.2ms\n",
      "976:\tlearn: 0.0345161\ttotal: 3.91s\tremaining: 92.2ms\n",
      "977:\tlearn: 0.0344645\ttotal: 3.92s\tremaining: 88.2ms\n",
      "978:\tlearn: 0.0344416\ttotal: 3.92s\tremaining: 84.1ms\n",
      "979:\tlearn: 0.0344071\ttotal: 3.93s\tremaining: 80.1ms\n",
      "980:\tlearn: 0.0343722\ttotal: 3.93s\tremaining: 76.1ms\n",
      "981:\tlearn: 0.0343557\ttotal: 3.93s\tremaining: 72.1ms\n",
      "982:\tlearn: 0.0342958\ttotal: 3.94s\tremaining: 68.1ms\n",
      "983:\tlearn: 0.0342597\ttotal: 3.94s\tremaining: 64.1ms\n",
      "984:\tlearn: 0.0342261\ttotal: 3.94s\tremaining: 60.1ms\n",
      "985:\tlearn: 0.0341677\ttotal: 3.95s\tremaining: 56.1ms\n",
      "986:\tlearn: 0.0341334\ttotal: 3.95s\tremaining: 52ms\n",
      "987:\tlearn: 0.0340905\ttotal: 3.96s\tremaining: 48ms\n",
      "988:\tlearn: 0.0340789\ttotal: 3.96s\tremaining: 44ms\n",
      "989:\tlearn: 0.0340336\ttotal: 3.96s\tremaining: 40ms\n",
      "990:\tlearn: 0.0339794\ttotal: 3.97s\tremaining: 36ms\n",
      "991:\tlearn: 0.0339585\ttotal: 3.97s\tremaining: 32ms\n",
      "992:\tlearn: 0.0339327\ttotal: 3.97s\tremaining: 28ms\n",
      "993:\tlearn: 0.0339050\ttotal: 3.98s\tremaining: 24ms\n",
      "994:\tlearn: 0.0339002\ttotal: 3.98s\tremaining: 20ms\n",
      "995:\tlearn: 0.0338709\ttotal: 3.98s\tremaining: 16ms\n",
      "996:\tlearn: 0.0338205\ttotal: 3.99s\tremaining: 12ms\n",
      "997:\tlearn: 0.0337887\ttotal: 3.99s\tremaining: 8ms\n",
      "998:\tlearn: 0.0337353\ttotal: 4s\tremaining: 4ms\n",
      "999:\tlearn: 0.0336970\ttotal: 4s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013279\n",
      "0:\tlearn: 0.6660229\ttotal: 4.51ms\tremaining: 4.51s\n",
      "1:\tlearn: 0.6414282\ttotal: 8.08ms\tremaining: 4.03s\n",
      "2:\tlearn: 0.6150794\ttotal: 12.1ms\tremaining: 4.04s\n",
      "3:\tlearn: 0.5923854\ttotal: 15.9ms\tremaining: 3.96s\n",
      "4:\tlearn: 0.5704092\ttotal: 19.4ms\tremaining: 3.87s\n",
      "5:\tlearn: 0.5553391\ttotal: 22.9ms\tremaining: 3.79s\n",
      "6:\tlearn: 0.5344908\ttotal: 26.5ms\tremaining: 3.76s\n",
      "7:\tlearn: 0.5167089\ttotal: 30.7ms\tremaining: 3.81s\n",
      "8:\tlearn: 0.5012335\ttotal: 35.5ms\tremaining: 3.91s\n",
      "9:\tlearn: 0.4836862\ttotal: 39.9ms\tremaining: 3.95s\n",
      "10:\tlearn: 0.4681008\ttotal: 43.9ms\tremaining: 3.95s\n",
      "11:\tlearn: 0.4522384\ttotal: 47.6ms\tremaining: 3.92s\n",
      "12:\tlearn: 0.4369995\ttotal: 51ms\tremaining: 3.88s\n",
      "13:\tlearn: 0.4232093\ttotal: 54.8ms\tremaining: 3.86s\n",
      "14:\tlearn: 0.4103062\ttotal: 58.8ms\tremaining: 3.86s\n",
      "15:\tlearn: 0.3960069\ttotal: 62.4ms\tremaining: 3.83s\n",
      "16:\tlearn: 0.3852059\ttotal: 66.8ms\tremaining: 3.86s\n",
      "17:\tlearn: 0.3740031\ttotal: 71ms\tremaining: 3.87s\n",
      "18:\tlearn: 0.3628770\ttotal: 75.2ms\tremaining: 3.88s\n",
      "19:\tlearn: 0.3526249\ttotal: 79.8ms\tremaining: 3.91s\n",
      "20:\tlearn: 0.3432338\ttotal: 83.7ms\tremaining: 3.9s\n",
      "21:\tlearn: 0.3363583\ttotal: 87.6ms\tremaining: 3.9s\n",
      "22:\tlearn: 0.3269026\ttotal: 91.5ms\tremaining: 3.89s\n",
      "23:\tlearn: 0.3201950\ttotal: 95.5ms\tremaining: 3.88s\n",
      "24:\tlearn: 0.3115198\ttotal: 99.3ms\tremaining: 3.87s\n",
      "25:\tlearn: 0.3038389\ttotal: 103ms\tremaining: 3.87s\n",
      "26:\tlearn: 0.2973312\ttotal: 107ms\tremaining: 3.87s\n",
      "27:\tlearn: 0.2894603\ttotal: 111ms\tremaining: 3.86s\n",
      "28:\tlearn: 0.2827512\ttotal: 115ms\tremaining: 3.85s\n",
      "29:\tlearn: 0.2764164\ttotal: 118ms\tremaining: 3.83s\n",
      "30:\tlearn: 0.2695349\ttotal: 122ms\tremaining: 3.8s\n",
      "31:\tlearn: 0.2626895\ttotal: 125ms\tremaining: 3.79s\n",
      "32:\tlearn: 0.2566088\ttotal: 129ms\tremaining: 3.77s\n",
      "33:\tlearn: 0.2512198\ttotal: 132ms\tremaining: 3.75s\n",
      "34:\tlearn: 0.2455004\ttotal: 136ms\tremaining: 3.74s\n",
      "35:\tlearn: 0.2409243\ttotal: 139ms\tremaining: 3.72s\n",
      "36:\tlearn: 0.2360071\ttotal: 143ms\tremaining: 3.71s\n",
      "37:\tlearn: 0.2317585\ttotal: 146ms\tremaining: 3.7s\n",
      "38:\tlearn: 0.2275214\ttotal: 150ms\tremaining: 3.7s\n",
      "39:\tlearn: 0.2238469\ttotal: 154ms\tremaining: 3.7s\n",
      "40:\tlearn: 0.2200433\ttotal: 158ms\tremaining: 3.69s\n",
      "41:\tlearn: 0.2160499\ttotal: 161ms\tremaining: 3.67s\n",
      "42:\tlearn: 0.2121020\ttotal: 165ms\tremaining: 3.66s\n",
      "43:\tlearn: 0.2085548\ttotal: 168ms\tremaining: 3.66s\n",
      "44:\tlearn: 0.2053297\ttotal: 172ms\tremaining: 3.64s\n",
      "45:\tlearn: 0.2020880\ttotal: 175ms\tremaining: 3.63s\n",
      "46:\tlearn: 0.1982395\ttotal: 179ms\tremaining: 3.63s\n",
      "47:\tlearn: 0.1955453\ttotal: 183ms\tremaining: 3.63s\n",
      "48:\tlearn: 0.1924575\ttotal: 187ms\tremaining: 3.63s\n",
      "49:\tlearn: 0.1896430\ttotal: 191ms\tremaining: 3.64s\n",
      "50:\tlearn: 0.1874530\ttotal: 195ms\tremaining: 3.63s\n",
      "51:\tlearn: 0.1848077\ttotal: 199ms\tremaining: 3.63s\n",
      "52:\tlearn: 0.1821646\ttotal: 204ms\tremaining: 3.64s\n",
      "53:\tlearn: 0.1794736\ttotal: 208ms\tremaining: 3.64s\n",
      "54:\tlearn: 0.1773039\ttotal: 212ms\tremaining: 3.63s\n",
      "55:\tlearn: 0.1750779\ttotal: 216ms\tremaining: 3.64s\n",
      "56:\tlearn: 0.1726511\ttotal: 219ms\tremaining: 3.63s\n",
      "57:\tlearn: 0.1705439\ttotal: 223ms\tremaining: 3.63s\n",
      "58:\tlearn: 0.1686770\ttotal: 227ms\tremaining: 3.62s\n",
      "59:\tlearn: 0.1663311\ttotal: 231ms\tremaining: 3.63s\n",
      "60:\tlearn: 0.1644944\ttotal: 236ms\tremaining: 3.63s\n",
      "61:\tlearn: 0.1628184\ttotal: 240ms\tremaining: 3.63s\n",
      "62:\tlearn: 0.1610945\ttotal: 245ms\tremaining: 3.64s\n",
      "63:\tlearn: 0.1595109\ttotal: 249ms\tremaining: 3.65s\n",
      "64:\tlearn: 0.1578284\ttotal: 254ms\tremaining: 3.66s\n",
      "65:\tlearn: 0.1566307\ttotal: 258ms\tremaining: 3.65s\n",
      "66:\tlearn: 0.1551482\ttotal: 263ms\tremaining: 3.66s\n",
      "67:\tlearn: 0.1532504\ttotal: 267ms\tremaining: 3.66s\n",
      "68:\tlearn: 0.1519172\ttotal: 272ms\tremaining: 3.66s\n",
      "69:\tlearn: 0.1505805\ttotal: 276ms\tremaining: 3.67s\n",
      "70:\tlearn: 0.1490093\ttotal: 280ms\tremaining: 3.66s\n",
      "71:\tlearn: 0.1475661\ttotal: 284ms\tremaining: 3.65s\n",
      "72:\tlearn: 0.1462513\ttotal: 287ms\tremaining: 3.65s\n",
      "73:\tlearn: 0.1449607\ttotal: 291ms\tremaining: 3.64s\n",
      "74:\tlearn: 0.1437230\ttotal: 296ms\tremaining: 3.65s\n",
      "75:\tlearn: 0.1423790\ttotal: 299ms\tremaining: 3.64s\n",
      "76:\tlearn: 0.1414710\ttotal: 303ms\tremaining: 3.64s\n",
      "77:\tlearn: 0.1403957\ttotal: 307ms\tremaining: 3.63s\n",
      "78:\tlearn: 0.1391872\ttotal: 311ms\tremaining: 3.62s\n",
      "79:\tlearn: 0.1381663\ttotal: 314ms\tremaining: 3.61s\n",
      "80:\tlearn: 0.1370816\ttotal: 318ms\tremaining: 3.61s\n",
      "81:\tlearn: 0.1359898\ttotal: 322ms\tremaining: 3.6s\n",
      "82:\tlearn: 0.1350427\ttotal: 325ms\tremaining: 3.59s\n",
      "83:\tlearn: 0.1343513\ttotal: 329ms\tremaining: 3.58s\n",
      "84:\tlearn: 0.1335746\ttotal: 333ms\tremaining: 3.58s\n",
      "85:\tlearn: 0.1325751\ttotal: 336ms\tremaining: 3.57s\n",
      "86:\tlearn: 0.1316812\ttotal: 340ms\tremaining: 3.56s\n",
      "87:\tlearn: 0.1306981\ttotal: 344ms\tremaining: 3.56s\n",
      "88:\tlearn: 0.1297103\ttotal: 347ms\tremaining: 3.55s\n",
      "89:\tlearn: 0.1290026\ttotal: 350ms\tremaining: 3.54s\n",
      "90:\tlearn: 0.1277374\ttotal: 355ms\tremaining: 3.55s\n",
      "91:\tlearn: 0.1272425\ttotal: 360ms\tremaining: 3.55s\n",
      "92:\tlearn: 0.1263638\ttotal: 364ms\tremaining: 3.55s\n",
      "93:\tlearn: 0.1257968\ttotal: 368ms\tremaining: 3.55s\n",
      "94:\tlearn: 0.1250963\ttotal: 372ms\tremaining: 3.55s\n",
      "95:\tlearn: 0.1244122\ttotal: 377ms\tremaining: 3.55s\n",
      "96:\tlearn: 0.1236398\ttotal: 381ms\tremaining: 3.54s\n",
      "97:\tlearn: 0.1231681\ttotal: 385ms\tremaining: 3.55s\n",
      "98:\tlearn: 0.1225168\ttotal: 390ms\tremaining: 3.54s\n",
      "99:\tlearn: 0.1220610\ttotal: 394ms\tremaining: 3.54s\n",
      "100:\tlearn: 0.1214112\ttotal: 398ms\tremaining: 3.54s\n",
      "101:\tlearn: 0.1207624\ttotal: 402ms\tremaining: 3.54s\n",
      "102:\tlearn: 0.1199597\ttotal: 407ms\tremaining: 3.54s\n",
      "103:\tlearn: 0.1195076\ttotal: 411ms\tremaining: 3.54s\n",
      "104:\tlearn: 0.1189098\ttotal: 416ms\tremaining: 3.55s\n",
      "105:\tlearn: 0.1184309\ttotal: 421ms\tremaining: 3.55s\n",
      "106:\tlearn: 0.1180368\ttotal: 425ms\tremaining: 3.55s\n",
      "107:\tlearn: 0.1175864\ttotal: 429ms\tremaining: 3.54s\n",
      "108:\tlearn: 0.1167859\ttotal: 434ms\tremaining: 3.54s\n",
      "109:\tlearn: 0.1160746\ttotal: 438ms\tremaining: 3.54s\n",
      "110:\tlearn: 0.1156017\ttotal: 442ms\tremaining: 3.54s\n",
      "111:\tlearn: 0.1152927\ttotal: 447ms\tremaining: 3.54s\n",
      "112:\tlearn: 0.1147799\ttotal: 452ms\tremaining: 3.55s\n",
      "113:\tlearn: 0.1142588\ttotal: 457ms\tremaining: 3.55s\n",
      "114:\tlearn: 0.1139135\ttotal: 460ms\tremaining: 3.54s\n",
      "115:\tlearn: 0.1134944\ttotal: 465ms\tremaining: 3.54s\n",
      "116:\tlearn: 0.1129569\ttotal: 470ms\tremaining: 3.54s\n",
      "117:\tlearn: 0.1123880\ttotal: 474ms\tremaining: 3.54s\n",
      "118:\tlearn: 0.1119855\ttotal: 479ms\tremaining: 3.54s\n",
      "119:\tlearn: 0.1115549\ttotal: 483ms\tremaining: 3.54s\n",
      "120:\tlearn: 0.1110601\ttotal: 488ms\tremaining: 3.54s\n",
      "121:\tlearn: 0.1106022\ttotal: 492ms\tremaining: 3.54s\n",
      "122:\tlearn: 0.1101901\ttotal: 496ms\tremaining: 3.54s\n",
      "123:\tlearn: 0.1098421\ttotal: 500ms\tremaining: 3.53s\n",
      "124:\tlearn: 0.1093282\ttotal: 504ms\tremaining: 3.53s\n",
      "125:\tlearn: 0.1088343\ttotal: 509ms\tremaining: 3.53s\n",
      "126:\tlearn: 0.1084061\ttotal: 513ms\tremaining: 3.53s\n",
      "127:\tlearn: 0.1079408\ttotal: 517ms\tremaining: 3.52s\n",
      "128:\tlearn: 0.1075742\ttotal: 521ms\tremaining: 3.52s\n",
      "129:\tlearn: 0.1071692\ttotal: 525ms\tremaining: 3.52s\n",
      "130:\tlearn: 0.1067950\ttotal: 530ms\tremaining: 3.52s\n",
      "131:\tlearn: 0.1064500\ttotal: 534ms\tremaining: 3.51s\n",
      "132:\tlearn: 0.1061522\ttotal: 538ms\tremaining: 3.51s\n",
      "133:\tlearn: 0.1058259\ttotal: 543ms\tremaining: 3.51s\n",
      "134:\tlearn: 0.1054756\ttotal: 547ms\tremaining: 3.51s\n",
      "135:\tlearn: 0.1050257\ttotal: 551ms\tremaining: 3.5s\n",
      "136:\tlearn: 0.1047893\ttotal: 555ms\tremaining: 3.5s\n",
      "137:\tlearn: 0.1044278\ttotal: 560ms\tremaining: 3.5s\n",
      "138:\tlearn: 0.1040880\ttotal: 564ms\tremaining: 3.49s\n",
      "139:\tlearn: 0.1037369\ttotal: 568ms\tremaining: 3.49s\n",
      "140:\tlearn: 0.1035145\ttotal: 573ms\tremaining: 3.49s\n",
      "141:\tlearn: 0.1029843\ttotal: 577ms\tremaining: 3.49s\n",
      "142:\tlearn: 0.1026099\ttotal: 581ms\tremaining: 3.48s\n",
      "143:\tlearn: 0.1023453\ttotal: 585ms\tremaining: 3.48s\n",
      "144:\tlearn: 0.1020728\ttotal: 589ms\tremaining: 3.48s\n",
      "145:\tlearn: 0.1016033\ttotal: 593ms\tremaining: 3.47s\n",
      "146:\tlearn: 0.1013490\ttotal: 597ms\tremaining: 3.46s\n",
      "147:\tlearn: 0.1010826\ttotal: 602ms\tremaining: 3.46s\n",
      "148:\tlearn: 0.1008520\ttotal: 606ms\tremaining: 3.46s\n",
      "149:\tlearn: 0.1005278\ttotal: 610ms\tremaining: 3.46s\n",
      "150:\tlearn: 0.1002113\ttotal: 614ms\tremaining: 3.45s\n",
      "151:\tlearn: 0.1000039\ttotal: 618ms\tremaining: 3.44s\n",
      "152:\tlearn: 0.0996106\ttotal: 621ms\tremaining: 3.44s\n",
      "153:\tlearn: 0.0993539\ttotal: 625ms\tremaining: 3.43s\n",
      "154:\tlearn: 0.0992024\ttotal: 629ms\tremaining: 3.43s\n",
      "155:\tlearn: 0.0989020\ttotal: 633ms\tremaining: 3.42s\n",
      "156:\tlearn: 0.0985397\ttotal: 636ms\tremaining: 3.42s\n",
      "157:\tlearn: 0.0983394\ttotal: 640ms\tremaining: 3.41s\n",
      "158:\tlearn: 0.0980932\ttotal: 644ms\tremaining: 3.4s\n",
      "159:\tlearn: 0.0976824\ttotal: 648ms\tremaining: 3.4s\n",
      "160:\tlearn: 0.0972942\ttotal: 651ms\tremaining: 3.39s\n",
      "161:\tlearn: 0.0969603\ttotal: 655ms\tremaining: 3.39s\n",
      "162:\tlearn: 0.0967238\ttotal: 658ms\tremaining: 3.38s\n",
      "163:\tlearn: 0.0965430\ttotal: 662ms\tremaining: 3.37s\n",
      "164:\tlearn: 0.0962223\ttotal: 666ms\tremaining: 3.37s\n",
      "165:\tlearn: 0.0959892\ttotal: 670ms\tremaining: 3.37s\n",
      "166:\tlearn: 0.0957050\ttotal: 675ms\tremaining: 3.37s\n",
      "167:\tlearn: 0.0953965\ttotal: 678ms\tremaining: 3.36s\n",
      "168:\tlearn: 0.0950957\ttotal: 682ms\tremaining: 3.35s\n",
      "169:\tlearn: 0.0948611\ttotal: 685ms\tremaining: 3.35s\n",
      "170:\tlearn: 0.0945341\ttotal: 689ms\tremaining: 3.34s\n",
      "171:\tlearn: 0.0943239\ttotal: 693ms\tremaining: 3.33s\n",
      "172:\tlearn: 0.0940968\ttotal: 697ms\tremaining: 3.33s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "173:\tlearn: 0.0939040\ttotal: 701ms\tremaining: 3.33s\n",
      "174:\tlearn: 0.0935053\ttotal: 705ms\tremaining: 3.32s\n",
      "175:\tlearn: 0.0933212\ttotal: 709ms\tremaining: 3.32s\n",
      "176:\tlearn: 0.0931419\ttotal: 713ms\tremaining: 3.31s\n",
      "177:\tlearn: 0.0928524\ttotal: 716ms\tremaining: 3.31s\n",
      "178:\tlearn: 0.0927083\ttotal: 720ms\tremaining: 3.3s\n",
      "179:\tlearn: 0.0923442\ttotal: 724ms\tremaining: 3.3s\n",
      "180:\tlearn: 0.0920925\ttotal: 729ms\tremaining: 3.3s\n",
      "181:\tlearn: 0.0918781\ttotal: 733ms\tremaining: 3.29s\n",
      "182:\tlearn: 0.0914424\ttotal: 737ms\tremaining: 3.29s\n",
      "183:\tlearn: 0.0912475\ttotal: 740ms\tremaining: 3.28s\n",
      "184:\tlearn: 0.0909969\ttotal: 744ms\tremaining: 3.28s\n",
      "185:\tlearn: 0.0907864\ttotal: 747ms\tremaining: 3.27s\n",
      "186:\tlearn: 0.0905634\ttotal: 751ms\tremaining: 3.27s\n",
      "187:\tlearn: 0.0902797\ttotal: 754ms\tremaining: 3.26s\n",
      "188:\tlearn: 0.0899881\ttotal: 758ms\tremaining: 3.25s\n",
      "189:\tlearn: 0.0896604\ttotal: 762ms\tremaining: 3.25s\n",
      "190:\tlearn: 0.0893288\ttotal: 765ms\tremaining: 3.24s\n",
      "191:\tlearn: 0.0890421\ttotal: 769ms\tremaining: 3.23s\n",
      "192:\tlearn: 0.0888696\ttotal: 772ms\tremaining: 3.23s\n",
      "193:\tlearn: 0.0886972\ttotal: 776ms\tremaining: 3.22s\n",
      "194:\tlearn: 0.0884210\ttotal: 780ms\tremaining: 3.22s\n",
      "195:\tlearn: 0.0882574\ttotal: 783ms\tremaining: 3.21s\n",
      "196:\tlearn: 0.0880804\ttotal: 787ms\tremaining: 3.21s\n",
      "197:\tlearn: 0.0878510\ttotal: 790ms\tremaining: 3.2s\n",
      "198:\tlearn: 0.0877059\ttotal: 794ms\tremaining: 3.19s\n",
      "199:\tlearn: 0.0875608\ttotal: 797ms\tremaining: 3.19s\n",
      "200:\tlearn: 0.0874099\ttotal: 801ms\tremaining: 3.18s\n",
      "201:\tlearn: 0.0872053\ttotal: 804ms\tremaining: 3.18s\n",
      "202:\tlearn: 0.0869883\ttotal: 808ms\tremaining: 3.17s\n",
      "203:\tlearn: 0.0867179\ttotal: 811ms\tremaining: 3.16s\n",
      "204:\tlearn: 0.0865634\ttotal: 815ms\tremaining: 3.16s\n",
      "205:\tlearn: 0.0864080\ttotal: 819ms\tremaining: 3.16s\n",
      "206:\tlearn: 0.0861391\ttotal: 823ms\tremaining: 3.15s\n",
      "207:\tlearn: 0.0859690\ttotal: 827ms\tremaining: 3.15s\n",
      "208:\tlearn: 0.0857030\ttotal: 831ms\tremaining: 3.15s\n",
      "209:\tlearn: 0.0855540\ttotal: 835ms\tremaining: 3.14s\n",
      "210:\tlearn: 0.0853238\ttotal: 839ms\tremaining: 3.13s\n",
      "211:\tlearn: 0.0851762\ttotal: 842ms\tremaining: 3.13s\n",
      "212:\tlearn: 0.0849296\ttotal: 846ms\tremaining: 3.12s\n",
      "213:\tlearn: 0.0847788\ttotal: 849ms\tremaining: 3.12s\n",
      "214:\tlearn: 0.0845139\ttotal: 854ms\tremaining: 3.12s\n",
      "215:\tlearn: 0.0843440\ttotal: 857ms\tremaining: 3.11s\n",
      "216:\tlearn: 0.0841074\ttotal: 861ms\tremaining: 3.1s\n",
      "217:\tlearn: 0.0839286\ttotal: 864ms\tremaining: 3.1s\n",
      "218:\tlearn: 0.0836284\ttotal: 868ms\tremaining: 3.09s\n",
      "219:\tlearn: 0.0834225\ttotal: 871ms\tremaining: 3.09s\n",
      "220:\tlearn: 0.0832000\ttotal: 874ms\tremaining: 3.08s\n",
      "221:\tlearn: 0.0830476\ttotal: 878ms\tremaining: 3.08s\n",
      "222:\tlearn: 0.0828220\ttotal: 883ms\tremaining: 3.08s\n",
      "223:\tlearn: 0.0826302\ttotal: 886ms\tremaining: 3.07s\n",
      "224:\tlearn: 0.0825078\ttotal: 890ms\tremaining: 3.06s\n",
      "225:\tlearn: 0.0823816\ttotal: 894ms\tremaining: 3.06s\n",
      "226:\tlearn: 0.0821790\ttotal: 897ms\tremaining: 3.06s\n",
      "227:\tlearn: 0.0820837\ttotal: 901ms\tremaining: 3.05s\n",
      "228:\tlearn: 0.0819125\ttotal: 905ms\tremaining: 3.05s\n",
      "229:\tlearn: 0.0815094\ttotal: 909ms\tremaining: 3.04s\n",
      "230:\tlearn: 0.0813652\ttotal: 913ms\tremaining: 3.04s\n",
      "231:\tlearn: 0.0811712\ttotal: 917ms\tremaining: 3.04s\n",
      "232:\tlearn: 0.0809610\ttotal: 921ms\tremaining: 3.03s\n",
      "233:\tlearn: 0.0807569\ttotal: 925ms\tremaining: 3.03s\n",
      "234:\tlearn: 0.0805039\ttotal: 929ms\tremaining: 3.02s\n",
      "235:\tlearn: 0.0803846\ttotal: 933ms\tremaining: 3.02s\n",
      "236:\tlearn: 0.0801871\ttotal: 937ms\tremaining: 3.02s\n",
      "237:\tlearn: 0.0799756\ttotal: 940ms\tremaining: 3.01s\n",
      "238:\tlearn: 0.0798210\ttotal: 944ms\tremaining: 3s\n",
      "239:\tlearn: 0.0796883\ttotal: 948ms\tremaining: 3s\n",
      "240:\tlearn: 0.0795904\ttotal: 951ms\tremaining: 3s\n",
      "241:\tlearn: 0.0794220\ttotal: 955ms\tremaining: 2.99s\n",
      "242:\tlearn: 0.0792913\ttotal: 959ms\tremaining: 2.99s\n",
      "243:\tlearn: 0.0790440\ttotal: 962ms\tremaining: 2.98s\n",
      "244:\tlearn: 0.0789371\ttotal: 966ms\tremaining: 2.98s\n",
      "245:\tlearn: 0.0787384\ttotal: 970ms\tremaining: 2.97s\n",
      "246:\tlearn: 0.0785109\ttotal: 974ms\tremaining: 2.97s\n",
      "247:\tlearn: 0.0783764\ttotal: 978ms\tremaining: 2.96s\n",
      "248:\tlearn: 0.0781461\ttotal: 982ms\tremaining: 2.96s\n",
      "249:\tlearn: 0.0779730\ttotal: 985ms\tremaining: 2.96s\n",
      "250:\tlearn: 0.0778835\ttotal: 989ms\tremaining: 2.95s\n",
      "251:\tlearn: 0.0777529\ttotal: 993ms\tremaining: 2.95s\n",
      "252:\tlearn: 0.0776168\ttotal: 996ms\tremaining: 2.94s\n",
      "253:\tlearn: 0.0773810\ttotal: 1s\tremaining: 2.94s\n",
      "254:\tlearn: 0.0772478\ttotal: 1s\tremaining: 2.93s\n",
      "255:\tlearn: 0.0771597\ttotal: 1.01s\tremaining: 2.93s\n",
      "256:\tlearn: 0.0770397\ttotal: 1.01s\tremaining: 2.92s\n",
      "257:\tlearn: 0.0768352\ttotal: 1.01s\tremaining: 2.92s\n",
      "258:\tlearn: 0.0766006\ttotal: 1.02s\tremaining: 2.92s\n",
      "259:\tlearn: 0.0764381\ttotal: 1.02s\tremaining: 2.91s\n",
      "260:\tlearn: 0.0761640\ttotal: 1.03s\tremaining: 2.9s\n",
      "261:\tlearn: 0.0760311\ttotal: 1.03s\tremaining: 2.9s\n",
      "262:\tlearn: 0.0758184\ttotal: 1.03s\tremaining: 2.89s\n",
      "263:\tlearn: 0.0756703\ttotal: 1.04s\tremaining: 2.89s\n",
      "264:\tlearn: 0.0755039\ttotal: 1.04s\tremaining: 2.89s\n",
      "265:\tlearn: 0.0753847\ttotal: 1.04s\tremaining: 2.88s\n",
      "266:\tlearn: 0.0753143\ttotal: 1.05s\tremaining: 2.88s\n",
      "267:\tlearn: 0.0751626\ttotal: 1.05s\tremaining: 2.87s\n",
      "268:\tlearn: 0.0749839\ttotal: 1.06s\tremaining: 2.87s\n",
      "269:\tlearn: 0.0747970\ttotal: 1.06s\tremaining: 2.87s\n",
      "270:\tlearn: 0.0747613\ttotal: 1.06s\tremaining: 2.86s\n",
      "271:\tlearn: 0.0746313\ttotal: 1.07s\tremaining: 2.86s\n",
      "272:\tlearn: 0.0745464\ttotal: 1.07s\tremaining: 2.85s\n",
      "273:\tlearn: 0.0743350\ttotal: 1.07s\tremaining: 2.85s\n",
      "274:\tlearn: 0.0741979\ttotal: 1.08s\tremaining: 2.85s\n",
      "275:\tlearn: 0.0741141\ttotal: 1.08s\tremaining: 2.84s\n",
      "276:\tlearn: 0.0740660\ttotal: 1.09s\tremaining: 2.84s\n",
      "277:\tlearn: 0.0739745\ttotal: 1.09s\tremaining: 2.84s\n",
      "278:\tlearn: 0.0738456\ttotal: 1.09s\tremaining: 2.83s\n",
      "279:\tlearn: 0.0737383\ttotal: 1.1s\tremaining: 2.83s\n",
      "280:\tlearn: 0.0736005\ttotal: 1.1s\tremaining: 2.83s\n",
      "281:\tlearn: 0.0734680\ttotal: 1.11s\tremaining: 2.82s\n",
      "282:\tlearn: 0.0733674\ttotal: 1.11s\tremaining: 2.82s\n",
      "283:\tlearn: 0.0731620\ttotal: 1.11s\tremaining: 2.81s\n",
      "284:\tlearn: 0.0730770\ttotal: 1.12s\tremaining: 2.81s\n",
      "285:\tlearn: 0.0729810\ttotal: 1.12s\tremaining: 2.8s\n",
      "286:\tlearn: 0.0728439\ttotal: 1.13s\tremaining: 2.8s\n",
      "287:\tlearn: 0.0727471\ttotal: 1.13s\tremaining: 2.79s\n",
      "288:\tlearn: 0.0726722\ttotal: 1.13s\tremaining: 2.79s\n",
      "289:\tlearn: 0.0726095\ttotal: 1.14s\tremaining: 2.78s\n",
      "290:\tlearn: 0.0725453\ttotal: 1.14s\tremaining: 2.78s\n",
      "291:\tlearn: 0.0724069\ttotal: 1.14s\tremaining: 2.77s\n",
      "292:\tlearn: 0.0722368\ttotal: 1.15s\tremaining: 2.77s\n",
      "293:\tlearn: 0.0721658\ttotal: 1.15s\tremaining: 2.76s\n",
      "294:\tlearn: 0.0720620\ttotal: 1.15s\tremaining: 2.76s\n",
      "295:\tlearn: 0.0720232\ttotal: 1.16s\tremaining: 2.75s\n",
      "296:\tlearn: 0.0718554\ttotal: 1.16s\tremaining: 2.75s\n",
      "297:\tlearn: 0.0717335\ttotal: 1.17s\tremaining: 2.75s\n",
      "298:\tlearn: 0.0716127\ttotal: 1.17s\tremaining: 2.74s\n",
      "299:\tlearn: 0.0715340\ttotal: 1.17s\tremaining: 2.74s\n",
      "300:\tlearn: 0.0714083\ttotal: 1.18s\tremaining: 2.73s\n",
      "301:\tlearn: 0.0713276\ttotal: 1.18s\tremaining: 2.73s\n",
      "302:\tlearn: 0.0710867\ttotal: 1.18s\tremaining: 2.72s\n",
      "303:\tlearn: 0.0710039\ttotal: 1.19s\tremaining: 2.72s\n",
      "304:\tlearn: 0.0709201\ttotal: 1.19s\tremaining: 2.71s\n",
      "305:\tlearn: 0.0708343\ttotal: 1.19s\tremaining: 2.71s\n",
      "306:\tlearn: 0.0707466\ttotal: 1.2s\tremaining: 2.7s\n",
      "307:\tlearn: 0.0706695\ttotal: 1.2s\tremaining: 2.7s\n",
      "308:\tlearn: 0.0706217\ttotal: 1.21s\tremaining: 2.7s\n",
      "309:\tlearn: 0.0704386\ttotal: 1.21s\tremaining: 2.7s\n",
      "310:\tlearn: 0.0703166\ttotal: 1.22s\tremaining: 2.69s\n",
      "311:\tlearn: 0.0702517\ttotal: 1.22s\tremaining: 2.69s\n",
      "312:\tlearn: 0.0701603\ttotal: 1.22s\tremaining: 2.69s\n",
      "313:\tlearn: 0.0700043\ttotal: 1.23s\tremaining: 2.68s\n",
      "314:\tlearn: 0.0699567\ttotal: 1.23s\tremaining: 2.68s\n",
      "315:\tlearn: 0.0698066\ttotal: 1.24s\tremaining: 2.67s\n",
      "316:\tlearn: 0.0696924\ttotal: 1.24s\tremaining: 2.67s\n",
      "317:\tlearn: 0.0695179\ttotal: 1.24s\tremaining: 2.67s\n",
      "318:\tlearn: 0.0693537\ttotal: 1.25s\tremaining: 2.66s\n",
      "319:\tlearn: 0.0692653\ttotal: 1.25s\tremaining: 2.66s\n",
      "320:\tlearn: 0.0691731\ttotal: 1.25s\tremaining: 2.66s\n",
      "321:\tlearn: 0.0690850\ttotal: 1.26s\tremaining: 2.65s\n",
      "322:\tlearn: 0.0689602\ttotal: 1.26s\tremaining: 2.65s\n",
      "323:\tlearn: 0.0688712\ttotal: 1.27s\tremaining: 2.65s\n",
      "324:\tlearn: 0.0687413\ttotal: 1.27s\tremaining: 2.64s\n",
      "325:\tlearn: 0.0686320\ttotal: 1.28s\tremaining: 2.64s\n",
      "326:\tlearn: 0.0685329\ttotal: 1.28s\tremaining: 2.63s\n",
      "327:\tlearn: 0.0684971\ttotal: 1.28s\tremaining: 2.63s\n",
      "328:\tlearn: 0.0683588\ttotal: 1.29s\tremaining: 2.63s\n",
      "329:\tlearn: 0.0681232\ttotal: 1.29s\tremaining: 2.62s\n",
      "330:\tlearn: 0.0679897\ttotal: 1.3s\tremaining: 2.62s\n",
      "331:\tlearn: 0.0679098\ttotal: 1.3s\tremaining: 2.62s\n",
      "332:\tlearn: 0.0678195\ttotal: 1.3s\tremaining: 2.61s\n",
      "333:\tlearn: 0.0677570\ttotal: 1.31s\tremaining: 2.61s\n",
      "334:\tlearn: 0.0677460\ttotal: 1.31s\tremaining: 2.6s\n",
      "335:\tlearn: 0.0676472\ttotal: 1.31s\tremaining: 2.6s\n",
      "336:\tlearn: 0.0675356\ttotal: 1.32s\tremaining: 2.59s\n",
      "337:\tlearn: 0.0674257\ttotal: 1.32s\tremaining: 2.59s\n",
      "338:\tlearn: 0.0673050\ttotal: 1.32s\tremaining: 2.58s\n",
      "339:\tlearn: 0.0672086\ttotal: 1.33s\tremaining: 2.58s\n",
      "340:\tlearn: 0.0670994\ttotal: 1.33s\tremaining: 2.57s\n",
      "341:\tlearn: 0.0669615\ttotal: 1.33s\tremaining: 2.57s\n",
      "342:\tlearn: 0.0668362\ttotal: 1.34s\tremaining: 2.56s\n",
      "343:\tlearn: 0.0667530\ttotal: 1.34s\tremaining: 2.56s\n",
      "344:\tlearn: 0.0665868\ttotal: 1.34s\tremaining: 2.56s\n",
      "345:\tlearn: 0.0663851\ttotal: 1.35s\tremaining: 2.55s\n",
      "346:\tlearn: 0.0662679\ttotal: 1.35s\tremaining: 2.55s\n",
      "347:\tlearn: 0.0661409\ttotal: 1.36s\tremaining: 2.54s\n",
      "348:\tlearn: 0.0660426\ttotal: 1.36s\tremaining: 2.54s\n",
      "349:\tlearn: 0.0659950\ttotal: 1.36s\tremaining: 2.53s\n",
      "350:\tlearn: 0.0658436\ttotal: 1.37s\tremaining: 2.53s\n",
      "351:\tlearn: 0.0657668\ttotal: 1.37s\tremaining: 2.52s\n",
      "352:\tlearn: 0.0656876\ttotal: 1.38s\tremaining: 2.52s\n",
      "353:\tlearn: 0.0656025\ttotal: 1.38s\tremaining: 2.52s\n",
      "354:\tlearn: 0.0654436\ttotal: 1.38s\tremaining: 2.51s\n",
      "355:\tlearn: 0.0653118\ttotal: 1.39s\tremaining: 2.51s\n",
      "356:\tlearn: 0.0652737\ttotal: 1.39s\tremaining: 2.5s\n",
      "357:\tlearn: 0.0651677\ttotal: 1.39s\tremaining: 2.5s\n",
      "358:\tlearn: 0.0651048\ttotal: 1.4s\tremaining: 2.49s\n",
      "359:\tlearn: 0.0649265\ttotal: 1.4s\tremaining: 2.49s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "360:\tlearn: 0.0648272\ttotal: 1.4s\tremaining: 2.48s\n",
      "361:\tlearn: 0.0647211\ttotal: 1.41s\tremaining: 2.48s\n",
      "362:\tlearn: 0.0645893\ttotal: 1.41s\tremaining: 2.48s\n",
      "363:\tlearn: 0.0644541\ttotal: 1.42s\tremaining: 2.47s\n",
      "364:\tlearn: 0.0643603\ttotal: 1.42s\tremaining: 2.47s\n",
      "365:\tlearn: 0.0642947\ttotal: 1.42s\tremaining: 2.46s\n",
      "366:\tlearn: 0.0642117\ttotal: 1.43s\tremaining: 2.46s\n",
      "367:\tlearn: 0.0640947\ttotal: 1.43s\tremaining: 2.46s\n",
      "368:\tlearn: 0.0640281\ttotal: 1.43s\tremaining: 2.45s\n",
      "369:\tlearn: 0.0639154\ttotal: 1.44s\tremaining: 2.45s\n",
      "370:\tlearn: 0.0637825\ttotal: 1.44s\tremaining: 2.44s\n",
      "371:\tlearn: 0.0636756\ttotal: 1.45s\tremaining: 2.44s\n",
      "372:\tlearn: 0.0636053\ttotal: 1.45s\tremaining: 2.44s\n",
      "373:\tlearn: 0.0635578\ttotal: 1.45s\tremaining: 2.43s\n",
      "374:\tlearn: 0.0635016\ttotal: 1.46s\tremaining: 2.43s\n",
      "375:\tlearn: 0.0633141\ttotal: 1.46s\tremaining: 2.42s\n",
      "376:\tlearn: 0.0632502\ttotal: 1.46s\tremaining: 2.42s\n",
      "377:\tlearn: 0.0631282\ttotal: 1.47s\tremaining: 2.41s\n",
      "378:\tlearn: 0.0629686\ttotal: 1.47s\tremaining: 2.41s\n",
      "379:\tlearn: 0.0628956\ttotal: 1.47s\tremaining: 2.4s\n",
      "380:\tlearn: 0.0627552\ttotal: 1.48s\tremaining: 2.4s\n",
      "381:\tlearn: 0.0626970\ttotal: 1.48s\tremaining: 2.39s\n",
      "382:\tlearn: 0.0626018\ttotal: 1.48s\tremaining: 2.39s\n",
      "383:\tlearn: 0.0624744\ttotal: 1.49s\tremaining: 2.39s\n",
      "384:\tlearn: 0.0623297\ttotal: 1.49s\tremaining: 2.38s\n",
      "385:\tlearn: 0.0622372\ttotal: 1.49s\tremaining: 2.38s\n",
      "386:\tlearn: 0.0621676\ttotal: 1.5s\tremaining: 2.37s\n",
      "387:\tlearn: 0.0620648\ttotal: 1.5s\tremaining: 2.37s\n",
      "388:\tlearn: 0.0619490\ttotal: 1.5s\tremaining: 2.36s\n",
      "389:\tlearn: 0.0617790\ttotal: 1.51s\tremaining: 2.36s\n",
      "390:\tlearn: 0.0616943\ttotal: 1.51s\tremaining: 2.35s\n",
      "391:\tlearn: 0.0616200\ttotal: 1.51s\tremaining: 2.35s\n",
      "392:\tlearn: 0.0615181\ttotal: 1.52s\tremaining: 2.35s\n",
      "393:\tlearn: 0.0613902\ttotal: 1.52s\tremaining: 2.34s\n",
      "394:\tlearn: 0.0612766\ttotal: 1.53s\tremaining: 2.34s\n",
      "395:\tlearn: 0.0612444\ttotal: 1.53s\tremaining: 2.33s\n",
      "396:\tlearn: 0.0611551\ttotal: 1.53s\tremaining: 2.33s\n",
      "397:\tlearn: 0.0610253\ttotal: 1.54s\tremaining: 2.33s\n",
      "398:\tlearn: 0.0609507\ttotal: 1.54s\tremaining: 2.32s\n",
      "399:\tlearn: 0.0608693\ttotal: 1.54s\tremaining: 2.32s\n",
      "400:\tlearn: 0.0608081\ttotal: 1.55s\tremaining: 2.31s\n",
      "401:\tlearn: 0.0607195\ttotal: 1.55s\tremaining: 2.31s\n",
      "402:\tlearn: 0.0606271\ttotal: 1.55s\tremaining: 2.3s\n",
      "403:\tlearn: 0.0605811\ttotal: 1.56s\tremaining: 2.3s\n",
      "404:\tlearn: 0.0604574\ttotal: 1.56s\tremaining: 2.3s\n",
      "405:\tlearn: 0.0603487\ttotal: 1.57s\tremaining: 2.29s\n",
      "406:\tlearn: 0.0602296\ttotal: 1.57s\tremaining: 2.29s\n",
      "407:\tlearn: 0.0601533\ttotal: 1.57s\tremaining: 2.28s\n",
      "408:\tlearn: 0.0601073\ttotal: 1.58s\tremaining: 2.28s\n",
      "409:\tlearn: 0.0600358\ttotal: 1.58s\tremaining: 2.27s\n",
      "410:\tlearn: 0.0598965\ttotal: 1.58s\tremaining: 2.27s\n",
      "411:\tlearn: 0.0598242\ttotal: 1.59s\tremaining: 2.27s\n",
      "412:\tlearn: 0.0597735\ttotal: 1.59s\tremaining: 2.26s\n",
      "413:\tlearn: 0.0596797\ttotal: 1.6s\tremaining: 2.26s\n",
      "414:\tlearn: 0.0595703\ttotal: 1.6s\tremaining: 2.26s\n",
      "415:\tlearn: 0.0595138\ttotal: 1.61s\tremaining: 2.26s\n",
      "416:\tlearn: 0.0594429\ttotal: 1.61s\tremaining: 2.25s\n",
      "417:\tlearn: 0.0594014\ttotal: 1.61s\tremaining: 2.25s\n",
      "418:\tlearn: 0.0593386\ttotal: 1.62s\tremaining: 2.24s\n",
      "419:\tlearn: 0.0592512\ttotal: 1.62s\tremaining: 2.24s\n",
      "420:\tlearn: 0.0592026\ttotal: 1.63s\tremaining: 2.23s\n",
      "421:\tlearn: 0.0590960\ttotal: 1.63s\tremaining: 2.23s\n",
      "422:\tlearn: 0.0590071\ttotal: 1.63s\tremaining: 2.23s\n",
      "423:\tlearn: 0.0589150\ttotal: 1.64s\tremaining: 2.22s\n",
      "424:\tlearn: 0.0588474\ttotal: 1.64s\tremaining: 2.22s\n",
      "425:\tlearn: 0.0588341\ttotal: 1.64s\tremaining: 2.21s\n",
      "426:\tlearn: 0.0587330\ttotal: 1.65s\tremaining: 2.21s\n",
      "427:\tlearn: 0.0586401\ttotal: 1.65s\tremaining: 2.21s\n",
      "428:\tlearn: 0.0585354\ttotal: 1.65s\tremaining: 2.2s\n",
      "429:\tlearn: 0.0584054\ttotal: 1.66s\tremaining: 2.2s\n",
      "430:\tlearn: 0.0583038\ttotal: 1.66s\tremaining: 2.19s\n",
      "431:\tlearn: 0.0582704\ttotal: 1.66s\tremaining: 2.19s\n",
      "432:\tlearn: 0.0582379\ttotal: 1.67s\tremaining: 2.18s\n",
      "433:\tlearn: 0.0581388\ttotal: 1.67s\tremaining: 2.18s\n",
      "434:\tlearn: 0.0580058\ttotal: 1.68s\tremaining: 2.18s\n",
      "435:\tlearn: 0.0578991\ttotal: 1.68s\tremaining: 2.17s\n",
      "436:\tlearn: 0.0578259\ttotal: 1.68s\tremaining: 2.17s\n",
      "437:\tlearn: 0.0576982\ttotal: 1.69s\tremaining: 2.16s\n",
      "438:\tlearn: 0.0576059\ttotal: 1.69s\tremaining: 2.16s\n",
      "439:\tlearn: 0.0574908\ttotal: 1.69s\tremaining: 2.15s\n",
      "440:\tlearn: 0.0573820\ttotal: 1.7s\tremaining: 2.15s\n",
      "441:\tlearn: 0.0572845\ttotal: 1.7s\tremaining: 2.15s\n",
      "442:\tlearn: 0.0571941\ttotal: 1.7s\tremaining: 2.14s\n",
      "443:\tlearn: 0.0571028\ttotal: 1.71s\tremaining: 2.14s\n",
      "444:\tlearn: 0.0570378\ttotal: 1.71s\tremaining: 2.13s\n",
      "445:\tlearn: 0.0568701\ttotal: 1.71s\tremaining: 2.13s\n",
      "446:\tlearn: 0.0568185\ttotal: 1.72s\tremaining: 2.13s\n",
      "447:\tlearn: 0.0567029\ttotal: 1.72s\tremaining: 2.12s\n",
      "448:\tlearn: 0.0565791\ttotal: 1.73s\tremaining: 2.12s\n",
      "449:\tlearn: 0.0564717\ttotal: 1.73s\tremaining: 2.11s\n",
      "450:\tlearn: 0.0563902\ttotal: 1.73s\tremaining: 2.11s\n",
      "451:\tlearn: 0.0563242\ttotal: 1.74s\tremaining: 2.1s\n",
      "452:\tlearn: 0.0562348\ttotal: 1.74s\tremaining: 2.1s\n",
      "453:\tlearn: 0.0561319\ttotal: 1.74s\tremaining: 2.1s\n",
      "454:\tlearn: 0.0560463\ttotal: 1.75s\tremaining: 2.09s\n",
      "455:\tlearn: 0.0559776\ttotal: 1.75s\tremaining: 2.09s\n",
      "456:\tlearn: 0.0559010\ttotal: 1.75s\tremaining: 2.08s\n",
      "457:\tlearn: 0.0558352\ttotal: 1.76s\tremaining: 2.08s\n",
      "458:\tlearn: 0.0557056\ttotal: 1.76s\tremaining: 2.08s\n",
      "459:\tlearn: 0.0556744\ttotal: 1.77s\tremaining: 2.07s\n",
      "460:\tlearn: 0.0555879\ttotal: 1.77s\tremaining: 2.07s\n",
      "461:\tlearn: 0.0555369\ttotal: 1.77s\tremaining: 2.07s\n",
      "462:\tlearn: 0.0554522\ttotal: 1.78s\tremaining: 2.06s\n",
      "463:\tlearn: 0.0554106\ttotal: 1.78s\tremaining: 2.06s\n",
      "464:\tlearn: 0.0553459\ttotal: 1.79s\tremaining: 2.06s\n",
      "465:\tlearn: 0.0552722\ttotal: 1.79s\tremaining: 2.05s\n",
      "466:\tlearn: 0.0552089\ttotal: 1.8s\tremaining: 2.05s\n",
      "467:\tlearn: 0.0551345\ttotal: 1.8s\tremaining: 2.05s\n",
      "468:\tlearn: 0.0549285\ttotal: 1.8s\tremaining: 2.04s\n",
      "469:\tlearn: 0.0548969\ttotal: 1.81s\tremaining: 2.04s\n",
      "470:\tlearn: 0.0548282\ttotal: 1.81s\tremaining: 2.03s\n",
      "471:\tlearn: 0.0547791\ttotal: 1.81s\tremaining: 2.03s\n",
      "472:\tlearn: 0.0546504\ttotal: 1.82s\tremaining: 2.02s\n",
      "473:\tlearn: 0.0546149\ttotal: 1.82s\tremaining: 2.02s\n",
      "474:\tlearn: 0.0545205\ttotal: 1.82s\tremaining: 2.02s\n",
      "475:\tlearn: 0.0544713\ttotal: 1.83s\tremaining: 2.01s\n",
      "476:\tlearn: 0.0543601\ttotal: 1.83s\tremaining: 2.01s\n",
      "477:\tlearn: 0.0543011\ttotal: 1.83s\tremaining: 2s\n",
      "478:\tlearn: 0.0542403\ttotal: 1.84s\tremaining: 2s\n",
      "479:\tlearn: 0.0542048\ttotal: 1.84s\tremaining: 2s\n",
      "480:\tlearn: 0.0541510\ttotal: 1.84s\tremaining: 1.99s\n",
      "481:\tlearn: 0.0540652\ttotal: 1.85s\tremaining: 1.99s\n",
      "482:\tlearn: 0.0540184\ttotal: 1.85s\tremaining: 1.98s\n",
      "483:\tlearn: 0.0539239\ttotal: 1.86s\tremaining: 1.98s\n",
      "484:\tlearn: 0.0538573\ttotal: 1.86s\tremaining: 1.98s\n",
      "485:\tlearn: 0.0537565\ttotal: 1.86s\tremaining: 1.97s\n",
      "486:\tlearn: 0.0535951\ttotal: 1.87s\tremaining: 1.97s\n",
      "487:\tlearn: 0.0535075\ttotal: 1.87s\tremaining: 1.96s\n",
      "488:\tlearn: 0.0534135\ttotal: 1.87s\tremaining: 1.96s\n",
      "489:\tlearn: 0.0533691\ttotal: 1.88s\tremaining: 1.95s\n",
      "490:\tlearn: 0.0533039\ttotal: 1.88s\tremaining: 1.95s\n",
      "491:\tlearn: 0.0532554\ttotal: 1.88s\tremaining: 1.95s\n",
      "492:\tlearn: 0.0532070\ttotal: 1.89s\tremaining: 1.94s\n",
      "493:\tlearn: 0.0531061\ttotal: 1.89s\tremaining: 1.94s\n",
      "494:\tlearn: 0.0529838\ttotal: 1.9s\tremaining: 1.93s\n",
      "495:\tlearn: 0.0528370\ttotal: 1.9s\tremaining: 1.93s\n",
      "496:\tlearn: 0.0527391\ttotal: 1.9s\tremaining: 1.93s\n",
      "497:\tlearn: 0.0526479\ttotal: 1.91s\tremaining: 1.92s\n",
      "498:\tlearn: 0.0526242\ttotal: 1.91s\tremaining: 1.92s\n",
      "499:\tlearn: 0.0525862\ttotal: 1.92s\tremaining: 1.92s\n",
      "500:\tlearn: 0.0525441\ttotal: 1.92s\tremaining: 1.91s\n",
      "501:\tlearn: 0.0524979\ttotal: 1.92s\tremaining: 1.91s\n",
      "502:\tlearn: 0.0523895\ttotal: 1.93s\tremaining: 1.9s\n",
      "503:\tlearn: 0.0523251\ttotal: 1.93s\tremaining: 1.9s\n",
      "504:\tlearn: 0.0522858\ttotal: 1.94s\tremaining: 1.9s\n",
      "505:\tlearn: 0.0522000\ttotal: 1.94s\tremaining: 1.89s\n",
      "506:\tlearn: 0.0521478\ttotal: 1.94s\tremaining: 1.89s\n",
      "507:\tlearn: 0.0520823\ttotal: 1.95s\tremaining: 1.89s\n",
      "508:\tlearn: 0.0520196\ttotal: 1.95s\tremaining: 1.88s\n",
      "509:\tlearn: 0.0519672\ttotal: 1.96s\tremaining: 1.88s\n",
      "510:\tlearn: 0.0519065\ttotal: 1.96s\tremaining: 1.88s\n",
      "511:\tlearn: 0.0518749\ttotal: 1.96s\tremaining: 1.87s\n",
      "512:\tlearn: 0.0517469\ttotal: 1.97s\tremaining: 1.87s\n",
      "513:\tlearn: 0.0516516\ttotal: 1.97s\tremaining: 1.86s\n",
      "514:\tlearn: 0.0515976\ttotal: 1.98s\tremaining: 1.86s\n",
      "515:\tlearn: 0.0515220\ttotal: 1.98s\tremaining: 1.86s\n",
      "516:\tlearn: 0.0514641\ttotal: 1.98s\tremaining: 1.85s\n",
      "517:\tlearn: 0.0513856\ttotal: 1.99s\tremaining: 1.85s\n",
      "518:\tlearn: 0.0513214\ttotal: 1.99s\tremaining: 1.84s\n",
      "519:\tlearn: 0.0512111\ttotal: 2s\tremaining: 1.84s\n",
      "520:\tlearn: 0.0511732\ttotal: 2s\tremaining: 1.84s\n",
      "521:\tlearn: 0.0511287\ttotal: 2s\tremaining: 1.83s\n",
      "522:\tlearn: 0.0510475\ttotal: 2.01s\tremaining: 1.83s\n",
      "523:\tlearn: 0.0510102\ttotal: 2.01s\tremaining: 1.83s\n",
      "524:\tlearn: 0.0509986\ttotal: 2.01s\tremaining: 1.82s\n",
      "525:\tlearn: 0.0508654\ttotal: 2.02s\tremaining: 1.82s\n",
      "526:\tlearn: 0.0508024\ttotal: 2.02s\tremaining: 1.81s\n",
      "527:\tlearn: 0.0507808\ttotal: 2.02s\tremaining: 1.81s\n",
      "528:\tlearn: 0.0507391\ttotal: 2.03s\tremaining: 1.81s\n",
      "529:\tlearn: 0.0506810\ttotal: 2.03s\tremaining: 1.8s\n",
      "530:\tlearn: 0.0506502\ttotal: 2.04s\tremaining: 1.8s\n",
      "531:\tlearn: 0.0506239\ttotal: 2.04s\tremaining: 1.79s\n",
      "532:\tlearn: 0.0505381\ttotal: 2.04s\tremaining: 1.79s\n",
      "533:\tlearn: 0.0504258\ttotal: 2.05s\tremaining: 1.79s\n",
      "534:\tlearn: 0.0503788\ttotal: 2.05s\tremaining: 1.78s\n",
      "535:\tlearn: 0.0503316\ttotal: 2.06s\tremaining: 1.78s\n",
      "536:\tlearn: 0.0502087\ttotal: 2.06s\tremaining: 1.77s\n",
      "537:\tlearn: 0.0501657\ttotal: 2.06s\tremaining: 1.77s\n",
      "538:\tlearn: 0.0501059\ttotal: 2.07s\tremaining: 1.77s\n",
      "539:\tlearn: 0.0500483\ttotal: 2.07s\tremaining: 1.76s\n",
      "540:\tlearn: 0.0499713\ttotal: 2.07s\tremaining: 1.76s\n",
      "541:\tlearn: 0.0499186\ttotal: 2.08s\tremaining: 1.75s\n",
      "542:\tlearn: 0.0498636\ttotal: 2.08s\tremaining: 1.75s\n",
      "543:\tlearn: 0.0498153\ttotal: 2.08s\tremaining: 1.75s\n",
      "544:\tlearn: 0.0497742\ttotal: 2.09s\tremaining: 1.74s\n",
      "545:\tlearn: 0.0496972\ttotal: 2.09s\tremaining: 1.74s\n",
      "546:\tlearn: 0.0495723\ttotal: 2.1s\tremaining: 1.74s\n",
      "547:\tlearn: 0.0495348\ttotal: 2.1s\tremaining: 1.73s\n",
      "548:\tlearn: 0.0494977\ttotal: 2.1s\tremaining: 1.73s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "549:\tlearn: 0.0494498\ttotal: 2.11s\tremaining: 1.72s\n",
      "550:\tlearn: 0.0493765\ttotal: 2.11s\tremaining: 1.72s\n",
      "551:\tlearn: 0.0493191\ttotal: 2.11s\tremaining: 1.72s\n",
      "552:\tlearn: 0.0492662\ttotal: 2.12s\tremaining: 1.71s\n",
      "553:\tlearn: 0.0491432\ttotal: 2.12s\tremaining: 1.71s\n",
      "554:\tlearn: 0.0490690\ttotal: 2.13s\tremaining: 1.7s\n",
      "555:\tlearn: 0.0490302\ttotal: 2.13s\tremaining: 1.7s\n",
      "556:\tlearn: 0.0490104\ttotal: 2.13s\tremaining: 1.7s\n",
      "557:\tlearn: 0.0489140\ttotal: 2.14s\tremaining: 1.69s\n",
      "558:\tlearn: 0.0488301\ttotal: 2.14s\tremaining: 1.69s\n",
      "559:\tlearn: 0.0487148\ttotal: 2.15s\tremaining: 1.69s\n",
      "560:\tlearn: 0.0486468\ttotal: 2.15s\tremaining: 1.68s\n",
      "561:\tlearn: 0.0485778\ttotal: 2.15s\tremaining: 1.68s\n",
      "562:\tlearn: 0.0484966\ttotal: 2.16s\tremaining: 1.68s\n",
      "563:\tlearn: 0.0484391\ttotal: 2.16s\tremaining: 1.67s\n",
      "564:\tlearn: 0.0483863\ttotal: 2.17s\tremaining: 1.67s\n",
      "565:\tlearn: 0.0483529\ttotal: 2.17s\tremaining: 1.66s\n",
      "566:\tlearn: 0.0482947\ttotal: 2.17s\tremaining: 1.66s\n",
      "567:\tlearn: 0.0482197\ttotal: 2.18s\tremaining: 1.66s\n",
      "568:\tlearn: 0.0481519\ttotal: 2.18s\tremaining: 1.65s\n",
      "569:\tlearn: 0.0480955\ttotal: 2.19s\tremaining: 1.65s\n",
      "570:\tlearn: 0.0480273\ttotal: 2.19s\tremaining: 1.64s\n",
      "571:\tlearn: 0.0480020\ttotal: 2.19s\tremaining: 1.64s\n",
      "572:\tlearn: 0.0478976\ttotal: 2.2s\tremaining: 1.64s\n",
      "573:\tlearn: 0.0478594\ttotal: 2.2s\tremaining: 1.63s\n",
      "574:\tlearn: 0.0478288\ttotal: 2.2s\tremaining: 1.63s\n",
      "575:\tlearn: 0.0478012\ttotal: 2.21s\tremaining: 1.62s\n",
      "576:\tlearn: 0.0477533\ttotal: 2.21s\tremaining: 1.62s\n",
      "577:\tlearn: 0.0476764\ttotal: 2.21s\tremaining: 1.62s\n",
      "578:\tlearn: 0.0476261\ttotal: 2.22s\tremaining: 1.61s\n",
      "579:\tlearn: 0.0475442\ttotal: 2.22s\tremaining: 1.61s\n",
      "580:\tlearn: 0.0474949\ttotal: 2.23s\tremaining: 1.6s\n",
      "581:\tlearn: 0.0474513\ttotal: 2.23s\tremaining: 1.6s\n",
      "582:\tlearn: 0.0474046\ttotal: 2.23s\tremaining: 1.6s\n",
      "583:\tlearn: 0.0473241\ttotal: 2.24s\tremaining: 1.59s\n",
      "584:\tlearn: 0.0472998\ttotal: 2.24s\tremaining: 1.59s\n",
      "585:\tlearn: 0.0472271\ttotal: 2.25s\tremaining: 1.59s\n",
      "586:\tlearn: 0.0471738\ttotal: 2.25s\tremaining: 1.58s\n",
      "587:\tlearn: 0.0470634\ttotal: 2.25s\tremaining: 1.58s\n",
      "588:\tlearn: 0.0469971\ttotal: 2.26s\tremaining: 1.58s\n",
      "589:\tlearn: 0.0469643\ttotal: 2.26s\tremaining: 1.57s\n",
      "590:\tlearn: 0.0468674\ttotal: 2.27s\tremaining: 1.57s\n",
      "591:\tlearn: 0.0468244\ttotal: 2.27s\tremaining: 1.57s\n",
      "592:\tlearn: 0.0467939\ttotal: 2.28s\tremaining: 1.56s\n",
      "593:\tlearn: 0.0466771\ttotal: 2.28s\tremaining: 1.56s\n",
      "594:\tlearn: 0.0466343\ttotal: 2.28s\tremaining: 1.55s\n",
      "595:\tlearn: 0.0465769\ttotal: 2.29s\tremaining: 1.55s\n",
      "596:\tlearn: 0.0464851\ttotal: 2.29s\tremaining: 1.55s\n",
      "597:\tlearn: 0.0464665\ttotal: 2.3s\tremaining: 1.54s\n",
      "598:\tlearn: 0.0463563\ttotal: 2.3s\tremaining: 1.54s\n",
      "599:\tlearn: 0.0463297\ttotal: 2.3s\tremaining: 1.54s\n",
      "600:\tlearn: 0.0463061\ttotal: 2.31s\tremaining: 1.53s\n",
      "601:\tlearn: 0.0462634\ttotal: 2.31s\tremaining: 1.53s\n",
      "602:\tlearn: 0.0462137\ttotal: 2.32s\tremaining: 1.52s\n",
      "603:\tlearn: 0.0462013\ttotal: 2.32s\tremaining: 1.52s\n",
      "604:\tlearn: 0.0461791\ttotal: 2.32s\tremaining: 1.52s\n",
      "605:\tlearn: 0.0461096\ttotal: 2.33s\tremaining: 1.51s\n",
      "606:\tlearn: 0.0460384\ttotal: 2.33s\tremaining: 1.51s\n",
      "607:\tlearn: 0.0459775\ttotal: 2.33s\tremaining: 1.5s\n",
      "608:\tlearn: 0.0459357\ttotal: 2.34s\tremaining: 1.5s\n",
      "609:\tlearn: 0.0458931\ttotal: 2.34s\tremaining: 1.5s\n",
      "610:\tlearn: 0.0458781\ttotal: 2.35s\tremaining: 1.49s\n",
      "611:\tlearn: 0.0458323\ttotal: 2.35s\tremaining: 1.49s\n",
      "612:\tlearn: 0.0457623\ttotal: 2.35s\tremaining: 1.49s\n",
      "613:\tlearn: 0.0457438\ttotal: 2.36s\tremaining: 1.48s\n",
      "614:\tlearn: 0.0457297\ttotal: 2.36s\tremaining: 1.48s\n",
      "615:\tlearn: 0.0456855\ttotal: 2.36s\tremaining: 1.47s\n",
      "616:\tlearn: 0.0456476\ttotal: 2.37s\tremaining: 1.47s\n",
      "617:\tlearn: 0.0455421\ttotal: 2.37s\tremaining: 1.47s\n",
      "618:\tlearn: 0.0455074\ttotal: 2.38s\tremaining: 1.46s\n",
      "619:\tlearn: 0.0454572\ttotal: 2.38s\tremaining: 1.46s\n",
      "620:\tlearn: 0.0454100\ttotal: 2.38s\tremaining: 1.45s\n",
      "621:\tlearn: 0.0453368\ttotal: 2.39s\tremaining: 1.45s\n",
      "622:\tlearn: 0.0452569\ttotal: 2.39s\tremaining: 1.45s\n",
      "623:\tlearn: 0.0452234\ttotal: 2.39s\tremaining: 1.44s\n",
      "624:\tlearn: 0.0451903\ttotal: 2.4s\tremaining: 1.44s\n",
      "625:\tlearn: 0.0451482\ttotal: 2.4s\tremaining: 1.43s\n",
      "626:\tlearn: 0.0451019\ttotal: 2.4s\tremaining: 1.43s\n",
      "627:\tlearn: 0.0450777\ttotal: 2.41s\tremaining: 1.43s\n",
      "628:\tlearn: 0.0450305\ttotal: 2.41s\tremaining: 1.42s\n",
      "629:\tlearn: 0.0449759\ttotal: 2.42s\tremaining: 1.42s\n",
      "630:\tlearn: 0.0449434\ttotal: 2.42s\tremaining: 1.42s\n",
      "631:\tlearn: 0.0449099\ttotal: 2.42s\tremaining: 1.41s\n",
      "632:\tlearn: 0.0448715\ttotal: 2.43s\tremaining: 1.41s\n",
      "633:\tlearn: 0.0448520\ttotal: 2.43s\tremaining: 1.4s\n",
      "634:\tlearn: 0.0448259\ttotal: 2.44s\tremaining: 1.4s\n",
      "635:\tlearn: 0.0448048\ttotal: 2.44s\tremaining: 1.4s\n",
      "636:\tlearn: 0.0447510\ttotal: 2.44s\tremaining: 1.39s\n",
      "637:\tlearn: 0.0447322\ttotal: 2.45s\tremaining: 1.39s\n",
      "638:\tlearn: 0.0447066\ttotal: 2.45s\tremaining: 1.39s\n",
      "639:\tlearn: 0.0446844\ttotal: 2.46s\tremaining: 1.38s\n",
      "640:\tlearn: 0.0446105\ttotal: 2.46s\tremaining: 1.38s\n",
      "641:\tlearn: 0.0445977\ttotal: 2.46s\tremaining: 1.37s\n",
      "642:\tlearn: 0.0445360\ttotal: 2.47s\tremaining: 1.37s\n",
      "643:\tlearn: 0.0445139\ttotal: 2.47s\tremaining: 1.37s\n",
      "644:\tlearn: 0.0444751\ttotal: 2.48s\tremaining: 1.36s\n",
      "645:\tlearn: 0.0444359\ttotal: 2.48s\tremaining: 1.36s\n",
      "646:\tlearn: 0.0444163\ttotal: 2.48s\tremaining: 1.36s\n",
      "647:\tlearn: 0.0443947\ttotal: 2.49s\tremaining: 1.35s\n",
      "648:\tlearn: 0.0443651\ttotal: 2.49s\tremaining: 1.35s\n",
      "649:\tlearn: 0.0443451\ttotal: 2.5s\tremaining: 1.34s\n",
      "650:\tlearn: 0.0443171\ttotal: 2.5s\tremaining: 1.34s\n",
      "651:\tlearn: 0.0442778\ttotal: 2.5s\tremaining: 1.34s\n",
      "652:\tlearn: 0.0442486\ttotal: 2.51s\tremaining: 1.33s\n",
      "653:\tlearn: 0.0441229\ttotal: 2.51s\tremaining: 1.33s\n",
      "654:\tlearn: 0.0440714\ttotal: 2.52s\tremaining: 1.33s\n",
      "655:\tlearn: 0.0440215\ttotal: 2.52s\tremaining: 1.32s\n",
      "656:\tlearn: 0.0439855\ttotal: 2.53s\tremaining: 1.32s\n",
      "657:\tlearn: 0.0439304\ttotal: 2.53s\tremaining: 1.31s\n",
      "658:\tlearn: 0.0438915\ttotal: 2.54s\tremaining: 1.31s\n",
      "659:\tlearn: 0.0438554\ttotal: 2.54s\tremaining: 1.31s\n",
      "660:\tlearn: 0.0437945\ttotal: 2.54s\tremaining: 1.3s\n",
      "661:\tlearn: 0.0437143\ttotal: 2.55s\tremaining: 1.3s\n",
      "662:\tlearn: 0.0436825\ttotal: 2.55s\tremaining: 1.3s\n",
      "663:\tlearn: 0.0436652\ttotal: 2.56s\tremaining: 1.29s\n",
      "664:\tlearn: 0.0436061\ttotal: 2.56s\tremaining: 1.29s\n",
      "665:\tlearn: 0.0435826\ttotal: 2.56s\tremaining: 1.28s\n",
      "666:\tlearn: 0.0435275\ttotal: 2.57s\tremaining: 1.28s\n",
      "667:\tlearn: 0.0434951\ttotal: 2.57s\tremaining: 1.28s\n",
      "668:\tlearn: 0.0434670\ttotal: 2.57s\tremaining: 1.27s\n",
      "669:\tlearn: 0.0434221\ttotal: 2.58s\tremaining: 1.27s\n",
      "670:\tlearn: 0.0433776\ttotal: 2.58s\tremaining: 1.27s\n",
      "671:\tlearn: 0.0433366\ttotal: 2.59s\tremaining: 1.26s\n",
      "672:\tlearn: 0.0433067\ttotal: 2.59s\tremaining: 1.26s\n",
      "673:\tlearn: 0.0432857\ttotal: 2.6s\tremaining: 1.25s\n",
      "674:\tlearn: 0.0432151\ttotal: 2.6s\tremaining: 1.25s\n",
      "675:\tlearn: 0.0432049\ttotal: 2.6s\tremaining: 1.25s\n",
      "676:\tlearn: 0.0431865\ttotal: 2.61s\tremaining: 1.24s\n",
      "677:\tlearn: 0.0431227\ttotal: 2.61s\tremaining: 1.24s\n",
      "678:\tlearn: 0.0430891\ttotal: 2.62s\tremaining: 1.24s\n",
      "679:\tlearn: 0.0430477\ttotal: 2.62s\tremaining: 1.23s\n",
      "680:\tlearn: 0.0430082\ttotal: 2.62s\tremaining: 1.23s\n",
      "681:\tlearn: 0.0429737\ttotal: 2.63s\tremaining: 1.22s\n",
      "682:\tlearn: 0.0429518\ttotal: 2.63s\tremaining: 1.22s\n",
      "683:\tlearn: 0.0429173\ttotal: 2.63s\tremaining: 1.22s\n",
      "684:\tlearn: 0.0428700\ttotal: 2.64s\tremaining: 1.21s\n",
      "685:\tlearn: 0.0428502\ttotal: 2.64s\tremaining: 1.21s\n",
      "686:\tlearn: 0.0428316\ttotal: 2.65s\tremaining: 1.21s\n",
      "687:\tlearn: 0.0427365\ttotal: 2.65s\tremaining: 1.2s\n",
      "688:\tlearn: 0.0426894\ttotal: 2.65s\tremaining: 1.2s\n",
      "689:\tlearn: 0.0426661\ttotal: 2.66s\tremaining: 1.19s\n",
      "690:\tlearn: 0.0426271\ttotal: 2.66s\tremaining: 1.19s\n",
      "691:\tlearn: 0.0425960\ttotal: 2.67s\tremaining: 1.19s\n",
      "692:\tlearn: 0.0425513\ttotal: 2.67s\tremaining: 1.18s\n",
      "693:\tlearn: 0.0425302\ttotal: 2.67s\tremaining: 1.18s\n",
      "694:\tlearn: 0.0425034\ttotal: 2.68s\tremaining: 1.17s\n",
      "695:\tlearn: 0.0424859\ttotal: 2.68s\tremaining: 1.17s\n",
      "696:\tlearn: 0.0424019\ttotal: 2.68s\tremaining: 1.17s\n",
      "697:\tlearn: 0.0423794\ttotal: 2.69s\tremaining: 1.16s\n",
      "698:\tlearn: 0.0423464\ttotal: 2.69s\tremaining: 1.16s\n",
      "699:\tlearn: 0.0423199\ttotal: 2.7s\tremaining: 1.16s\n",
      "700:\tlearn: 0.0422989\ttotal: 2.7s\tremaining: 1.15s\n",
      "701:\tlearn: 0.0422882\ttotal: 2.7s\tremaining: 1.15s\n",
      "702:\tlearn: 0.0421779\ttotal: 2.71s\tremaining: 1.14s\n",
      "703:\tlearn: 0.0421333\ttotal: 2.71s\tremaining: 1.14s\n",
      "704:\tlearn: 0.0420562\ttotal: 2.72s\tremaining: 1.14s\n",
      "705:\tlearn: 0.0420312\ttotal: 2.72s\tremaining: 1.13s\n",
      "706:\tlearn: 0.0419964\ttotal: 2.73s\tremaining: 1.13s\n",
      "707:\tlearn: 0.0419754\ttotal: 2.73s\tremaining: 1.13s\n",
      "708:\tlearn: 0.0418529\ttotal: 2.73s\tremaining: 1.12s\n",
      "709:\tlearn: 0.0418364\ttotal: 2.74s\tremaining: 1.12s\n",
      "710:\tlearn: 0.0418221\ttotal: 2.74s\tremaining: 1.11s\n",
      "711:\tlearn: 0.0417244\ttotal: 2.74s\tremaining: 1.11s\n",
      "712:\tlearn: 0.0416977\ttotal: 2.75s\tremaining: 1.1s\n",
      "713:\tlearn: 0.0416193\ttotal: 2.75s\tremaining: 1.1s\n",
      "714:\tlearn: 0.0415926\ttotal: 2.75s\tremaining: 1.1s\n",
      "715:\tlearn: 0.0415020\ttotal: 2.76s\tremaining: 1.09s\n",
      "716:\tlearn: 0.0414374\ttotal: 2.76s\tremaining: 1.09s\n",
      "717:\tlearn: 0.0413777\ttotal: 2.77s\tremaining: 1.09s\n",
      "718:\tlearn: 0.0413600\ttotal: 2.77s\tremaining: 1.08s\n",
      "719:\tlearn: 0.0413472\ttotal: 2.77s\tremaining: 1.08s\n",
      "720:\tlearn: 0.0413171\ttotal: 2.78s\tremaining: 1.07s\n",
      "721:\tlearn: 0.0412820\ttotal: 2.78s\tremaining: 1.07s\n",
      "722:\tlearn: 0.0412261\ttotal: 2.79s\tremaining: 1.07s\n",
      "723:\tlearn: 0.0412096\ttotal: 2.79s\tremaining: 1.06s\n",
      "724:\tlearn: 0.0411726\ttotal: 2.79s\tremaining: 1.06s\n",
      "725:\tlearn: 0.0411381\ttotal: 2.8s\tremaining: 1.06s\n",
      "726:\tlearn: 0.0411237\ttotal: 2.8s\tremaining: 1.05s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "727:\tlearn: 0.0410689\ttotal: 2.81s\tremaining: 1.05s\n",
      "728:\tlearn: 0.0410362\ttotal: 2.81s\tremaining: 1.04s\n",
      "729:\tlearn: 0.0410254\ttotal: 2.81s\tremaining: 1.04s\n",
      "730:\tlearn: 0.0410087\ttotal: 2.82s\tremaining: 1.04s\n",
      "731:\tlearn: 0.0409923\ttotal: 2.82s\tremaining: 1.03s\n",
      "732:\tlearn: 0.0409672\ttotal: 2.83s\tremaining: 1.03s\n",
      "733:\tlearn: 0.0409377\ttotal: 2.83s\tremaining: 1.02s\n",
      "734:\tlearn: 0.0409120\ttotal: 2.83s\tremaining: 1.02s\n",
      "735:\tlearn: 0.0408955\ttotal: 2.84s\tremaining: 1.02s\n",
      "736:\tlearn: 0.0408560\ttotal: 2.84s\tremaining: 1.01s\n",
      "737:\tlearn: 0.0408417\ttotal: 2.85s\tremaining: 1.01s\n",
      "738:\tlearn: 0.0407666\ttotal: 2.85s\tremaining: 1.01s\n",
      "739:\tlearn: 0.0406864\ttotal: 2.85s\tremaining: 1s\n",
      "740:\tlearn: 0.0406671\ttotal: 2.86s\tremaining: 999ms\n",
      "741:\tlearn: 0.0406503\ttotal: 2.86s\tremaining: 995ms\n",
      "742:\tlearn: 0.0405978\ttotal: 2.87s\tremaining: 991ms\n",
      "743:\tlearn: 0.0405763\ttotal: 2.87s\tremaining: 988ms\n",
      "744:\tlearn: 0.0404938\ttotal: 2.87s\tremaining: 984ms\n",
      "745:\tlearn: 0.0404611\ttotal: 2.88s\tremaining: 980ms\n",
      "746:\tlearn: 0.0404339\ttotal: 2.88s\tremaining: 976ms\n",
      "747:\tlearn: 0.0403982\ttotal: 2.89s\tremaining: 972ms\n",
      "748:\tlearn: 0.0403799\ttotal: 2.89s\tremaining: 968ms\n",
      "749:\tlearn: 0.0403628\ttotal: 2.89s\tremaining: 964ms\n",
      "750:\tlearn: 0.0403339\ttotal: 2.9s\tremaining: 961ms\n",
      "751:\tlearn: 0.0403102\ttotal: 2.9s\tremaining: 957ms\n",
      "752:\tlearn: 0.0402776\ttotal: 2.9s\tremaining: 953ms\n",
      "753:\tlearn: 0.0402572\ttotal: 2.91s\tremaining: 949ms\n",
      "754:\tlearn: 0.0402432\ttotal: 2.91s\tremaining: 946ms\n",
      "755:\tlearn: 0.0402260\ttotal: 2.92s\tremaining: 942ms\n",
      "756:\tlearn: 0.0402109\ttotal: 2.92s\tremaining: 938ms\n",
      "757:\tlearn: 0.0401941\ttotal: 2.93s\tremaining: 935ms\n",
      "758:\tlearn: 0.0401252\ttotal: 2.93s\tremaining: 931ms\n",
      "759:\tlearn: 0.0400847\ttotal: 2.94s\tremaining: 927ms\n",
      "760:\tlearn: 0.0400609\ttotal: 2.94s\tremaining: 923ms\n",
      "761:\tlearn: 0.0400379\ttotal: 2.94s\tremaining: 919ms\n",
      "762:\tlearn: 0.0399713\ttotal: 2.95s\tremaining: 916ms\n",
      "763:\tlearn: 0.0399313\ttotal: 2.95s\tremaining: 912ms\n",
      "764:\tlearn: 0.0399155\ttotal: 2.96s\tremaining: 908ms\n",
      "765:\tlearn: 0.0399022\ttotal: 2.96s\tremaining: 904ms\n",
      "766:\tlearn: 0.0398854\ttotal: 2.96s\tremaining: 900ms\n",
      "767:\tlearn: 0.0398354\ttotal: 2.97s\tremaining: 896ms\n",
      "768:\tlearn: 0.0398101\ttotal: 2.97s\tremaining: 893ms\n",
      "769:\tlearn: 0.0397676\ttotal: 2.98s\tremaining: 889ms\n",
      "770:\tlearn: 0.0397337\ttotal: 2.98s\tremaining: 885ms\n",
      "771:\tlearn: 0.0397124\ttotal: 2.98s\tremaining: 881ms\n",
      "772:\tlearn: 0.0396982\ttotal: 2.99s\tremaining: 877ms\n",
      "773:\tlearn: 0.0396696\ttotal: 2.99s\tremaining: 873ms\n",
      "774:\tlearn: 0.0396555\ttotal: 2.99s\tremaining: 869ms\n",
      "775:\tlearn: 0.0396405\ttotal: 3s\tremaining: 865ms\n",
      "776:\tlearn: 0.0396251\ttotal: 3s\tremaining: 862ms\n",
      "777:\tlearn: 0.0395881\ttotal: 3.01s\tremaining: 858ms\n",
      "778:\tlearn: 0.0395747\ttotal: 3.01s\tremaining: 854ms\n",
      "779:\tlearn: 0.0395620\ttotal: 3.02s\tremaining: 850ms\n",
      "780:\tlearn: 0.0395406\ttotal: 3.02s\tremaining: 847ms\n",
      "781:\tlearn: 0.0395012\ttotal: 3.02s\tremaining: 843ms\n",
      "782:\tlearn: 0.0394445\ttotal: 3.03s\tremaining: 839ms\n",
      "783:\tlearn: 0.0393508\ttotal: 3.03s\tremaining: 835ms\n",
      "784:\tlearn: 0.0393322\ttotal: 3.03s\tremaining: 831ms\n",
      "785:\tlearn: 0.0393178\ttotal: 3.04s\tremaining: 827ms\n",
      "786:\tlearn: 0.0392541\ttotal: 3.04s\tremaining: 823ms\n",
      "787:\tlearn: 0.0392304\ttotal: 3.04s\tremaining: 819ms\n",
      "788:\tlearn: 0.0391968\ttotal: 3.05s\tremaining: 815ms\n",
      "789:\tlearn: 0.0391654\ttotal: 3.05s\tremaining: 811ms\n",
      "790:\tlearn: 0.0390788\ttotal: 3.06s\tremaining: 807ms\n",
      "791:\tlearn: 0.0389962\ttotal: 3.06s\tremaining: 803ms\n",
      "792:\tlearn: 0.0389634\ttotal: 3.06s\tremaining: 800ms\n",
      "793:\tlearn: 0.0389072\ttotal: 3.07s\tremaining: 796ms\n",
      "794:\tlearn: 0.0388961\ttotal: 3.07s\tremaining: 792ms\n",
      "795:\tlearn: 0.0388478\ttotal: 3.07s\tremaining: 788ms\n",
      "796:\tlearn: 0.0387707\ttotal: 3.08s\tremaining: 784ms\n",
      "797:\tlearn: 0.0387069\ttotal: 3.08s\tremaining: 780ms\n",
      "798:\tlearn: 0.0386505\ttotal: 3.09s\tremaining: 776ms\n",
      "799:\tlearn: 0.0386377\ttotal: 3.09s\tremaining: 772ms\n",
      "800:\tlearn: 0.0386202\ttotal: 3.09s\tremaining: 769ms\n",
      "801:\tlearn: 0.0385200\ttotal: 3.1s\tremaining: 765ms\n",
      "802:\tlearn: 0.0384735\ttotal: 3.1s\tremaining: 761ms\n",
      "803:\tlearn: 0.0384585\ttotal: 3.11s\tremaining: 757ms\n",
      "804:\tlearn: 0.0384404\ttotal: 3.11s\tremaining: 753ms\n",
      "805:\tlearn: 0.0384236\ttotal: 3.11s\tremaining: 750ms\n",
      "806:\tlearn: 0.0383695\ttotal: 3.12s\tremaining: 746ms\n",
      "807:\tlearn: 0.0383515\ttotal: 3.12s\tremaining: 742ms\n",
      "808:\tlearn: 0.0383049\ttotal: 3.13s\tremaining: 738ms\n",
      "809:\tlearn: 0.0382234\ttotal: 3.13s\tremaining: 734ms\n",
      "810:\tlearn: 0.0381924\ttotal: 3.13s\tremaining: 730ms\n",
      "811:\tlearn: 0.0381793\ttotal: 3.14s\tremaining: 726ms\n",
      "812:\tlearn: 0.0381618\ttotal: 3.14s\tremaining: 723ms\n",
      "813:\tlearn: 0.0381401\ttotal: 3.15s\tremaining: 719ms\n",
      "814:\tlearn: 0.0381264\ttotal: 3.15s\tremaining: 715ms\n",
      "815:\tlearn: 0.0380960\ttotal: 3.15s\tremaining: 711ms\n",
      "816:\tlearn: 0.0379875\ttotal: 3.16s\tremaining: 708ms\n",
      "817:\tlearn: 0.0379158\ttotal: 3.16s\tremaining: 704ms\n",
      "818:\tlearn: 0.0378885\ttotal: 3.17s\tremaining: 700ms\n",
      "819:\tlearn: 0.0378759\ttotal: 3.17s\tremaining: 697ms\n",
      "820:\tlearn: 0.0378466\ttotal: 3.18s\tremaining: 693ms\n",
      "821:\tlearn: 0.0377706\ttotal: 3.18s\tremaining: 689ms\n",
      "822:\tlearn: 0.0377593\ttotal: 3.19s\tremaining: 685ms\n",
      "823:\tlearn: 0.0376742\ttotal: 3.19s\tremaining: 682ms\n",
      "824:\tlearn: 0.0376541\ttotal: 3.19s\tremaining: 678ms\n",
      "825:\tlearn: 0.0376355\ttotal: 3.2s\tremaining: 674ms\n",
      "826:\tlearn: 0.0375951\ttotal: 3.2s\tremaining: 670ms\n",
      "827:\tlearn: 0.0375838\ttotal: 3.21s\tremaining: 667ms\n",
      "828:\tlearn: 0.0375615\ttotal: 3.21s\tremaining: 663ms\n",
      "829:\tlearn: 0.0374919\ttotal: 3.22s\tremaining: 659ms\n",
      "830:\tlearn: 0.0374160\ttotal: 3.22s\tremaining: 655ms\n",
      "831:\tlearn: 0.0373884\ttotal: 3.23s\tremaining: 652ms\n",
      "832:\tlearn: 0.0373578\ttotal: 3.23s\tremaining: 648ms\n",
      "833:\tlearn: 0.0372755\ttotal: 3.23s\tremaining: 644ms\n",
      "834:\tlearn: 0.0372634\ttotal: 3.24s\tremaining: 640ms\n",
      "835:\tlearn: 0.0372376\ttotal: 3.24s\tremaining: 636ms\n",
      "836:\tlearn: 0.0371762\ttotal: 3.25s\tremaining: 633ms\n",
      "837:\tlearn: 0.0371574\ttotal: 3.25s\tremaining: 629ms\n",
      "838:\tlearn: 0.0371488\ttotal: 3.26s\tremaining: 626ms\n",
      "839:\tlearn: 0.0371010\ttotal: 3.26s\tremaining: 622ms\n",
      "840:\tlearn: 0.0370809\ttotal: 3.27s\tremaining: 618ms\n",
      "841:\tlearn: 0.0370582\ttotal: 3.27s\tremaining: 614ms\n",
      "842:\tlearn: 0.0370470\ttotal: 3.28s\tremaining: 611ms\n",
      "843:\tlearn: 0.0369952\ttotal: 3.29s\tremaining: 607ms\n",
      "844:\tlearn: 0.0369772\ttotal: 3.29s\tremaining: 604ms\n",
      "845:\tlearn: 0.0369587\ttotal: 3.29s\tremaining: 600ms\n",
      "846:\tlearn: 0.0369155\ttotal: 3.3s\tremaining: 596ms\n",
      "847:\tlearn: 0.0368331\ttotal: 3.31s\tremaining: 592ms\n",
      "848:\tlearn: 0.0368155\ttotal: 3.31s\tremaining: 589ms\n",
      "849:\tlearn: 0.0367627\ttotal: 3.31s\tremaining: 585ms\n",
      "850:\tlearn: 0.0366841\ttotal: 3.32s\tremaining: 581ms\n",
      "851:\tlearn: 0.0366425\ttotal: 3.33s\tremaining: 578ms\n",
      "852:\tlearn: 0.0365534\ttotal: 3.33s\tremaining: 574ms\n",
      "853:\tlearn: 0.0364773\ttotal: 3.33s\tremaining: 570ms\n",
      "854:\tlearn: 0.0363988\ttotal: 3.34s\tremaining: 566ms\n",
      "855:\tlearn: 0.0363817\ttotal: 3.34s\tremaining: 563ms\n",
      "856:\tlearn: 0.0363737\ttotal: 3.35s\tremaining: 559ms\n",
      "857:\tlearn: 0.0363564\ttotal: 3.35s\tremaining: 555ms\n",
      "858:\tlearn: 0.0363394\ttotal: 3.36s\tremaining: 551ms\n",
      "859:\tlearn: 0.0363152\ttotal: 3.36s\tremaining: 547ms\n",
      "860:\tlearn: 0.0362719\ttotal: 3.37s\tremaining: 543ms\n",
      "861:\tlearn: 0.0362475\ttotal: 3.37s\tremaining: 540ms\n",
      "862:\tlearn: 0.0362186\ttotal: 3.37s\tremaining: 536ms\n",
      "863:\tlearn: 0.0361911\ttotal: 3.38s\tremaining: 532ms\n",
      "864:\tlearn: 0.0361148\ttotal: 3.38s\tremaining: 528ms\n",
      "865:\tlearn: 0.0360825\ttotal: 3.38s\tremaining: 524ms\n",
      "866:\tlearn: 0.0360134\ttotal: 3.39s\tremaining: 520ms\n",
      "867:\tlearn: 0.0359466\ttotal: 3.39s\tremaining: 516ms\n",
      "868:\tlearn: 0.0358888\ttotal: 3.4s\tremaining: 512ms\n",
      "869:\tlearn: 0.0358502\ttotal: 3.4s\tremaining: 508ms\n",
      "870:\tlearn: 0.0357600\ttotal: 3.4s\tremaining: 504ms\n",
      "871:\tlearn: 0.0356935\ttotal: 3.41s\tremaining: 500ms\n",
      "872:\tlearn: 0.0356265\ttotal: 3.41s\tremaining: 496ms\n",
      "873:\tlearn: 0.0356075\ttotal: 3.42s\tremaining: 492ms\n",
      "874:\tlearn: 0.0355912\ttotal: 3.42s\tremaining: 489ms\n",
      "875:\tlearn: 0.0355397\ttotal: 3.42s\tremaining: 485ms\n",
      "876:\tlearn: 0.0355127\ttotal: 3.43s\tremaining: 481ms\n",
      "877:\tlearn: 0.0354939\ttotal: 3.43s\tremaining: 477ms\n",
      "878:\tlearn: 0.0354815\ttotal: 3.44s\tremaining: 473ms\n",
      "879:\tlearn: 0.0354660\ttotal: 3.44s\tremaining: 469ms\n",
      "880:\tlearn: 0.0354500\ttotal: 3.44s\tremaining: 465ms\n",
      "881:\tlearn: 0.0353922\ttotal: 3.45s\tremaining: 461ms\n",
      "882:\tlearn: 0.0353655\ttotal: 3.45s\tremaining: 457ms\n",
      "883:\tlearn: 0.0353110\ttotal: 3.45s\tremaining: 453ms\n",
      "884:\tlearn: 0.0352720\ttotal: 3.46s\tremaining: 449ms\n",
      "885:\tlearn: 0.0352242\ttotal: 3.46s\tremaining: 445ms\n",
      "886:\tlearn: 0.0351393\ttotal: 3.46s\tremaining: 441ms\n",
      "887:\tlearn: 0.0351237\ttotal: 3.47s\tremaining: 438ms\n",
      "888:\tlearn: 0.0350511\ttotal: 3.47s\tremaining: 434ms\n",
      "889:\tlearn: 0.0350234\ttotal: 3.48s\tremaining: 430ms\n",
      "890:\tlearn: 0.0349815\ttotal: 3.48s\tremaining: 426ms\n",
      "891:\tlearn: 0.0349290\ttotal: 3.48s\tremaining: 422ms\n",
      "892:\tlearn: 0.0349018\ttotal: 3.49s\tremaining: 418ms\n",
      "893:\tlearn: 0.0348740\ttotal: 3.49s\tremaining: 414ms\n",
      "894:\tlearn: 0.0347921\ttotal: 3.5s\tremaining: 410ms\n",
      "895:\tlearn: 0.0347822\ttotal: 3.5s\tremaining: 407ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "896:\tlearn: 0.0347366\ttotal: 3.51s\tremaining: 403ms\n",
      "897:\tlearn: 0.0347269\ttotal: 3.51s\tremaining: 399ms\n",
      "898:\tlearn: 0.0346822\ttotal: 3.52s\tremaining: 395ms\n",
      "899:\tlearn: 0.0346181\ttotal: 3.52s\tremaining: 391ms\n",
      "900:\tlearn: 0.0346084\ttotal: 3.52s\tremaining: 387ms\n",
      "901:\tlearn: 0.0345379\ttotal: 3.53s\tremaining: 383ms\n",
      "902:\tlearn: 0.0345224\ttotal: 3.53s\tremaining: 379ms\n",
      "903:\tlearn: 0.0344722\ttotal: 3.54s\tremaining: 375ms\n",
      "904:\tlearn: 0.0344565\ttotal: 3.54s\tremaining: 371ms\n",
      "905:\tlearn: 0.0344317\ttotal: 3.54s\tremaining: 368ms\n",
      "906:\tlearn: 0.0343546\ttotal: 3.54s\tremaining: 364ms\n",
      "907:\tlearn: 0.0342873\ttotal: 3.55s\tremaining: 360ms\n",
      "908:\tlearn: 0.0342723\ttotal: 3.55s\tremaining: 356ms\n",
      "909:\tlearn: 0.0342617\ttotal: 3.56s\tremaining: 352ms\n",
      "910:\tlearn: 0.0342003\ttotal: 3.56s\tremaining: 348ms\n",
      "911:\tlearn: 0.0341614\ttotal: 3.56s\tremaining: 344ms\n",
      "912:\tlearn: 0.0341070\ttotal: 3.57s\tremaining: 340ms\n",
      "913:\tlearn: 0.0340964\ttotal: 3.57s\tremaining: 336ms\n",
      "914:\tlearn: 0.0340846\ttotal: 3.58s\tremaining: 332ms\n",
      "915:\tlearn: 0.0340697\ttotal: 3.58s\tremaining: 328ms\n",
      "916:\tlearn: 0.0340553\ttotal: 3.58s\tremaining: 324ms\n",
      "917:\tlearn: 0.0339896\ttotal: 3.59s\tremaining: 320ms\n",
      "918:\tlearn: 0.0339820\ttotal: 3.59s\tremaining: 317ms\n",
      "919:\tlearn: 0.0339611\ttotal: 3.6s\tremaining: 313ms\n",
      "920:\tlearn: 0.0339151\ttotal: 3.6s\tremaining: 309ms\n",
      "921:\tlearn: 0.0338630\ttotal: 3.6s\tremaining: 305ms\n",
      "922:\tlearn: 0.0338035\ttotal: 3.61s\tremaining: 301ms\n",
      "923:\tlearn: 0.0337943\ttotal: 3.61s\tremaining: 297ms\n",
      "924:\tlearn: 0.0337583\ttotal: 3.61s\tremaining: 293ms\n",
      "925:\tlearn: 0.0336946\ttotal: 3.62s\tremaining: 289ms\n",
      "926:\tlearn: 0.0336855\ttotal: 3.62s\tremaining: 285ms\n",
      "927:\tlearn: 0.0336676\ttotal: 3.62s\tremaining: 281ms\n",
      "928:\tlearn: 0.0336094\ttotal: 3.63s\tremaining: 277ms\n",
      "929:\tlearn: 0.0336011\ttotal: 3.63s\tremaining: 273ms\n",
      "930:\tlearn: 0.0335906\ttotal: 3.63s\tremaining: 269ms\n",
      "931:\tlearn: 0.0335282\ttotal: 3.64s\tremaining: 266ms\n",
      "932:\tlearn: 0.0334971\ttotal: 3.64s\tremaining: 262ms\n",
      "933:\tlearn: 0.0334907\ttotal: 3.65s\tremaining: 258ms\n",
      "934:\tlearn: 0.0334768\ttotal: 3.65s\tremaining: 254ms\n",
      "935:\tlearn: 0.0334608\ttotal: 3.65s\tremaining: 250ms\n",
      "936:\tlearn: 0.0334172\ttotal: 3.66s\tremaining: 246ms\n",
      "937:\tlearn: 0.0333643\ttotal: 3.66s\tremaining: 242ms\n",
      "938:\tlearn: 0.0333129\ttotal: 3.67s\tremaining: 238ms\n",
      "939:\tlearn: 0.0333039\ttotal: 3.67s\tremaining: 234ms\n",
      "940:\tlearn: 0.0332902\ttotal: 3.67s\tremaining: 230ms\n",
      "941:\tlearn: 0.0332051\ttotal: 3.68s\tremaining: 226ms\n",
      "942:\tlearn: 0.0331896\ttotal: 3.68s\tremaining: 222ms\n",
      "943:\tlearn: 0.0331637\ttotal: 3.69s\tremaining: 219ms\n",
      "944:\tlearn: 0.0331107\ttotal: 3.69s\tremaining: 215ms\n",
      "945:\tlearn: 0.0330545\ttotal: 3.69s\tremaining: 211ms\n",
      "946:\tlearn: 0.0330462\ttotal: 3.7s\tremaining: 207ms\n",
      "947:\tlearn: 0.0329952\ttotal: 3.7s\tremaining: 203ms\n",
      "948:\tlearn: 0.0329812\ttotal: 3.71s\tremaining: 199ms\n",
      "949:\tlearn: 0.0329731\ttotal: 3.71s\tremaining: 195ms\n",
      "950:\tlearn: 0.0329228\ttotal: 3.71s\tremaining: 191ms\n",
      "951:\tlearn: 0.0329152\ttotal: 3.72s\tremaining: 187ms\n",
      "952:\tlearn: 0.0328667\ttotal: 3.72s\tremaining: 183ms\n",
      "953:\tlearn: 0.0328436\ttotal: 3.72s\tremaining: 180ms\n",
      "954:\tlearn: 0.0328199\ttotal: 3.73s\tremaining: 176ms\n",
      "955:\tlearn: 0.0328116\ttotal: 3.73s\tremaining: 172ms\n",
      "956:\tlearn: 0.0327981\ttotal: 3.73s\tremaining: 168ms\n",
      "957:\tlearn: 0.0327902\ttotal: 3.74s\tremaining: 164ms\n",
      "958:\tlearn: 0.0327646\ttotal: 3.74s\tremaining: 160ms\n",
      "959:\tlearn: 0.0327420\ttotal: 3.75s\tremaining: 156ms\n",
      "960:\tlearn: 0.0326932\ttotal: 3.75s\tremaining: 152ms\n",
      "961:\tlearn: 0.0326074\ttotal: 3.75s\tremaining: 148ms\n",
      "962:\tlearn: 0.0325614\ttotal: 3.76s\tremaining: 144ms\n",
      "963:\tlearn: 0.0325140\ttotal: 3.76s\tremaining: 140ms\n",
      "964:\tlearn: 0.0324345\ttotal: 3.76s\tremaining: 137ms\n",
      "965:\tlearn: 0.0323880\ttotal: 3.77s\tremaining: 133ms\n",
      "966:\tlearn: 0.0323785\ttotal: 3.77s\tremaining: 129ms\n",
      "967:\tlearn: 0.0323711\ttotal: 3.77s\tremaining: 125ms\n",
      "968:\tlearn: 0.0323212\ttotal: 3.78s\tremaining: 121ms\n",
      "969:\tlearn: 0.0322961\ttotal: 3.78s\tremaining: 117ms\n",
      "970:\tlearn: 0.0322829\ttotal: 3.79s\tremaining: 113ms\n",
      "971:\tlearn: 0.0322570\ttotal: 3.79s\tremaining: 109ms\n",
      "972:\tlearn: 0.0322151\ttotal: 3.79s\tremaining: 105ms\n",
      "973:\tlearn: 0.0321934\ttotal: 3.8s\tremaining: 101ms\n",
      "974:\tlearn: 0.0321495\ttotal: 3.8s\tremaining: 97.5ms\n",
      "975:\tlearn: 0.0321022\ttotal: 3.81s\tremaining: 93.6ms\n",
      "976:\tlearn: 0.0320354\ttotal: 3.81s\tremaining: 89.7ms\n",
      "977:\tlearn: 0.0320090\ttotal: 3.81s\tremaining: 85.8ms\n",
      "978:\tlearn: 0.0319938\ttotal: 3.82s\tremaining: 81.9ms\n",
      "979:\tlearn: 0.0319725\ttotal: 3.82s\tremaining: 78ms\n",
      "980:\tlearn: 0.0319584\ttotal: 3.82s\tremaining: 74.1ms\n",
      "981:\tlearn: 0.0319179\ttotal: 3.83s\tremaining: 70.2ms\n",
      "982:\tlearn: 0.0318381\ttotal: 3.83s\tremaining: 66.3ms\n",
      "983:\tlearn: 0.0318208\ttotal: 3.83s\tremaining: 62.4ms\n",
      "984:\tlearn: 0.0317763\ttotal: 3.84s\tremaining: 58.5ms\n",
      "985:\tlearn: 0.0317646\ttotal: 3.84s\tremaining: 54.6ms\n",
      "986:\tlearn: 0.0317414\ttotal: 3.85s\tremaining: 50.7ms\n",
      "987:\tlearn: 0.0317340\ttotal: 3.85s\tremaining: 46.8ms\n",
      "988:\tlearn: 0.0316972\ttotal: 3.85s\tremaining: 42.9ms\n",
      "989:\tlearn: 0.0316324\ttotal: 3.86s\tremaining: 39ms\n",
      "990:\tlearn: 0.0316119\ttotal: 3.86s\tremaining: 35.1ms\n",
      "991:\tlearn: 0.0315919\ttotal: 3.87s\tremaining: 31.2ms\n",
      "992:\tlearn: 0.0315277\ttotal: 3.87s\tremaining: 27.3ms\n",
      "993:\tlearn: 0.0315201\ttotal: 3.87s\tremaining: 23.4ms\n",
      "994:\tlearn: 0.0314812\ttotal: 3.88s\tremaining: 19.5ms\n",
      "995:\tlearn: 0.0314741\ttotal: 3.88s\tremaining: 15.6ms\n",
      "996:\tlearn: 0.0314306\ttotal: 3.88s\tremaining: 11.7ms\n",
      "997:\tlearn: 0.0313877\ttotal: 3.89s\tremaining: 7.79ms\n",
      "998:\tlearn: 0.0313783\ttotal: 3.89s\tremaining: 3.9ms\n",
      "999:\tlearn: 0.0313599\ttotal: 3.9s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013279\n",
      "0:\tlearn: 0.6676845\ttotal: 4.29ms\tremaining: 4.29s\n",
      "1:\tlearn: 0.6433090\ttotal: 9.11ms\tremaining: 4.55s\n",
      "2:\tlearn: 0.6193446\ttotal: 14ms\tremaining: 4.66s\n",
      "3:\tlearn: 0.5968071\ttotal: 18.4ms\tremaining: 4.58s\n",
      "4:\tlearn: 0.5751984\ttotal: 22.6ms\tremaining: 4.49s\n",
      "5:\tlearn: 0.5595988\ttotal: 27.4ms\tremaining: 4.53s\n",
      "6:\tlearn: 0.5394993\ttotal: 33.5ms\tremaining: 4.75s\n",
      "7:\tlearn: 0.5220824\ttotal: 39.9ms\tremaining: 4.94s\n",
      "8:\tlearn: 0.5062013\ttotal: 46.4ms\tremaining: 5.11s\n",
      "9:\tlearn: 0.4891493\ttotal: 50.3ms\tremaining: 4.98s\n",
      "10:\tlearn: 0.4731482\ttotal: 54.6ms\tremaining: 4.91s\n",
      "11:\tlearn: 0.4573374\ttotal: 61.8ms\tremaining: 5.09s\n",
      "12:\tlearn: 0.4426357\ttotal: 67.7ms\tremaining: 5.14s\n",
      "13:\tlearn: 0.4286627\ttotal: 73.6ms\tremaining: 5.19s\n",
      "14:\tlearn: 0.4148720\ttotal: 79.1ms\tremaining: 5.19s\n",
      "15:\tlearn: 0.4016103\ttotal: 83ms\tremaining: 5.1s\n",
      "16:\tlearn: 0.3906567\ttotal: 87.1ms\tremaining: 5.04s\n",
      "17:\tlearn: 0.3794505\ttotal: 92.4ms\tremaining: 5.04s\n",
      "18:\tlearn: 0.3682888\ttotal: 97.6ms\tremaining: 5.04s\n",
      "19:\tlearn: 0.3578617\ttotal: 103ms\tremaining: 5.03s\n",
      "20:\tlearn: 0.3484975\ttotal: 108ms\tremaining: 5.05s\n",
      "21:\tlearn: 0.3414235\ttotal: 112ms\tremaining: 5s\n",
      "22:\tlearn: 0.3323020\ttotal: 116ms\tremaining: 4.94s\n",
      "23:\tlearn: 0.3252588\ttotal: 121ms\tremaining: 4.93s\n",
      "24:\tlearn: 0.3168303\ttotal: 126ms\tremaining: 4.91s\n",
      "25:\tlearn: 0.3089253\ttotal: 130ms\tremaining: 4.86s\n",
      "26:\tlearn: 0.3021421\ttotal: 134ms\tremaining: 4.83s\n",
      "27:\tlearn: 0.2948208\ttotal: 139ms\tremaining: 4.81s\n",
      "28:\tlearn: 0.2883051\ttotal: 143ms\tremaining: 4.77s\n",
      "29:\tlearn: 0.2818053\ttotal: 146ms\tremaining: 4.72s\n",
      "30:\tlearn: 0.2756956\ttotal: 150ms\tremaining: 4.69s\n",
      "31:\tlearn: 0.2688760\ttotal: 155ms\tremaining: 4.69s\n",
      "32:\tlearn: 0.2628793\ttotal: 160ms\tremaining: 4.68s\n",
      "33:\tlearn: 0.2572755\ttotal: 164ms\tremaining: 4.66s\n",
      "34:\tlearn: 0.2514117\ttotal: 168ms\tremaining: 4.63s\n",
      "35:\tlearn: 0.2466038\ttotal: 172ms\tremaining: 4.61s\n",
      "36:\tlearn: 0.2417077\ttotal: 176ms\tremaining: 4.57s\n",
      "37:\tlearn: 0.2371461\ttotal: 180ms\tremaining: 4.55s\n",
      "38:\tlearn: 0.2328719\ttotal: 185ms\tremaining: 4.55s\n",
      "39:\tlearn: 0.2288701\ttotal: 189ms\tremaining: 4.55s\n",
      "40:\tlearn: 0.2254900\ttotal: 193ms\tremaining: 4.52s\n",
      "41:\tlearn: 0.2214453\ttotal: 197ms\tremaining: 4.49s\n",
      "42:\tlearn: 0.2174302\ttotal: 201ms\tremaining: 4.47s\n",
      "43:\tlearn: 0.2140108\ttotal: 204ms\tremaining: 4.44s\n",
      "44:\tlearn: 0.2108869\ttotal: 208ms\tremaining: 4.42s\n",
      "45:\tlearn: 0.2074843\ttotal: 212ms\tremaining: 4.4s\n",
      "46:\tlearn: 0.2038729\ttotal: 217ms\tremaining: 4.4s\n",
      "47:\tlearn: 0.2004081\ttotal: 221ms\tremaining: 4.38s\n",
      "48:\tlearn: 0.1979062\ttotal: 224ms\tremaining: 4.35s\n",
      "49:\tlearn: 0.1949464\ttotal: 228ms\tremaining: 4.33s\n",
      "50:\tlearn: 0.1924185\ttotal: 232ms\tremaining: 4.32s\n",
      "51:\tlearn: 0.1899556\ttotal: 236ms\tremaining: 4.3s\n",
      "52:\tlearn: 0.1876456\ttotal: 240ms\tremaining: 4.28s\n",
      "53:\tlearn: 0.1850830\ttotal: 243ms\tremaining: 4.26s\n",
      "54:\tlearn: 0.1830889\ttotal: 247ms\tremaining: 4.25s\n",
      "55:\tlearn: 0.1803813\ttotal: 251ms\tremaining: 4.23s\n",
      "56:\tlearn: 0.1778237\ttotal: 255ms\tremaining: 4.22s\n",
      "57:\tlearn: 0.1758830\ttotal: 259ms\tremaining: 4.2s\n",
      "58:\tlearn: 0.1740852\ttotal: 262ms\tremaining: 4.19s\n",
      "59:\tlearn: 0.1715470\ttotal: 266ms\tremaining: 4.17s\n",
      "60:\tlearn: 0.1695678\ttotal: 270ms\tremaining: 4.15s\n",
      "61:\tlearn: 0.1678660\ttotal: 273ms\tremaining: 4.13s\n",
      "62:\tlearn: 0.1661977\ttotal: 277ms\tremaining: 4.12s\n",
      "63:\tlearn: 0.1646875\ttotal: 281ms\tremaining: 4.11s\n",
      "64:\tlearn: 0.1629236\ttotal: 285ms\tremaining: 4.1s\n",
      "65:\tlearn: 0.1614600\ttotal: 289ms\tremaining: 4.08s\n",
      "66:\tlearn: 0.1598507\ttotal: 292ms\tremaining: 4.07s\n",
      "67:\tlearn: 0.1583275\ttotal: 295ms\tremaining: 4.05s\n",
      "68:\tlearn: 0.1569332\ttotal: 299ms\tremaining: 4.04s\n",
      "69:\tlearn: 0.1555495\ttotal: 303ms\tremaining: 4.02s\n",
      "70:\tlearn: 0.1543288\ttotal: 307ms\tremaining: 4.01s\n",
      "71:\tlearn: 0.1528089\ttotal: 310ms\tremaining: 4s\n",
      "72:\tlearn: 0.1516837\ttotal: 314ms\tremaining: 3.99s\n",
      "73:\tlearn: 0.1506227\ttotal: 317ms\tremaining: 3.97s\n",
      "74:\tlearn: 0.1493255\ttotal: 321ms\tremaining: 3.96s\n",
      "75:\tlearn: 0.1482950\ttotal: 325ms\tremaining: 3.95s\n",
      "76:\tlearn: 0.1471856\ttotal: 328ms\tremaining: 3.93s\n",
      "77:\tlearn: 0.1459411\ttotal: 332ms\tremaining: 3.92s\n",
      "78:\tlearn: 0.1447458\ttotal: 335ms\tremaining: 3.91s\n",
      "79:\tlearn: 0.1435885\ttotal: 340ms\tremaining: 3.91s\n",
      "80:\tlearn: 0.1428835\ttotal: 344ms\tremaining: 3.9s\n",
      "81:\tlearn: 0.1417406\ttotal: 348ms\tremaining: 3.9s\n",
      "82:\tlearn: 0.1409164\ttotal: 353ms\tremaining: 3.9s\n",
      "83:\tlearn: 0.1398787\ttotal: 357ms\tremaining: 3.89s\n",
      "84:\tlearn: 0.1390541\ttotal: 361ms\tremaining: 3.88s\n",
      "85:\tlearn: 0.1381888\ttotal: 365ms\tremaining: 3.88s\n",
      "86:\tlearn: 0.1373178\ttotal: 369ms\tremaining: 3.88s\n",
      "87:\tlearn: 0.1363499\ttotal: 374ms\tremaining: 3.87s\n",
      "88:\tlearn: 0.1353182\ttotal: 377ms\tremaining: 3.86s\n",
      "89:\tlearn: 0.1344853\ttotal: 382ms\tremaining: 3.86s\n",
      "90:\tlearn: 0.1335681\ttotal: 386ms\tremaining: 3.85s\n",
      "91:\tlearn: 0.1328910\ttotal: 390ms\tremaining: 3.85s\n",
      "92:\tlearn: 0.1320571\ttotal: 394ms\tremaining: 3.84s\n",
      "93:\tlearn: 0.1310568\ttotal: 399ms\tremaining: 3.84s\n",
      "94:\tlearn: 0.1303796\ttotal: 405ms\tremaining: 3.86s\n",
      "95:\tlearn: 0.1296047\ttotal: 409ms\tremaining: 3.85s\n",
      "96:\tlearn: 0.1288261\ttotal: 413ms\tremaining: 3.85s\n",
      "97:\tlearn: 0.1282732\ttotal: 418ms\tremaining: 3.84s\n",
      "98:\tlearn: 0.1274887\ttotal: 422ms\tremaining: 3.84s\n",
      "99:\tlearn: 0.1267774\ttotal: 426ms\tremaining: 3.83s\n",
      "100:\tlearn: 0.1261589\ttotal: 430ms\tremaining: 3.83s\n",
      "101:\tlearn: 0.1254400\ttotal: 434ms\tremaining: 3.82s\n",
      "102:\tlearn: 0.1247783\ttotal: 438ms\tremaining: 3.82s\n",
      "103:\tlearn: 0.1242054\ttotal: 442ms\tremaining: 3.81s\n",
      "104:\tlearn: 0.1235758\ttotal: 447ms\tremaining: 3.81s\n",
      "105:\tlearn: 0.1229696\ttotal: 450ms\tremaining: 3.8s\n",
      "106:\tlearn: 0.1224886\ttotal: 455ms\tremaining: 3.79s\n",
      "107:\tlearn: 0.1218179\ttotal: 459ms\tremaining: 3.79s\n",
      "108:\tlearn: 0.1211160\ttotal: 463ms\tremaining: 3.79s\n",
      "109:\tlearn: 0.1207859\ttotal: 467ms\tremaining: 3.78s\n",
      "110:\tlearn: 0.1202156\ttotal: 471ms\tremaining: 3.77s\n",
      "111:\tlearn: 0.1197469\ttotal: 475ms\tremaining: 3.77s\n",
      "112:\tlearn: 0.1192156\ttotal: 479ms\tremaining: 3.76s\n",
      "113:\tlearn: 0.1187546\ttotal: 483ms\tremaining: 3.75s\n",
      "114:\tlearn: 0.1182391\ttotal: 487ms\tremaining: 3.75s\n",
      "115:\tlearn: 0.1177917\ttotal: 490ms\tremaining: 3.74s\n",
      "116:\tlearn: 0.1172167\ttotal: 494ms\tremaining: 3.73s\n",
      "117:\tlearn: 0.1168608\ttotal: 499ms\tremaining: 3.73s\n",
      "118:\tlearn: 0.1165124\ttotal: 503ms\tremaining: 3.72s\n",
      "119:\tlearn: 0.1158121\ttotal: 507ms\tremaining: 3.72s\n",
      "120:\tlearn: 0.1152750\ttotal: 511ms\tremaining: 3.71s\n",
      "121:\tlearn: 0.1147733\ttotal: 514ms\tremaining: 3.7s\n",
      "122:\tlearn: 0.1144372\ttotal: 519ms\tremaining: 3.7s\n",
      "123:\tlearn: 0.1140040\ttotal: 522ms\tremaining: 3.69s\n",
      "124:\tlearn: 0.1135011\ttotal: 527ms\tremaining: 3.69s\n",
      "125:\tlearn: 0.1130620\ttotal: 532ms\tremaining: 3.69s\n",
      "126:\tlearn: 0.1126883\ttotal: 535ms\tremaining: 3.68s\n",
      "127:\tlearn: 0.1121009\ttotal: 539ms\tremaining: 3.67s\n",
      "128:\tlearn: 0.1115257\ttotal: 543ms\tremaining: 3.67s\n",
      "129:\tlearn: 0.1112629\ttotal: 547ms\tremaining: 3.66s\n",
      "130:\tlearn: 0.1108111\ttotal: 551ms\tremaining: 3.66s\n",
      "131:\tlearn: 0.1103320\ttotal: 555ms\tremaining: 3.65s\n",
      "132:\tlearn: 0.1100390\ttotal: 559ms\tremaining: 3.65s\n",
      "133:\tlearn: 0.1096721\ttotal: 564ms\tremaining: 3.64s\n",
      "134:\tlearn: 0.1093815\ttotal: 567ms\tremaining: 3.64s\n",
      "135:\tlearn: 0.1090298\ttotal: 572ms\tremaining: 3.63s\n",
      "136:\tlearn: 0.1085617\ttotal: 576ms\tremaining: 3.63s\n",
      "137:\tlearn: 0.1081987\ttotal: 579ms\tremaining: 3.62s\n",
      "138:\tlearn: 0.1078001\ttotal: 583ms\tremaining: 3.61s\n",
      "139:\tlearn: 0.1073609\ttotal: 587ms\tremaining: 3.6s\n",
      "140:\tlearn: 0.1071682\ttotal: 591ms\tremaining: 3.6s\n",
      "141:\tlearn: 0.1065137\ttotal: 594ms\tremaining: 3.59s\n",
      "142:\tlearn: 0.1060481\ttotal: 598ms\tremaining: 3.58s\n",
      "143:\tlearn: 0.1055670\ttotal: 602ms\tremaining: 3.58s\n",
      "144:\tlearn: 0.1051940\ttotal: 606ms\tremaining: 3.57s\n",
      "145:\tlearn: 0.1048350\ttotal: 610ms\tremaining: 3.57s\n",
      "146:\tlearn: 0.1045763\ttotal: 614ms\tremaining: 3.56s\n",
      "147:\tlearn: 0.1042150\ttotal: 617ms\tremaining: 3.55s\n",
      "148:\tlearn: 0.1040261\ttotal: 622ms\tremaining: 3.55s\n",
      "149:\tlearn: 0.1037264\ttotal: 626ms\tremaining: 3.54s\n",
      "150:\tlearn: 0.1034070\ttotal: 629ms\tremaining: 3.54s\n",
      "151:\tlearn: 0.1031188\ttotal: 634ms\tremaining: 3.54s\n",
      "152:\tlearn: 0.1026960\ttotal: 638ms\tremaining: 3.53s\n",
      "153:\tlearn: 0.1024024\ttotal: 642ms\tremaining: 3.53s\n",
      "154:\tlearn: 0.1022029\ttotal: 646ms\tremaining: 3.52s\n",
      "155:\tlearn: 0.1019536\ttotal: 650ms\tremaining: 3.52s\n",
      "156:\tlearn: 0.1017283\ttotal: 654ms\tremaining: 3.51s\n",
      "157:\tlearn: 0.1014647\ttotal: 658ms\tremaining: 3.5s\n",
      "158:\tlearn: 0.1011563\ttotal: 661ms\tremaining: 3.5s\n",
      "159:\tlearn: 0.1010306\ttotal: 665ms\tremaining: 3.49s\n",
      "160:\tlearn: 0.1008477\ttotal: 669ms\tremaining: 3.48s\n",
      "161:\tlearn: 0.1005830\ttotal: 672ms\tremaining: 3.48s\n",
      "162:\tlearn: 0.1004190\ttotal: 676ms\tremaining: 3.47s\n",
      "163:\tlearn: 0.1002477\ttotal: 680ms\tremaining: 3.47s\n",
      "164:\tlearn: 0.0998137\ttotal: 684ms\tremaining: 3.46s\n",
      "165:\tlearn: 0.0996012\ttotal: 687ms\tremaining: 3.45s\n",
      "166:\tlearn: 0.0993002\ttotal: 691ms\tremaining: 3.45s\n",
      "167:\tlearn: 0.0990278\ttotal: 695ms\tremaining: 3.44s\n",
      "168:\tlearn: 0.0987239\ttotal: 699ms\tremaining: 3.44s\n",
      "169:\tlearn: 0.0984727\ttotal: 702ms\tremaining: 3.43s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "170:\tlearn: 0.0982429\ttotal: 706ms\tremaining: 3.42s\n",
      "171:\tlearn: 0.0979798\ttotal: 710ms\tremaining: 3.42s\n",
      "172:\tlearn: 0.0975999\ttotal: 714ms\tremaining: 3.41s\n",
      "173:\tlearn: 0.0973756\ttotal: 718ms\tremaining: 3.41s\n",
      "174:\tlearn: 0.0971128\ttotal: 722ms\tremaining: 3.4s\n",
      "175:\tlearn: 0.0969621\ttotal: 727ms\tremaining: 3.4s\n",
      "176:\tlearn: 0.0967452\ttotal: 731ms\tremaining: 3.4s\n",
      "177:\tlearn: 0.0965278\ttotal: 734ms\tremaining: 3.39s\n",
      "178:\tlearn: 0.0963468\ttotal: 738ms\tremaining: 3.38s\n",
      "179:\tlearn: 0.0962158\ttotal: 742ms\tremaining: 3.38s\n",
      "180:\tlearn: 0.0960573\ttotal: 747ms\tremaining: 3.38s\n",
      "181:\tlearn: 0.0958289\ttotal: 752ms\tremaining: 3.38s\n",
      "182:\tlearn: 0.0955882\ttotal: 756ms\tremaining: 3.38s\n",
      "183:\tlearn: 0.0952717\ttotal: 762ms\tremaining: 3.38s\n",
      "184:\tlearn: 0.0950881\ttotal: 766ms\tremaining: 3.37s\n",
      "185:\tlearn: 0.0948375\ttotal: 770ms\tremaining: 3.37s\n",
      "186:\tlearn: 0.0944970\ttotal: 775ms\tremaining: 3.37s\n",
      "187:\tlearn: 0.0942248\ttotal: 779ms\tremaining: 3.37s\n",
      "188:\tlearn: 0.0940088\ttotal: 783ms\tremaining: 3.36s\n",
      "189:\tlearn: 0.0938051\ttotal: 787ms\tremaining: 3.36s\n",
      "190:\tlearn: 0.0935793\ttotal: 791ms\tremaining: 3.35s\n",
      "191:\tlearn: 0.0932916\ttotal: 795ms\tremaining: 3.34s\n",
      "192:\tlearn: 0.0930660\ttotal: 798ms\tremaining: 3.34s\n",
      "193:\tlearn: 0.0928118\ttotal: 803ms\tremaining: 3.33s\n",
      "194:\tlearn: 0.0927077\ttotal: 807ms\tremaining: 3.33s\n",
      "195:\tlearn: 0.0924726\ttotal: 811ms\tremaining: 3.33s\n",
      "196:\tlearn: 0.0923296\ttotal: 815ms\tremaining: 3.32s\n",
      "197:\tlearn: 0.0921915\ttotal: 819ms\tremaining: 3.32s\n",
      "198:\tlearn: 0.0918867\ttotal: 823ms\tremaining: 3.31s\n",
      "199:\tlearn: 0.0916576\ttotal: 826ms\tremaining: 3.31s\n",
      "200:\tlearn: 0.0914530\ttotal: 830ms\tremaining: 3.3s\n",
      "201:\tlearn: 0.0912455\ttotal: 834ms\tremaining: 3.29s\n",
      "202:\tlearn: 0.0909772\ttotal: 838ms\tremaining: 3.29s\n",
      "203:\tlearn: 0.0908240\ttotal: 841ms\tremaining: 3.28s\n",
      "204:\tlearn: 0.0906615\ttotal: 845ms\tremaining: 3.28s\n",
      "205:\tlearn: 0.0905107\ttotal: 849ms\tremaining: 3.27s\n",
      "206:\tlearn: 0.0902990\ttotal: 852ms\tremaining: 3.27s\n",
      "207:\tlearn: 0.0900585\ttotal: 856ms\tremaining: 3.26s\n",
      "208:\tlearn: 0.0898448\ttotal: 860ms\tremaining: 3.25s\n",
      "209:\tlearn: 0.0895762\ttotal: 863ms\tremaining: 3.25s\n",
      "210:\tlearn: 0.0892646\ttotal: 867ms\tremaining: 3.24s\n",
      "211:\tlearn: 0.0890897\ttotal: 872ms\tremaining: 3.24s\n",
      "212:\tlearn: 0.0889383\ttotal: 876ms\tremaining: 3.24s\n",
      "213:\tlearn: 0.0887970\ttotal: 880ms\tremaining: 3.23s\n",
      "214:\tlearn: 0.0886027\ttotal: 884ms\tremaining: 3.23s\n",
      "215:\tlearn: 0.0883797\ttotal: 888ms\tremaining: 3.22s\n",
      "216:\tlearn: 0.0881420\ttotal: 893ms\tremaining: 3.22s\n",
      "217:\tlearn: 0.0880375\ttotal: 897ms\tremaining: 3.22s\n",
      "218:\tlearn: 0.0878525\ttotal: 902ms\tremaining: 3.22s\n",
      "219:\tlearn: 0.0877417\ttotal: 906ms\tremaining: 3.21s\n",
      "220:\tlearn: 0.0875586\ttotal: 910ms\tremaining: 3.21s\n",
      "221:\tlearn: 0.0872840\ttotal: 914ms\tremaining: 3.2s\n",
      "222:\tlearn: 0.0870906\ttotal: 918ms\tremaining: 3.2s\n",
      "223:\tlearn: 0.0869830\ttotal: 922ms\tremaining: 3.19s\n",
      "224:\tlearn: 0.0868665\ttotal: 925ms\tremaining: 3.19s\n",
      "225:\tlearn: 0.0867662\ttotal: 929ms\tremaining: 3.18s\n",
      "226:\tlearn: 0.0864899\ttotal: 933ms\tremaining: 3.18s\n",
      "227:\tlearn: 0.0863606\ttotal: 937ms\tremaining: 3.17s\n",
      "228:\tlearn: 0.0861325\ttotal: 941ms\tremaining: 3.17s\n",
      "229:\tlearn: 0.0858638\ttotal: 944ms\tremaining: 3.16s\n",
      "230:\tlearn: 0.0857256\ttotal: 948ms\tremaining: 3.15s\n",
      "231:\tlearn: 0.0855621\ttotal: 951ms\tremaining: 3.15s\n",
      "232:\tlearn: 0.0853580\ttotal: 955ms\tremaining: 3.14s\n",
      "233:\tlearn: 0.0851842\ttotal: 959ms\tremaining: 3.14s\n",
      "234:\tlearn: 0.0850399\ttotal: 963ms\tremaining: 3.13s\n",
      "235:\tlearn: 0.0848438\ttotal: 966ms\tremaining: 3.13s\n",
      "236:\tlearn: 0.0845813\ttotal: 970ms\tremaining: 3.12s\n",
      "237:\tlearn: 0.0844303\ttotal: 973ms\tremaining: 3.12s\n",
      "238:\tlearn: 0.0842702\ttotal: 977ms\tremaining: 3.11s\n",
      "239:\tlearn: 0.0841103\ttotal: 981ms\tremaining: 3.1s\n",
      "240:\tlearn: 0.0840045\ttotal: 984ms\tremaining: 3.1s\n",
      "241:\tlearn: 0.0839235\ttotal: 988ms\tremaining: 3.09s\n",
      "242:\tlearn: 0.0837817\ttotal: 992ms\tremaining: 3.09s\n",
      "243:\tlearn: 0.0836159\ttotal: 996ms\tremaining: 3.09s\n",
      "244:\tlearn: 0.0834952\ttotal: 1000ms\tremaining: 3.08s\n",
      "245:\tlearn: 0.0832462\ttotal: 1s\tremaining: 3.08s\n",
      "246:\tlearn: 0.0831676\ttotal: 1.01s\tremaining: 3.07s\n",
      "247:\tlearn: 0.0830670\ttotal: 1.01s\tremaining: 3.06s\n",
      "248:\tlearn: 0.0829501\ttotal: 1.01s\tremaining: 3.06s\n",
      "249:\tlearn: 0.0828804\ttotal: 1.02s\tremaining: 3.06s\n",
      "250:\tlearn: 0.0828136\ttotal: 1.02s\tremaining: 3.05s\n",
      "251:\tlearn: 0.0827428\ttotal: 1.02s\tremaining: 3.04s\n",
      "252:\tlearn: 0.0826228\ttotal: 1.03s\tremaining: 3.04s\n",
      "253:\tlearn: 0.0824936\ttotal: 1.03s\tremaining: 3.03s\n",
      "254:\tlearn: 0.0823791\ttotal: 1.04s\tremaining: 3.03s\n",
      "255:\tlearn: 0.0822913\ttotal: 1.04s\tremaining: 3.02s\n",
      "256:\tlearn: 0.0821750\ttotal: 1.04s\tremaining: 3.02s\n",
      "257:\tlearn: 0.0820131\ttotal: 1.05s\tremaining: 3.01s\n",
      "258:\tlearn: 0.0819676\ttotal: 1.05s\tremaining: 3s\n",
      "259:\tlearn: 0.0817682\ttotal: 1.05s\tremaining: 3s\n",
      "260:\tlearn: 0.0816411\ttotal: 1.06s\tremaining: 3s\n",
      "261:\tlearn: 0.0814775\ttotal: 1.06s\tremaining: 2.99s\n",
      "262:\tlearn: 0.0813475\ttotal: 1.07s\tremaining: 2.99s\n",
      "263:\tlearn: 0.0812385\ttotal: 1.07s\tremaining: 2.98s\n",
      "264:\tlearn: 0.0811291\ttotal: 1.07s\tremaining: 2.98s\n",
      "265:\tlearn: 0.0810255\ttotal: 1.08s\tremaining: 2.97s\n",
      "266:\tlearn: 0.0809581\ttotal: 1.08s\tremaining: 2.97s\n",
      "267:\tlearn: 0.0807789\ttotal: 1.08s\tremaining: 2.96s\n",
      "268:\tlearn: 0.0806202\ttotal: 1.09s\tremaining: 2.96s\n",
      "269:\tlearn: 0.0804470\ttotal: 1.09s\tremaining: 2.96s\n",
      "270:\tlearn: 0.0803809\ttotal: 1.1s\tremaining: 2.96s\n",
      "271:\tlearn: 0.0802196\ttotal: 1.1s\tremaining: 2.95s\n",
      "272:\tlearn: 0.0800404\ttotal: 1.11s\tremaining: 2.94s\n",
      "273:\tlearn: 0.0798527\ttotal: 1.11s\tremaining: 2.94s\n",
      "274:\tlearn: 0.0796803\ttotal: 1.11s\tremaining: 2.94s\n",
      "275:\tlearn: 0.0795952\ttotal: 1.12s\tremaining: 2.93s\n",
      "276:\tlearn: 0.0793958\ttotal: 1.12s\tremaining: 2.92s\n",
      "277:\tlearn: 0.0792928\ttotal: 1.12s\tremaining: 2.92s\n",
      "278:\tlearn: 0.0791889\ttotal: 1.13s\tremaining: 2.92s\n",
      "279:\tlearn: 0.0790465\ttotal: 1.13s\tremaining: 2.91s\n",
      "280:\tlearn: 0.0789309\ttotal: 1.14s\tremaining: 2.9s\n",
      "281:\tlearn: 0.0787696\ttotal: 1.14s\tremaining: 2.9s\n",
      "282:\tlearn: 0.0786611\ttotal: 1.14s\tremaining: 2.89s\n",
      "283:\tlearn: 0.0785995\ttotal: 1.15s\tremaining: 2.89s\n",
      "284:\tlearn: 0.0784463\ttotal: 1.15s\tremaining: 2.88s\n",
      "285:\tlearn: 0.0783109\ttotal: 1.15s\tremaining: 2.88s\n",
      "286:\tlearn: 0.0781539\ttotal: 1.16s\tremaining: 2.88s\n",
      "287:\tlearn: 0.0779869\ttotal: 1.16s\tremaining: 2.87s\n",
      "288:\tlearn: 0.0779047\ttotal: 1.16s\tremaining: 2.87s\n",
      "289:\tlearn: 0.0778359\ttotal: 1.17s\tremaining: 2.86s\n",
      "290:\tlearn: 0.0777110\ttotal: 1.17s\tremaining: 2.86s\n",
      "291:\tlearn: 0.0776273\ttotal: 1.18s\tremaining: 2.85s\n",
      "292:\tlearn: 0.0774681\ttotal: 1.18s\tremaining: 2.85s\n",
      "293:\tlearn: 0.0773875\ttotal: 1.18s\tremaining: 2.84s\n",
      "294:\tlearn: 0.0772042\ttotal: 1.19s\tremaining: 2.84s\n",
      "295:\tlearn: 0.0771638\ttotal: 1.19s\tremaining: 2.83s\n",
      "296:\tlearn: 0.0770076\ttotal: 1.2s\tremaining: 2.83s\n",
      "297:\tlearn: 0.0768336\ttotal: 1.2s\tremaining: 2.82s\n",
      "298:\tlearn: 0.0766619\ttotal: 1.2s\tremaining: 2.82s\n",
      "299:\tlearn: 0.0765177\ttotal: 1.21s\tremaining: 2.81s\n",
      "300:\tlearn: 0.0763729\ttotal: 1.21s\tremaining: 2.81s\n",
      "301:\tlearn: 0.0763194\ttotal: 1.21s\tremaining: 2.81s\n",
      "302:\tlearn: 0.0762192\ttotal: 1.22s\tremaining: 2.8s\n",
      "303:\tlearn: 0.0761821\ttotal: 1.22s\tremaining: 2.8s\n",
      "304:\tlearn: 0.0761064\ttotal: 1.23s\tremaining: 2.79s\n",
      "305:\tlearn: 0.0760332\ttotal: 1.23s\tremaining: 2.79s\n",
      "306:\tlearn: 0.0759376\ttotal: 1.24s\tremaining: 2.79s\n",
      "307:\tlearn: 0.0758083\ttotal: 1.24s\tremaining: 2.78s\n",
      "308:\tlearn: 0.0757228\ttotal: 1.25s\tremaining: 2.78s\n",
      "309:\tlearn: 0.0755838\ttotal: 1.25s\tremaining: 2.78s\n",
      "310:\tlearn: 0.0755162\ttotal: 1.25s\tremaining: 2.77s\n",
      "311:\tlearn: 0.0753715\ttotal: 1.26s\tremaining: 2.77s\n",
      "312:\tlearn: 0.0753199\ttotal: 1.26s\tremaining: 2.77s\n",
      "313:\tlearn: 0.0751153\ttotal: 1.26s\tremaining: 2.76s\n",
      "314:\tlearn: 0.0750714\ttotal: 1.27s\tremaining: 2.76s\n",
      "315:\tlearn: 0.0748805\ttotal: 1.27s\tremaining: 2.76s\n",
      "316:\tlearn: 0.0747915\ttotal: 1.28s\tremaining: 2.75s\n",
      "317:\tlearn: 0.0746270\ttotal: 1.28s\tremaining: 2.75s\n",
      "318:\tlearn: 0.0744663\ttotal: 1.29s\tremaining: 2.75s\n",
      "319:\tlearn: 0.0743572\ttotal: 1.29s\tremaining: 2.74s\n",
      "320:\tlearn: 0.0742631\ttotal: 1.29s\tremaining: 2.74s\n",
      "321:\tlearn: 0.0741708\ttotal: 1.3s\tremaining: 2.73s\n",
      "322:\tlearn: 0.0739413\ttotal: 1.3s\tremaining: 2.73s\n",
      "323:\tlearn: 0.0737917\ttotal: 1.31s\tremaining: 2.73s\n",
      "324:\tlearn: 0.0736154\ttotal: 1.31s\tremaining: 2.73s\n",
      "325:\tlearn: 0.0735685\ttotal: 1.32s\tremaining: 2.73s\n",
      "326:\tlearn: 0.0735035\ttotal: 1.32s\tremaining: 2.72s\n",
      "327:\tlearn: 0.0733894\ttotal: 1.33s\tremaining: 2.72s\n",
      "328:\tlearn: 0.0732176\ttotal: 1.33s\tremaining: 2.71s\n",
      "329:\tlearn: 0.0730920\ttotal: 1.33s\tremaining: 2.71s\n",
      "330:\tlearn: 0.0729585\ttotal: 1.34s\tremaining: 2.71s\n",
      "331:\tlearn: 0.0728024\ttotal: 1.34s\tremaining: 2.7s\n",
      "332:\tlearn: 0.0727016\ttotal: 1.35s\tremaining: 2.7s\n",
      "333:\tlearn: 0.0725912\ttotal: 1.35s\tremaining: 2.7s\n",
      "334:\tlearn: 0.0724569\ttotal: 1.36s\tremaining: 2.69s\n",
      "335:\tlearn: 0.0722943\ttotal: 1.36s\tremaining: 2.69s\n",
      "336:\tlearn: 0.0722017\ttotal: 1.37s\tremaining: 2.69s\n",
      "337:\tlearn: 0.0720996\ttotal: 1.37s\tremaining: 2.69s\n",
      "338:\tlearn: 0.0720301\ttotal: 1.38s\tremaining: 2.68s\n",
      "339:\tlearn: 0.0719299\ttotal: 1.38s\tremaining: 2.68s\n",
      "340:\tlearn: 0.0717808\ttotal: 1.38s\tremaining: 2.67s\n",
      "341:\tlearn: 0.0717248\ttotal: 1.39s\tremaining: 2.67s\n",
      "342:\tlearn: 0.0716039\ttotal: 1.39s\tremaining: 2.66s\n",
      "343:\tlearn: 0.0714535\ttotal: 1.4s\tremaining: 2.66s\n",
      "344:\tlearn: 0.0713913\ttotal: 1.4s\tremaining: 2.66s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "345:\tlearn: 0.0712908\ttotal: 1.4s\tremaining: 2.65s\n",
      "346:\tlearn: 0.0711904\ttotal: 1.41s\tremaining: 2.65s\n",
      "347:\tlearn: 0.0710138\ttotal: 1.41s\tremaining: 2.64s\n",
      "348:\tlearn: 0.0709230\ttotal: 1.41s\tremaining: 2.64s\n",
      "349:\tlearn: 0.0708108\ttotal: 1.42s\tremaining: 2.63s\n",
      "350:\tlearn: 0.0707126\ttotal: 1.42s\tremaining: 2.63s\n",
      "351:\tlearn: 0.0706005\ttotal: 1.43s\tremaining: 2.63s\n",
      "352:\tlearn: 0.0704370\ttotal: 1.43s\tremaining: 2.62s\n",
      "353:\tlearn: 0.0703740\ttotal: 1.44s\tremaining: 2.62s\n",
      "354:\tlearn: 0.0703338\ttotal: 1.44s\tremaining: 2.62s\n",
      "355:\tlearn: 0.0701963\ttotal: 1.45s\tremaining: 2.61s\n",
      "356:\tlearn: 0.0700934\ttotal: 1.45s\tremaining: 2.61s\n",
      "357:\tlearn: 0.0700460\ttotal: 1.45s\tremaining: 2.6s\n",
      "358:\tlearn: 0.0699768\ttotal: 1.46s\tremaining: 2.6s\n",
      "359:\tlearn: 0.0698519\ttotal: 1.46s\tremaining: 2.6s\n",
      "360:\tlearn: 0.0697425\ttotal: 1.47s\tremaining: 2.6s\n",
      "361:\tlearn: 0.0697039\ttotal: 1.47s\tremaining: 2.59s\n",
      "362:\tlearn: 0.0696093\ttotal: 1.47s\tremaining: 2.59s\n",
      "363:\tlearn: 0.0695308\ttotal: 1.48s\tremaining: 2.58s\n",
      "364:\tlearn: 0.0694290\ttotal: 1.48s\tremaining: 2.58s\n",
      "365:\tlearn: 0.0693505\ttotal: 1.48s\tremaining: 2.57s\n",
      "366:\tlearn: 0.0692407\ttotal: 1.49s\tremaining: 2.57s\n",
      "367:\tlearn: 0.0691729\ttotal: 1.49s\tremaining: 2.56s\n",
      "368:\tlearn: 0.0690047\ttotal: 1.5s\tremaining: 2.56s\n",
      "369:\tlearn: 0.0688321\ttotal: 1.5s\tremaining: 2.55s\n",
      "370:\tlearn: 0.0686395\ttotal: 1.5s\tremaining: 2.55s\n",
      "371:\tlearn: 0.0685889\ttotal: 1.51s\tremaining: 2.54s\n",
      "372:\tlearn: 0.0685271\ttotal: 1.51s\tremaining: 2.54s\n",
      "373:\tlearn: 0.0683844\ttotal: 1.51s\tremaining: 2.53s\n",
      "374:\tlearn: 0.0682679\ttotal: 1.52s\tremaining: 2.53s\n",
      "375:\tlearn: 0.0681252\ttotal: 1.52s\tremaining: 2.52s\n",
      "376:\tlearn: 0.0680363\ttotal: 1.52s\tremaining: 2.52s\n",
      "377:\tlearn: 0.0679770\ttotal: 1.53s\tremaining: 2.52s\n",
      "378:\tlearn: 0.0679035\ttotal: 1.53s\tremaining: 2.51s\n",
      "379:\tlearn: 0.0678537\ttotal: 1.54s\tremaining: 2.51s\n",
      "380:\tlearn: 0.0677543\ttotal: 1.54s\tremaining: 2.5s\n",
      "381:\tlearn: 0.0676869\ttotal: 1.54s\tremaining: 2.5s\n",
      "382:\tlearn: 0.0675714\ttotal: 1.55s\tremaining: 2.49s\n",
      "383:\tlearn: 0.0674652\ttotal: 1.55s\tremaining: 2.49s\n",
      "384:\tlearn: 0.0674343\ttotal: 1.55s\tremaining: 2.48s\n",
      "385:\tlearn: 0.0672761\ttotal: 1.56s\tremaining: 2.48s\n",
      "386:\tlearn: 0.0671874\ttotal: 1.56s\tremaining: 2.47s\n",
      "387:\tlearn: 0.0670506\ttotal: 1.56s\tremaining: 2.47s\n",
      "388:\tlearn: 0.0668758\ttotal: 1.57s\tremaining: 2.47s\n",
      "389:\tlearn: 0.0667758\ttotal: 1.57s\tremaining: 2.46s\n",
      "390:\tlearn: 0.0666562\ttotal: 1.58s\tremaining: 2.46s\n",
      "391:\tlearn: 0.0665808\ttotal: 1.58s\tremaining: 2.45s\n",
      "392:\tlearn: 0.0665110\ttotal: 1.59s\tremaining: 2.45s\n",
      "393:\tlearn: 0.0664488\ttotal: 1.59s\tremaining: 2.45s\n",
      "394:\tlearn: 0.0663505\ttotal: 1.59s\tremaining: 2.44s\n",
      "395:\tlearn: 0.0663227\ttotal: 1.6s\tremaining: 2.44s\n",
      "396:\tlearn: 0.0662237\ttotal: 1.6s\tremaining: 2.44s\n",
      "397:\tlearn: 0.0660783\ttotal: 1.61s\tremaining: 2.43s\n",
      "398:\tlearn: 0.0659656\ttotal: 1.61s\tremaining: 2.43s\n",
      "399:\tlearn: 0.0659110\ttotal: 1.61s\tremaining: 2.42s\n",
      "400:\tlearn: 0.0658072\ttotal: 1.62s\tremaining: 2.42s\n",
      "401:\tlearn: 0.0657197\ttotal: 1.62s\tremaining: 2.41s\n",
      "402:\tlearn: 0.0655791\ttotal: 1.63s\tremaining: 2.41s\n",
      "403:\tlearn: 0.0655153\ttotal: 1.63s\tremaining: 2.4s\n",
      "404:\tlearn: 0.0654516\ttotal: 1.63s\tremaining: 2.4s\n",
      "405:\tlearn: 0.0653451\ttotal: 1.64s\tremaining: 2.39s\n",
      "406:\tlearn: 0.0652666\ttotal: 1.64s\tremaining: 2.39s\n",
      "407:\tlearn: 0.0651671\ttotal: 1.64s\tremaining: 2.38s\n",
      "408:\tlearn: 0.0650755\ttotal: 1.65s\tremaining: 2.38s\n",
      "409:\tlearn: 0.0649772\ttotal: 1.65s\tremaining: 2.38s\n",
      "410:\tlearn: 0.0649167\ttotal: 1.65s\tremaining: 2.37s\n",
      "411:\tlearn: 0.0648312\ttotal: 1.66s\tremaining: 2.37s\n",
      "412:\tlearn: 0.0647781\ttotal: 1.66s\tremaining: 2.36s\n",
      "413:\tlearn: 0.0647414\ttotal: 1.67s\tremaining: 2.36s\n",
      "414:\tlearn: 0.0646329\ttotal: 1.67s\tremaining: 2.35s\n",
      "415:\tlearn: 0.0644977\ttotal: 1.67s\tremaining: 2.35s\n",
      "416:\tlearn: 0.0643532\ttotal: 1.68s\tremaining: 2.35s\n",
      "417:\tlearn: 0.0642740\ttotal: 1.68s\tremaining: 2.34s\n",
      "418:\tlearn: 0.0641397\ttotal: 1.69s\tremaining: 2.34s\n",
      "419:\tlearn: 0.0640246\ttotal: 1.69s\tremaining: 2.33s\n",
      "420:\tlearn: 0.0638840\ttotal: 1.69s\tremaining: 2.33s\n",
      "421:\tlearn: 0.0638277\ttotal: 1.7s\tremaining: 2.33s\n",
      "422:\tlearn: 0.0637584\ttotal: 1.7s\tremaining: 2.32s\n",
      "423:\tlearn: 0.0636307\ttotal: 1.71s\tremaining: 2.32s\n",
      "424:\tlearn: 0.0635925\ttotal: 1.71s\tremaining: 2.32s\n",
      "425:\tlearn: 0.0635365\ttotal: 1.72s\tremaining: 2.31s\n",
      "426:\tlearn: 0.0633839\ttotal: 1.72s\tremaining: 2.31s\n",
      "427:\tlearn: 0.0633394\ttotal: 1.73s\tremaining: 2.31s\n",
      "428:\tlearn: 0.0632884\ttotal: 1.73s\tremaining: 2.3s\n",
      "429:\tlearn: 0.0632182\ttotal: 1.73s\tremaining: 2.3s\n",
      "430:\tlearn: 0.0631789\ttotal: 1.74s\tremaining: 2.3s\n",
      "431:\tlearn: 0.0630997\ttotal: 1.74s\tremaining: 2.29s\n",
      "432:\tlearn: 0.0630232\ttotal: 1.75s\tremaining: 2.29s\n",
      "433:\tlearn: 0.0629626\ttotal: 1.75s\tremaining: 2.28s\n",
      "434:\tlearn: 0.0628240\ttotal: 1.76s\tremaining: 2.28s\n",
      "435:\tlearn: 0.0627073\ttotal: 1.76s\tremaining: 2.28s\n",
      "436:\tlearn: 0.0625837\ttotal: 1.76s\tremaining: 2.27s\n",
      "437:\tlearn: 0.0624466\ttotal: 1.77s\tremaining: 2.27s\n",
      "438:\tlearn: 0.0623539\ttotal: 1.77s\tremaining: 2.27s\n",
      "439:\tlearn: 0.0622741\ttotal: 1.78s\tremaining: 2.26s\n",
      "440:\tlearn: 0.0621612\ttotal: 1.78s\tremaining: 2.26s\n",
      "441:\tlearn: 0.0620499\ttotal: 1.79s\tremaining: 2.25s\n",
      "442:\tlearn: 0.0619802\ttotal: 1.79s\tremaining: 2.25s\n",
      "443:\tlearn: 0.0618794\ttotal: 1.79s\tremaining: 2.25s\n",
      "444:\tlearn: 0.0617418\ttotal: 1.8s\tremaining: 2.24s\n",
      "445:\tlearn: 0.0616794\ttotal: 1.8s\tremaining: 2.24s\n",
      "446:\tlearn: 0.0616080\ttotal: 1.81s\tremaining: 2.23s\n",
      "447:\tlearn: 0.0615549\ttotal: 1.81s\tremaining: 2.23s\n",
      "448:\tlearn: 0.0614571\ttotal: 1.81s\tremaining: 2.23s\n",
      "449:\tlearn: 0.0614146\ttotal: 1.82s\tremaining: 2.22s\n",
      "450:\tlearn: 0.0613421\ttotal: 1.82s\tremaining: 2.22s\n",
      "451:\tlearn: 0.0612386\ttotal: 1.83s\tremaining: 2.22s\n",
      "452:\tlearn: 0.0611801\ttotal: 1.83s\tremaining: 2.21s\n",
      "453:\tlearn: 0.0611179\ttotal: 1.84s\tremaining: 2.21s\n",
      "454:\tlearn: 0.0610545\ttotal: 1.84s\tremaining: 2.21s\n",
      "455:\tlearn: 0.0610227\ttotal: 1.85s\tremaining: 2.2s\n",
      "456:\tlearn: 0.0609983\ttotal: 1.85s\tremaining: 2.2s\n",
      "457:\tlearn: 0.0609685\ttotal: 1.85s\tremaining: 2.19s\n",
      "458:\tlearn: 0.0608834\ttotal: 1.86s\tremaining: 2.19s\n",
      "459:\tlearn: 0.0608064\ttotal: 1.86s\tremaining: 2.19s\n",
      "460:\tlearn: 0.0606965\ttotal: 1.87s\tremaining: 2.18s\n",
      "461:\tlearn: 0.0605961\ttotal: 1.87s\tremaining: 2.18s\n",
      "462:\tlearn: 0.0604874\ttotal: 1.88s\tremaining: 2.17s\n",
      "463:\tlearn: 0.0603845\ttotal: 1.88s\tremaining: 2.17s\n",
      "464:\tlearn: 0.0603217\ttotal: 1.88s\tremaining: 2.17s\n",
      "465:\tlearn: 0.0602399\ttotal: 1.89s\tremaining: 2.16s\n",
      "466:\tlearn: 0.0601561\ttotal: 1.89s\tremaining: 2.16s\n",
      "467:\tlearn: 0.0600496\ttotal: 1.9s\tremaining: 2.15s\n",
      "468:\tlearn: 0.0599574\ttotal: 1.9s\tremaining: 2.15s\n",
      "469:\tlearn: 0.0599061\ttotal: 1.9s\tremaining: 2.15s\n",
      "470:\tlearn: 0.0598794\ttotal: 1.91s\tremaining: 2.14s\n",
      "471:\tlearn: 0.0598313\ttotal: 1.91s\tremaining: 2.14s\n",
      "472:\tlearn: 0.0597611\ttotal: 1.91s\tremaining: 2.13s\n",
      "473:\tlearn: 0.0597168\ttotal: 1.92s\tremaining: 2.13s\n",
      "474:\tlearn: 0.0596534\ttotal: 1.92s\tremaining: 2.12s\n",
      "475:\tlearn: 0.0595240\ttotal: 1.92s\tremaining: 2.12s\n",
      "476:\tlearn: 0.0594463\ttotal: 1.93s\tremaining: 2.11s\n",
      "477:\tlearn: 0.0593739\ttotal: 1.93s\tremaining: 2.11s\n",
      "478:\tlearn: 0.0592861\ttotal: 1.94s\tremaining: 2.11s\n",
      "479:\tlearn: 0.0592437\ttotal: 1.94s\tremaining: 2.1s\n",
      "480:\tlearn: 0.0591119\ttotal: 1.94s\tremaining: 2.1s\n",
      "481:\tlearn: 0.0590425\ttotal: 1.95s\tremaining: 2.09s\n",
      "482:\tlearn: 0.0589627\ttotal: 1.95s\tremaining: 2.09s\n",
      "483:\tlearn: 0.0588820\ttotal: 1.96s\tremaining: 2.08s\n",
      "484:\tlearn: 0.0588575\ttotal: 1.96s\tremaining: 2.08s\n",
      "485:\tlearn: 0.0587829\ttotal: 1.96s\tremaining: 2.08s\n",
      "486:\tlearn: 0.0587187\ttotal: 1.97s\tremaining: 2.07s\n",
      "487:\tlearn: 0.0586320\ttotal: 1.97s\tremaining: 2.07s\n",
      "488:\tlearn: 0.0585552\ttotal: 1.97s\tremaining: 2.06s\n",
      "489:\tlearn: 0.0585150\ttotal: 1.98s\tremaining: 2.06s\n",
      "490:\tlearn: 0.0583958\ttotal: 1.98s\tremaining: 2.05s\n",
      "491:\tlearn: 0.0582978\ttotal: 1.99s\tremaining: 2.05s\n",
      "492:\tlearn: 0.0581998\ttotal: 1.99s\tremaining: 2.04s\n",
      "493:\tlearn: 0.0581322\ttotal: 1.99s\tremaining: 2.04s\n",
      "494:\tlearn: 0.0580545\ttotal: 2s\tremaining: 2.04s\n",
      "495:\tlearn: 0.0579772\ttotal: 2s\tremaining: 2.03s\n",
      "496:\tlearn: 0.0579394\ttotal: 2s\tremaining: 2.03s\n",
      "497:\tlearn: 0.0578638\ttotal: 2.01s\tremaining: 2.02s\n",
      "498:\tlearn: 0.0578184\ttotal: 2.01s\tremaining: 2.02s\n",
      "499:\tlearn: 0.0577769\ttotal: 2.01s\tremaining: 2.01s\n",
      "500:\tlearn: 0.0577450\ttotal: 2.02s\tremaining: 2.01s\n",
      "501:\tlearn: 0.0577128\ttotal: 2.02s\tremaining: 2s\n",
      "502:\tlearn: 0.0576064\ttotal: 2.02s\tremaining: 2s\n",
      "503:\tlearn: 0.0575286\ttotal: 2.03s\tremaining: 2s\n",
      "504:\tlearn: 0.0574902\ttotal: 2.03s\tremaining: 1.99s\n",
      "505:\tlearn: 0.0573878\ttotal: 2.04s\tremaining: 1.99s\n",
      "506:\tlearn: 0.0573542\ttotal: 2.04s\tremaining: 1.98s\n",
      "507:\tlearn: 0.0573168\ttotal: 2.04s\tremaining: 1.98s\n",
      "508:\tlearn: 0.0572119\ttotal: 2.05s\tremaining: 1.98s\n",
      "509:\tlearn: 0.0571277\ttotal: 2.05s\tremaining: 1.97s\n",
      "510:\tlearn: 0.0570486\ttotal: 2.06s\tremaining: 1.97s\n",
      "511:\tlearn: 0.0569971\ttotal: 2.06s\tremaining: 1.96s\n",
      "512:\tlearn: 0.0569602\ttotal: 2.06s\tremaining: 1.96s\n",
      "513:\tlearn: 0.0568400\ttotal: 2.07s\tremaining: 1.95s\n",
      "514:\tlearn: 0.0567018\ttotal: 2.07s\tremaining: 1.95s\n",
      "515:\tlearn: 0.0565856\ttotal: 2.08s\tremaining: 1.95s\n",
      "516:\tlearn: 0.0565140\ttotal: 2.08s\tremaining: 1.94s\n",
      "517:\tlearn: 0.0564210\ttotal: 2.08s\tremaining: 1.94s\n",
      "518:\tlearn: 0.0563570\ttotal: 2.09s\tremaining: 1.94s\n",
      "519:\tlearn: 0.0563292\ttotal: 2.09s\tremaining: 1.93s\n",
      "520:\tlearn: 0.0562557\ttotal: 2.1s\tremaining: 1.93s\n",
      "521:\tlearn: 0.0561729\ttotal: 2.1s\tremaining: 1.92s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "522:\tlearn: 0.0561217\ttotal: 2.1s\tremaining: 1.92s\n",
      "523:\tlearn: 0.0560653\ttotal: 2.11s\tremaining: 1.91s\n",
      "524:\tlearn: 0.0560241\ttotal: 2.11s\tremaining: 1.91s\n",
      "525:\tlearn: 0.0559213\ttotal: 2.12s\tremaining: 1.91s\n",
      "526:\tlearn: 0.0557809\ttotal: 2.12s\tremaining: 1.9s\n",
      "527:\tlearn: 0.0557344\ttotal: 2.12s\tremaining: 1.9s\n",
      "528:\tlearn: 0.0556955\ttotal: 2.13s\tremaining: 1.89s\n",
      "529:\tlearn: 0.0556293\ttotal: 2.13s\tremaining: 1.89s\n",
      "530:\tlearn: 0.0555485\ttotal: 2.13s\tremaining: 1.89s\n",
      "531:\tlearn: 0.0554788\ttotal: 2.14s\tremaining: 1.88s\n",
      "532:\tlearn: 0.0554074\ttotal: 2.14s\tremaining: 1.88s\n",
      "533:\tlearn: 0.0553757\ttotal: 2.15s\tremaining: 1.87s\n",
      "534:\tlearn: 0.0552903\ttotal: 2.15s\tremaining: 1.87s\n",
      "535:\tlearn: 0.0552146\ttotal: 2.15s\tremaining: 1.86s\n",
      "536:\tlearn: 0.0551347\ttotal: 2.16s\tremaining: 1.86s\n",
      "537:\tlearn: 0.0551053\ttotal: 2.16s\tremaining: 1.86s\n",
      "538:\tlearn: 0.0550129\ttotal: 2.17s\tremaining: 1.85s\n",
      "539:\tlearn: 0.0548706\ttotal: 2.17s\tremaining: 1.85s\n",
      "540:\tlearn: 0.0548071\ttotal: 2.17s\tremaining: 1.84s\n",
      "541:\tlearn: 0.0547778\ttotal: 2.18s\tremaining: 1.84s\n",
      "542:\tlearn: 0.0547463\ttotal: 2.18s\tremaining: 1.83s\n",
      "543:\tlearn: 0.0547141\ttotal: 2.18s\tremaining: 1.83s\n",
      "544:\tlearn: 0.0546080\ttotal: 2.19s\tremaining: 1.83s\n",
      "545:\tlearn: 0.0545757\ttotal: 2.19s\tremaining: 1.82s\n",
      "546:\tlearn: 0.0544573\ttotal: 2.19s\tremaining: 1.82s\n",
      "547:\tlearn: 0.0544319\ttotal: 2.2s\tremaining: 1.81s\n",
      "548:\tlearn: 0.0544110\ttotal: 2.2s\tremaining: 1.81s\n",
      "549:\tlearn: 0.0542905\ttotal: 2.21s\tremaining: 1.81s\n",
      "550:\tlearn: 0.0542319\ttotal: 2.21s\tremaining: 1.8s\n",
      "551:\tlearn: 0.0541509\ttotal: 2.21s\tremaining: 1.8s\n",
      "552:\tlearn: 0.0540396\ttotal: 2.22s\tremaining: 1.79s\n",
      "553:\tlearn: 0.0539746\ttotal: 2.22s\tremaining: 1.79s\n",
      "554:\tlearn: 0.0539218\ttotal: 2.23s\tremaining: 1.78s\n",
      "555:\tlearn: 0.0538578\ttotal: 2.23s\tremaining: 1.78s\n",
      "556:\tlearn: 0.0537152\ttotal: 2.23s\tremaining: 1.78s\n",
      "557:\tlearn: 0.0536504\ttotal: 2.24s\tremaining: 1.77s\n",
      "558:\tlearn: 0.0535400\ttotal: 2.24s\tremaining: 1.77s\n",
      "559:\tlearn: 0.0535048\ttotal: 2.25s\tremaining: 1.76s\n",
      "560:\tlearn: 0.0534109\ttotal: 2.25s\tremaining: 1.76s\n",
      "561:\tlearn: 0.0533361\ttotal: 2.25s\tremaining: 1.76s\n",
      "562:\tlearn: 0.0532773\ttotal: 2.26s\tremaining: 1.75s\n",
      "563:\tlearn: 0.0531685\ttotal: 2.26s\tremaining: 1.75s\n",
      "564:\tlearn: 0.0530845\ttotal: 2.27s\tremaining: 1.75s\n",
      "565:\tlearn: 0.0530235\ttotal: 2.27s\tremaining: 1.74s\n",
      "566:\tlearn: 0.0529481\ttotal: 2.27s\tremaining: 1.74s\n",
      "567:\tlearn: 0.0529075\ttotal: 2.28s\tremaining: 1.73s\n",
      "568:\tlearn: 0.0528430\ttotal: 2.28s\tremaining: 1.73s\n",
      "569:\tlearn: 0.0527766\ttotal: 2.29s\tremaining: 1.72s\n",
      "570:\tlearn: 0.0527285\ttotal: 2.29s\tremaining: 1.72s\n",
      "571:\tlearn: 0.0526800\ttotal: 2.29s\tremaining: 1.72s\n",
      "572:\tlearn: 0.0526204\ttotal: 2.3s\tremaining: 1.71s\n",
      "573:\tlearn: 0.0525719\ttotal: 2.3s\tremaining: 1.71s\n",
      "574:\tlearn: 0.0525051\ttotal: 2.31s\tremaining: 1.7s\n",
      "575:\tlearn: 0.0524279\ttotal: 2.31s\tremaining: 1.7s\n",
      "576:\tlearn: 0.0523950\ttotal: 2.31s\tremaining: 1.69s\n",
      "577:\tlearn: 0.0523535\ttotal: 2.31s\tremaining: 1.69s\n",
      "578:\tlearn: 0.0523143\ttotal: 2.32s\tremaining: 1.69s\n",
      "579:\tlearn: 0.0522455\ttotal: 2.32s\tremaining: 1.68s\n",
      "580:\tlearn: 0.0522228\ttotal: 2.33s\tremaining: 1.68s\n",
      "581:\tlearn: 0.0521170\ttotal: 2.33s\tremaining: 1.67s\n",
      "582:\tlearn: 0.0520784\ttotal: 2.33s\tremaining: 1.67s\n",
      "583:\tlearn: 0.0520196\ttotal: 2.34s\tremaining: 1.67s\n",
      "584:\tlearn: 0.0519513\ttotal: 2.34s\tremaining: 1.66s\n",
      "585:\tlearn: 0.0519265\ttotal: 2.34s\tremaining: 1.66s\n",
      "586:\tlearn: 0.0518994\ttotal: 2.35s\tremaining: 1.65s\n",
      "587:\tlearn: 0.0518632\ttotal: 2.35s\tremaining: 1.65s\n",
      "588:\tlearn: 0.0518461\ttotal: 2.35s\tremaining: 1.64s\n",
      "589:\tlearn: 0.0517863\ttotal: 2.36s\tremaining: 1.64s\n",
      "590:\tlearn: 0.0517631\ttotal: 2.36s\tremaining: 1.64s\n",
      "591:\tlearn: 0.0516937\ttotal: 2.37s\tremaining: 1.63s\n",
      "592:\tlearn: 0.0516562\ttotal: 2.37s\tremaining: 1.63s\n",
      "593:\tlearn: 0.0516299\ttotal: 2.37s\tremaining: 1.62s\n",
      "594:\tlearn: 0.0515925\ttotal: 2.38s\tremaining: 1.62s\n",
      "595:\tlearn: 0.0515310\ttotal: 2.38s\tremaining: 1.61s\n",
      "596:\tlearn: 0.0515037\ttotal: 2.39s\tremaining: 1.61s\n",
      "597:\tlearn: 0.0514252\ttotal: 2.39s\tremaining: 1.61s\n",
      "598:\tlearn: 0.0513898\ttotal: 2.39s\tremaining: 1.6s\n",
      "599:\tlearn: 0.0513745\ttotal: 2.4s\tremaining: 1.6s\n",
      "600:\tlearn: 0.0513301\ttotal: 2.4s\tremaining: 1.59s\n",
      "601:\tlearn: 0.0512749\ttotal: 2.41s\tremaining: 1.59s\n",
      "602:\tlearn: 0.0512416\ttotal: 2.41s\tremaining: 1.59s\n",
      "603:\tlearn: 0.0511781\ttotal: 2.41s\tremaining: 1.58s\n",
      "604:\tlearn: 0.0511439\ttotal: 2.42s\tremaining: 1.58s\n",
      "605:\tlearn: 0.0510832\ttotal: 2.42s\tremaining: 1.57s\n",
      "606:\tlearn: 0.0510467\ttotal: 2.43s\tremaining: 1.57s\n",
      "607:\tlearn: 0.0510078\ttotal: 2.43s\tremaining: 1.57s\n",
      "608:\tlearn: 0.0509899\ttotal: 2.43s\tremaining: 1.56s\n",
      "609:\tlearn: 0.0509469\ttotal: 2.44s\tremaining: 1.56s\n",
      "610:\tlearn: 0.0509195\ttotal: 2.44s\tremaining: 1.55s\n",
      "611:\tlearn: 0.0508846\ttotal: 2.45s\tremaining: 1.55s\n",
      "612:\tlearn: 0.0508347\ttotal: 2.45s\tremaining: 1.55s\n",
      "613:\tlearn: 0.0508044\ttotal: 2.46s\tremaining: 1.54s\n",
      "614:\tlearn: 0.0507861\ttotal: 2.46s\tremaining: 1.54s\n",
      "615:\tlearn: 0.0507608\ttotal: 2.46s\tremaining: 1.53s\n",
      "616:\tlearn: 0.0506963\ttotal: 2.47s\tremaining: 1.53s\n",
      "617:\tlearn: 0.0506517\ttotal: 2.47s\tremaining: 1.53s\n",
      "618:\tlearn: 0.0505986\ttotal: 2.48s\tremaining: 1.52s\n",
      "619:\tlearn: 0.0505659\ttotal: 2.48s\tremaining: 1.52s\n",
      "620:\tlearn: 0.0504915\ttotal: 2.48s\tremaining: 1.52s\n",
      "621:\tlearn: 0.0504458\ttotal: 2.49s\tremaining: 1.51s\n",
      "622:\tlearn: 0.0504047\ttotal: 2.49s\tremaining: 1.51s\n",
      "623:\tlearn: 0.0503748\ttotal: 2.5s\tremaining: 1.5s\n",
      "624:\tlearn: 0.0503467\ttotal: 2.5s\tremaining: 1.5s\n",
      "625:\tlearn: 0.0503101\ttotal: 2.5s\tremaining: 1.5s\n",
      "626:\tlearn: 0.0502645\ttotal: 2.51s\tremaining: 1.49s\n",
      "627:\tlearn: 0.0502207\ttotal: 2.51s\tremaining: 1.49s\n",
      "628:\tlearn: 0.0501923\ttotal: 2.52s\tremaining: 1.48s\n",
      "629:\tlearn: 0.0501634\ttotal: 2.52s\tremaining: 1.48s\n",
      "630:\tlearn: 0.0501360\ttotal: 2.53s\tremaining: 1.48s\n",
      "631:\tlearn: 0.0501052\ttotal: 2.53s\tremaining: 1.47s\n",
      "632:\tlearn: 0.0500875\ttotal: 2.53s\tremaining: 1.47s\n",
      "633:\tlearn: 0.0500130\ttotal: 2.54s\tremaining: 1.47s\n",
      "634:\tlearn: 0.0499780\ttotal: 2.54s\tremaining: 1.46s\n",
      "635:\tlearn: 0.0499570\ttotal: 2.55s\tremaining: 1.46s\n",
      "636:\tlearn: 0.0499181\ttotal: 2.55s\tremaining: 1.45s\n",
      "637:\tlearn: 0.0498820\ttotal: 2.56s\tremaining: 1.45s\n",
      "638:\tlearn: 0.0498428\ttotal: 2.56s\tremaining: 1.45s\n",
      "639:\tlearn: 0.0498073\ttotal: 2.56s\tremaining: 1.44s\n",
      "640:\tlearn: 0.0497890\ttotal: 2.57s\tremaining: 1.44s\n",
      "641:\tlearn: 0.0497499\ttotal: 2.57s\tremaining: 1.43s\n",
      "642:\tlearn: 0.0496942\ttotal: 2.58s\tremaining: 1.43s\n",
      "643:\tlearn: 0.0496163\ttotal: 2.58s\tremaining: 1.43s\n",
      "644:\tlearn: 0.0495802\ttotal: 2.58s\tremaining: 1.42s\n",
      "645:\tlearn: 0.0495602\ttotal: 2.59s\tremaining: 1.42s\n",
      "646:\tlearn: 0.0494767\ttotal: 2.59s\tremaining: 1.41s\n",
      "647:\tlearn: 0.0494429\ttotal: 2.6s\tremaining: 1.41s\n",
      "648:\tlearn: 0.0493611\ttotal: 2.6s\tremaining: 1.41s\n",
      "649:\tlearn: 0.0493341\ttotal: 2.61s\tremaining: 1.4s\n",
      "650:\tlearn: 0.0493003\ttotal: 2.61s\tremaining: 1.4s\n",
      "651:\tlearn: 0.0492488\ttotal: 2.61s\tremaining: 1.4s\n",
      "652:\tlearn: 0.0492198\ttotal: 2.62s\tremaining: 1.39s\n",
      "653:\tlearn: 0.0492010\ttotal: 2.62s\tremaining: 1.39s\n",
      "654:\tlearn: 0.0491712\ttotal: 2.63s\tremaining: 1.38s\n",
      "655:\tlearn: 0.0491297\ttotal: 2.63s\tremaining: 1.38s\n",
      "656:\tlearn: 0.0490876\ttotal: 2.64s\tremaining: 1.38s\n",
      "657:\tlearn: 0.0490530\ttotal: 2.64s\tremaining: 1.37s\n",
      "658:\tlearn: 0.0490322\ttotal: 2.65s\tremaining: 1.37s\n",
      "659:\tlearn: 0.0489500\ttotal: 2.65s\tremaining: 1.37s\n",
      "660:\tlearn: 0.0489167\ttotal: 2.66s\tremaining: 1.36s\n",
      "661:\tlearn: 0.0488441\ttotal: 2.66s\tremaining: 1.36s\n",
      "662:\tlearn: 0.0487811\ttotal: 2.66s\tremaining: 1.35s\n",
      "663:\tlearn: 0.0487104\ttotal: 2.67s\tremaining: 1.35s\n",
      "664:\tlearn: 0.0486795\ttotal: 2.67s\tremaining: 1.35s\n",
      "665:\tlearn: 0.0486568\ttotal: 2.68s\tremaining: 1.34s\n",
      "666:\tlearn: 0.0486242\ttotal: 2.68s\tremaining: 1.34s\n",
      "667:\tlearn: 0.0485769\ttotal: 2.68s\tremaining: 1.33s\n",
      "668:\tlearn: 0.0485496\ttotal: 2.69s\tremaining: 1.33s\n",
      "669:\tlearn: 0.0485234\ttotal: 2.69s\tremaining: 1.32s\n",
      "670:\tlearn: 0.0485020\ttotal: 2.69s\tremaining: 1.32s\n",
      "671:\tlearn: 0.0484659\ttotal: 2.7s\tremaining: 1.32s\n",
      "672:\tlearn: 0.0484370\ttotal: 2.7s\tremaining: 1.31s\n",
      "673:\tlearn: 0.0483346\ttotal: 2.71s\tremaining: 1.31s\n",
      "674:\tlearn: 0.0482702\ttotal: 2.71s\tremaining: 1.3s\n",
      "675:\tlearn: 0.0482294\ttotal: 2.71s\tremaining: 1.3s\n",
      "676:\tlearn: 0.0481512\ttotal: 2.72s\tremaining: 1.3s\n",
      "677:\tlearn: 0.0480936\ttotal: 2.72s\tremaining: 1.29s\n",
      "678:\tlearn: 0.0480544\ttotal: 2.73s\tremaining: 1.29s\n",
      "679:\tlearn: 0.0480146\ttotal: 2.73s\tremaining: 1.28s\n",
      "680:\tlearn: 0.0479614\ttotal: 2.73s\tremaining: 1.28s\n",
      "681:\tlearn: 0.0479253\ttotal: 2.74s\tremaining: 1.28s\n",
      "682:\tlearn: 0.0479062\ttotal: 2.74s\tremaining: 1.27s\n",
      "683:\tlearn: 0.0478608\ttotal: 2.75s\tremaining: 1.27s\n",
      "684:\tlearn: 0.0478355\ttotal: 2.75s\tremaining: 1.26s\n",
      "685:\tlearn: 0.0478007\ttotal: 2.75s\tremaining: 1.26s\n",
      "686:\tlearn: 0.0477807\ttotal: 2.76s\tremaining: 1.26s\n",
      "687:\tlearn: 0.0477531\ttotal: 2.76s\tremaining: 1.25s\n",
      "688:\tlearn: 0.0477107\ttotal: 2.77s\tremaining: 1.25s\n",
      "689:\tlearn: 0.0476775\ttotal: 2.77s\tremaining: 1.24s\n",
      "690:\tlearn: 0.0476324\ttotal: 2.77s\tremaining: 1.24s\n",
      "691:\tlearn: 0.0476117\ttotal: 2.78s\tremaining: 1.24s\n",
      "692:\tlearn: 0.0475787\ttotal: 2.78s\tremaining: 1.23s\n",
      "693:\tlearn: 0.0475531\ttotal: 2.79s\tremaining: 1.23s\n",
      "694:\tlearn: 0.0475163\ttotal: 2.79s\tremaining: 1.22s\n",
      "695:\tlearn: 0.0474833\ttotal: 2.79s\tremaining: 1.22s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "696:\tlearn: 0.0474522\ttotal: 2.8s\tremaining: 1.22s\n",
      "697:\tlearn: 0.0473977\ttotal: 2.8s\tremaining: 1.21s\n",
      "698:\tlearn: 0.0473630\ttotal: 2.81s\tremaining: 1.21s\n",
      "699:\tlearn: 0.0473310\ttotal: 2.81s\tremaining: 1.2s\n",
      "700:\tlearn: 0.0473097\ttotal: 2.81s\tremaining: 1.2s\n",
      "701:\tlearn: 0.0472679\ttotal: 2.82s\tremaining: 1.2s\n",
      "702:\tlearn: 0.0472206\ttotal: 2.82s\tremaining: 1.19s\n",
      "703:\tlearn: 0.0471170\ttotal: 2.83s\tremaining: 1.19s\n",
      "704:\tlearn: 0.0470966\ttotal: 2.83s\tremaining: 1.18s\n",
      "705:\tlearn: 0.0470712\ttotal: 2.83s\tremaining: 1.18s\n",
      "706:\tlearn: 0.0470421\ttotal: 2.84s\tremaining: 1.18s\n",
      "707:\tlearn: 0.0469586\ttotal: 2.84s\tremaining: 1.17s\n",
      "708:\tlearn: 0.0469213\ttotal: 2.84s\tremaining: 1.17s\n",
      "709:\tlearn: 0.0468617\ttotal: 2.85s\tremaining: 1.16s\n",
      "710:\tlearn: 0.0468008\ttotal: 2.85s\tremaining: 1.16s\n",
      "711:\tlearn: 0.0467787\ttotal: 2.86s\tremaining: 1.16s\n",
      "712:\tlearn: 0.0467531\ttotal: 2.86s\tremaining: 1.15s\n",
      "713:\tlearn: 0.0467223\ttotal: 2.86s\tremaining: 1.15s\n",
      "714:\tlearn: 0.0466909\ttotal: 2.87s\tremaining: 1.14s\n",
      "715:\tlearn: 0.0466358\ttotal: 2.87s\tremaining: 1.14s\n",
      "716:\tlearn: 0.0465815\ttotal: 2.88s\tremaining: 1.13s\n",
      "717:\tlearn: 0.0465615\ttotal: 2.88s\tremaining: 1.13s\n",
      "718:\tlearn: 0.0465224\ttotal: 2.88s\tremaining: 1.13s\n",
      "719:\tlearn: 0.0464926\ttotal: 2.89s\tremaining: 1.12s\n",
      "720:\tlearn: 0.0464613\ttotal: 2.89s\tremaining: 1.12s\n",
      "721:\tlearn: 0.0464393\ttotal: 2.9s\tremaining: 1.11s\n",
      "722:\tlearn: 0.0464251\ttotal: 2.9s\tremaining: 1.11s\n",
      "723:\tlearn: 0.0463956\ttotal: 2.9s\tremaining: 1.11s\n",
      "724:\tlearn: 0.0463665\ttotal: 2.91s\tremaining: 1.1s\n",
      "725:\tlearn: 0.0463355\ttotal: 2.91s\tremaining: 1.1s\n",
      "726:\tlearn: 0.0463062\ttotal: 2.91s\tremaining: 1.09s\n",
      "727:\tlearn: 0.0462689\ttotal: 2.92s\tremaining: 1.09s\n",
      "728:\tlearn: 0.0462076\ttotal: 2.92s\tremaining: 1.09s\n",
      "729:\tlearn: 0.0461603\ttotal: 2.93s\tremaining: 1.08s\n",
      "730:\tlearn: 0.0461322\ttotal: 2.93s\tremaining: 1.08s\n",
      "731:\tlearn: 0.0460970\ttotal: 2.93s\tremaining: 1.07s\n",
      "732:\tlearn: 0.0460712\ttotal: 2.94s\tremaining: 1.07s\n",
      "733:\tlearn: 0.0460379\ttotal: 2.94s\tremaining: 1.06s\n",
      "734:\tlearn: 0.0460215\ttotal: 2.94s\tremaining: 1.06s\n",
      "735:\tlearn: 0.0460084\ttotal: 2.95s\tremaining: 1.06s\n",
      "736:\tlearn: 0.0459914\ttotal: 2.95s\tremaining: 1.05s\n",
      "737:\tlearn: 0.0459440\ttotal: 2.96s\tremaining: 1.05s\n",
      "738:\tlearn: 0.0459241\ttotal: 2.96s\tremaining: 1.04s\n",
      "739:\tlearn: 0.0459040\ttotal: 2.96s\tremaining: 1.04s\n",
      "740:\tlearn: 0.0458760\ttotal: 2.97s\tremaining: 1.04s\n",
      "741:\tlearn: 0.0458528\ttotal: 2.97s\tremaining: 1.03s\n",
      "742:\tlearn: 0.0458367\ttotal: 2.98s\tremaining: 1.03s\n",
      "743:\tlearn: 0.0458079\ttotal: 2.98s\tremaining: 1.03s\n",
      "744:\tlearn: 0.0457634\ttotal: 2.98s\tremaining: 1.02s\n",
      "745:\tlearn: 0.0457483\ttotal: 2.99s\tremaining: 1.02s\n",
      "746:\tlearn: 0.0457244\ttotal: 2.99s\tremaining: 1.01s\n",
      "747:\tlearn: 0.0457020\ttotal: 3s\tremaining: 1.01s\n",
      "748:\tlearn: 0.0456621\ttotal: 3s\tremaining: 1s\n",
      "749:\tlearn: 0.0456340\ttotal: 3s\tremaining: 1s\n",
      "750:\tlearn: 0.0455789\ttotal: 3.01s\tremaining: 998ms\n",
      "751:\tlearn: 0.0455124\ttotal: 3.01s\tremaining: 994ms\n",
      "752:\tlearn: 0.0454811\ttotal: 3.02s\tremaining: 990ms\n",
      "753:\tlearn: 0.0454657\ttotal: 3.02s\tremaining: 986ms\n",
      "754:\tlearn: 0.0454239\ttotal: 3.02s\tremaining: 982ms\n",
      "755:\tlearn: 0.0453965\ttotal: 3.03s\tremaining: 977ms\n",
      "756:\tlearn: 0.0453343\ttotal: 3.03s\tremaining: 973ms\n",
      "757:\tlearn: 0.0452663\ttotal: 3.04s\tremaining: 969ms\n",
      "758:\tlearn: 0.0452191\ttotal: 3.04s\tremaining: 965ms\n",
      "759:\tlearn: 0.0452026\ttotal: 3.04s\tremaining: 961ms\n",
      "760:\tlearn: 0.0451875\ttotal: 3.05s\tremaining: 957ms\n",
      "761:\tlearn: 0.0451516\ttotal: 3.05s\tremaining: 953ms\n",
      "762:\tlearn: 0.0451051\ttotal: 3.06s\tremaining: 949ms\n",
      "763:\tlearn: 0.0450392\ttotal: 3.06s\tremaining: 945ms\n",
      "764:\tlearn: 0.0450214\ttotal: 3.06s\tremaining: 941ms\n",
      "765:\tlearn: 0.0449932\ttotal: 3.07s\tremaining: 937ms\n",
      "766:\tlearn: 0.0449665\ttotal: 3.07s\tremaining: 933ms\n",
      "767:\tlearn: 0.0449050\ttotal: 3.07s\tremaining: 929ms\n",
      "768:\tlearn: 0.0448836\ttotal: 3.08s\tremaining: 925ms\n",
      "769:\tlearn: 0.0448368\ttotal: 3.08s\tremaining: 920ms\n",
      "770:\tlearn: 0.0448209\ttotal: 3.08s\tremaining: 916ms\n",
      "771:\tlearn: 0.0448066\ttotal: 3.09s\tremaining: 912ms\n",
      "772:\tlearn: 0.0447676\ttotal: 3.09s\tremaining: 908ms\n",
      "773:\tlearn: 0.0447405\ttotal: 3.1s\tremaining: 904ms\n",
      "774:\tlearn: 0.0446747\ttotal: 3.1s\tremaining: 900ms\n",
      "775:\tlearn: 0.0446337\ttotal: 3.1s\tremaining: 896ms\n",
      "776:\tlearn: 0.0446077\ttotal: 3.11s\tremaining: 892ms\n",
      "777:\tlearn: 0.0445814\ttotal: 3.11s\tremaining: 888ms\n",
      "778:\tlearn: 0.0445146\ttotal: 3.12s\tremaining: 884ms\n",
      "779:\tlearn: 0.0444369\ttotal: 3.12s\tremaining: 880ms\n",
      "780:\tlearn: 0.0444114\ttotal: 3.12s\tremaining: 876ms\n",
      "781:\tlearn: 0.0443548\ttotal: 3.13s\tremaining: 872ms\n",
      "782:\tlearn: 0.0443403\ttotal: 3.13s\tremaining: 868ms\n",
      "783:\tlearn: 0.0443148\ttotal: 3.13s\tremaining: 864ms\n",
      "784:\tlearn: 0.0442872\ttotal: 3.14s\tremaining: 860ms\n",
      "785:\tlearn: 0.0442548\ttotal: 3.14s\tremaining: 856ms\n",
      "786:\tlearn: 0.0442222\ttotal: 3.15s\tremaining: 852ms\n",
      "787:\tlearn: 0.0441780\ttotal: 3.15s\tremaining: 848ms\n",
      "788:\tlearn: 0.0441207\ttotal: 3.16s\tremaining: 844ms\n",
      "789:\tlearn: 0.0440440\ttotal: 3.16s\tremaining: 840ms\n",
      "790:\tlearn: 0.0439747\ttotal: 3.16s\tremaining: 836ms\n",
      "791:\tlearn: 0.0439463\ttotal: 3.17s\tremaining: 832ms\n",
      "792:\tlearn: 0.0438639\ttotal: 3.17s\tremaining: 828ms\n",
      "793:\tlearn: 0.0438379\ttotal: 3.18s\tremaining: 824ms\n",
      "794:\tlearn: 0.0438127\ttotal: 3.18s\tremaining: 820ms\n",
      "795:\tlearn: 0.0437920\ttotal: 3.19s\tremaining: 816ms\n",
      "796:\tlearn: 0.0437708\ttotal: 3.19s\tremaining: 812ms\n",
      "797:\tlearn: 0.0437452\ttotal: 3.19s\tremaining: 808ms\n",
      "798:\tlearn: 0.0437264\ttotal: 3.2s\tremaining: 804ms\n",
      "799:\tlearn: 0.0437115\ttotal: 3.2s\tremaining: 800ms\n",
      "800:\tlearn: 0.0436860\ttotal: 3.2s\tremaining: 796ms\n",
      "801:\tlearn: 0.0436616\ttotal: 3.21s\tremaining: 792ms\n",
      "802:\tlearn: 0.0436344\ttotal: 3.21s\tremaining: 788ms\n",
      "803:\tlearn: 0.0436153\ttotal: 3.21s\tremaining: 784ms\n",
      "804:\tlearn: 0.0435401\ttotal: 3.22s\tremaining: 780ms\n",
      "805:\tlearn: 0.0435158\ttotal: 3.22s\tremaining: 776ms\n",
      "806:\tlearn: 0.0434896\ttotal: 3.23s\tremaining: 772ms\n",
      "807:\tlearn: 0.0434770\ttotal: 3.23s\tremaining: 768ms\n",
      "808:\tlearn: 0.0434508\ttotal: 3.24s\tremaining: 764ms\n",
      "809:\tlearn: 0.0434358\ttotal: 3.24s\tremaining: 760ms\n",
      "810:\tlearn: 0.0434232\ttotal: 3.24s\tremaining: 756ms\n",
      "811:\tlearn: 0.0434094\ttotal: 3.25s\tremaining: 752ms\n",
      "812:\tlearn: 0.0433850\ttotal: 3.25s\tremaining: 748ms\n",
      "813:\tlearn: 0.0433471\ttotal: 3.25s\tremaining: 744ms\n",
      "814:\tlearn: 0.0433163\ttotal: 3.26s\tremaining: 740ms\n",
      "815:\tlearn: 0.0432544\ttotal: 3.26s\tremaining: 736ms\n",
      "816:\tlearn: 0.0432179\ttotal: 3.27s\tremaining: 732ms\n",
      "817:\tlearn: 0.0431699\ttotal: 3.27s\tremaining: 728ms\n",
      "818:\tlearn: 0.0431571\ttotal: 3.27s\tremaining: 724ms\n",
      "819:\tlearn: 0.0430783\ttotal: 3.28s\tremaining: 720ms\n",
      "820:\tlearn: 0.0430557\ttotal: 3.28s\tremaining: 715ms\n",
      "821:\tlearn: 0.0430312\ttotal: 3.29s\tremaining: 711ms\n",
      "822:\tlearn: 0.0430068\ttotal: 3.29s\tremaining: 707ms\n",
      "823:\tlearn: 0.0429837\ttotal: 3.29s\tremaining: 703ms\n",
      "824:\tlearn: 0.0429598\ttotal: 3.29s\tremaining: 699ms\n",
      "825:\tlearn: 0.0429367\ttotal: 3.3s\tremaining: 695ms\n",
      "826:\tlearn: 0.0429130\ttotal: 3.3s\tremaining: 691ms\n",
      "827:\tlearn: 0.0428408\ttotal: 3.31s\tremaining: 687ms\n",
      "828:\tlearn: 0.0428288\ttotal: 3.31s\tremaining: 683ms\n",
      "829:\tlearn: 0.0427579\ttotal: 3.31s\tremaining: 679ms\n",
      "830:\tlearn: 0.0427345\ttotal: 3.32s\tremaining: 675ms\n",
      "831:\tlearn: 0.0426683\ttotal: 3.32s\tremaining: 671ms\n",
      "832:\tlearn: 0.0426045\ttotal: 3.33s\tremaining: 667ms\n",
      "833:\tlearn: 0.0425908\ttotal: 3.33s\tremaining: 663ms\n",
      "834:\tlearn: 0.0425590\ttotal: 3.33s\tremaining: 659ms\n",
      "835:\tlearn: 0.0425305\ttotal: 3.34s\tremaining: 655ms\n",
      "836:\tlearn: 0.0425019\ttotal: 3.34s\tremaining: 651ms\n",
      "837:\tlearn: 0.0424738\ttotal: 3.35s\tremaining: 647ms\n",
      "838:\tlearn: 0.0424506\ttotal: 3.35s\tremaining: 643ms\n",
      "839:\tlearn: 0.0424370\ttotal: 3.35s\tremaining: 639ms\n",
      "840:\tlearn: 0.0423840\ttotal: 3.36s\tremaining: 635ms\n",
      "841:\tlearn: 0.0423706\ttotal: 3.36s\tremaining: 631ms\n",
      "842:\tlearn: 0.0423463\ttotal: 3.37s\tremaining: 627ms\n",
      "843:\tlearn: 0.0422719\ttotal: 3.37s\tremaining: 623ms\n",
      "844:\tlearn: 0.0422490\ttotal: 3.37s\tremaining: 619ms\n",
      "845:\tlearn: 0.0422372\ttotal: 3.38s\tremaining: 615ms\n",
      "846:\tlearn: 0.0422083\ttotal: 3.38s\tremaining: 611ms\n",
      "847:\tlearn: 0.0421705\ttotal: 3.39s\tremaining: 607ms\n",
      "848:\tlearn: 0.0421067\ttotal: 3.39s\tremaining: 603ms\n",
      "849:\tlearn: 0.0420842\ttotal: 3.4s\tremaining: 599ms\n",
      "850:\tlearn: 0.0420561\ttotal: 3.4s\tremaining: 595ms\n",
      "851:\tlearn: 0.0420430\ttotal: 3.4s\tremaining: 591ms\n",
      "852:\tlearn: 0.0420149\ttotal: 3.41s\tremaining: 587ms\n",
      "853:\tlearn: 0.0419912\ttotal: 3.41s\tremaining: 584ms\n",
      "854:\tlearn: 0.0419226\ttotal: 3.42s\tremaining: 580ms\n",
      "855:\tlearn: 0.0418517\ttotal: 3.42s\tremaining: 576ms\n",
      "856:\tlearn: 0.0418080\ttotal: 3.42s\tremaining: 572ms\n",
      "857:\tlearn: 0.0417975\ttotal: 3.43s\tremaining: 568ms\n",
      "858:\tlearn: 0.0417843\ttotal: 3.43s\tremaining: 564ms\n",
      "859:\tlearn: 0.0417573\ttotal: 3.44s\tremaining: 560ms\n",
      "860:\tlearn: 0.0417208\ttotal: 3.44s\tremaining: 556ms\n",
      "861:\tlearn: 0.0416711\ttotal: 3.45s\tremaining: 552ms\n",
      "862:\tlearn: 0.0416491\ttotal: 3.45s\tremaining: 548ms\n",
      "863:\tlearn: 0.0415823\ttotal: 3.46s\tremaining: 544ms\n",
      "864:\tlearn: 0.0415591\ttotal: 3.46s\tremaining: 540ms\n",
      "865:\tlearn: 0.0414660\ttotal: 3.47s\tremaining: 536ms\n",
      "866:\tlearn: 0.0414534\ttotal: 3.47s\tremaining: 533ms\n",
      "867:\tlearn: 0.0414305\ttotal: 3.48s\tremaining: 529ms\n",
      "868:\tlearn: 0.0414090\ttotal: 3.48s\tremaining: 525ms\n",
      "869:\tlearn: 0.0413990\ttotal: 3.48s\tremaining: 521ms\n",
      "870:\tlearn: 0.0413501\ttotal: 3.49s\tremaining: 517ms\n",
      "871:\tlearn: 0.0412878\ttotal: 3.49s\tremaining: 513ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "872:\tlearn: 0.0412661\ttotal: 3.5s\tremaining: 509ms\n",
      "873:\tlearn: 0.0412536\ttotal: 3.5s\tremaining: 505ms\n",
      "874:\tlearn: 0.0412014\ttotal: 3.5s\tremaining: 501ms\n",
      "875:\tlearn: 0.0411554\ttotal: 3.51s\tremaining: 497ms\n",
      "876:\tlearn: 0.0411340\ttotal: 3.51s\tremaining: 493ms\n",
      "877:\tlearn: 0.0411089\ttotal: 3.52s\tremaining: 489ms\n",
      "878:\tlearn: 0.0410391\ttotal: 3.52s\tremaining: 485ms\n",
      "879:\tlearn: 0.0409492\ttotal: 3.53s\tremaining: 481ms\n",
      "880:\tlearn: 0.0409284\ttotal: 3.53s\tremaining: 477ms\n",
      "881:\tlearn: 0.0409018\ttotal: 3.53s\tremaining: 473ms\n",
      "882:\tlearn: 0.0408764\ttotal: 3.54s\tremaining: 469ms\n",
      "883:\tlearn: 0.0408552\ttotal: 3.54s\tremaining: 465ms\n",
      "884:\tlearn: 0.0408332\ttotal: 3.55s\tremaining: 461ms\n",
      "885:\tlearn: 0.0408080\ttotal: 3.55s\tremaining: 457ms\n",
      "886:\tlearn: 0.0407875\ttotal: 3.56s\tremaining: 453ms\n",
      "887:\tlearn: 0.0407758\ttotal: 3.56s\tremaining: 449ms\n",
      "888:\tlearn: 0.0407549\ttotal: 3.56s\tremaining: 445ms\n",
      "889:\tlearn: 0.0407302\ttotal: 3.57s\tremaining: 441ms\n",
      "890:\tlearn: 0.0406670\ttotal: 3.57s\tremaining: 437ms\n",
      "891:\tlearn: 0.0406454\ttotal: 3.58s\tremaining: 433ms\n",
      "892:\tlearn: 0.0405597\ttotal: 3.58s\tremaining: 429ms\n",
      "893:\tlearn: 0.0405485\ttotal: 3.59s\tremaining: 425ms\n",
      "894:\tlearn: 0.0405370\ttotal: 3.59s\tremaining: 421ms\n",
      "895:\tlearn: 0.0405126\ttotal: 3.6s\tremaining: 417ms\n",
      "896:\tlearn: 0.0404473\ttotal: 3.6s\tremaining: 413ms\n",
      "897:\tlearn: 0.0404269\ttotal: 3.6s\tremaining: 409ms\n",
      "898:\tlearn: 0.0403685\ttotal: 3.61s\tremaining: 405ms\n",
      "899:\tlearn: 0.0403566\ttotal: 3.61s\tremaining: 401ms\n",
      "900:\tlearn: 0.0402851\ttotal: 3.62s\tremaining: 397ms\n",
      "901:\tlearn: 0.0402154\ttotal: 3.62s\tremaining: 393ms\n",
      "902:\tlearn: 0.0401759\ttotal: 3.62s\tremaining: 389ms\n",
      "903:\tlearn: 0.0401548\ttotal: 3.63s\tremaining: 385ms\n",
      "904:\tlearn: 0.0401311\ttotal: 3.63s\tremaining: 381ms\n",
      "905:\tlearn: 0.0401078\ttotal: 3.64s\tremaining: 377ms\n",
      "906:\tlearn: 0.0400961\ttotal: 3.64s\tremaining: 373ms\n",
      "907:\tlearn: 0.0400846\ttotal: 3.65s\tremaining: 369ms\n",
      "908:\tlearn: 0.0400646\ttotal: 3.65s\tremaining: 365ms\n",
      "909:\tlearn: 0.0400082\ttotal: 3.65s\tremaining: 361ms\n",
      "910:\tlearn: 0.0399885\ttotal: 3.66s\tremaining: 357ms\n",
      "911:\tlearn: 0.0399317\ttotal: 3.66s\tremaining: 353ms\n",
      "912:\tlearn: 0.0398935\ttotal: 3.66s\tremaining: 349ms\n",
      "913:\tlearn: 0.0398298\ttotal: 3.67s\tremaining: 345ms\n",
      "914:\tlearn: 0.0397414\ttotal: 3.67s\tremaining: 341ms\n",
      "915:\tlearn: 0.0397185\ttotal: 3.67s\tremaining: 337ms\n",
      "916:\tlearn: 0.0396961\ttotal: 3.68s\tremaining: 333ms\n",
      "917:\tlearn: 0.0396101\ttotal: 3.68s\tremaining: 329ms\n",
      "918:\tlearn: 0.0395489\ttotal: 3.69s\tremaining: 325ms\n",
      "919:\tlearn: 0.0395221\ttotal: 3.69s\tremaining: 321ms\n",
      "920:\tlearn: 0.0394638\ttotal: 3.7s\tremaining: 317ms\n",
      "921:\tlearn: 0.0394420\ttotal: 3.7s\tremaining: 313ms\n",
      "922:\tlearn: 0.0394182\ttotal: 3.7s\tremaining: 309ms\n",
      "923:\tlearn: 0.0393588\ttotal: 3.71s\tremaining: 305ms\n",
      "924:\tlearn: 0.0393116\ttotal: 3.71s\tremaining: 301ms\n",
      "925:\tlearn: 0.0392459\ttotal: 3.72s\tremaining: 297ms\n",
      "926:\tlearn: 0.0392225\ttotal: 3.72s\tremaining: 293ms\n",
      "927:\tlearn: 0.0392132\ttotal: 3.72s\tremaining: 289ms\n",
      "928:\tlearn: 0.0391902\ttotal: 3.73s\tremaining: 285ms\n",
      "929:\tlearn: 0.0391697\ttotal: 3.73s\tremaining: 281ms\n",
      "930:\tlearn: 0.0391167\ttotal: 3.73s\tremaining: 277ms\n",
      "931:\tlearn: 0.0391080\ttotal: 3.74s\tremaining: 273ms\n",
      "932:\tlearn: 0.0390352\ttotal: 3.74s\tremaining: 269ms\n",
      "933:\tlearn: 0.0389716\ttotal: 3.75s\tremaining: 265ms\n",
      "934:\tlearn: 0.0389604\ttotal: 3.75s\tremaining: 261ms\n",
      "935:\tlearn: 0.0388916\ttotal: 3.75s\tremaining: 257ms\n",
      "936:\tlearn: 0.0388688\ttotal: 3.76s\tremaining: 253ms\n",
      "937:\tlearn: 0.0388485\ttotal: 3.76s\tremaining: 249ms\n",
      "938:\tlearn: 0.0388285\ttotal: 3.77s\tremaining: 245ms\n",
      "939:\tlearn: 0.0388173\ttotal: 3.77s\tremaining: 241ms\n",
      "940:\tlearn: 0.0387510\ttotal: 3.77s\tremaining: 237ms\n",
      "941:\tlearn: 0.0387400\ttotal: 3.77s\tremaining: 232ms\n",
      "942:\tlearn: 0.0387152\ttotal: 3.78s\tremaining: 228ms\n",
      "943:\tlearn: 0.0386927\ttotal: 3.78s\tremaining: 224ms\n",
      "944:\tlearn: 0.0386737\ttotal: 3.79s\tremaining: 220ms\n",
      "945:\tlearn: 0.0386424\ttotal: 3.79s\tremaining: 216ms\n",
      "946:\tlearn: 0.0386205\ttotal: 3.79s\tremaining: 212ms\n",
      "947:\tlearn: 0.0385698\ttotal: 3.8s\tremaining: 208ms\n",
      "948:\tlearn: 0.0385507\ttotal: 3.8s\tremaining: 204ms\n",
      "949:\tlearn: 0.0385398\ttotal: 3.81s\tremaining: 200ms\n",
      "950:\tlearn: 0.0385157\ttotal: 3.81s\tremaining: 196ms\n",
      "951:\tlearn: 0.0384962\ttotal: 3.81s\tremaining: 192ms\n",
      "952:\tlearn: 0.0384435\ttotal: 3.82s\tremaining: 188ms\n",
      "953:\tlearn: 0.0384198\ttotal: 3.82s\tremaining: 184ms\n",
      "954:\tlearn: 0.0384004\ttotal: 3.82s\tremaining: 180ms\n",
      "955:\tlearn: 0.0383897\ttotal: 3.83s\tremaining: 176ms\n",
      "956:\tlearn: 0.0383160\ttotal: 3.83s\tremaining: 172ms\n",
      "957:\tlearn: 0.0382942\ttotal: 3.83s\tremaining: 168ms\n",
      "958:\tlearn: 0.0382727\ttotal: 3.84s\tremaining: 164ms\n",
      "959:\tlearn: 0.0382533\ttotal: 3.84s\tremaining: 160ms\n",
      "960:\tlearn: 0.0382427\ttotal: 3.85s\tremaining: 156ms\n",
      "961:\tlearn: 0.0381933\ttotal: 3.85s\tremaining: 152ms\n",
      "962:\tlearn: 0.0381723\ttotal: 3.85s\tremaining: 148ms\n",
      "963:\tlearn: 0.0381531\ttotal: 3.86s\tremaining: 144ms\n",
      "964:\tlearn: 0.0381385\ttotal: 3.86s\tremaining: 140ms\n",
      "965:\tlearn: 0.0381289\ttotal: 3.87s\tremaining: 136ms\n",
      "966:\tlearn: 0.0380865\ttotal: 3.87s\tremaining: 132ms\n",
      "967:\tlearn: 0.0380061\ttotal: 3.88s\tremaining: 128ms\n",
      "968:\tlearn: 0.0379957\ttotal: 3.88s\tremaining: 124ms\n",
      "969:\tlearn: 0.0379727\ttotal: 3.88s\tremaining: 120ms\n",
      "970:\tlearn: 0.0378952\ttotal: 3.89s\tremaining: 116ms\n",
      "971:\tlearn: 0.0378772\ttotal: 3.89s\tremaining: 112ms\n",
      "972:\tlearn: 0.0378570\ttotal: 3.9s\tremaining: 108ms\n",
      "973:\tlearn: 0.0378381\ttotal: 3.9s\tremaining: 104ms\n",
      "974:\tlearn: 0.0378193\ttotal: 3.9s\tremaining: 100ms\n",
      "975:\tlearn: 0.0378114\ttotal: 3.91s\tremaining: 96.1ms\n",
      "976:\tlearn: 0.0377710\ttotal: 3.91s\tremaining: 92.1ms\n",
      "977:\tlearn: 0.0377525\ttotal: 3.92s\tremaining: 88.1ms\n",
      "978:\tlearn: 0.0376767\ttotal: 3.92s\tremaining: 84.1ms\n",
      "979:\tlearn: 0.0376569\ttotal: 3.92s\tremaining: 80.1ms\n",
      "980:\tlearn: 0.0376370\ttotal: 3.93s\tremaining: 76.1ms\n",
      "981:\tlearn: 0.0375746\ttotal: 3.93s\tremaining: 72.1ms\n",
      "982:\tlearn: 0.0375643\ttotal: 3.94s\tremaining: 68.1ms\n",
      "983:\tlearn: 0.0375446\ttotal: 3.94s\tremaining: 64.1ms\n",
      "984:\tlearn: 0.0375223\ttotal: 3.94s\tremaining: 60.1ms\n",
      "985:\tlearn: 0.0374774\ttotal: 3.95s\tremaining: 56ms\n",
      "986:\tlearn: 0.0374528\ttotal: 3.95s\tremaining: 52ms\n",
      "987:\tlearn: 0.0374230\ttotal: 3.95s\tremaining: 48ms\n",
      "988:\tlearn: 0.0373938\ttotal: 3.96s\tremaining: 44ms\n",
      "989:\tlearn: 0.0373812\ttotal: 3.96s\tremaining: 40ms\n",
      "990:\tlearn: 0.0373284\ttotal: 3.96s\tremaining: 36ms\n",
      "991:\tlearn: 0.0373092\ttotal: 3.97s\tremaining: 32ms\n",
      "992:\tlearn: 0.0372632\ttotal: 3.97s\tremaining: 28ms\n",
      "993:\tlearn: 0.0372449\ttotal: 3.98s\tremaining: 24ms\n",
      "994:\tlearn: 0.0371709\ttotal: 3.98s\tremaining: 20ms\n",
      "995:\tlearn: 0.0371520\ttotal: 3.98s\tremaining: 16ms\n",
      "996:\tlearn: 0.0371444\ttotal: 3.99s\tremaining: 12ms\n",
      "997:\tlearn: 0.0370687\ttotal: 3.99s\tremaining: 8ms\n",
      "998:\tlearn: 0.0369927\ttotal: 4s\tremaining: 4ms\n",
      "999:\tlearn: 0.0369707\ttotal: 4s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013279\n",
      "0:\tlearn: 0.6669218\ttotal: 6.38ms\tremaining: 6.37s\n",
      "1:\tlearn: 0.6438385\ttotal: 10.5ms\tremaining: 5.23s\n",
      "2:\tlearn: 0.6193130\ttotal: 14ms\tremaining: 4.65s\n",
      "3:\tlearn: 0.5972235\ttotal: 17.5ms\tremaining: 4.36s\n",
      "4:\tlearn: 0.5759581\ttotal: 21ms\tremaining: 4.18s\n",
      "5:\tlearn: 0.5605932\ttotal: 24.4ms\tremaining: 4.04s\n",
      "6:\tlearn: 0.5407810\ttotal: 28ms\tremaining: 3.97s\n",
      "7:\tlearn: 0.5238172\ttotal: 31.6ms\tremaining: 3.92s\n",
      "8:\tlearn: 0.5086500\ttotal: 35.4ms\tremaining: 3.9s\n",
      "9:\tlearn: 0.4918339\ttotal: 39.4ms\tremaining: 3.9s\n",
      "10:\tlearn: 0.4763387\ttotal: 42.9ms\tremaining: 3.86s\n",
      "11:\tlearn: 0.4605174\ttotal: 46.8ms\tremaining: 3.86s\n",
      "12:\tlearn: 0.4460371\ttotal: 50.5ms\tremaining: 3.83s\n",
      "13:\tlearn: 0.4321998\ttotal: 54ms\tremaining: 3.81s\n",
      "14:\tlearn: 0.4188069\ttotal: 57.7ms\tremaining: 3.79s\n",
      "15:\tlearn: 0.4052205\ttotal: 61.2ms\tremaining: 3.76s\n",
      "16:\tlearn: 0.3945656\ttotal: 65.4ms\tremaining: 3.78s\n",
      "17:\tlearn: 0.3831652\ttotal: 70.3ms\tremaining: 3.83s\n",
      "18:\tlearn: 0.3721967\ttotal: 74.4ms\tremaining: 3.84s\n",
      "19:\tlearn: 0.3622156\ttotal: 77.9ms\tremaining: 3.82s\n",
      "20:\tlearn: 0.3528464\ttotal: 81.4ms\tremaining: 3.8s\n",
      "21:\tlearn: 0.3459414\ttotal: 85.2ms\tremaining: 3.79s\n",
      "22:\tlearn: 0.3372651\ttotal: 88.9ms\tremaining: 3.78s\n",
      "23:\tlearn: 0.3296355\ttotal: 92.4ms\tremaining: 3.76s\n",
      "24:\tlearn: 0.3209496\ttotal: 96ms\tremaining: 3.74s\n",
      "25:\tlearn: 0.3129144\ttotal: 100ms\tremaining: 3.75s\n",
      "26:\tlearn: 0.3061651\ttotal: 104ms\tremaining: 3.74s\n",
      "27:\tlearn: 0.2989463\ttotal: 108ms\tremaining: 3.74s\n",
      "28:\tlearn: 0.2927301\ttotal: 112ms\tremaining: 3.74s\n",
      "29:\tlearn: 0.2859438\ttotal: 116ms\tremaining: 3.75s\n",
      "30:\tlearn: 0.2796683\ttotal: 120ms\tremaining: 3.76s\n",
      "31:\tlearn: 0.2731094\ttotal: 125ms\tremaining: 3.77s\n",
      "32:\tlearn: 0.2670301\ttotal: 128ms\tremaining: 3.75s\n",
      "33:\tlearn: 0.2613528\ttotal: 132ms\tremaining: 3.76s\n",
      "34:\tlearn: 0.2555554\ttotal: 136ms\tremaining: 3.74s\n",
      "35:\tlearn: 0.2507760\ttotal: 139ms\tremaining: 3.73s\n",
      "36:\tlearn: 0.2459842\ttotal: 143ms\tremaining: 3.72s\n",
      "37:\tlearn: 0.2415661\ttotal: 146ms\tremaining: 3.7s\n",
      "38:\tlearn: 0.2373796\ttotal: 150ms\tremaining: 3.69s\n",
      "39:\tlearn: 0.2325564\ttotal: 153ms\tremaining: 3.68s\n",
      "40:\tlearn: 0.2289830\ttotal: 157ms\tremaining: 3.68s\n",
      "41:\tlearn: 0.2249628\ttotal: 161ms\tremaining: 3.67s\n",
      "42:\tlearn: 0.2209613\ttotal: 165ms\tremaining: 3.67s\n",
      "43:\tlearn: 0.2170461\ttotal: 168ms\tremaining: 3.66s\n",
      "44:\tlearn: 0.2137927\ttotal: 173ms\tremaining: 3.66s\n",
      "45:\tlearn: 0.2103338\ttotal: 177ms\tremaining: 3.67s\n",
      "46:\tlearn: 0.2068024\ttotal: 181ms\tremaining: 3.67s\n",
      "47:\tlearn: 0.2038653\ttotal: 185ms\tremaining: 3.66s\n",
      "48:\tlearn: 0.2014608\ttotal: 189ms\tremaining: 3.66s\n",
      "49:\tlearn: 0.1985768\ttotal: 193ms\tremaining: 3.66s\n",
      "50:\tlearn: 0.1960889\ttotal: 196ms\tremaining: 3.65s\n",
      "51:\tlearn: 0.1937570\ttotal: 200ms\tremaining: 3.64s\n",
      "52:\tlearn: 0.1912534\ttotal: 204ms\tremaining: 3.64s\n",
      "53:\tlearn: 0.1886019\ttotal: 208ms\tremaining: 3.65s\n",
      "54:\tlearn: 0.1865813\ttotal: 212ms\tremaining: 3.63s\n",
      "55:\tlearn: 0.1841018\ttotal: 215ms\tremaining: 3.63s\n",
      "56:\tlearn: 0.1818841\ttotal: 219ms\tremaining: 3.63s\n",
      "57:\tlearn: 0.1796849\ttotal: 224ms\tremaining: 3.65s\n",
      "58:\tlearn: 0.1778074\ttotal: 228ms\tremaining: 3.64s\n",
      "59:\tlearn: 0.1758070\ttotal: 232ms\tremaining: 3.63s\n",
      "60:\tlearn: 0.1737468\ttotal: 235ms\tremaining: 3.63s\n",
      "61:\tlearn: 0.1715433\ttotal: 239ms\tremaining: 3.62s\n",
      "62:\tlearn: 0.1700688\ttotal: 243ms\tremaining: 3.62s\n",
      "63:\tlearn: 0.1683150\ttotal: 247ms\tremaining: 3.62s\n",
      "64:\tlearn: 0.1664723\ttotal: 251ms\tremaining: 3.61s\n",
      "65:\tlearn: 0.1648847\ttotal: 255ms\tremaining: 3.6s\n",
      "66:\tlearn: 0.1635171\ttotal: 259ms\tremaining: 3.6s\n",
      "67:\tlearn: 0.1620306\ttotal: 262ms\tremaining: 3.59s\n",
      "68:\tlearn: 0.1605030\ttotal: 266ms\tremaining: 3.59s\n",
      "69:\tlearn: 0.1590363\ttotal: 269ms\tremaining: 3.58s\n",
      "70:\tlearn: 0.1578354\ttotal: 273ms\tremaining: 3.56s\n",
      "71:\tlearn: 0.1562537\ttotal: 276ms\tremaining: 3.56s\n",
      "72:\tlearn: 0.1546905\ttotal: 280ms\tremaining: 3.55s\n",
      "73:\tlearn: 0.1536649\ttotal: 283ms\tremaining: 3.54s\n",
      "74:\tlearn: 0.1521828\ttotal: 287ms\tremaining: 3.54s\n",
      "75:\tlearn: 0.1509869\ttotal: 291ms\tremaining: 3.53s\n",
      "76:\tlearn: 0.1501020\ttotal: 294ms\tremaining: 3.53s\n",
      "77:\tlearn: 0.1488972\ttotal: 298ms\tremaining: 3.52s\n",
      "78:\tlearn: 0.1477120\ttotal: 301ms\tremaining: 3.51s\n",
      "79:\tlearn: 0.1463665\ttotal: 305ms\tremaining: 3.5s\n",
      "80:\tlearn: 0.1454099\ttotal: 308ms\tremaining: 3.5s\n",
      "81:\tlearn: 0.1441791\ttotal: 312ms\tremaining: 3.49s\n",
      "82:\tlearn: 0.1430780\ttotal: 316ms\tremaining: 3.48s\n",
      "83:\tlearn: 0.1423596\ttotal: 319ms\tremaining: 3.48s\n",
      "84:\tlearn: 0.1415085\ttotal: 323ms\tremaining: 3.48s\n",
      "85:\tlearn: 0.1405275\ttotal: 326ms\tremaining: 3.47s\n",
      "86:\tlearn: 0.1395133\ttotal: 330ms\tremaining: 3.46s\n",
      "87:\tlearn: 0.1383429\ttotal: 334ms\tremaining: 3.46s\n",
      "88:\tlearn: 0.1374513\ttotal: 337ms\tremaining: 3.45s\n",
      "89:\tlearn: 0.1366616\ttotal: 341ms\tremaining: 3.45s\n",
      "90:\tlearn: 0.1359522\ttotal: 345ms\tremaining: 3.44s\n",
      "91:\tlearn: 0.1350685\ttotal: 349ms\tremaining: 3.44s\n",
      "92:\tlearn: 0.1342275\ttotal: 353ms\tremaining: 3.44s\n",
      "93:\tlearn: 0.1333216\ttotal: 358ms\tremaining: 3.45s\n",
      "94:\tlearn: 0.1324624\ttotal: 362ms\tremaining: 3.45s\n",
      "95:\tlearn: 0.1317854\ttotal: 366ms\tremaining: 3.44s\n",
      "96:\tlearn: 0.1310712\ttotal: 370ms\tremaining: 3.44s\n",
      "97:\tlearn: 0.1304065\ttotal: 373ms\tremaining: 3.44s\n",
      "98:\tlearn: 0.1296828\ttotal: 377ms\tremaining: 3.43s\n",
      "99:\tlearn: 0.1290587\ttotal: 381ms\tremaining: 3.43s\n",
      "100:\tlearn: 0.1282920\ttotal: 385ms\tremaining: 3.42s\n",
      "101:\tlearn: 0.1274187\ttotal: 389ms\tremaining: 3.42s\n",
      "102:\tlearn: 0.1267507\ttotal: 393ms\tremaining: 3.42s\n",
      "103:\tlearn: 0.1261859\ttotal: 396ms\tremaining: 3.41s\n",
      "104:\tlearn: 0.1257326\ttotal: 400ms\tremaining: 3.41s\n",
      "105:\tlearn: 0.1251987\ttotal: 403ms\tremaining: 3.4s\n",
      "106:\tlearn: 0.1246569\ttotal: 408ms\tremaining: 3.4s\n",
      "107:\tlearn: 0.1239756\ttotal: 412ms\tremaining: 3.4s\n",
      "108:\tlearn: 0.1232531\ttotal: 416ms\tremaining: 3.4s\n",
      "109:\tlearn: 0.1224232\ttotal: 420ms\tremaining: 3.4s\n",
      "110:\tlearn: 0.1218077\ttotal: 423ms\tremaining: 3.39s\n",
      "111:\tlearn: 0.1211495\ttotal: 427ms\tremaining: 3.39s\n",
      "112:\tlearn: 0.1206440\ttotal: 431ms\tremaining: 3.39s\n",
      "113:\tlearn: 0.1201121\ttotal: 436ms\tremaining: 3.39s\n",
      "114:\tlearn: 0.1197891\ttotal: 441ms\tremaining: 3.39s\n",
      "115:\tlearn: 0.1193869\ttotal: 445ms\tremaining: 3.39s\n",
      "116:\tlearn: 0.1188819\ttotal: 450ms\tremaining: 3.39s\n",
      "117:\tlearn: 0.1183314\ttotal: 454ms\tremaining: 3.39s\n",
      "118:\tlearn: 0.1178887\ttotal: 458ms\tremaining: 3.39s\n",
      "119:\tlearn: 0.1173820\ttotal: 462ms\tremaining: 3.39s\n",
      "120:\tlearn: 0.1168575\ttotal: 468ms\tremaining: 3.4s\n",
      "121:\tlearn: 0.1164410\ttotal: 473ms\tremaining: 3.4s\n",
      "122:\tlearn: 0.1159549\ttotal: 477ms\tremaining: 3.4s\n",
      "123:\tlearn: 0.1155747\ttotal: 482ms\tremaining: 3.4s\n",
      "124:\tlearn: 0.1152369\ttotal: 485ms\tremaining: 3.4s\n",
      "125:\tlearn: 0.1148204\ttotal: 489ms\tremaining: 3.39s\n",
      "126:\tlearn: 0.1144061\ttotal: 494ms\tremaining: 3.39s\n",
      "127:\tlearn: 0.1140024\ttotal: 498ms\tremaining: 3.39s\n",
      "128:\tlearn: 0.1136190\ttotal: 502ms\tremaining: 3.39s\n",
      "129:\tlearn: 0.1133412\ttotal: 506ms\tremaining: 3.39s\n",
      "130:\tlearn: 0.1130359\ttotal: 509ms\tremaining: 3.38s\n",
      "131:\tlearn: 0.1124817\ttotal: 513ms\tremaining: 3.38s\n",
      "132:\tlearn: 0.1121894\ttotal: 517ms\tremaining: 3.37s\n",
      "133:\tlearn: 0.1118373\ttotal: 520ms\tremaining: 3.36s\n",
      "134:\tlearn: 0.1114620\ttotal: 524ms\tremaining: 3.36s\n",
      "135:\tlearn: 0.1110770\ttotal: 528ms\tremaining: 3.35s\n",
      "136:\tlearn: 0.1106864\ttotal: 531ms\tremaining: 3.35s\n",
      "137:\tlearn: 0.1102974\ttotal: 535ms\tremaining: 3.34s\n",
      "138:\tlearn: 0.1099927\ttotal: 539ms\tremaining: 3.34s\n",
      "139:\tlearn: 0.1098036\ttotal: 542ms\tremaining: 3.33s\n",
      "140:\tlearn: 0.1093715\ttotal: 546ms\tremaining: 3.33s\n",
      "141:\tlearn: 0.1088225\ttotal: 550ms\tremaining: 3.32s\n",
      "142:\tlearn: 0.1083640\ttotal: 554ms\tremaining: 3.32s\n",
      "143:\tlearn: 0.1080132\ttotal: 558ms\tremaining: 3.32s\n",
      "144:\tlearn: 0.1077826\ttotal: 562ms\tremaining: 3.31s\n",
      "145:\tlearn: 0.1074433\ttotal: 566ms\tremaining: 3.31s\n",
      "146:\tlearn: 0.1071802\ttotal: 570ms\tremaining: 3.31s\n",
      "147:\tlearn: 0.1068702\ttotal: 573ms\tremaining: 3.3s\n",
      "148:\tlearn: 0.1066439\ttotal: 577ms\tremaining: 3.3s\n",
      "149:\tlearn: 0.1062970\ttotal: 581ms\tremaining: 3.29s\n",
      "150:\tlearn: 0.1059900\ttotal: 585ms\tremaining: 3.29s\n",
      "151:\tlearn: 0.1057279\ttotal: 588ms\tremaining: 3.28s\n",
      "152:\tlearn: 0.1054403\ttotal: 592ms\tremaining: 3.28s\n",
      "153:\tlearn: 0.1051263\ttotal: 595ms\tremaining: 3.27s\n",
      "154:\tlearn: 0.1048698\ttotal: 599ms\tremaining: 3.27s\n",
      "155:\tlearn: 0.1045686\ttotal: 603ms\tremaining: 3.26s\n",
      "156:\tlearn: 0.1042842\ttotal: 606ms\tremaining: 3.25s\n",
      "157:\tlearn: 0.1039731\ttotal: 610ms\tremaining: 3.25s\n",
      "158:\tlearn: 0.1036662\ttotal: 613ms\tremaining: 3.24s\n",
      "159:\tlearn: 0.1034185\ttotal: 617ms\tremaining: 3.24s\n",
      "160:\tlearn: 0.1030617\ttotal: 621ms\tremaining: 3.23s\n",
      "161:\tlearn: 0.1027381\ttotal: 624ms\tremaining: 3.23s\n",
      "162:\tlearn: 0.1025248\ttotal: 628ms\tremaining: 3.22s\n",
      "163:\tlearn: 0.1022738\ttotal: 631ms\tremaining: 3.22s\n",
      "164:\tlearn: 0.1019244\ttotal: 635ms\tremaining: 3.21s\n",
      "165:\tlearn: 0.1016209\ttotal: 638ms\tremaining: 3.21s\n",
      "166:\tlearn: 0.1012506\ttotal: 642ms\tremaining: 3.2s\n",
      "167:\tlearn: 0.1010010\ttotal: 645ms\tremaining: 3.19s\n",
      "168:\tlearn: 0.1006881\ttotal: 648ms\tremaining: 3.19s\n",
      "169:\tlearn: 0.1003659\ttotal: 652ms\tremaining: 3.18s\n",
      "170:\tlearn: 0.1001637\ttotal: 655ms\tremaining: 3.18s\n",
      "171:\tlearn: 0.0998564\ttotal: 659ms\tremaining: 3.17s\n",
      "172:\tlearn: 0.0995981\ttotal: 663ms\tremaining: 3.17s\n",
      "173:\tlearn: 0.0993230\ttotal: 666ms\tremaining: 3.16s\n",
      "174:\tlearn: 0.0989492\ttotal: 670ms\tremaining: 3.16s\n",
      "175:\tlearn: 0.0987376\ttotal: 674ms\tremaining: 3.15s\n",
      "176:\tlearn: 0.0983609\ttotal: 678ms\tremaining: 3.15s\n",
      "177:\tlearn: 0.0982156\ttotal: 682ms\tremaining: 3.15s\n",
      "178:\tlearn: 0.0981121\ttotal: 686ms\tremaining: 3.14s\n",
      "179:\tlearn: 0.0978710\ttotal: 689ms\tremaining: 3.14s\n",
      "180:\tlearn: 0.0976764\ttotal: 693ms\tremaining: 3.14s\n",
      "181:\tlearn: 0.0974117\ttotal: 697ms\tremaining: 3.13s\n",
      "182:\tlearn: 0.0970096\ttotal: 700ms\tremaining: 3.13s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "183:\tlearn: 0.0966288\ttotal: 704ms\tremaining: 3.12s\n",
      "184:\tlearn: 0.0963632\ttotal: 708ms\tremaining: 3.12s\n",
      "185:\tlearn: 0.0961238\ttotal: 711ms\tremaining: 3.11s\n",
      "186:\tlearn: 0.0959384\ttotal: 715ms\tremaining: 3.11s\n",
      "187:\tlearn: 0.0955886\ttotal: 719ms\tremaining: 3.1s\n",
      "188:\tlearn: 0.0952518\ttotal: 723ms\tremaining: 3.1s\n",
      "189:\tlearn: 0.0949898\ttotal: 727ms\tremaining: 3.1s\n",
      "190:\tlearn: 0.0946942\ttotal: 731ms\tremaining: 3.1s\n",
      "191:\tlearn: 0.0944632\ttotal: 735ms\tremaining: 3.09s\n",
      "192:\tlearn: 0.0942722\ttotal: 738ms\tremaining: 3.09s\n",
      "193:\tlearn: 0.0941329\ttotal: 742ms\tremaining: 3.08s\n",
      "194:\tlearn: 0.0939351\ttotal: 746ms\tremaining: 3.08s\n",
      "195:\tlearn: 0.0936723\ttotal: 750ms\tremaining: 3.07s\n",
      "196:\tlearn: 0.0935145\ttotal: 754ms\tremaining: 3.07s\n",
      "197:\tlearn: 0.0933751\ttotal: 757ms\tremaining: 3.07s\n",
      "198:\tlearn: 0.0931808\ttotal: 761ms\tremaining: 3.06s\n",
      "199:\tlearn: 0.0930101\ttotal: 764ms\tremaining: 3.06s\n",
      "200:\tlearn: 0.0928573\ttotal: 768ms\tremaining: 3.05s\n",
      "201:\tlearn: 0.0926201\ttotal: 771ms\tremaining: 3.05s\n",
      "202:\tlearn: 0.0924778\ttotal: 774ms\tremaining: 3.04s\n",
      "203:\tlearn: 0.0923473\ttotal: 778ms\tremaining: 3.04s\n",
      "204:\tlearn: 0.0921696\ttotal: 782ms\tremaining: 3.03s\n",
      "205:\tlearn: 0.0918734\ttotal: 786ms\tremaining: 3.03s\n",
      "206:\tlearn: 0.0916315\ttotal: 789ms\tremaining: 3.02s\n",
      "207:\tlearn: 0.0914430\ttotal: 793ms\tremaining: 3.02s\n",
      "208:\tlearn: 0.0911923\ttotal: 797ms\tremaining: 3.01s\n",
      "209:\tlearn: 0.0910092\ttotal: 800ms\tremaining: 3.01s\n",
      "210:\tlearn: 0.0908568\ttotal: 803ms\tremaining: 3s\n",
      "211:\tlearn: 0.0907354\ttotal: 807ms\tremaining: 3s\n",
      "212:\tlearn: 0.0905455\ttotal: 811ms\tremaining: 3s\n",
      "213:\tlearn: 0.0903845\ttotal: 814ms\tremaining: 2.99s\n",
      "214:\tlearn: 0.0902239\ttotal: 818ms\tremaining: 2.99s\n",
      "215:\tlearn: 0.0900862\ttotal: 822ms\tremaining: 2.98s\n",
      "216:\tlearn: 0.0898711\ttotal: 826ms\tremaining: 2.98s\n",
      "217:\tlearn: 0.0897601\ttotal: 829ms\tremaining: 2.97s\n",
      "218:\tlearn: 0.0895312\ttotal: 832ms\tremaining: 2.97s\n",
      "219:\tlearn: 0.0893825\ttotal: 836ms\tremaining: 2.96s\n",
      "220:\tlearn: 0.0891577\ttotal: 840ms\tremaining: 2.96s\n",
      "221:\tlearn: 0.0889808\ttotal: 843ms\tremaining: 2.96s\n",
      "222:\tlearn: 0.0887660\ttotal: 847ms\tremaining: 2.95s\n",
      "223:\tlearn: 0.0885192\ttotal: 851ms\tremaining: 2.95s\n",
      "224:\tlearn: 0.0884019\ttotal: 854ms\tremaining: 2.94s\n",
      "225:\tlearn: 0.0881617\ttotal: 858ms\tremaining: 2.94s\n",
      "226:\tlearn: 0.0879071\ttotal: 862ms\tremaining: 2.94s\n",
      "227:\tlearn: 0.0877216\ttotal: 866ms\tremaining: 2.93s\n",
      "228:\tlearn: 0.0875404\ttotal: 870ms\tremaining: 2.93s\n",
      "229:\tlearn: 0.0872158\ttotal: 874ms\tremaining: 2.93s\n",
      "230:\tlearn: 0.0871074\ttotal: 878ms\tremaining: 2.92s\n",
      "231:\tlearn: 0.0869725\ttotal: 882ms\tremaining: 2.92s\n",
      "232:\tlearn: 0.0867236\ttotal: 886ms\tremaining: 2.92s\n",
      "233:\tlearn: 0.0865916\ttotal: 890ms\tremaining: 2.91s\n",
      "234:\tlearn: 0.0863854\ttotal: 894ms\tremaining: 2.91s\n",
      "235:\tlearn: 0.0862032\ttotal: 897ms\tremaining: 2.9s\n",
      "236:\tlearn: 0.0859731\ttotal: 901ms\tremaining: 2.9s\n",
      "237:\tlearn: 0.0857413\ttotal: 906ms\tremaining: 2.9s\n",
      "238:\tlearn: 0.0856049\ttotal: 910ms\tremaining: 2.9s\n",
      "239:\tlearn: 0.0854276\ttotal: 914ms\tremaining: 2.89s\n",
      "240:\tlearn: 0.0853538\ttotal: 918ms\tremaining: 2.89s\n",
      "241:\tlearn: 0.0851766\ttotal: 922ms\tremaining: 2.89s\n",
      "242:\tlearn: 0.0850499\ttotal: 925ms\tremaining: 2.88s\n",
      "243:\tlearn: 0.0848678\ttotal: 929ms\tremaining: 2.88s\n",
      "244:\tlearn: 0.0847577\ttotal: 932ms\tremaining: 2.87s\n",
      "245:\tlearn: 0.0846576\ttotal: 936ms\tremaining: 2.87s\n",
      "246:\tlearn: 0.0844876\ttotal: 940ms\tremaining: 2.87s\n",
      "247:\tlearn: 0.0843528\ttotal: 943ms\tremaining: 2.86s\n",
      "248:\tlearn: 0.0841414\ttotal: 947ms\tremaining: 2.86s\n",
      "249:\tlearn: 0.0838881\ttotal: 951ms\tremaining: 2.85s\n",
      "250:\tlearn: 0.0837594\ttotal: 955ms\tremaining: 2.85s\n",
      "251:\tlearn: 0.0836485\ttotal: 959ms\tremaining: 2.85s\n",
      "252:\tlearn: 0.0835874\ttotal: 962ms\tremaining: 2.84s\n",
      "253:\tlearn: 0.0834431\ttotal: 966ms\tremaining: 2.84s\n",
      "254:\tlearn: 0.0833310\ttotal: 969ms\tremaining: 2.83s\n",
      "255:\tlearn: 0.0831971\ttotal: 973ms\tremaining: 2.83s\n",
      "256:\tlearn: 0.0830725\ttotal: 976ms\tremaining: 2.82s\n",
      "257:\tlearn: 0.0829034\ttotal: 980ms\tremaining: 2.82s\n",
      "258:\tlearn: 0.0827788\ttotal: 984ms\tremaining: 2.81s\n",
      "259:\tlearn: 0.0825953\ttotal: 987ms\tremaining: 2.81s\n",
      "260:\tlearn: 0.0824329\ttotal: 991ms\tremaining: 2.81s\n",
      "261:\tlearn: 0.0823094\ttotal: 995ms\tremaining: 2.8s\n",
      "262:\tlearn: 0.0821818\ttotal: 1000ms\tremaining: 2.8s\n",
      "263:\tlearn: 0.0820353\ttotal: 1s\tremaining: 2.8s\n",
      "264:\tlearn: 0.0819503\ttotal: 1.01s\tremaining: 2.79s\n",
      "265:\tlearn: 0.0818030\ttotal: 1.01s\tremaining: 2.79s\n",
      "266:\tlearn: 0.0817366\ttotal: 1.01s\tremaining: 2.79s\n",
      "267:\tlearn: 0.0815247\ttotal: 1.02s\tremaining: 2.78s\n",
      "268:\tlearn: 0.0813887\ttotal: 1.02s\tremaining: 2.77s\n",
      "269:\tlearn: 0.0812850\ttotal: 1.02s\tremaining: 2.77s\n",
      "270:\tlearn: 0.0812347\ttotal: 1.03s\tremaining: 2.77s\n",
      "271:\tlearn: 0.0810628\ttotal: 1.03s\tremaining: 2.76s\n",
      "272:\tlearn: 0.0810273\ttotal: 1.03s\tremaining: 2.76s\n",
      "273:\tlearn: 0.0808589\ttotal: 1.04s\tremaining: 2.75s\n",
      "274:\tlearn: 0.0806918\ttotal: 1.04s\tremaining: 2.75s\n",
      "275:\tlearn: 0.0805885\ttotal: 1.04s\tremaining: 2.74s\n",
      "276:\tlearn: 0.0805151\ttotal: 1.05s\tremaining: 2.74s\n",
      "277:\tlearn: 0.0804336\ttotal: 1.05s\tremaining: 2.73s\n",
      "278:\tlearn: 0.0803118\ttotal: 1.06s\tremaining: 2.73s\n",
      "279:\tlearn: 0.0801285\ttotal: 1.06s\tremaining: 2.73s\n",
      "280:\tlearn: 0.0799648\ttotal: 1.06s\tremaining: 2.73s\n",
      "281:\tlearn: 0.0798823\ttotal: 1.07s\tremaining: 2.72s\n",
      "282:\tlearn: 0.0797151\ttotal: 1.07s\tremaining: 2.72s\n",
      "283:\tlearn: 0.0795665\ttotal: 1.08s\tremaining: 2.71s\n",
      "284:\tlearn: 0.0794776\ttotal: 1.08s\tremaining: 2.71s\n",
      "285:\tlearn: 0.0793972\ttotal: 1.08s\tremaining: 2.71s\n",
      "286:\tlearn: 0.0792728\ttotal: 1.09s\tremaining: 2.7s\n",
      "287:\tlearn: 0.0790910\ttotal: 1.09s\tremaining: 2.7s\n",
      "288:\tlearn: 0.0789475\ttotal: 1.09s\tremaining: 2.69s\n",
      "289:\tlearn: 0.0787258\ttotal: 1.1s\tremaining: 2.69s\n",
      "290:\tlearn: 0.0786026\ttotal: 1.1s\tremaining: 2.69s\n",
      "291:\tlearn: 0.0784559\ttotal: 1.11s\tremaining: 2.68s\n",
      "292:\tlearn: 0.0783025\ttotal: 1.11s\tremaining: 2.68s\n",
      "293:\tlearn: 0.0781964\ttotal: 1.11s\tremaining: 2.67s\n",
      "294:\tlearn: 0.0781271\ttotal: 1.12s\tremaining: 2.67s\n",
      "295:\tlearn: 0.0780153\ttotal: 1.12s\tremaining: 2.67s\n",
      "296:\tlearn: 0.0778567\ttotal: 1.13s\tremaining: 2.67s\n",
      "297:\tlearn: 0.0777506\ttotal: 1.13s\tremaining: 2.66s\n",
      "298:\tlearn: 0.0776134\ttotal: 1.13s\tremaining: 2.66s\n",
      "299:\tlearn: 0.0775308\ttotal: 1.14s\tremaining: 2.65s\n",
      "300:\tlearn: 0.0774709\ttotal: 1.14s\tremaining: 2.65s\n",
      "301:\tlearn: 0.0773903\ttotal: 1.14s\tremaining: 2.65s\n",
      "302:\tlearn: 0.0772161\ttotal: 1.15s\tremaining: 2.64s\n",
      "303:\tlearn: 0.0771375\ttotal: 1.15s\tremaining: 2.64s\n",
      "304:\tlearn: 0.0770439\ttotal: 1.16s\tremaining: 2.63s\n",
      "305:\tlearn: 0.0769697\ttotal: 1.16s\tremaining: 2.63s\n",
      "306:\tlearn: 0.0768383\ttotal: 1.16s\tremaining: 2.62s\n",
      "307:\tlearn: 0.0767226\ttotal: 1.17s\tremaining: 2.62s\n",
      "308:\tlearn: 0.0765935\ttotal: 1.17s\tremaining: 2.62s\n",
      "309:\tlearn: 0.0764556\ttotal: 1.17s\tremaining: 2.61s\n",
      "310:\tlearn: 0.0763186\ttotal: 1.18s\tremaining: 2.61s\n",
      "311:\tlearn: 0.0761912\ttotal: 1.18s\tremaining: 2.6s\n",
      "312:\tlearn: 0.0761103\ttotal: 1.18s\tremaining: 2.6s\n",
      "313:\tlearn: 0.0759302\ttotal: 1.19s\tremaining: 2.59s\n",
      "314:\tlearn: 0.0757223\ttotal: 1.19s\tremaining: 2.59s\n",
      "315:\tlearn: 0.0756109\ttotal: 1.19s\tremaining: 2.58s\n",
      "316:\tlearn: 0.0754619\ttotal: 1.2s\tremaining: 2.58s\n",
      "317:\tlearn: 0.0752847\ttotal: 1.2s\tremaining: 2.58s\n",
      "318:\tlearn: 0.0752218\ttotal: 1.21s\tremaining: 2.57s\n",
      "319:\tlearn: 0.0751113\ttotal: 1.21s\tremaining: 2.57s\n",
      "320:\tlearn: 0.0749606\ttotal: 1.21s\tremaining: 2.56s\n",
      "321:\tlearn: 0.0748547\ttotal: 1.22s\tremaining: 2.56s\n",
      "322:\tlearn: 0.0747314\ttotal: 1.22s\tremaining: 2.55s\n",
      "323:\tlearn: 0.0745987\ttotal: 1.22s\tremaining: 2.55s\n",
      "324:\tlearn: 0.0744366\ttotal: 1.23s\tremaining: 2.54s\n",
      "325:\tlearn: 0.0742053\ttotal: 1.23s\tremaining: 2.54s\n",
      "326:\tlearn: 0.0740807\ttotal: 1.23s\tremaining: 2.54s\n",
      "327:\tlearn: 0.0739946\ttotal: 1.24s\tremaining: 2.54s\n",
      "328:\tlearn: 0.0738218\ttotal: 1.24s\tremaining: 2.53s\n",
      "329:\tlearn: 0.0737168\ttotal: 1.25s\tremaining: 2.53s\n",
      "330:\tlearn: 0.0736147\ttotal: 1.25s\tremaining: 2.53s\n",
      "331:\tlearn: 0.0734928\ttotal: 1.25s\tremaining: 2.52s\n",
      "332:\tlearn: 0.0733324\ttotal: 1.26s\tremaining: 2.52s\n",
      "333:\tlearn: 0.0732394\ttotal: 1.26s\tremaining: 2.52s\n",
      "334:\tlearn: 0.0731770\ttotal: 1.27s\tremaining: 2.52s\n",
      "335:\tlearn: 0.0730374\ttotal: 1.27s\tremaining: 2.51s\n",
      "336:\tlearn: 0.0729434\ttotal: 1.27s\tremaining: 2.51s\n",
      "337:\tlearn: 0.0728679\ttotal: 1.28s\tremaining: 2.5s\n",
      "338:\tlearn: 0.0728202\ttotal: 1.28s\tremaining: 2.5s\n",
      "339:\tlearn: 0.0726921\ttotal: 1.28s\tremaining: 2.5s\n",
      "340:\tlearn: 0.0725427\ttotal: 1.29s\tremaining: 2.49s\n",
      "341:\tlearn: 0.0724787\ttotal: 1.29s\tremaining: 2.49s\n",
      "342:\tlearn: 0.0723772\ttotal: 1.3s\tremaining: 2.48s\n",
      "343:\tlearn: 0.0722658\ttotal: 1.3s\tremaining: 2.48s\n",
      "344:\tlearn: 0.0722138\ttotal: 1.3s\tremaining: 2.48s\n",
      "345:\tlearn: 0.0721485\ttotal: 1.31s\tremaining: 2.47s\n",
      "346:\tlearn: 0.0720567\ttotal: 1.31s\tremaining: 2.47s\n",
      "347:\tlearn: 0.0718342\ttotal: 1.31s\tremaining: 2.46s\n",
      "348:\tlearn: 0.0716954\ttotal: 1.32s\tremaining: 2.46s\n",
      "349:\tlearn: 0.0715448\ttotal: 1.32s\tremaining: 2.46s\n",
      "350:\tlearn: 0.0714046\ttotal: 1.32s\tremaining: 2.45s\n",
      "351:\tlearn: 0.0712971\ttotal: 1.33s\tremaining: 2.45s\n",
      "352:\tlearn: 0.0712061\ttotal: 1.33s\tremaining: 2.44s\n",
      "353:\tlearn: 0.0710992\ttotal: 1.34s\tremaining: 2.44s\n",
      "354:\tlearn: 0.0709861\ttotal: 1.34s\tremaining: 2.44s\n",
      "355:\tlearn: 0.0708217\ttotal: 1.34s\tremaining: 2.43s\n",
      "356:\tlearn: 0.0707576\ttotal: 1.35s\tremaining: 2.43s\n",
      "357:\tlearn: 0.0707021\ttotal: 1.35s\tremaining: 2.43s\n",
      "358:\tlearn: 0.0706280\ttotal: 1.36s\tremaining: 2.43s\n",
      "359:\tlearn: 0.0704916\ttotal: 1.36s\tremaining: 2.42s\n",
      "360:\tlearn: 0.0703800\ttotal: 1.37s\tremaining: 2.42s\n",
      "361:\tlearn: 0.0702710\ttotal: 1.37s\tremaining: 2.42s\n",
      "362:\tlearn: 0.0701377\ttotal: 1.38s\tremaining: 2.41s\n",
      "363:\tlearn: 0.0700481\ttotal: 1.38s\tremaining: 2.41s\n",
      "364:\tlearn: 0.0699548\ttotal: 1.38s\tremaining: 2.41s\n",
      "365:\tlearn: 0.0698716\ttotal: 1.39s\tremaining: 2.4s\n",
      "366:\tlearn: 0.0697610\ttotal: 1.39s\tremaining: 2.4s\n",
      "367:\tlearn: 0.0697137\ttotal: 1.39s\tremaining: 2.39s\n",
      "368:\tlearn: 0.0695768\ttotal: 1.4s\tremaining: 2.39s\n",
      "369:\tlearn: 0.0694322\ttotal: 1.4s\tremaining: 2.38s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "370:\tlearn: 0.0692387\ttotal: 1.41s\tremaining: 2.38s\n",
      "371:\tlearn: 0.0691115\ttotal: 1.41s\tremaining: 2.38s\n",
      "372:\tlearn: 0.0689861\ttotal: 1.41s\tremaining: 2.38s\n",
      "373:\tlearn: 0.0689115\ttotal: 1.42s\tremaining: 2.37s\n",
      "374:\tlearn: 0.0687987\ttotal: 1.42s\tremaining: 2.37s\n",
      "375:\tlearn: 0.0687586\ttotal: 1.43s\tremaining: 2.37s\n",
      "376:\tlearn: 0.0686626\ttotal: 1.43s\tremaining: 2.36s\n",
      "377:\tlearn: 0.0685977\ttotal: 1.43s\tremaining: 2.36s\n",
      "378:\tlearn: 0.0685132\ttotal: 1.44s\tremaining: 2.35s\n",
      "379:\tlearn: 0.0684288\ttotal: 1.44s\tremaining: 2.35s\n",
      "380:\tlearn: 0.0683609\ttotal: 1.45s\tremaining: 2.35s\n",
      "381:\tlearn: 0.0683030\ttotal: 1.45s\tremaining: 2.35s\n",
      "382:\tlearn: 0.0681584\ttotal: 1.46s\tremaining: 2.34s\n",
      "383:\tlearn: 0.0680869\ttotal: 1.46s\tremaining: 2.34s\n",
      "384:\tlearn: 0.0679924\ttotal: 1.46s\tremaining: 2.34s\n",
      "385:\tlearn: 0.0678501\ttotal: 1.47s\tremaining: 2.33s\n",
      "386:\tlearn: 0.0677081\ttotal: 1.47s\tremaining: 2.33s\n",
      "387:\tlearn: 0.0675966\ttotal: 1.48s\tremaining: 2.33s\n",
      "388:\tlearn: 0.0674601\ttotal: 1.48s\tremaining: 2.32s\n",
      "389:\tlearn: 0.0673672\ttotal: 1.48s\tremaining: 2.32s\n",
      "390:\tlearn: 0.0673299\ttotal: 1.49s\tremaining: 2.32s\n",
      "391:\tlearn: 0.0672341\ttotal: 1.49s\tremaining: 2.31s\n",
      "392:\tlearn: 0.0671378\ttotal: 1.5s\tremaining: 2.31s\n",
      "393:\tlearn: 0.0670633\ttotal: 1.5s\tremaining: 2.31s\n",
      "394:\tlearn: 0.0669707\ttotal: 1.5s\tremaining: 2.3s\n",
      "395:\tlearn: 0.0669032\ttotal: 1.51s\tremaining: 2.3s\n",
      "396:\tlearn: 0.0668273\ttotal: 1.51s\tremaining: 2.29s\n",
      "397:\tlearn: 0.0666803\ttotal: 1.51s\tremaining: 2.29s\n",
      "398:\tlearn: 0.0665906\ttotal: 1.52s\tremaining: 2.28s\n",
      "399:\tlearn: 0.0664210\ttotal: 1.52s\tremaining: 2.28s\n",
      "400:\tlearn: 0.0663376\ttotal: 1.52s\tremaining: 2.28s\n",
      "401:\tlearn: 0.0662448\ttotal: 1.53s\tremaining: 2.27s\n",
      "402:\tlearn: 0.0661799\ttotal: 1.53s\tremaining: 2.27s\n",
      "403:\tlearn: 0.0661152\ttotal: 1.53s\tremaining: 2.27s\n",
      "404:\tlearn: 0.0660225\ttotal: 1.54s\tremaining: 2.26s\n",
      "405:\tlearn: 0.0658934\ttotal: 1.54s\tremaining: 2.26s\n",
      "406:\tlearn: 0.0658324\ttotal: 1.55s\tremaining: 2.25s\n",
      "407:\tlearn: 0.0657168\ttotal: 1.55s\tremaining: 2.25s\n",
      "408:\tlearn: 0.0656846\ttotal: 1.55s\tremaining: 2.24s\n",
      "409:\tlearn: 0.0655771\ttotal: 1.56s\tremaining: 2.24s\n",
      "410:\tlearn: 0.0655288\ttotal: 1.56s\tremaining: 2.24s\n",
      "411:\tlearn: 0.0654266\ttotal: 1.56s\tremaining: 2.23s\n",
      "412:\tlearn: 0.0653182\ttotal: 1.57s\tremaining: 2.23s\n",
      "413:\tlearn: 0.0651693\ttotal: 1.57s\tremaining: 2.22s\n",
      "414:\tlearn: 0.0650762\ttotal: 1.57s\tremaining: 2.22s\n",
      "415:\tlearn: 0.0649099\ttotal: 1.58s\tremaining: 2.21s\n",
      "416:\tlearn: 0.0648250\ttotal: 1.58s\tremaining: 2.21s\n",
      "417:\tlearn: 0.0647826\ttotal: 1.59s\tremaining: 2.21s\n",
      "418:\tlearn: 0.0647051\ttotal: 1.59s\tremaining: 2.21s\n",
      "419:\tlearn: 0.0646261\ttotal: 1.59s\tremaining: 2.2s\n",
      "420:\tlearn: 0.0645498\ttotal: 1.6s\tremaining: 2.2s\n",
      "421:\tlearn: 0.0644254\ttotal: 1.6s\tremaining: 2.19s\n",
      "422:\tlearn: 0.0642635\ttotal: 1.6s\tremaining: 2.19s\n",
      "423:\tlearn: 0.0641749\ttotal: 1.61s\tremaining: 2.19s\n",
      "424:\tlearn: 0.0641037\ttotal: 1.61s\tremaining: 2.18s\n",
      "425:\tlearn: 0.0640453\ttotal: 1.62s\tremaining: 2.18s\n",
      "426:\tlearn: 0.0639258\ttotal: 1.62s\tremaining: 2.17s\n",
      "427:\tlearn: 0.0638500\ttotal: 1.63s\tremaining: 2.17s\n",
      "428:\tlearn: 0.0637733\ttotal: 1.63s\tremaining: 2.17s\n",
      "429:\tlearn: 0.0636225\ttotal: 1.63s\tremaining: 2.16s\n",
      "430:\tlearn: 0.0635838\ttotal: 1.64s\tremaining: 2.16s\n",
      "431:\tlearn: 0.0635112\ttotal: 1.64s\tremaining: 2.16s\n",
      "432:\tlearn: 0.0634569\ttotal: 1.64s\tremaining: 2.15s\n",
      "433:\tlearn: 0.0633532\ttotal: 1.65s\tremaining: 2.15s\n",
      "434:\tlearn: 0.0632637\ttotal: 1.65s\tremaining: 2.14s\n",
      "435:\tlearn: 0.0631890\ttotal: 1.65s\tremaining: 2.14s\n",
      "436:\tlearn: 0.0631214\ttotal: 1.66s\tremaining: 2.14s\n",
      "437:\tlearn: 0.0630430\ttotal: 1.66s\tremaining: 2.13s\n",
      "438:\tlearn: 0.0629860\ttotal: 1.67s\tremaining: 2.13s\n",
      "439:\tlearn: 0.0629331\ttotal: 1.67s\tremaining: 2.12s\n",
      "440:\tlearn: 0.0628495\ttotal: 1.67s\tremaining: 2.12s\n",
      "441:\tlearn: 0.0628203\ttotal: 1.68s\tremaining: 2.12s\n",
      "442:\tlearn: 0.0627581\ttotal: 1.68s\tremaining: 2.11s\n",
      "443:\tlearn: 0.0626574\ttotal: 1.68s\tremaining: 2.11s\n",
      "444:\tlearn: 0.0625022\ttotal: 1.69s\tremaining: 2.1s\n",
      "445:\tlearn: 0.0623912\ttotal: 1.69s\tremaining: 2.1s\n",
      "446:\tlearn: 0.0623545\ttotal: 1.69s\tremaining: 2.1s\n",
      "447:\tlearn: 0.0622886\ttotal: 1.7s\tremaining: 2.09s\n",
      "448:\tlearn: 0.0621914\ttotal: 1.7s\tremaining: 2.09s\n",
      "449:\tlearn: 0.0620880\ttotal: 1.71s\tremaining: 2.08s\n",
      "450:\tlearn: 0.0620042\ttotal: 1.71s\tremaining: 2.08s\n",
      "451:\tlearn: 0.0619067\ttotal: 1.71s\tremaining: 2.08s\n",
      "452:\tlearn: 0.0618146\ttotal: 1.72s\tremaining: 2.07s\n",
      "453:\tlearn: 0.0617523\ttotal: 1.72s\tremaining: 2.07s\n",
      "454:\tlearn: 0.0616352\ttotal: 1.72s\tremaining: 2.06s\n",
      "455:\tlearn: 0.0615654\ttotal: 1.73s\tremaining: 2.06s\n",
      "456:\tlearn: 0.0615488\ttotal: 1.73s\tremaining: 2.06s\n",
      "457:\tlearn: 0.0614535\ttotal: 1.74s\tremaining: 2.05s\n",
      "458:\tlearn: 0.0613531\ttotal: 1.74s\tremaining: 2.05s\n",
      "459:\tlearn: 0.0612679\ttotal: 1.74s\tremaining: 2.04s\n",
      "460:\tlearn: 0.0612009\ttotal: 1.75s\tremaining: 2.04s\n",
      "461:\tlearn: 0.0610624\ttotal: 1.75s\tremaining: 2.04s\n",
      "462:\tlearn: 0.0610070\ttotal: 1.75s\tremaining: 2.03s\n",
      "463:\tlearn: 0.0609584\ttotal: 1.76s\tremaining: 2.03s\n",
      "464:\tlearn: 0.0609055\ttotal: 1.76s\tremaining: 2.03s\n",
      "465:\tlearn: 0.0608280\ttotal: 1.76s\tremaining: 2.02s\n",
      "466:\tlearn: 0.0607195\ttotal: 1.77s\tremaining: 2.02s\n",
      "467:\tlearn: 0.0606387\ttotal: 1.77s\tremaining: 2.02s\n",
      "468:\tlearn: 0.0605527\ttotal: 1.78s\tremaining: 2.01s\n",
      "469:\tlearn: 0.0605007\ttotal: 1.78s\tremaining: 2.01s\n",
      "470:\tlearn: 0.0604448\ttotal: 1.78s\tremaining: 2s\n",
      "471:\tlearn: 0.0603517\ttotal: 1.79s\tremaining: 2s\n",
      "472:\tlearn: 0.0602664\ttotal: 1.79s\tremaining: 2s\n",
      "473:\tlearn: 0.0601785\ttotal: 1.79s\tremaining: 1.99s\n",
      "474:\tlearn: 0.0601187\ttotal: 1.8s\tremaining: 1.99s\n",
      "475:\tlearn: 0.0600200\ttotal: 1.8s\tremaining: 1.98s\n",
      "476:\tlearn: 0.0599843\ttotal: 1.8s\tremaining: 1.98s\n",
      "477:\tlearn: 0.0598916\ttotal: 1.81s\tremaining: 1.98s\n",
      "478:\tlearn: 0.0598257\ttotal: 1.81s\tremaining: 1.97s\n",
      "479:\tlearn: 0.0597900\ttotal: 1.82s\tremaining: 1.97s\n",
      "480:\tlearn: 0.0597061\ttotal: 1.82s\tremaining: 1.96s\n",
      "481:\tlearn: 0.0596437\ttotal: 1.82s\tremaining: 1.96s\n",
      "482:\tlearn: 0.0595640\ttotal: 1.83s\tremaining: 1.96s\n",
      "483:\tlearn: 0.0594726\ttotal: 1.83s\tremaining: 1.95s\n",
      "484:\tlearn: 0.0593813\ttotal: 1.83s\tremaining: 1.95s\n",
      "485:\tlearn: 0.0592860\ttotal: 1.84s\tremaining: 1.94s\n",
      "486:\tlearn: 0.0591586\ttotal: 1.84s\tremaining: 1.94s\n",
      "487:\tlearn: 0.0590817\ttotal: 1.84s\tremaining: 1.94s\n",
      "488:\tlearn: 0.0589976\ttotal: 1.85s\tremaining: 1.93s\n",
      "489:\tlearn: 0.0589579\ttotal: 1.85s\tremaining: 1.93s\n",
      "490:\tlearn: 0.0588585\ttotal: 1.86s\tremaining: 1.93s\n",
      "491:\tlearn: 0.0587593\ttotal: 1.86s\tremaining: 1.92s\n",
      "492:\tlearn: 0.0586877\ttotal: 1.86s\tremaining: 1.92s\n",
      "493:\tlearn: 0.0585965\ttotal: 1.87s\tremaining: 1.91s\n",
      "494:\tlearn: 0.0585056\ttotal: 1.87s\tremaining: 1.91s\n",
      "495:\tlearn: 0.0584423\ttotal: 1.88s\tremaining: 1.91s\n",
      "496:\tlearn: 0.0583506\ttotal: 1.88s\tremaining: 1.9s\n",
      "497:\tlearn: 0.0583132\ttotal: 1.88s\tremaining: 1.9s\n",
      "498:\tlearn: 0.0582600\ttotal: 1.89s\tremaining: 1.9s\n",
      "499:\tlearn: 0.0582287\ttotal: 1.89s\tremaining: 1.89s\n",
      "500:\tlearn: 0.0581958\ttotal: 1.89s\tremaining: 1.89s\n",
      "501:\tlearn: 0.0580645\ttotal: 1.9s\tremaining: 1.88s\n",
      "502:\tlearn: 0.0579966\ttotal: 1.9s\tremaining: 1.88s\n",
      "503:\tlearn: 0.0579208\ttotal: 1.91s\tremaining: 1.88s\n",
      "504:\tlearn: 0.0578587\ttotal: 1.91s\tremaining: 1.87s\n",
      "505:\tlearn: 0.0577832\ttotal: 1.91s\tremaining: 1.87s\n",
      "506:\tlearn: 0.0577210\ttotal: 1.92s\tremaining: 1.86s\n",
      "507:\tlearn: 0.0576136\ttotal: 1.92s\tremaining: 1.86s\n",
      "508:\tlearn: 0.0575943\ttotal: 1.92s\tremaining: 1.85s\n",
      "509:\tlearn: 0.0575516\ttotal: 1.93s\tremaining: 1.85s\n",
      "510:\tlearn: 0.0574473\ttotal: 1.93s\tremaining: 1.85s\n",
      "511:\tlearn: 0.0573969\ttotal: 1.94s\tremaining: 1.84s\n",
      "512:\tlearn: 0.0573607\ttotal: 1.94s\tremaining: 1.84s\n",
      "513:\tlearn: 0.0573135\ttotal: 1.94s\tremaining: 1.84s\n",
      "514:\tlearn: 0.0572767\ttotal: 1.95s\tremaining: 1.83s\n",
      "515:\tlearn: 0.0571444\ttotal: 1.95s\tremaining: 1.83s\n",
      "516:\tlearn: 0.0570900\ttotal: 1.96s\tremaining: 1.83s\n",
      "517:\tlearn: 0.0570551\ttotal: 1.96s\tremaining: 1.82s\n",
      "518:\tlearn: 0.0570220\ttotal: 1.96s\tremaining: 1.82s\n",
      "519:\tlearn: 0.0569920\ttotal: 1.97s\tremaining: 1.81s\n",
      "520:\tlearn: 0.0569343\ttotal: 1.97s\tremaining: 1.81s\n",
      "521:\tlearn: 0.0568360\ttotal: 1.97s\tremaining: 1.81s\n",
      "522:\tlearn: 0.0567809\ttotal: 1.98s\tremaining: 1.8s\n",
      "523:\tlearn: 0.0567458\ttotal: 1.98s\tremaining: 1.8s\n",
      "524:\tlearn: 0.0566932\ttotal: 1.99s\tremaining: 1.8s\n",
      "525:\tlearn: 0.0566430\ttotal: 1.99s\tremaining: 1.79s\n",
      "526:\tlearn: 0.0565655\ttotal: 1.99s\tremaining: 1.79s\n",
      "527:\tlearn: 0.0565049\ttotal: 2s\tremaining: 1.78s\n",
      "528:\tlearn: 0.0564492\ttotal: 2s\tremaining: 1.78s\n",
      "529:\tlearn: 0.0563813\ttotal: 2s\tremaining: 1.78s\n",
      "530:\tlearn: 0.0563345\ttotal: 2.01s\tremaining: 1.77s\n",
      "531:\tlearn: 0.0562430\ttotal: 2.01s\tremaining: 1.77s\n",
      "532:\tlearn: 0.0561272\ttotal: 2.02s\tremaining: 1.76s\n",
      "533:\tlearn: 0.0561045\ttotal: 2.02s\tremaining: 1.76s\n",
      "534:\tlearn: 0.0560680\ttotal: 2.02s\tremaining: 1.76s\n",
      "535:\tlearn: 0.0559583\ttotal: 2.03s\tremaining: 1.75s\n",
      "536:\tlearn: 0.0558505\ttotal: 2.03s\tremaining: 1.75s\n",
      "537:\tlearn: 0.0558349\ttotal: 2.03s\tremaining: 1.75s\n",
      "538:\tlearn: 0.0557999\ttotal: 2.04s\tremaining: 1.74s\n",
      "539:\tlearn: 0.0556990\ttotal: 2.04s\tremaining: 1.74s\n",
      "540:\tlearn: 0.0556579\ttotal: 2.04s\tremaining: 1.74s\n",
      "541:\tlearn: 0.0556111\ttotal: 2.05s\tremaining: 1.73s\n",
      "542:\tlearn: 0.0555395\ttotal: 2.05s\tremaining: 1.73s\n",
      "543:\tlearn: 0.0554905\ttotal: 2.06s\tremaining: 1.72s\n",
      "544:\tlearn: 0.0554598\ttotal: 2.06s\tremaining: 1.72s\n",
      "545:\tlearn: 0.0554148\ttotal: 2.06s\tremaining: 1.72s\n",
      "546:\tlearn: 0.0553341\ttotal: 2.07s\tremaining: 1.71s\n",
      "547:\tlearn: 0.0553163\ttotal: 2.07s\tremaining: 1.71s\n",
      "548:\tlearn: 0.0552677\ttotal: 2.07s\tremaining: 1.7s\n",
      "549:\tlearn: 0.0552222\ttotal: 2.08s\tremaining: 1.7s\n",
      "550:\tlearn: 0.0551216\ttotal: 2.08s\tremaining: 1.7s\n",
      "551:\tlearn: 0.0550472\ttotal: 2.08s\tremaining: 1.69s\n",
      "552:\tlearn: 0.0549726\ttotal: 2.09s\tremaining: 1.69s\n",
      "553:\tlearn: 0.0549138\ttotal: 2.09s\tremaining: 1.69s\n",
      "554:\tlearn: 0.0548858\ttotal: 2.1s\tremaining: 1.68s\n",
      "555:\tlearn: 0.0548159\ttotal: 2.1s\tremaining: 1.68s\n",
      "556:\tlearn: 0.0546638\ttotal: 2.1s\tremaining: 1.67s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "557:\tlearn: 0.0546331\ttotal: 2.11s\tremaining: 1.67s\n",
      "558:\tlearn: 0.0545157\ttotal: 2.11s\tremaining: 1.67s\n",
      "559:\tlearn: 0.0544742\ttotal: 2.12s\tremaining: 1.66s\n",
      "560:\tlearn: 0.0544309\ttotal: 2.12s\tremaining: 1.66s\n",
      "561:\tlearn: 0.0543619\ttotal: 2.12s\tremaining: 1.66s\n",
      "562:\tlearn: 0.0543043\ttotal: 2.13s\tremaining: 1.65s\n",
      "563:\tlearn: 0.0542558\ttotal: 2.13s\tremaining: 1.65s\n",
      "564:\tlearn: 0.0541375\ttotal: 2.13s\tremaining: 1.64s\n",
      "565:\tlearn: 0.0540271\ttotal: 2.14s\tremaining: 1.64s\n",
      "566:\tlearn: 0.0539829\ttotal: 2.14s\tremaining: 1.64s\n",
      "567:\tlearn: 0.0539568\ttotal: 2.15s\tremaining: 1.63s\n",
      "568:\tlearn: 0.0539173\ttotal: 2.15s\tremaining: 1.63s\n",
      "569:\tlearn: 0.0538983\ttotal: 2.15s\tremaining: 1.62s\n",
      "570:\tlearn: 0.0538804\ttotal: 2.16s\tremaining: 1.62s\n",
      "571:\tlearn: 0.0538111\ttotal: 2.16s\tremaining: 1.62s\n",
      "572:\tlearn: 0.0537526\ttotal: 2.16s\tremaining: 1.61s\n",
      "573:\tlearn: 0.0537184\ttotal: 2.17s\tremaining: 1.61s\n",
      "574:\tlearn: 0.0536385\ttotal: 2.17s\tremaining: 1.6s\n",
      "575:\tlearn: 0.0535813\ttotal: 2.17s\tremaining: 1.6s\n",
      "576:\tlearn: 0.0534851\ttotal: 2.18s\tremaining: 1.6s\n",
      "577:\tlearn: 0.0533868\ttotal: 2.18s\tremaining: 1.59s\n",
      "578:\tlearn: 0.0533364\ttotal: 2.19s\tremaining: 1.59s\n",
      "579:\tlearn: 0.0532464\ttotal: 2.19s\tremaining: 1.59s\n",
      "580:\tlearn: 0.0531451\ttotal: 2.19s\tremaining: 1.58s\n",
      "581:\tlearn: 0.0531039\ttotal: 2.2s\tremaining: 1.58s\n",
      "582:\tlearn: 0.0530322\ttotal: 2.2s\tremaining: 1.57s\n",
      "583:\tlearn: 0.0529592\ttotal: 2.21s\tremaining: 1.57s\n",
      "584:\tlearn: 0.0529270\ttotal: 2.21s\tremaining: 1.57s\n",
      "585:\tlearn: 0.0528430\ttotal: 2.21s\tremaining: 1.56s\n",
      "586:\tlearn: 0.0527810\ttotal: 2.21s\tremaining: 1.56s\n",
      "587:\tlearn: 0.0527113\ttotal: 2.22s\tremaining: 1.55s\n",
      "588:\tlearn: 0.0526315\ttotal: 2.22s\tremaining: 1.55s\n",
      "589:\tlearn: 0.0525126\ttotal: 2.23s\tremaining: 1.55s\n",
      "590:\tlearn: 0.0524372\ttotal: 2.23s\tremaining: 1.54s\n",
      "591:\tlearn: 0.0523603\ttotal: 2.23s\tremaining: 1.54s\n",
      "592:\tlearn: 0.0523250\ttotal: 2.24s\tremaining: 1.54s\n",
      "593:\tlearn: 0.0522462\ttotal: 2.24s\tremaining: 1.53s\n",
      "594:\tlearn: 0.0521808\ttotal: 2.25s\tremaining: 1.53s\n",
      "595:\tlearn: 0.0520990\ttotal: 2.25s\tremaining: 1.52s\n",
      "596:\tlearn: 0.0520685\ttotal: 2.25s\tremaining: 1.52s\n",
      "597:\tlearn: 0.0520334\ttotal: 2.26s\tremaining: 1.52s\n",
      "598:\tlearn: 0.0519912\ttotal: 2.26s\tremaining: 1.51s\n",
      "599:\tlearn: 0.0519295\ttotal: 2.27s\tremaining: 1.51s\n",
      "600:\tlearn: 0.0519019\ttotal: 2.27s\tremaining: 1.51s\n",
      "601:\tlearn: 0.0518343\ttotal: 2.27s\tremaining: 1.5s\n",
      "602:\tlearn: 0.0517570\ttotal: 2.27s\tremaining: 1.5s\n",
      "603:\tlearn: 0.0517316\ttotal: 2.28s\tremaining: 1.49s\n",
      "604:\tlearn: 0.0516871\ttotal: 2.28s\tremaining: 1.49s\n",
      "605:\tlearn: 0.0516579\ttotal: 2.29s\tremaining: 1.49s\n",
      "606:\tlearn: 0.0516241\ttotal: 2.29s\tremaining: 1.48s\n",
      "607:\tlearn: 0.0515944\ttotal: 2.29s\tremaining: 1.48s\n",
      "608:\tlearn: 0.0515394\ttotal: 2.3s\tremaining: 1.48s\n",
      "609:\tlearn: 0.0514992\ttotal: 2.3s\tremaining: 1.47s\n",
      "610:\tlearn: 0.0514747\ttotal: 2.31s\tremaining: 1.47s\n",
      "611:\tlearn: 0.0514420\ttotal: 2.31s\tremaining: 1.47s\n",
      "612:\tlearn: 0.0513746\ttotal: 2.31s\tremaining: 1.46s\n",
      "613:\tlearn: 0.0513573\ttotal: 2.32s\tremaining: 1.46s\n",
      "614:\tlearn: 0.0513183\ttotal: 2.32s\tremaining: 1.45s\n",
      "615:\tlearn: 0.0512755\ttotal: 2.33s\tremaining: 1.45s\n",
      "616:\tlearn: 0.0512221\ttotal: 2.33s\tremaining: 1.45s\n",
      "617:\tlearn: 0.0511761\ttotal: 2.33s\tremaining: 1.44s\n",
      "618:\tlearn: 0.0511385\ttotal: 2.34s\tremaining: 1.44s\n",
      "619:\tlearn: 0.0511127\ttotal: 2.34s\tremaining: 1.44s\n",
      "620:\tlearn: 0.0510737\ttotal: 2.35s\tremaining: 1.43s\n",
      "621:\tlearn: 0.0510276\ttotal: 2.35s\tremaining: 1.43s\n",
      "622:\tlearn: 0.0510016\ttotal: 2.35s\tremaining: 1.42s\n",
      "623:\tlearn: 0.0509768\ttotal: 2.36s\tremaining: 1.42s\n",
      "624:\tlearn: 0.0509385\ttotal: 2.36s\tremaining: 1.42s\n",
      "625:\tlearn: 0.0508567\ttotal: 2.36s\tremaining: 1.41s\n",
      "626:\tlearn: 0.0507647\ttotal: 2.37s\tremaining: 1.41s\n",
      "627:\tlearn: 0.0507162\ttotal: 2.37s\tremaining: 1.4s\n",
      "628:\tlearn: 0.0506606\ttotal: 2.38s\tremaining: 1.4s\n",
      "629:\tlearn: 0.0506301\ttotal: 2.38s\tremaining: 1.4s\n",
      "630:\tlearn: 0.0505738\ttotal: 2.38s\tremaining: 1.39s\n",
      "631:\tlearn: 0.0505208\ttotal: 2.38s\tremaining: 1.39s\n",
      "632:\tlearn: 0.0504952\ttotal: 2.39s\tremaining: 1.39s\n",
      "633:\tlearn: 0.0504352\ttotal: 2.39s\tremaining: 1.38s\n",
      "634:\tlearn: 0.0504110\ttotal: 2.4s\tremaining: 1.38s\n",
      "635:\tlearn: 0.0503985\ttotal: 2.4s\tremaining: 1.37s\n",
      "636:\tlearn: 0.0503396\ttotal: 2.4s\tremaining: 1.37s\n",
      "637:\tlearn: 0.0502890\ttotal: 2.41s\tremaining: 1.36s\n",
      "638:\tlearn: 0.0502359\ttotal: 2.41s\tremaining: 1.36s\n",
      "639:\tlearn: 0.0501856\ttotal: 2.42s\tremaining: 1.36s\n",
      "640:\tlearn: 0.0501061\ttotal: 2.42s\tremaining: 1.35s\n",
      "641:\tlearn: 0.0500762\ttotal: 2.42s\tremaining: 1.35s\n",
      "642:\tlearn: 0.0500391\ttotal: 2.42s\tremaining: 1.35s\n",
      "643:\tlearn: 0.0500106\ttotal: 2.43s\tremaining: 1.34s\n",
      "644:\tlearn: 0.0499431\ttotal: 2.43s\tremaining: 1.34s\n",
      "645:\tlearn: 0.0498932\ttotal: 2.44s\tremaining: 1.34s\n",
      "646:\tlearn: 0.0498614\ttotal: 2.44s\tremaining: 1.33s\n",
      "647:\tlearn: 0.0498392\ttotal: 2.45s\tremaining: 1.33s\n",
      "648:\tlearn: 0.0497592\ttotal: 2.45s\tremaining: 1.32s\n",
      "649:\tlearn: 0.0496768\ttotal: 2.45s\tremaining: 1.32s\n",
      "650:\tlearn: 0.0496417\ttotal: 2.46s\tremaining: 1.32s\n",
      "651:\tlearn: 0.0496070\ttotal: 2.46s\tremaining: 1.31s\n",
      "652:\tlearn: 0.0495705\ttotal: 2.47s\tremaining: 1.31s\n",
      "653:\tlearn: 0.0495459\ttotal: 2.47s\tremaining: 1.31s\n",
      "654:\tlearn: 0.0494727\ttotal: 2.48s\tremaining: 1.3s\n",
      "655:\tlearn: 0.0494063\ttotal: 2.48s\tremaining: 1.3s\n",
      "656:\tlearn: 0.0493829\ttotal: 2.49s\tremaining: 1.3s\n",
      "657:\tlearn: 0.0493448\ttotal: 2.49s\tremaining: 1.29s\n",
      "658:\tlearn: 0.0493215\ttotal: 2.5s\tremaining: 1.29s\n",
      "659:\tlearn: 0.0492406\ttotal: 2.5s\tremaining: 1.29s\n",
      "660:\tlearn: 0.0492048\ttotal: 2.5s\tremaining: 1.28s\n",
      "661:\tlearn: 0.0491774\ttotal: 2.51s\tremaining: 1.28s\n",
      "662:\tlearn: 0.0491269\ttotal: 2.51s\tremaining: 1.28s\n",
      "663:\tlearn: 0.0491067\ttotal: 2.52s\tremaining: 1.27s\n",
      "664:\tlearn: 0.0490696\ttotal: 2.52s\tremaining: 1.27s\n",
      "665:\tlearn: 0.0489864\ttotal: 2.52s\tremaining: 1.26s\n",
      "666:\tlearn: 0.0489643\ttotal: 2.53s\tremaining: 1.26s\n",
      "667:\tlearn: 0.0489252\ttotal: 2.53s\tremaining: 1.26s\n",
      "668:\tlearn: 0.0489013\ttotal: 2.53s\tremaining: 1.25s\n",
      "669:\tlearn: 0.0488302\ttotal: 2.54s\tremaining: 1.25s\n",
      "670:\tlearn: 0.0487765\ttotal: 2.54s\tremaining: 1.25s\n",
      "671:\tlearn: 0.0487539\ttotal: 2.54s\tremaining: 1.24s\n",
      "672:\tlearn: 0.0487176\ttotal: 2.55s\tremaining: 1.24s\n",
      "673:\tlearn: 0.0486045\ttotal: 2.55s\tremaining: 1.23s\n",
      "674:\tlearn: 0.0485369\ttotal: 2.56s\tremaining: 1.23s\n",
      "675:\tlearn: 0.0484159\ttotal: 2.56s\tremaining: 1.23s\n",
      "676:\tlearn: 0.0483617\ttotal: 2.56s\tremaining: 1.22s\n",
      "677:\tlearn: 0.0483261\ttotal: 2.57s\tremaining: 1.22s\n",
      "678:\tlearn: 0.0482891\ttotal: 2.57s\tremaining: 1.22s\n",
      "679:\tlearn: 0.0482544\ttotal: 2.58s\tremaining: 1.21s\n",
      "680:\tlearn: 0.0482078\ttotal: 2.58s\tremaining: 1.21s\n",
      "681:\tlearn: 0.0481716\ttotal: 2.58s\tremaining: 1.2s\n",
      "682:\tlearn: 0.0481512\ttotal: 2.59s\tremaining: 1.2s\n",
      "683:\tlearn: 0.0480545\ttotal: 2.59s\tremaining: 1.2s\n",
      "684:\tlearn: 0.0479831\ttotal: 2.59s\tremaining: 1.19s\n",
      "685:\tlearn: 0.0479751\ttotal: 2.6s\tremaining: 1.19s\n",
      "686:\tlearn: 0.0479425\ttotal: 2.6s\tremaining: 1.18s\n",
      "687:\tlearn: 0.0479079\ttotal: 2.6s\tremaining: 1.18s\n",
      "688:\tlearn: 0.0478724\ttotal: 2.61s\tremaining: 1.18s\n",
      "689:\tlearn: 0.0478262\ttotal: 2.61s\tremaining: 1.17s\n",
      "690:\tlearn: 0.0477982\ttotal: 2.62s\tremaining: 1.17s\n",
      "691:\tlearn: 0.0477648\ttotal: 2.62s\tremaining: 1.17s\n",
      "692:\tlearn: 0.0477533\ttotal: 2.62s\tremaining: 1.16s\n",
      "693:\tlearn: 0.0477326\ttotal: 2.63s\tremaining: 1.16s\n",
      "694:\tlearn: 0.0476966\ttotal: 2.63s\tremaining: 1.15s\n",
      "695:\tlearn: 0.0475896\ttotal: 2.64s\tremaining: 1.15s\n",
      "696:\tlearn: 0.0475551\ttotal: 2.64s\tremaining: 1.15s\n",
      "697:\tlearn: 0.0475365\ttotal: 2.64s\tremaining: 1.14s\n",
      "698:\tlearn: 0.0475108\ttotal: 2.65s\tremaining: 1.14s\n",
      "699:\tlearn: 0.0474887\ttotal: 2.65s\tremaining: 1.14s\n",
      "700:\tlearn: 0.0474371\ttotal: 2.66s\tremaining: 1.13s\n",
      "701:\tlearn: 0.0474006\ttotal: 2.66s\tremaining: 1.13s\n",
      "702:\tlearn: 0.0473699\ttotal: 2.66s\tremaining: 1.13s\n",
      "703:\tlearn: 0.0473267\ttotal: 2.67s\tremaining: 1.12s\n",
      "704:\tlearn: 0.0472931\ttotal: 2.67s\tremaining: 1.12s\n",
      "705:\tlearn: 0.0472585\ttotal: 2.67s\tremaining: 1.11s\n",
      "706:\tlearn: 0.0472114\ttotal: 2.68s\tremaining: 1.11s\n",
      "707:\tlearn: 0.0471995\ttotal: 2.68s\tremaining: 1.11s\n",
      "708:\tlearn: 0.0471780\ttotal: 2.69s\tremaining: 1.1s\n",
      "709:\tlearn: 0.0471448\ttotal: 2.69s\tremaining: 1.1s\n",
      "710:\tlearn: 0.0471114\ttotal: 2.7s\tremaining: 1.1s\n",
      "711:\tlearn: 0.0470806\ttotal: 2.7s\tremaining: 1.09s\n",
      "712:\tlearn: 0.0470419\ttotal: 2.7s\tremaining: 1.09s\n",
      "713:\tlearn: 0.0470101\ttotal: 2.71s\tremaining: 1.08s\n",
      "714:\tlearn: 0.0470027\ttotal: 2.71s\tremaining: 1.08s\n",
      "715:\tlearn: 0.0469387\ttotal: 2.71s\tremaining: 1.08s\n",
      "716:\tlearn: 0.0469056\ttotal: 2.72s\tremaining: 1.07s\n",
      "717:\tlearn: 0.0468430\ttotal: 2.72s\tremaining: 1.07s\n",
      "718:\tlearn: 0.0468142\ttotal: 2.73s\tremaining: 1.06s\n",
      "719:\tlearn: 0.0467475\ttotal: 2.73s\tremaining: 1.06s\n",
      "720:\tlearn: 0.0466458\ttotal: 2.73s\tremaining: 1.06s\n",
      "721:\tlearn: 0.0466042\ttotal: 2.74s\tremaining: 1.05s\n",
      "722:\tlearn: 0.0465850\ttotal: 2.74s\tremaining: 1.05s\n",
      "723:\tlearn: 0.0465289\ttotal: 2.74s\tremaining: 1.04s\n",
      "724:\tlearn: 0.0464510\ttotal: 2.75s\tremaining: 1.04s\n",
      "725:\tlearn: 0.0464219\ttotal: 2.75s\tremaining: 1.04s\n",
      "726:\tlearn: 0.0463469\ttotal: 2.75s\tremaining: 1.03s\n",
      "727:\tlearn: 0.0463145\ttotal: 2.76s\tremaining: 1.03s\n",
      "728:\tlearn: 0.0462845\ttotal: 2.76s\tremaining: 1.03s\n",
      "729:\tlearn: 0.0462568\ttotal: 2.77s\tremaining: 1.02s\n",
      "730:\tlearn: 0.0461988\ttotal: 2.77s\tremaining: 1.02s\n",
      "731:\tlearn: 0.0461845\ttotal: 2.77s\tremaining: 1.01s\n",
      "732:\tlearn: 0.0461560\ttotal: 2.78s\tremaining: 1.01s\n",
      "733:\tlearn: 0.0460739\ttotal: 2.78s\tremaining: 1.01s\n",
      "734:\tlearn: 0.0460628\ttotal: 2.78s\tremaining: 1s\n",
      "735:\tlearn: 0.0460350\ttotal: 2.79s\tremaining: 1000ms\n",
      "736:\tlearn: 0.0460155\ttotal: 2.79s\tremaining: 996ms\n",
      "737:\tlearn: 0.0459889\ttotal: 2.79s\tremaining: 992ms\n",
      "738:\tlearn: 0.0459630\ttotal: 2.8s\tremaining: 988ms\n",
      "739:\tlearn: 0.0459284\ttotal: 2.8s\tremaining: 984ms\n",
      "740:\tlearn: 0.0458643\ttotal: 2.8s\tremaining: 980ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "741:\tlearn: 0.0457707\ttotal: 2.81s\tremaining: 977ms\n",
      "742:\tlearn: 0.0456947\ttotal: 2.81s\tremaining: 973ms\n",
      "743:\tlearn: 0.0456461\ttotal: 2.81s\tremaining: 969ms\n",
      "744:\tlearn: 0.0456179\ttotal: 2.82s\tremaining: 965ms\n",
      "745:\tlearn: 0.0455827\ttotal: 2.82s\tremaining: 962ms\n",
      "746:\tlearn: 0.0455352\ttotal: 2.83s\tremaining: 958ms\n",
      "747:\tlearn: 0.0454870\ttotal: 2.83s\tremaining: 954ms\n",
      "748:\tlearn: 0.0454499\ttotal: 2.84s\tremaining: 950ms\n",
      "749:\tlearn: 0.0454230\ttotal: 2.84s\tremaining: 947ms\n",
      "750:\tlearn: 0.0453916\ttotal: 2.84s\tremaining: 943ms\n",
      "751:\tlearn: 0.0453665\ttotal: 2.85s\tremaining: 940ms\n",
      "752:\tlearn: 0.0453402\ttotal: 2.85s\tremaining: 936ms\n",
      "753:\tlearn: 0.0452860\ttotal: 2.86s\tremaining: 932ms\n",
      "754:\tlearn: 0.0452554\ttotal: 2.86s\tremaining: 929ms\n",
      "755:\tlearn: 0.0452354\ttotal: 2.87s\tremaining: 925ms\n",
      "756:\tlearn: 0.0451950\ttotal: 2.87s\tremaining: 922ms\n",
      "757:\tlearn: 0.0451830\ttotal: 2.87s\tremaining: 918ms\n",
      "758:\tlearn: 0.0451565\ttotal: 2.88s\tremaining: 914ms\n",
      "759:\tlearn: 0.0451073\ttotal: 2.88s\tremaining: 910ms\n",
      "760:\tlearn: 0.0450611\ttotal: 2.89s\tremaining: 907ms\n",
      "761:\tlearn: 0.0450332\ttotal: 2.89s\tremaining: 903ms\n",
      "762:\tlearn: 0.0450148\ttotal: 2.89s\tremaining: 899ms\n",
      "763:\tlearn: 0.0449838\ttotal: 2.9s\tremaining: 895ms\n",
      "764:\tlearn: 0.0449453\ttotal: 2.9s\tremaining: 892ms\n",
      "765:\tlearn: 0.0449205\ttotal: 2.91s\tremaining: 888ms\n",
      "766:\tlearn: 0.0449109\ttotal: 2.91s\tremaining: 884ms\n",
      "767:\tlearn: 0.0448081\ttotal: 2.91s\tremaining: 881ms\n",
      "768:\tlearn: 0.0447637\ttotal: 2.92s\tremaining: 877ms\n",
      "769:\tlearn: 0.0447374\ttotal: 2.92s\tremaining: 873ms\n",
      "770:\tlearn: 0.0447131\ttotal: 2.93s\tremaining: 869ms\n",
      "771:\tlearn: 0.0446880\ttotal: 2.93s\tremaining: 866ms\n",
      "772:\tlearn: 0.0446787\ttotal: 2.94s\tremaining: 862ms\n",
      "773:\tlearn: 0.0446215\ttotal: 2.94s\tremaining: 858ms\n",
      "774:\tlearn: 0.0445872\ttotal: 2.94s\tremaining: 854ms\n",
      "775:\tlearn: 0.0445317\ttotal: 2.95s\tremaining: 851ms\n",
      "776:\tlearn: 0.0445240\ttotal: 2.95s\tremaining: 847ms\n",
      "777:\tlearn: 0.0444689\ttotal: 2.95s\tremaining: 843ms\n",
      "778:\tlearn: 0.0443985\ttotal: 2.96s\tremaining: 839ms\n",
      "779:\tlearn: 0.0443754\ttotal: 2.96s\tremaining: 836ms\n",
      "780:\tlearn: 0.0443507\ttotal: 2.97s\tremaining: 832ms\n",
      "781:\tlearn: 0.0442784\ttotal: 2.97s\tremaining: 828ms\n",
      "782:\tlearn: 0.0442223\ttotal: 2.98s\tremaining: 824ms\n",
      "783:\tlearn: 0.0441981\ttotal: 2.98s\tremaining: 821ms\n",
      "784:\tlearn: 0.0441721\ttotal: 2.98s\tremaining: 817ms\n",
      "785:\tlearn: 0.0441463\ttotal: 2.99s\tremaining: 813ms\n",
      "786:\tlearn: 0.0440789\ttotal: 2.99s\tremaining: 809ms\n",
      "787:\tlearn: 0.0440090\ttotal: 2.99s\tremaining: 806ms\n",
      "788:\tlearn: 0.0439524\ttotal: 3s\tremaining: 802ms\n",
      "789:\tlearn: 0.0439044\ttotal: 3s\tremaining: 798ms\n",
      "790:\tlearn: 0.0438801\ttotal: 3.01s\tremaining: 795ms\n",
      "791:\tlearn: 0.0438680\ttotal: 3.01s\tremaining: 791ms\n",
      "792:\tlearn: 0.0438190\ttotal: 3.01s\tremaining: 787ms\n",
      "793:\tlearn: 0.0437941\ttotal: 3.02s\tremaining: 783ms\n",
      "794:\tlearn: 0.0437673\ttotal: 3.02s\tremaining: 779ms\n",
      "795:\tlearn: 0.0437051\ttotal: 3.03s\tremaining: 776ms\n",
      "796:\tlearn: 0.0436970\ttotal: 3.03s\tremaining: 772ms\n",
      "797:\tlearn: 0.0435880\ttotal: 3.03s\tremaining: 768ms\n",
      "798:\tlearn: 0.0435659\ttotal: 3.04s\tremaining: 764ms\n",
      "799:\tlearn: 0.0435187\ttotal: 3.04s\tremaining: 760ms\n",
      "800:\tlearn: 0.0435023\ttotal: 3.04s\tremaining: 756ms\n",
      "801:\tlearn: 0.0434552\ttotal: 3.05s\tremaining: 752ms\n",
      "802:\tlearn: 0.0433652\ttotal: 3.05s\tremaining: 748ms\n",
      "803:\tlearn: 0.0433419\ttotal: 3.05s\tremaining: 745ms\n",
      "804:\tlearn: 0.0433076\ttotal: 3.06s\tremaining: 741ms\n",
      "805:\tlearn: 0.0432660\ttotal: 3.06s\tremaining: 737ms\n",
      "806:\tlearn: 0.0432328\ttotal: 3.06s\tremaining: 733ms\n",
      "807:\tlearn: 0.0431532\ttotal: 3.07s\tremaining: 729ms\n",
      "808:\tlearn: 0.0431370\ttotal: 3.07s\tremaining: 725ms\n",
      "809:\tlearn: 0.0431089\ttotal: 3.08s\tremaining: 721ms\n",
      "810:\tlearn: 0.0430585\ttotal: 3.08s\tremaining: 718ms\n",
      "811:\tlearn: 0.0429581\ttotal: 3.08s\tremaining: 714ms\n",
      "812:\tlearn: 0.0429353\ttotal: 3.09s\tremaining: 710ms\n",
      "813:\tlearn: 0.0429156\ttotal: 3.09s\tremaining: 706ms\n",
      "814:\tlearn: 0.0428884\ttotal: 3.09s\tremaining: 702ms\n",
      "815:\tlearn: 0.0428827\ttotal: 3.1s\tremaining: 698ms\n",
      "816:\tlearn: 0.0428605\ttotal: 3.1s\tremaining: 694ms\n",
      "817:\tlearn: 0.0428125\ttotal: 3.1s\tremaining: 691ms\n",
      "818:\tlearn: 0.0427733\ttotal: 3.11s\tremaining: 687ms\n",
      "819:\tlearn: 0.0427512\ttotal: 3.11s\tremaining: 683ms\n",
      "820:\tlearn: 0.0427203\ttotal: 3.12s\tremaining: 679ms\n",
      "821:\tlearn: 0.0427053\ttotal: 3.12s\tremaining: 676ms\n",
      "822:\tlearn: 0.0426283\ttotal: 3.12s\tremaining: 672ms\n",
      "823:\tlearn: 0.0425633\ttotal: 3.13s\tremaining: 668ms\n",
      "824:\tlearn: 0.0425424\ttotal: 3.13s\tremaining: 664ms\n",
      "825:\tlearn: 0.0425175\ttotal: 3.13s\tremaining: 661ms\n",
      "826:\tlearn: 0.0424497\ttotal: 3.14s\tremaining: 657ms\n",
      "827:\tlearn: 0.0424279\ttotal: 3.14s\tremaining: 653ms\n",
      "828:\tlearn: 0.0423526\ttotal: 3.15s\tremaining: 650ms\n",
      "829:\tlearn: 0.0423313\ttotal: 3.15s\tremaining: 646ms\n",
      "830:\tlearn: 0.0423062\ttotal: 3.16s\tremaining: 642ms\n",
      "831:\tlearn: 0.0422740\ttotal: 3.16s\tremaining: 638ms\n",
      "832:\tlearn: 0.0422413\ttotal: 3.16s\tremaining: 634ms\n",
      "833:\tlearn: 0.0422248\ttotal: 3.17s\tremaining: 631ms\n",
      "834:\tlearn: 0.0422010\ttotal: 3.17s\tremaining: 627ms\n",
      "835:\tlearn: 0.0421602\ttotal: 3.18s\tremaining: 623ms\n",
      "836:\tlearn: 0.0421291\ttotal: 3.18s\tremaining: 619ms\n",
      "837:\tlearn: 0.0420756\ttotal: 3.18s\tremaining: 616ms\n",
      "838:\tlearn: 0.0420214\ttotal: 3.19s\tremaining: 612ms\n",
      "839:\tlearn: 0.0419990\ttotal: 3.19s\tremaining: 608ms\n",
      "840:\tlearn: 0.0419779\ttotal: 3.2s\tremaining: 605ms\n",
      "841:\tlearn: 0.0419565\ttotal: 3.2s\tremaining: 601ms\n",
      "842:\tlearn: 0.0419091\ttotal: 3.21s\tremaining: 597ms\n",
      "843:\tlearn: 0.0418892\ttotal: 3.21s\tremaining: 593ms\n",
      "844:\tlearn: 0.0418270\ttotal: 3.21s\tremaining: 589ms\n",
      "845:\tlearn: 0.0417656\ttotal: 3.22s\tremaining: 586ms\n",
      "846:\tlearn: 0.0417468\ttotal: 3.22s\tremaining: 582ms\n",
      "847:\tlearn: 0.0416742\ttotal: 3.23s\tremaining: 578ms\n",
      "848:\tlearn: 0.0416038\ttotal: 3.23s\tremaining: 574ms\n",
      "849:\tlearn: 0.0415833\ttotal: 3.23s\tremaining: 570ms\n",
      "850:\tlearn: 0.0415168\ttotal: 3.24s\tremaining: 567ms\n",
      "851:\tlearn: 0.0414612\ttotal: 3.24s\tremaining: 563ms\n",
      "852:\tlearn: 0.0414435\ttotal: 3.24s\tremaining: 559ms\n",
      "853:\tlearn: 0.0414229\ttotal: 3.25s\tremaining: 555ms\n",
      "854:\tlearn: 0.0414028\ttotal: 3.25s\tremaining: 551ms\n",
      "855:\tlearn: 0.0413733\ttotal: 3.25s\tremaining: 548ms\n",
      "856:\tlearn: 0.0413407\ttotal: 3.26s\tremaining: 544ms\n",
      "857:\tlearn: 0.0413048\ttotal: 3.26s\tremaining: 540ms\n",
      "858:\tlearn: 0.0412846\ttotal: 3.27s\tremaining: 536ms\n",
      "859:\tlearn: 0.0412648\ttotal: 3.27s\tremaining: 532ms\n",
      "860:\tlearn: 0.0412236\ttotal: 3.27s\tremaining: 528ms\n",
      "861:\tlearn: 0.0412041\ttotal: 3.27s\tremaining: 524ms\n",
      "862:\tlearn: 0.0411645\ttotal: 3.28s\tremaining: 521ms\n",
      "863:\tlearn: 0.0411373\ttotal: 3.28s\tremaining: 517ms\n",
      "864:\tlearn: 0.0411191\ttotal: 3.29s\tremaining: 513ms\n",
      "865:\tlearn: 0.0411000\ttotal: 3.29s\tremaining: 509ms\n",
      "866:\tlearn: 0.0410726\ttotal: 3.29s\tremaining: 505ms\n",
      "867:\tlearn: 0.0410136\ttotal: 3.3s\tremaining: 501ms\n",
      "868:\tlearn: 0.0409308\ttotal: 3.3s\tremaining: 497ms\n",
      "869:\tlearn: 0.0409131\ttotal: 3.3s\tremaining: 494ms\n",
      "870:\tlearn: 0.0408693\ttotal: 3.31s\tremaining: 490ms\n",
      "871:\tlearn: 0.0408271\ttotal: 3.31s\tremaining: 486ms\n",
      "872:\tlearn: 0.0407949\ttotal: 3.31s\tremaining: 482ms\n",
      "873:\tlearn: 0.0407776\ttotal: 3.32s\tremaining: 478ms\n",
      "874:\tlearn: 0.0407610\ttotal: 3.32s\tremaining: 475ms\n",
      "875:\tlearn: 0.0407017\ttotal: 3.33s\tremaining: 471ms\n",
      "876:\tlearn: 0.0406707\ttotal: 3.33s\tremaining: 467ms\n",
      "877:\tlearn: 0.0406521\ttotal: 3.33s\tremaining: 463ms\n",
      "878:\tlearn: 0.0406421\ttotal: 3.34s\tremaining: 459ms\n",
      "879:\tlearn: 0.0405723\ttotal: 3.34s\tremaining: 455ms\n",
      "880:\tlearn: 0.0405401\ttotal: 3.34s\tremaining: 452ms\n",
      "881:\tlearn: 0.0404915\ttotal: 3.35s\tremaining: 448ms\n",
      "882:\tlearn: 0.0404587\ttotal: 3.35s\tremaining: 444ms\n",
      "883:\tlearn: 0.0404398\ttotal: 3.35s\tremaining: 440ms\n",
      "884:\tlearn: 0.0403973\ttotal: 3.36s\tremaining: 436ms\n",
      "885:\tlearn: 0.0403679\ttotal: 3.36s\tremaining: 433ms\n",
      "886:\tlearn: 0.0403366\ttotal: 3.37s\tremaining: 429ms\n",
      "887:\tlearn: 0.0403312\ttotal: 3.37s\tremaining: 425ms\n",
      "888:\tlearn: 0.0403145\ttotal: 3.37s\tremaining: 421ms\n",
      "889:\tlearn: 0.0402863\ttotal: 3.38s\tremaining: 417ms\n",
      "890:\tlearn: 0.0402299\ttotal: 3.38s\tremaining: 414ms\n",
      "891:\tlearn: 0.0402115\ttotal: 3.38s\tremaining: 410ms\n",
      "892:\tlearn: 0.0401452\ttotal: 3.39s\tremaining: 406ms\n",
      "893:\tlearn: 0.0400652\ttotal: 3.39s\tremaining: 402ms\n",
      "894:\tlearn: 0.0400216\ttotal: 3.4s\tremaining: 398ms\n",
      "895:\tlearn: 0.0399929\ttotal: 3.4s\tremaining: 395ms\n",
      "896:\tlearn: 0.0399690\ttotal: 3.4s\tremaining: 391ms\n",
      "897:\tlearn: 0.0399384\ttotal: 3.41s\tremaining: 387ms\n",
      "898:\tlearn: 0.0398525\ttotal: 3.41s\tremaining: 383ms\n",
      "899:\tlearn: 0.0398362\ttotal: 3.41s\tremaining: 379ms\n",
      "900:\tlearn: 0.0397880\ttotal: 3.42s\tremaining: 376ms\n",
      "901:\tlearn: 0.0397415\ttotal: 3.42s\tremaining: 372ms\n",
      "902:\tlearn: 0.0397086\ttotal: 3.42s\tremaining: 368ms\n",
      "903:\tlearn: 0.0396904\ttotal: 3.43s\tremaining: 364ms\n",
      "904:\tlearn: 0.0396618\ttotal: 3.43s\tremaining: 360ms\n",
      "905:\tlearn: 0.0396525\ttotal: 3.44s\tremaining: 357ms\n",
      "906:\tlearn: 0.0395840\ttotal: 3.44s\tremaining: 353ms\n",
      "907:\tlearn: 0.0395788\ttotal: 3.44s\tremaining: 349ms\n",
      "908:\tlearn: 0.0395647\ttotal: 3.45s\tremaining: 345ms\n",
      "909:\tlearn: 0.0395349\ttotal: 3.45s\tremaining: 341ms\n",
      "910:\tlearn: 0.0395143\ttotal: 3.46s\tremaining: 338ms\n",
      "911:\tlearn: 0.0394946\ttotal: 3.46s\tremaining: 334ms\n",
      "912:\tlearn: 0.0394565\ttotal: 3.46s\tremaining: 330ms\n",
      "913:\tlearn: 0.0394387\ttotal: 3.47s\tremaining: 326ms\n",
      "914:\tlearn: 0.0394107\ttotal: 3.47s\tremaining: 323ms\n",
      "915:\tlearn: 0.0393737\ttotal: 3.48s\tremaining: 319ms\n",
      "916:\tlearn: 0.0393389\ttotal: 3.48s\tremaining: 315ms\n",
      "917:\tlearn: 0.0393212\ttotal: 3.48s\tremaining: 311ms\n",
      "918:\tlearn: 0.0393125\ttotal: 3.49s\tremaining: 308ms\n",
      "919:\tlearn: 0.0392969\ttotal: 3.49s\tremaining: 304ms\n",
      "920:\tlearn: 0.0392811\ttotal: 3.5s\tremaining: 300ms\n",
      "921:\tlearn: 0.0392635\ttotal: 3.5s\tremaining: 296ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "922:\tlearn: 0.0392366\ttotal: 3.5s\tremaining: 292ms\n",
      "923:\tlearn: 0.0392243\ttotal: 3.51s\tremaining: 289ms\n",
      "924:\tlearn: 0.0391764\ttotal: 3.51s\tremaining: 285ms\n",
      "925:\tlearn: 0.0390999\ttotal: 3.52s\tremaining: 281ms\n",
      "926:\tlearn: 0.0390849\ttotal: 3.52s\tremaining: 277ms\n",
      "927:\tlearn: 0.0390658\ttotal: 3.52s\tremaining: 274ms\n",
      "928:\tlearn: 0.0390370\ttotal: 3.53s\tremaining: 270ms\n",
      "929:\tlearn: 0.0390320\ttotal: 3.53s\tremaining: 266ms\n",
      "930:\tlearn: 0.0390238\ttotal: 3.54s\tremaining: 262ms\n",
      "931:\tlearn: 0.0390061\ttotal: 3.54s\tremaining: 258ms\n",
      "932:\tlearn: 0.0389908\ttotal: 3.54s\tremaining: 255ms\n",
      "933:\tlearn: 0.0389450\ttotal: 3.55s\tremaining: 251ms\n",
      "934:\tlearn: 0.0389265\ttotal: 3.55s\tremaining: 247ms\n",
      "935:\tlearn: 0.0388985\ttotal: 3.56s\tremaining: 243ms\n",
      "936:\tlearn: 0.0388726\ttotal: 3.56s\tremaining: 239ms\n",
      "937:\tlearn: 0.0388549\ttotal: 3.56s\tremaining: 236ms\n",
      "938:\tlearn: 0.0388034\ttotal: 3.57s\tremaining: 232ms\n",
      "939:\tlearn: 0.0387861\ttotal: 3.57s\tremaining: 228ms\n",
      "940:\tlearn: 0.0387756\ttotal: 3.58s\tremaining: 224ms\n",
      "941:\tlearn: 0.0387138\ttotal: 3.58s\tremaining: 220ms\n",
      "942:\tlearn: 0.0386739\ttotal: 3.58s\tremaining: 217ms\n",
      "943:\tlearn: 0.0386466\ttotal: 3.59s\tremaining: 213ms\n",
      "944:\tlearn: 0.0386350\ttotal: 3.59s\tremaining: 209ms\n",
      "945:\tlearn: 0.0385915\ttotal: 3.59s\tremaining: 205ms\n",
      "946:\tlearn: 0.0385744\ttotal: 3.6s\tremaining: 201ms\n",
      "947:\tlearn: 0.0385566\ttotal: 3.6s\tremaining: 198ms\n",
      "948:\tlearn: 0.0385166\ttotal: 3.6s\tremaining: 194ms\n",
      "949:\tlearn: 0.0384573\ttotal: 3.61s\tremaining: 190ms\n",
      "950:\tlearn: 0.0384410\ttotal: 3.61s\tremaining: 186ms\n",
      "951:\tlearn: 0.0383853\ttotal: 3.62s\tremaining: 182ms\n",
      "952:\tlearn: 0.0383638\ttotal: 3.62s\tremaining: 179ms\n",
      "953:\tlearn: 0.0383280\ttotal: 3.62s\tremaining: 175ms\n",
      "954:\tlearn: 0.0383217\ttotal: 3.63s\tremaining: 171ms\n",
      "955:\tlearn: 0.0382966\ttotal: 3.63s\tremaining: 167ms\n",
      "956:\tlearn: 0.0382822\ttotal: 3.63s\tremaining: 163ms\n",
      "957:\tlearn: 0.0382438\ttotal: 3.64s\tremaining: 159ms\n",
      "958:\tlearn: 0.0382282\ttotal: 3.64s\tremaining: 156ms\n",
      "959:\tlearn: 0.0382169\ttotal: 3.65s\tremaining: 152ms\n",
      "960:\tlearn: 0.0381848\ttotal: 3.65s\tremaining: 148ms\n",
      "961:\tlearn: 0.0381603\ttotal: 3.65s\tremaining: 144ms\n",
      "962:\tlearn: 0.0381491\ttotal: 3.66s\tremaining: 140ms\n",
      "963:\tlearn: 0.0381143\ttotal: 3.66s\tremaining: 137ms\n",
      "964:\tlearn: 0.0380795\ttotal: 3.66s\tremaining: 133ms\n",
      "965:\tlearn: 0.0380648\ttotal: 3.67s\tremaining: 129ms\n",
      "966:\tlearn: 0.0380218\ttotal: 3.67s\tremaining: 125ms\n",
      "967:\tlearn: 0.0380063\ttotal: 3.67s\tremaining: 121ms\n",
      "968:\tlearn: 0.0379916\ttotal: 3.68s\tremaining: 118ms\n",
      "969:\tlearn: 0.0379735\ttotal: 3.68s\tremaining: 114ms\n",
      "970:\tlearn: 0.0379636\ttotal: 3.69s\tremaining: 110ms\n",
      "971:\tlearn: 0.0379468\ttotal: 3.69s\tremaining: 106ms\n",
      "972:\tlearn: 0.0379303\ttotal: 3.69s\tremaining: 102ms\n",
      "973:\tlearn: 0.0379193\ttotal: 3.7s\tremaining: 98.7ms\n",
      "974:\tlearn: 0.0378912\ttotal: 3.7s\tremaining: 94.9ms\n",
      "975:\tlearn: 0.0378743\ttotal: 3.7s\tremaining: 91.1ms\n",
      "976:\tlearn: 0.0378212\ttotal: 3.71s\tremaining: 87.3ms\n",
      "977:\tlearn: 0.0377896\ttotal: 3.71s\tremaining: 83.5ms\n",
      "978:\tlearn: 0.0377663\ttotal: 3.71s\tremaining: 79.7ms\n",
      "979:\tlearn: 0.0377241\ttotal: 3.72s\tremaining: 75.9ms\n",
      "980:\tlearn: 0.0377181\ttotal: 3.72s\tremaining: 72.1ms\n",
      "981:\tlearn: 0.0377016\ttotal: 3.73s\tremaining: 68.3ms\n",
      "982:\tlearn: 0.0376851\ttotal: 3.73s\tremaining: 64.5ms\n",
      "983:\tlearn: 0.0376707\ttotal: 3.73s\tremaining: 60.7ms\n",
      "984:\tlearn: 0.0376287\ttotal: 3.74s\tremaining: 56.9ms\n",
      "985:\tlearn: 0.0376137\ttotal: 3.74s\tremaining: 53.1ms\n",
      "986:\tlearn: 0.0375574\ttotal: 3.74s\tremaining: 49.3ms\n",
      "987:\tlearn: 0.0375408\ttotal: 3.75s\tremaining: 45.5ms\n",
      "988:\tlearn: 0.0374892\ttotal: 3.75s\tremaining: 41.7ms\n",
      "989:\tlearn: 0.0374688\ttotal: 3.75s\tremaining: 37.9ms\n",
      "990:\tlearn: 0.0374453\ttotal: 3.76s\tremaining: 34.1ms\n",
      "991:\tlearn: 0.0373998\ttotal: 3.76s\tremaining: 30.3ms\n",
      "992:\tlearn: 0.0373922\ttotal: 3.77s\tremaining: 26.5ms\n",
      "993:\tlearn: 0.0373779\ttotal: 3.77s\tremaining: 22.8ms\n",
      "994:\tlearn: 0.0373156\ttotal: 3.77s\tremaining: 19ms\n",
      "995:\tlearn: 0.0372758\ttotal: 3.78s\tremaining: 15.2ms\n",
      "996:\tlearn: 0.0372201\ttotal: 3.78s\tremaining: 11.4ms\n",
      "997:\tlearn: 0.0371737\ttotal: 3.79s\tremaining: 7.59ms\n",
      "998:\tlearn: 0.0371632\ttotal: 3.79s\tremaining: 3.79ms\n",
      "999:\tlearn: 0.0371447\ttotal: 3.79s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013279\n",
      "0:\tlearn: 0.6679957\ttotal: 6.86ms\tremaining: 6.86s\n",
      "1:\tlearn: 0.6444039\ttotal: 12ms\tremaining: 6s\n",
      "2:\tlearn: 0.6196868\ttotal: 17.1ms\tremaining: 5.68s\n",
      "3:\tlearn: 0.5975463\ttotal: 21.4ms\tremaining: 5.32s\n",
      "4:\tlearn: 0.5763682\ttotal: 25.7ms\tremaining: 5.11s\n",
      "5:\tlearn: 0.5607647\ttotal: 30.4ms\tremaining: 5.04s\n",
      "6:\tlearn: 0.5407910\ttotal: 36.9ms\tremaining: 5.24s\n",
      "7:\tlearn: 0.5230446\ttotal: 42.3ms\tremaining: 5.24s\n",
      "8:\tlearn: 0.5078704\ttotal: 48.6ms\tremaining: 5.36s\n",
      "9:\tlearn: 0.4909569\ttotal: 52.8ms\tremaining: 5.22s\n",
      "10:\tlearn: 0.4754676\ttotal: 57ms\tremaining: 5.13s\n",
      "11:\tlearn: 0.4596353\ttotal: 61ms\tremaining: 5.02s\n",
      "12:\tlearn: 0.4450233\ttotal: 65.8ms\tremaining: 5s\n",
      "13:\tlearn: 0.4310674\ttotal: 70.7ms\tremaining: 4.97s\n",
      "14:\tlearn: 0.4176614\ttotal: 76.8ms\tremaining: 5.04s\n",
      "15:\tlearn: 0.4043196\ttotal: 80.4ms\tremaining: 4.94s\n",
      "16:\tlearn: 0.3938683\ttotal: 84ms\tremaining: 4.86s\n",
      "17:\tlearn: 0.3827340\ttotal: 87.8ms\tremaining: 4.79s\n",
      "18:\tlearn: 0.3718396\ttotal: 91.6ms\tremaining: 4.73s\n",
      "19:\tlearn: 0.3615995\ttotal: 95.4ms\tremaining: 4.67s\n",
      "20:\tlearn: 0.3522458\ttotal: 99.9ms\tremaining: 4.66s\n",
      "21:\tlearn: 0.3433051\ttotal: 105ms\tremaining: 4.67s\n",
      "22:\tlearn: 0.3341116\ttotal: 109ms\tremaining: 4.63s\n",
      "23:\tlearn: 0.3269091\ttotal: 113ms\tremaining: 4.58s\n",
      "24:\tlearn: 0.3185594\ttotal: 116ms\tremaining: 4.53s\n",
      "25:\tlearn: 0.3109386\ttotal: 120ms\tremaining: 4.49s\n",
      "26:\tlearn: 0.3045146\ttotal: 123ms\tremaining: 4.45s\n",
      "27:\tlearn: 0.2969938\ttotal: 127ms\tremaining: 4.41s\n",
      "28:\tlearn: 0.2905171\ttotal: 131ms\tremaining: 4.4s\n",
      "29:\tlearn: 0.2840848\ttotal: 136ms\tremaining: 4.38s\n",
      "30:\tlearn: 0.2778460\ttotal: 140ms\tremaining: 4.38s\n",
      "31:\tlearn: 0.2710468\ttotal: 144ms\tremaining: 4.36s\n",
      "32:\tlearn: 0.2649530\ttotal: 148ms\tremaining: 4.35s\n",
      "33:\tlearn: 0.2595235\ttotal: 152ms\tremaining: 4.32s\n",
      "34:\tlearn: 0.2547954\ttotal: 156ms\tremaining: 4.3s\n",
      "35:\tlearn: 0.2496560\ttotal: 160ms\tremaining: 4.29s\n",
      "36:\tlearn: 0.2448084\ttotal: 166ms\tremaining: 4.32s\n",
      "37:\tlearn: 0.2404156\ttotal: 170ms\tremaining: 4.3s\n",
      "38:\tlearn: 0.2361410\ttotal: 173ms\tremaining: 4.27s\n",
      "39:\tlearn: 0.2323447\ttotal: 178ms\tremaining: 4.26s\n",
      "40:\tlearn: 0.2282341\ttotal: 181ms\tremaining: 4.24s\n",
      "41:\tlearn: 0.2242704\ttotal: 185ms\tremaining: 4.23s\n",
      "42:\tlearn: 0.2201823\ttotal: 190ms\tremaining: 4.23s\n",
      "43:\tlearn: 0.2162941\ttotal: 194ms\tremaining: 4.22s\n",
      "44:\tlearn: 0.2122527\ttotal: 198ms\tremaining: 4.21s\n",
      "45:\tlearn: 0.2085434\ttotal: 202ms\tremaining: 4.19s\n",
      "46:\tlearn: 0.2050459\ttotal: 207ms\tremaining: 4.19s\n",
      "47:\tlearn: 0.2015933\ttotal: 210ms\tremaining: 4.17s\n",
      "48:\tlearn: 0.1985460\ttotal: 214ms\tremaining: 4.16s\n",
      "49:\tlearn: 0.1957533\ttotal: 218ms\tremaining: 4.14s\n",
      "50:\tlearn: 0.1932502\ttotal: 223ms\tremaining: 4.14s\n",
      "51:\tlearn: 0.1907866\ttotal: 228ms\tremaining: 4.15s\n",
      "52:\tlearn: 0.1883811\ttotal: 231ms\tremaining: 4.13s\n",
      "53:\tlearn: 0.1857213\ttotal: 235ms\tremaining: 4.12s\n",
      "54:\tlearn: 0.1835125\ttotal: 239ms\tremaining: 4.1s\n",
      "55:\tlearn: 0.1809635\ttotal: 242ms\tremaining: 4.08s\n",
      "56:\tlearn: 0.1785206\ttotal: 246ms\tremaining: 4.07s\n",
      "57:\tlearn: 0.1762391\ttotal: 250ms\tremaining: 4.06s\n",
      "58:\tlearn: 0.1744032\ttotal: 255ms\tremaining: 4.07s\n",
      "59:\tlearn: 0.1722520\ttotal: 261ms\tremaining: 4.09s\n",
      "60:\tlearn: 0.1701716\ttotal: 265ms\tremaining: 4.08s\n",
      "61:\tlearn: 0.1682213\ttotal: 268ms\tremaining: 4.06s\n",
      "62:\tlearn: 0.1667312\ttotal: 273ms\tremaining: 4.06s\n",
      "63:\tlearn: 0.1650919\ttotal: 277ms\tremaining: 4.05s\n",
      "64:\tlearn: 0.1632204\ttotal: 281ms\tremaining: 4.04s\n",
      "65:\tlearn: 0.1619695\ttotal: 286ms\tremaining: 4.04s\n",
      "66:\tlearn: 0.1605650\ttotal: 291ms\tremaining: 4.05s\n",
      "67:\tlearn: 0.1588083\ttotal: 296ms\tremaining: 4.05s\n",
      "68:\tlearn: 0.1573263\ttotal: 300ms\tremaining: 4.04s\n",
      "69:\tlearn: 0.1559382\ttotal: 304ms\tremaining: 4.04s\n",
      "70:\tlearn: 0.1547170\ttotal: 309ms\tremaining: 4.04s\n",
      "71:\tlearn: 0.1531768\ttotal: 313ms\tremaining: 4.04s\n",
      "72:\tlearn: 0.1517522\ttotal: 317ms\tremaining: 4.03s\n",
      "73:\tlearn: 0.1506599\ttotal: 323ms\tremaining: 4.04s\n",
      "74:\tlearn: 0.1493709\ttotal: 327ms\tremaining: 4.03s\n",
      "75:\tlearn: 0.1480974\ttotal: 331ms\tremaining: 4.03s\n",
      "76:\tlearn: 0.1468827\ttotal: 336ms\tremaining: 4.03s\n",
      "77:\tlearn: 0.1459305\ttotal: 341ms\tremaining: 4.03s\n",
      "78:\tlearn: 0.1447415\ttotal: 345ms\tremaining: 4.03s\n",
      "79:\tlearn: 0.1437224\ttotal: 351ms\tremaining: 4.03s\n",
      "80:\tlearn: 0.1426318\ttotal: 357ms\tremaining: 4.04s\n",
      "81:\tlearn: 0.1414927\ttotal: 361ms\tremaining: 4.04s\n",
      "82:\tlearn: 0.1404691\ttotal: 365ms\tremaining: 4.03s\n",
      "83:\tlearn: 0.1397278\ttotal: 370ms\tremaining: 4.03s\n",
      "84:\tlearn: 0.1388713\ttotal: 375ms\tremaining: 4.04s\n",
      "85:\tlearn: 0.1380393\ttotal: 380ms\tremaining: 4.03s\n",
      "86:\tlearn: 0.1370978\ttotal: 384ms\tremaining: 4.03s\n",
      "87:\tlearn: 0.1361668\ttotal: 388ms\tremaining: 4.03s\n",
      "88:\tlearn: 0.1350955\ttotal: 392ms\tremaining: 4.02s\n",
      "89:\tlearn: 0.1344404\ttotal: 397ms\tremaining: 4.02s\n",
      "90:\tlearn: 0.1335865\ttotal: 401ms\tremaining: 4.01s\n",
      "91:\tlearn: 0.1329456\ttotal: 405ms\tremaining: 4s\n",
      "92:\tlearn: 0.1322007\ttotal: 409ms\tremaining: 3.99s\n",
      "93:\tlearn: 0.1315533\ttotal: 414ms\tremaining: 3.99s\n",
      "94:\tlearn: 0.1307471\ttotal: 418ms\tremaining: 3.98s\n",
      "95:\tlearn: 0.1297889\ttotal: 422ms\tremaining: 3.98s\n",
      "96:\tlearn: 0.1289653\ttotal: 427ms\tremaining: 3.97s\n",
      "97:\tlearn: 0.1281709\ttotal: 431ms\tremaining: 3.96s\n",
      "98:\tlearn: 0.1275467\ttotal: 435ms\tremaining: 3.96s\n",
      "99:\tlearn: 0.1268534\ttotal: 439ms\tremaining: 3.95s\n",
      "100:\tlearn: 0.1261617\ttotal: 443ms\tremaining: 3.94s\n",
      "101:\tlearn: 0.1254004\ttotal: 447ms\tremaining: 3.94s\n",
      "102:\tlearn: 0.1248538\ttotal: 451ms\tremaining: 3.93s\n",
      "103:\tlearn: 0.1245167\ttotal: 455ms\tremaining: 3.92s\n",
      "104:\tlearn: 0.1237899\ttotal: 459ms\tremaining: 3.91s\n",
      "105:\tlearn: 0.1232544\ttotal: 462ms\tremaining: 3.9s\n",
      "106:\tlearn: 0.1226495\ttotal: 466ms\tremaining: 3.89s\n",
      "107:\tlearn: 0.1221274\ttotal: 471ms\tremaining: 3.89s\n",
      "108:\tlearn: 0.1214327\ttotal: 475ms\tremaining: 3.88s\n",
      "109:\tlearn: 0.1209975\ttotal: 478ms\tremaining: 3.87s\n",
      "110:\tlearn: 0.1204487\ttotal: 482ms\tremaining: 3.86s\n",
      "111:\tlearn: 0.1200095\ttotal: 486ms\tremaining: 3.85s\n",
      "112:\tlearn: 0.1194396\ttotal: 490ms\tremaining: 3.84s\n",
      "113:\tlearn: 0.1188529\ttotal: 493ms\tremaining: 3.83s\n",
      "114:\tlearn: 0.1183677\ttotal: 497ms\tremaining: 3.83s\n",
      "115:\tlearn: 0.1179425\ttotal: 501ms\tremaining: 3.82s\n",
      "116:\tlearn: 0.1173741\ttotal: 505ms\tremaining: 3.81s\n",
      "117:\tlearn: 0.1168332\ttotal: 510ms\tremaining: 3.81s\n",
      "118:\tlearn: 0.1164379\ttotal: 514ms\tremaining: 3.8s\n",
      "119:\tlearn: 0.1158703\ttotal: 518ms\tremaining: 3.79s\n",
      "120:\tlearn: 0.1153803\ttotal: 521ms\tremaining: 3.79s\n",
      "121:\tlearn: 0.1148719\ttotal: 525ms\tremaining: 3.78s\n",
      "122:\tlearn: 0.1145698\ttotal: 529ms\tremaining: 3.77s\n",
      "123:\tlearn: 0.1141990\ttotal: 534ms\tremaining: 3.77s\n",
      "124:\tlearn: 0.1137560\ttotal: 539ms\tremaining: 3.77s\n",
      "125:\tlearn: 0.1132089\ttotal: 543ms\tremaining: 3.76s\n",
      "126:\tlearn: 0.1130056\ttotal: 547ms\tremaining: 3.76s\n",
      "127:\tlearn: 0.1125647\ttotal: 551ms\tremaining: 3.76s\n",
      "128:\tlearn: 0.1120681\ttotal: 556ms\tremaining: 3.75s\n",
      "129:\tlearn: 0.1118040\ttotal: 561ms\tremaining: 3.75s\n",
      "130:\tlearn: 0.1114380\ttotal: 565ms\tremaining: 3.75s\n",
      "131:\tlearn: 0.1109341\ttotal: 571ms\tremaining: 3.75s\n",
      "132:\tlearn: 0.1104604\ttotal: 577ms\tremaining: 3.76s\n",
      "133:\tlearn: 0.1099283\ttotal: 582ms\tremaining: 3.76s\n",
      "134:\tlearn: 0.1095574\ttotal: 586ms\tremaining: 3.76s\n",
      "135:\tlearn: 0.1092015\ttotal: 591ms\tremaining: 3.75s\n",
      "136:\tlearn: 0.1088752\ttotal: 596ms\tremaining: 3.75s\n",
      "137:\tlearn: 0.1086220\ttotal: 600ms\tremaining: 3.75s\n",
      "138:\tlearn: 0.1083464\ttotal: 605ms\tremaining: 3.75s\n",
      "139:\tlearn: 0.1081856\ttotal: 609ms\tremaining: 3.74s\n",
      "140:\tlearn: 0.1078641\ttotal: 614ms\tremaining: 3.74s\n",
      "141:\tlearn: 0.1076147\ttotal: 618ms\tremaining: 3.73s\n",
      "142:\tlearn: 0.1073308\ttotal: 622ms\tremaining: 3.73s\n",
      "143:\tlearn: 0.1069755\ttotal: 626ms\tremaining: 3.72s\n",
      "144:\tlearn: 0.1066941\ttotal: 630ms\tremaining: 3.72s\n",
      "145:\tlearn: 0.1063402\ttotal: 634ms\tremaining: 3.71s\n",
      "146:\tlearn: 0.1060939\ttotal: 638ms\tremaining: 3.7s\n",
      "147:\tlearn: 0.1057008\ttotal: 642ms\tremaining: 3.7s\n",
      "148:\tlearn: 0.1056082\ttotal: 646ms\tremaining: 3.69s\n",
      "149:\tlearn: 0.1052754\ttotal: 650ms\tremaining: 3.68s\n",
      "150:\tlearn: 0.1049753\ttotal: 654ms\tremaining: 3.68s\n",
      "151:\tlearn: 0.1047109\ttotal: 659ms\tremaining: 3.67s\n",
      "152:\tlearn: 0.1043082\ttotal: 663ms\tremaining: 3.67s\n",
      "153:\tlearn: 0.1039608\ttotal: 667ms\tremaining: 3.67s\n",
      "154:\tlearn: 0.1035200\ttotal: 671ms\tremaining: 3.66s\n",
      "155:\tlearn: 0.1032864\ttotal: 675ms\tremaining: 3.65s\n",
      "156:\tlearn: 0.1029470\ttotal: 679ms\tremaining: 3.65s\n",
      "157:\tlearn: 0.1026787\ttotal: 684ms\tremaining: 3.65s\n",
      "158:\tlearn: 0.1023915\ttotal: 689ms\tremaining: 3.65s\n",
      "159:\tlearn: 0.1021056\ttotal: 695ms\tremaining: 3.65s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "160:\tlearn: 0.1018528\ttotal: 699ms\tremaining: 3.64s\n",
      "161:\tlearn: 0.1015191\ttotal: 704ms\tremaining: 3.64s\n",
      "162:\tlearn: 0.1012202\ttotal: 709ms\tremaining: 3.64s\n",
      "163:\tlearn: 0.1009037\ttotal: 714ms\tremaining: 3.64s\n",
      "164:\tlearn: 0.1006024\ttotal: 718ms\tremaining: 3.63s\n",
      "165:\tlearn: 0.1003182\ttotal: 723ms\tremaining: 3.63s\n",
      "166:\tlearn: 0.1001148\ttotal: 727ms\tremaining: 3.63s\n",
      "167:\tlearn: 0.0998384\ttotal: 731ms\tremaining: 3.62s\n",
      "168:\tlearn: 0.0994657\ttotal: 735ms\tremaining: 3.61s\n",
      "169:\tlearn: 0.0992659\ttotal: 738ms\tremaining: 3.6s\n",
      "170:\tlearn: 0.0989788\ttotal: 742ms\tremaining: 3.6s\n",
      "171:\tlearn: 0.0987793\ttotal: 746ms\tremaining: 3.59s\n",
      "172:\tlearn: 0.0985259\ttotal: 751ms\tremaining: 3.59s\n",
      "173:\tlearn: 0.0983339\ttotal: 754ms\tremaining: 3.58s\n",
      "174:\tlearn: 0.0980511\ttotal: 758ms\tremaining: 3.57s\n",
      "175:\tlearn: 0.0978258\ttotal: 762ms\tremaining: 3.56s\n",
      "176:\tlearn: 0.0976895\ttotal: 766ms\tremaining: 3.56s\n",
      "177:\tlearn: 0.0973765\ttotal: 769ms\tremaining: 3.55s\n",
      "178:\tlearn: 0.0972046\ttotal: 773ms\tremaining: 3.55s\n",
      "179:\tlearn: 0.0970448\ttotal: 777ms\tremaining: 3.54s\n",
      "180:\tlearn: 0.0967606\ttotal: 782ms\tremaining: 3.54s\n",
      "181:\tlearn: 0.0965440\ttotal: 786ms\tremaining: 3.53s\n",
      "182:\tlearn: 0.0962320\ttotal: 790ms\tremaining: 3.52s\n",
      "183:\tlearn: 0.0959916\ttotal: 793ms\tremaining: 3.52s\n",
      "184:\tlearn: 0.0957485\ttotal: 797ms\tremaining: 3.51s\n",
      "185:\tlearn: 0.0955139\ttotal: 801ms\tremaining: 3.5s\n",
      "186:\tlearn: 0.0952578\ttotal: 804ms\tremaining: 3.5s\n",
      "187:\tlearn: 0.0950581\ttotal: 809ms\tremaining: 3.49s\n",
      "188:\tlearn: 0.0949062\ttotal: 813ms\tremaining: 3.49s\n",
      "189:\tlearn: 0.0946075\ttotal: 817ms\tremaining: 3.48s\n",
      "190:\tlearn: 0.0943999\ttotal: 820ms\tremaining: 3.47s\n",
      "191:\tlearn: 0.0941665\ttotal: 824ms\tremaining: 3.47s\n",
      "192:\tlearn: 0.0938877\ttotal: 828ms\tremaining: 3.46s\n",
      "193:\tlearn: 0.0936243\ttotal: 831ms\tremaining: 3.45s\n",
      "194:\tlearn: 0.0933706\ttotal: 835ms\tremaining: 3.44s\n",
      "195:\tlearn: 0.0932242\ttotal: 839ms\tremaining: 3.44s\n",
      "196:\tlearn: 0.0929712\ttotal: 843ms\tremaining: 3.44s\n",
      "197:\tlearn: 0.0928333\ttotal: 847ms\tremaining: 3.43s\n",
      "198:\tlearn: 0.0925744\ttotal: 850ms\tremaining: 3.42s\n",
      "199:\tlearn: 0.0924135\ttotal: 854ms\tremaining: 3.41s\n",
      "200:\tlearn: 0.0923071\ttotal: 858ms\tremaining: 3.41s\n",
      "201:\tlearn: 0.0921306\ttotal: 862ms\tremaining: 3.4s\n",
      "202:\tlearn: 0.0920120\ttotal: 865ms\tremaining: 3.4s\n",
      "203:\tlearn: 0.0918213\ttotal: 870ms\tremaining: 3.39s\n",
      "204:\tlearn: 0.0916524\ttotal: 875ms\tremaining: 3.39s\n",
      "205:\tlearn: 0.0915035\ttotal: 879ms\tremaining: 3.39s\n",
      "206:\tlearn: 0.0912819\ttotal: 883ms\tremaining: 3.38s\n",
      "207:\tlearn: 0.0911206\ttotal: 886ms\tremaining: 3.37s\n",
      "208:\tlearn: 0.0908846\ttotal: 890ms\tremaining: 3.37s\n",
      "209:\tlearn: 0.0907360\ttotal: 894ms\tremaining: 3.36s\n",
      "210:\tlearn: 0.0905038\ttotal: 898ms\tremaining: 3.36s\n",
      "211:\tlearn: 0.0903513\ttotal: 902ms\tremaining: 3.35s\n",
      "212:\tlearn: 0.0901313\ttotal: 906ms\tremaining: 3.35s\n",
      "213:\tlearn: 0.0899815\ttotal: 911ms\tremaining: 3.35s\n",
      "214:\tlearn: 0.0897843\ttotal: 914ms\tremaining: 3.34s\n",
      "215:\tlearn: 0.0895900\ttotal: 918ms\tremaining: 3.33s\n",
      "216:\tlearn: 0.0894175\ttotal: 921ms\tremaining: 3.32s\n",
      "217:\tlearn: 0.0893174\ttotal: 925ms\tremaining: 3.32s\n",
      "218:\tlearn: 0.0891296\ttotal: 929ms\tremaining: 3.31s\n",
      "219:\tlearn: 0.0889782\ttotal: 933ms\tremaining: 3.31s\n",
      "220:\tlearn: 0.0888260\ttotal: 937ms\tremaining: 3.3s\n",
      "221:\tlearn: 0.0886381\ttotal: 941ms\tremaining: 3.3s\n",
      "222:\tlearn: 0.0884316\ttotal: 945ms\tremaining: 3.29s\n",
      "223:\tlearn: 0.0882268\ttotal: 949ms\tremaining: 3.29s\n",
      "224:\tlearn: 0.0880999\ttotal: 954ms\tremaining: 3.29s\n",
      "225:\tlearn: 0.0878708\ttotal: 958ms\tremaining: 3.28s\n",
      "226:\tlearn: 0.0876726\ttotal: 962ms\tremaining: 3.27s\n",
      "227:\tlearn: 0.0876035\ttotal: 966ms\tremaining: 3.27s\n",
      "228:\tlearn: 0.0873921\ttotal: 970ms\tremaining: 3.27s\n",
      "229:\tlearn: 0.0870958\ttotal: 976ms\tremaining: 3.27s\n",
      "230:\tlearn: 0.0870017\ttotal: 979ms\tremaining: 3.26s\n",
      "231:\tlearn: 0.0868575\ttotal: 984ms\tremaining: 3.26s\n",
      "232:\tlearn: 0.0866607\ttotal: 988ms\tremaining: 3.25s\n",
      "233:\tlearn: 0.0865427\ttotal: 992ms\tremaining: 3.25s\n",
      "234:\tlearn: 0.0863321\ttotal: 996ms\tremaining: 3.24s\n",
      "235:\tlearn: 0.0861452\ttotal: 1s\tremaining: 3.24s\n",
      "236:\tlearn: 0.0861001\ttotal: 1.01s\tremaining: 3.24s\n",
      "237:\tlearn: 0.0859160\ttotal: 1.01s\tremaining: 3.23s\n",
      "238:\tlearn: 0.0858136\ttotal: 1.01s\tremaining: 3.23s\n",
      "239:\tlearn: 0.0857461\ttotal: 1.02s\tremaining: 3.23s\n",
      "240:\tlearn: 0.0856756\ttotal: 1.02s\tremaining: 3.22s\n",
      "241:\tlearn: 0.0855214\ttotal: 1.03s\tremaining: 3.22s\n",
      "242:\tlearn: 0.0853921\ttotal: 1.03s\tremaining: 3.22s\n",
      "243:\tlearn: 0.0851894\ttotal: 1.04s\tremaining: 3.21s\n",
      "244:\tlearn: 0.0849874\ttotal: 1.04s\tremaining: 3.21s\n",
      "245:\tlearn: 0.0848534\ttotal: 1.04s\tremaining: 3.21s\n",
      "246:\tlearn: 0.0846247\ttotal: 1.05s\tremaining: 3.2s\n",
      "247:\tlearn: 0.0845190\ttotal: 1.05s\tremaining: 3.2s\n",
      "248:\tlearn: 0.0843534\ttotal: 1.06s\tremaining: 3.19s\n",
      "249:\tlearn: 0.0841460\ttotal: 1.06s\tremaining: 3.19s\n",
      "250:\tlearn: 0.0839840\ttotal: 1.07s\tremaining: 3.19s\n",
      "251:\tlearn: 0.0838487\ttotal: 1.07s\tremaining: 3.18s\n",
      "252:\tlearn: 0.0836915\ttotal: 1.08s\tremaining: 3.18s\n",
      "253:\tlearn: 0.0835672\ttotal: 1.08s\tremaining: 3.18s\n",
      "254:\tlearn: 0.0834545\ttotal: 1.09s\tremaining: 3.17s\n",
      "255:\tlearn: 0.0833246\ttotal: 1.09s\tremaining: 3.17s\n",
      "256:\tlearn: 0.0831121\ttotal: 1.09s\tremaining: 3.17s\n",
      "257:\tlearn: 0.0829101\ttotal: 1.1s\tremaining: 3.16s\n",
      "258:\tlearn: 0.0828333\ttotal: 1.1s\tremaining: 3.16s\n",
      "259:\tlearn: 0.0826306\ttotal: 1.11s\tremaining: 3.15s\n",
      "260:\tlearn: 0.0824229\ttotal: 1.11s\tremaining: 3.15s\n",
      "261:\tlearn: 0.0822593\ttotal: 1.12s\tremaining: 3.15s\n",
      "262:\tlearn: 0.0821360\ttotal: 1.12s\tremaining: 3.15s\n",
      "263:\tlearn: 0.0820302\ttotal: 1.13s\tremaining: 3.14s\n",
      "264:\tlearn: 0.0818260\ttotal: 1.13s\tremaining: 3.14s\n",
      "265:\tlearn: 0.0816199\ttotal: 1.14s\tremaining: 3.14s\n",
      "266:\tlearn: 0.0814662\ttotal: 1.14s\tremaining: 3.13s\n",
      "267:\tlearn: 0.0812316\ttotal: 1.15s\tremaining: 3.13s\n",
      "268:\tlearn: 0.0810936\ttotal: 1.15s\tremaining: 3.13s\n",
      "269:\tlearn: 0.0809782\ttotal: 1.15s\tremaining: 3.12s\n",
      "270:\tlearn: 0.0808733\ttotal: 1.16s\tremaining: 3.12s\n",
      "271:\tlearn: 0.0805900\ttotal: 1.16s\tremaining: 3.11s\n",
      "272:\tlearn: 0.0804010\ttotal: 1.17s\tremaining: 3.11s\n",
      "273:\tlearn: 0.0802860\ttotal: 1.17s\tremaining: 3.1s\n",
      "274:\tlearn: 0.0801702\ttotal: 1.18s\tremaining: 3.1s\n",
      "275:\tlearn: 0.0800946\ttotal: 1.18s\tremaining: 3.09s\n",
      "276:\tlearn: 0.0799925\ttotal: 1.18s\tremaining: 3.09s\n",
      "277:\tlearn: 0.0798322\ttotal: 1.19s\tremaining: 3.08s\n",
      "278:\tlearn: 0.0796941\ttotal: 1.19s\tremaining: 3.08s\n",
      "279:\tlearn: 0.0795743\ttotal: 1.19s\tremaining: 3.07s\n",
      "280:\tlearn: 0.0794558\ttotal: 1.2s\tremaining: 3.07s\n",
      "281:\tlearn: 0.0793069\ttotal: 1.2s\tremaining: 3.06s\n",
      "282:\tlearn: 0.0791592\ttotal: 1.21s\tremaining: 3.06s\n",
      "283:\tlearn: 0.0790534\ttotal: 1.21s\tremaining: 3.05s\n",
      "284:\tlearn: 0.0789718\ttotal: 1.21s\tremaining: 3.05s\n",
      "285:\tlearn: 0.0788135\ttotal: 1.22s\tremaining: 3.04s\n",
      "286:\tlearn: 0.0786318\ttotal: 1.22s\tremaining: 3.04s\n",
      "287:\tlearn: 0.0784833\ttotal: 1.23s\tremaining: 3.03s\n",
      "288:\tlearn: 0.0783821\ttotal: 1.23s\tremaining: 3.03s\n",
      "289:\tlearn: 0.0781875\ttotal: 1.23s\tremaining: 3.02s\n",
      "290:\tlearn: 0.0780394\ttotal: 1.24s\tremaining: 3.02s\n",
      "291:\tlearn: 0.0779250\ttotal: 1.24s\tremaining: 3.01s\n",
      "292:\tlearn: 0.0777874\ttotal: 1.25s\tremaining: 3.01s\n",
      "293:\tlearn: 0.0776458\ttotal: 1.25s\tremaining: 3s\n",
      "294:\tlearn: 0.0775253\ttotal: 1.25s\tremaining: 3s\n",
      "295:\tlearn: 0.0773946\ttotal: 1.26s\tremaining: 2.99s\n",
      "296:\tlearn: 0.0772340\ttotal: 1.26s\tremaining: 2.99s\n",
      "297:\tlearn: 0.0770933\ttotal: 1.27s\tremaining: 2.98s\n",
      "298:\tlearn: 0.0769577\ttotal: 1.27s\tremaining: 2.98s\n",
      "299:\tlearn: 0.0768460\ttotal: 1.27s\tremaining: 2.97s\n",
      "300:\tlearn: 0.0767793\ttotal: 1.28s\tremaining: 2.97s\n",
      "301:\tlearn: 0.0766147\ttotal: 1.28s\tremaining: 2.96s\n",
      "302:\tlearn: 0.0764627\ttotal: 1.28s\tremaining: 2.95s\n",
      "303:\tlearn: 0.0763608\ttotal: 1.29s\tremaining: 2.95s\n",
      "304:\tlearn: 0.0763066\ttotal: 1.29s\tremaining: 2.94s\n",
      "305:\tlearn: 0.0762138\ttotal: 1.29s\tremaining: 2.94s\n",
      "306:\tlearn: 0.0760523\ttotal: 1.3s\tremaining: 2.94s\n",
      "307:\tlearn: 0.0759374\ttotal: 1.3s\tremaining: 2.93s\n",
      "308:\tlearn: 0.0758551\ttotal: 1.31s\tremaining: 2.93s\n",
      "309:\tlearn: 0.0757494\ttotal: 1.31s\tremaining: 2.92s\n",
      "310:\tlearn: 0.0756362\ttotal: 1.32s\tremaining: 2.92s\n",
      "311:\tlearn: 0.0754913\ttotal: 1.32s\tremaining: 2.91s\n",
      "312:\tlearn: 0.0754278\ttotal: 1.32s\tremaining: 2.91s\n",
      "313:\tlearn: 0.0753055\ttotal: 1.33s\tremaining: 2.9s\n",
      "314:\tlearn: 0.0751967\ttotal: 1.33s\tremaining: 2.9s\n",
      "315:\tlearn: 0.0751181\ttotal: 1.34s\tremaining: 2.89s\n",
      "316:\tlearn: 0.0750397\ttotal: 1.34s\tremaining: 2.89s\n",
      "317:\tlearn: 0.0747785\ttotal: 1.34s\tremaining: 2.88s\n",
      "318:\tlearn: 0.0745976\ttotal: 1.35s\tremaining: 2.88s\n",
      "319:\tlearn: 0.0745050\ttotal: 1.35s\tremaining: 2.87s\n",
      "320:\tlearn: 0.0743441\ttotal: 1.36s\tremaining: 2.87s\n",
      "321:\tlearn: 0.0742539\ttotal: 1.36s\tremaining: 2.87s\n",
      "322:\tlearn: 0.0740948\ttotal: 1.36s\tremaining: 2.86s\n",
      "323:\tlearn: 0.0739953\ttotal: 1.37s\tremaining: 2.85s\n",
      "324:\tlearn: 0.0738228\ttotal: 1.37s\tremaining: 2.85s\n",
      "325:\tlearn: 0.0736588\ttotal: 1.38s\tremaining: 2.85s\n",
      "326:\tlearn: 0.0735667\ttotal: 1.38s\tremaining: 2.84s\n",
      "327:\tlearn: 0.0734898\ttotal: 1.38s\tremaining: 2.83s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "328:\tlearn: 0.0733688\ttotal: 1.39s\tremaining: 2.83s\n",
      "329:\tlearn: 0.0731825\ttotal: 1.39s\tremaining: 2.83s\n",
      "330:\tlearn: 0.0730364\ttotal: 1.4s\tremaining: 2.82s\n",
      "331:\tlearn: 0.0729374\ttotal: 1.4s\tremaining: 2.82s\n",
      "332:\tlearn: 0.0728570\ttotal: 1.41s\tremaining: 2.82s\n",
      "333:\tlearn: 0.0727838\ttotal: 1.41s\tremaining: 2.81s\n",
      "334:\tlearn: 0.0726731\ttotal: 1.42s\tremaining: 2.81s\n",
      "335:\tlearn: 0.0724767\ttotal: 1.42s\tremaining: 2.81s\n",
      "336:\tlearn: 0.0723653\ttotal: 1.42s\tremaining: 2.8s\n",
      "337:\tlearn: 0.0722492\ttotal: 1.43s\tremaining: 2.8s\n",
      "338:\tlearn: 0.0721515\ttotal: 1.43s\tremaining: 2.79s\n",
      "339:\tlearn: 0.0720409\ttotal: 1.44s\tremaining: 2.79s\n",
      "340:\tlearn: 0.0718835\ttotal: 1.44s\tremaining: 2.78s\n",
      "341:\tlearn: 0.0717515\ttotal: 1.45s\tremaining: 2.78s\n",
      "342:\tlearn: 0.0716483\ttotal: 1.45s\tremaining: 2.78s\n",
      "343:\tlearn: 0.0714815\ttotal: 1.45s\tremaining: 2.77s\n",
      "344:\tlearn: 0.0713438\ttotal: 1.46s\tremaining: 2.77s\n",
      "345:\tlearn: 0.0712579\ttotal: 1.46s\tremaining: 2.76s\n",
      "346:\tlearn: 0.0711742\ttotal: 1.47s\tremaining: 2.76s\n",
      "347:\tlearn: 0.0710823\ttotal: 1.47s\tremaining: 2.75s\n",
      "348:\tlearn: 0.0710209\ttotal: 1.47s\tremaining: 2.75s\n",
      "349:\tlearn: 0.0709162\ttotal: 1.48s\tremaining: 2.74s\n",
      "350:\tlearn: 0.0707632\ttotal: 1.48s\tremaining: 2.74s\n",
      "351:\tlearn: 0.0706645\ttotal: 1.49s\tremaining: 2.74s\n",
      "352:\tlearn: 0.0704689\ttotal: 1.49s\tremaining: 2.73s\n",
      "353:\tlearn: 0.0703860\ttotal: 1.49s\tremaining: 2.73s\n",
      "354:\tlearn: 0.0702933\ttotal: 1.5s\tremaining: 2.72s\n",
      "355:\tlearn: 0.0700758\ttotal: 1.5s\tremaining: 2.72s\n",
      "356:\tlearn: 0.0700280\ttotal: 1.51s\tremaining: 2.71s\n",
      "357:\tlearn: 0.0699559\ttotal: 1.51s\tremaining: 2.71s\n",
      "358:\tlearn: 0.0697902\ttotal: 1.52s\tremaining: 2.71s\n",
      "359:\tlearn: 0.0696771\ttotal: 1.52s\tremaining: 2.7s\n",
      "360:\tlearn: 0.0695671\ttotal: 1.52s\tremaining: 2.7s\n",
      "361:\tlearn: 0.0695126\ttotal: 1.53s\tremaining: 2.69s\n",
      "362:\tlearn: 0.0694383\ttotal: 1.53s\tremaining: 2.69s\n",
      "363:\tlearn: 0.0692957\ttotal: 1.54s\tremaining: 2.68s\n",
      "364:\tlearn: 0.0691968\ttotal: 1.54s\tremaining: 2.68s\n",
      "365:\tlearn: 0.0690617\ttotal: 1.54s\tremaining: 2.68s\n",
      "366:\tlearn: 0.0689127\ttotal: 1.55s\tremaining: 2.67s\n",
      "367:\tlearn: 0.0688206\ttotal: 1.55s\tremaining: 2.67s\n",
      "368:\tlearn: 0.0686918\ttotal: 1.56s\tremaining: 2.67s\n",
      "369:\tlearn: 0.0686156\ttotal: 1.56s\tremaining: 2.66s\n",
      "370:\tlearn: 0.0684701\ttotal: 1.57s\tremaining: 2.66s\n",
      "371:\tlearn: 0.0683507\ttotal: 1.57s\tremaining: 2.65s\n",
      "372:\tlearn: 0.0682192\ttotal: 1.58s\tremaining: 2.65s\n",
      "373:\tlearn: 0.0680991\ttotal: 1.58s\tremaining: 2.65s\n",
      "374:\tlearn: 0.0680258\ttotal: 1.59s\tremaining: 2.65s\n",
      "375:\tlearn: 0.0679429\ttotal: 1.59s\tremaining: 2.64s\n",
      "376:\tlearn: 0.0678527\ttotal: 1.6s\tremaining: 2.64s\n",
      "377:\tlearn: 0.0677539\ttotal: 1.6s\tremaining: 2.63s\n",
      "378:\tlearn: 0.0676630\ttotal: 1.61s\tremaining: 2.63s\n",
      "379:\tlearn: 0.0676290\ttotal: 1.61s\tremaining: 2.63s\n",
      "380:\tlearn: 0.0674975\ttotal: 1.61s\tremaining: 2.62s\n",
      "381:\tlearn: 0.0673930\ttotal: 1.62s\tremaining: 2.62s\n",
      "382:\tlearn: 0.0672526\ttotal: 1.62s\tremaining: 2.61s\n",
      "383:\tlearn: 0.0671748\ttotal: 1.63s\tremaining: 2.61s\n",
      "384:\tlearn: 0.0670965\ttotal: 1.63s\tremaining: 2.6s\n",
      "385:\tlearn: 0.0670627\ttotal: 1.63s\tremaining: 2.6s\n",
      "386:\tlearn: 0.0670261\ttotal: 1.64s\tremaining: 2.59s\n",
      "387:\tlearn: 0.0669222\ttotal: 1.64s\tremaining: 2.59s\n",
      "388:\tlearn: 0.0667894\ttotal: 1.65s\tremaining: 2.59s\n",
      "389:\tlearn: 0.0667274\ttotal: 1.65s\tremaining: 2.58s\n",
      "390:\tlearn: 0.0666830\ttotal: 1.65s\tremaining: 2.58s\n",
      "391:\tlearn: 0.0666337\ttotal: 1.66s\tremaining: 2.57s\n",
      "392:\tlearn: 0.0665316\ttotal: 1.66s\tremaining: 2.57s\n",
      "393:\tlearn: 0.0664637\ttotal: 1.67s\tremaining: 2.56s\n",
      "394:\tlearn: 0.0663481\ttotal: 1.67s\tremaining: 2.56s\n",
      "395:\tlearn: 0.0662365\ttotal: 1.68s\tremaining: 2.56s\n",
      "396:\tlearn: 0.0661576\ttotal: 1.68s\tremaining: 2.56s\n",
      "397:\tlearn: 0.0660827\ttotal: 1.69s\tremaining: 2.55s\n",
      "398:\tlearn: 0.0659869\ttotal: 1.69s\tremaining: 2.55s\n",
      "399:\tlearn: 0.0658267\ttotal: 1.7s\tremaining: 2.54s\n",
      "400:\tlearn: 0.0656822\ttotal: 1.7s\tremaining: 2.54s\n",
      "401:\tlearn: 0.0656465\ttotal: 1.71s\tremaining: 2.54s\n",
      "402:\tlearn: 0.0654978\ttotal: 1.71s\tremaining: 2.53s\n",
      "403:\tlearn: 0.0654291\ttotal: 1.71s\tremaining: 2.53s\n",
      "404:\tlearn: 0.0653506\ttotal: 1.72s\tremaining: 2.52s\n",
      "405:\tlearn: 0.0651393\ttotal: 1.72s\tremaining: 2.52s\n",
      "406:\tlearn: 0.0650566\ttotal: 1.73s\tremaining: 2.52s\n",
      "407:\tlearn: 0.0648864\ttotal: 1.73s\tremaining: 2.51s\n",
      "408:\tlearn: 0.0648206\ttotal: 1.74s\tremaining: 2.51s\n",
      "409:\tlearn: 0.0647258\ttotal: 1.74s\tremaining: 2.51s\n",
      "410:\tlearn: 0.0646594\ttotal: 1.75s\tremaining: 2.5s\n",
      "411:\tlearn: 0.0646132\ttotal: 1.75s\tremaining: 2.5s\n",
      "412:\tlearn: 0.0645240\ttotal: 1.75s\tremaining: 2.49s\n",
      "413:\tlearn: 0.0644056\ttotal: 1.76s\tremaining: 2.49s\n",
      "414:\tlearn: 0.0643440\ttotal: 1.76s\tremaining: 2.49s\n",
      "415:\tlearn: 0.0642871\ttotal: 1.77s\tremaining: 2.48s\n",
      "416:\tlearn: 0.0641673\ttotal: 1.77s\tremaining: 2.48s\n",
      "417:\tlearn: 0.0640673\ttotal: 1.78s\tremaining: 2.47s\n",
      "418:\tlearn: 0.0638933\ttotal: 1.78s\tremaining: 2.47s\n",
      "419:\tlearn: 0.0637981\ttotal: 1.79s\tremaining: 2.47s\n",
      "420:\tlearn: 0.0637363\ttotal: 1.79s\tremaining: 2.46s\n",
      "421:\tlearn: 0.0637000\ttotal: 1.79s\tremaining: 2.46s\n",
      "422:\tlearn: 0.0635833\ttotal: 1.8s\tremaining: 2.45s\n",
      "423:\tlearn: 0.0634846\ttotal: 1.8s\tremaining: 2.45s\n",
      "424:\tlearn: 0.0634078\ttotal: 1.81s\tremaining: 2.45s\n",
      "425:\tlearn: 0.0633289\ttotal: 1.81s\tremaining: 2.44s\n",
      "426:\tlearn: 0.0632421\ttotal: 1.82s\tremaining: 2.44s\n",
      "427:\tlearn: 0.0631700\ttotal: 1.82s\tremaining: 2.43s\n",
      "428:\tlearn: 0.0630879\ttotal: 1.83s\tremaining: 2.43s\n",
      "429:\tlearn: 0.0629664\ttotal: 1.83s\tremaining: 2.43s\n",
      "430:\tlearn: 0.0629039\ttotal: 1.83s\tremaining: 2.42s\n",
      "431:\tlearn: 0.0627989\ttotal: 1.84s\tremaining: 2.42s\n",
      "432:\tlearn: 0.0627404\ttotal: 1.84s\tremaining: 2.41s\n",
      "433:\tlearn: 0.0626693\ttotal: 1.85s\tremaining: 2.41s\n",
      "434:\tlearn: 0.0625711\ttotal: 1.85s\tremaining: 2.4s\n",
      "435:\tlearn: 0.0624553\ttotal: 1.85s\tremaining: 2.4s\n",
      "436:\tlearn: 0.0623202\ttotal: 1.86s\tremaining: 2.4s\n",
      "437:\tlearn: 0.0621864\ttotal: 1.86s\tremaining: 2.39s\n",
      "438:\tlearn: 0.0621116\ttotal: 1.87s\tremaining: 2.39s\n",
      "439:\tlearn: 0.0620801\ttotal: 1.87s\tremaining: 2.38s\n",
      "440:\tlearn: 0.0619885\ttotal: 1.88s\tremaining: 2.38s\n",
      "441:\tlearn: 0.0619582\ttotal: 1.88s\tremaining: 2.37s\n",
      "442:\tlearn: 0.0619101\ttotal: 1.89s\tremaining: 2.37s\n",
      "443:\tlearn: 0.0618079\ttotal: 1.89s\tremaining: 2.37s\n",
      "444:\tlearn: 0.0617022\ttotal: 1.89s\tremaining: 2.36s\n",
      "445:\tlearn: 0.0616679\ttotal: 1.9s\tremaining: 2.36s\n",
      "446:\tlearn: 0.0615977\ttotal: 1.9s\tremaining: 2.35s\n",
      "447:\tlearn: 0.0615708\ttotal: 1.91s\tremaining: 2.35s\n",
      "448:\tlearn: 0.0614054\ttotal: 1.91s\tremaining: 2.34s\n",
      "449:\tlearn: 0.0612619\ttotal: 1.91s\tremaining: 2.34s\n",
      "450:\tlearn: 0.0611646\ttotal: 1.92s\tremaining: 2.33s\n",
      "451:\tlearn: 0.0610583\ttotal: 1.92s\tremaining: 2.33s\n",
      "452:\tlearn: 0.0609887\ttotal: 1.93s\tremaining: 2.33s\n",
      "453:\tlearn: 0.0609260\ttotal: 1.93s\tremaining: 2.32s\n",
      "454:\tlearn: 0.0607904\ttotal: 1.93s\tremaining: 2.32s\n",
      "455:\tlearn: 0.0607389\ttotal: 1.94s\tremaining: 2.31s\n",
      "456:\tlearn: 0.0606778\ttotal: 1.94s\tremaining: 2.31s\n",
      "457:\tlearn: 0.0605742\ttotal: 1.95s\tremaining: 2.3s\n",
      "458:\tlearn: 0.0604965\ttotal: 1.95s\tremaining: 2.3s\n",
      "459:\tlearn: 0.0604333\ttotal: 1.96s\tremaining: 2.29s\n",
      "460:\tlearn: 0.0604115\ttotal: 1.96s\tremaining: 2.29s\n",
      "461:\tlearn: 0.0603025\ttotal: 1.96s\tremaining: 2.29s\n",
      "462:\tlearn: 0.0602180\ttotal: 1.97s\tremaining: 2.28s\n",
      "463:\tlearn: 0.0601767\ttotal: 1.97s\tremaining: 2.28s\n",
      "464:\tlearn: 0.0601017\ttotal: 1.98s\tremaining: 2.27s\n",
      "465:\tlearn: 0.0600017\ttotal: 1.98s\tremaining: 2.27s\n",
      "466:\tlearn: 0.0599408\ttotal: 1.99s\tremaining: 2.27s\n",
      "467:\tlearn: 0.0598893\ttotal: 1.99s\tremaining: 2.26s\n",
      "468:\tlearn: 0.0598043\ttotal: 1.99s\tremaining: 2.26s\n",
      "469:\tlearn: 0.0597631\ttotal: 2s\tremaining: 2.25s\n",
      "470:\tlearn: 0.0597044\ttotal: 2s\tremaining: 2.25s\n",
      "471:\tlearn: 0.0595953\ttotal: 2.01s\tremaining: 2.25s\n",
      "472:\tlearn: 0.0594921\ttotal: 2.01s\tremaining: 2.24s\n",
      "473:\tlearn: 0.0594124\ttotal: 2.02s\tremaining: 2.24s\n",
      "474:\tlearn: 0.0593443\ttotal: 2.02s\tremaining: 2.23s\n",
      "475:\tlearn: 0.0592907\ttotal: 2.03s\tremaining: 2.23s\n",
      "476:\tlearn: 0.0592176\ttotal: 2.03s\tremaining: 2.23s\n",
      "477:\tlearn: 0.0590824\ttotal: 2.04s\tremaining: 2.22s\n",
      "478:\tlearn: 0.0590125\ttotal: 2.04s\tremaining: 2.22s\n",
      "479:\tlearn: 0.0588926\ttotal: 2.04s\tremaining: 2.21s\n",
      "480:\tlearn: 0.0587859\ttotal: 2.05s\tremaining: 2.21s\n",
      "481:\tlearn: 0.0587097\ttotal: 2.05s\tremaining: 2.21s\n",
      "482:\tlearn: 0.0586596\ttotal: 2.06s\tremaining: 2.2s\n",
      "483:\tlearn: 0.0585669\ttotal: 2.06s\tremaining: 2.2s\n",
      "484:\tlearn: 0.0584853\ttotal: 2.07s\tremaining: 2.19s\n",
      "485:\tlearn: 0.0584184\ttotal: 2.07s\tremaining: 2.19s\n",
      "486:\tlearn: 0.0582836\ttotal: 2.08s\tremaining: 2.19s\n",
      "487:\tlearn: 0.0581910\ttotal: 2.08s\tremaining: 2.18s\n",
      "488:\tlearn: 0.0581196\ttotal: 2.08s\tremaining: 2.18s\n",
      "489:\tlearn: 0.0580592\ttotal: 2.09s\tremaining: 2.17s\n",
      "490:\tlearn: 0.0580180\ttotal: 2.09s\tremaining: 2.17s\n",
      "491:\tlearn: 0.0579080\ttotal: 2.1s\tremaining: 2.16s\n",
      "492:\tlearn: 0.0578722\ttotal: 2.1s\tremaining: 2.16s\n",
      "493:\tlearn: 0.0577882\ttotal: 2.1s\tremaining: 2.15s\n",
      "494:\tlearn: 0.0577030\ttotal: 2.11s\tremaining: 2.15s\n",
      "495:\tlearn: 0.0576158\ttotal: 2.11s\tremaining: 2.15s\n",
      "496:\tlearn: 0.0575465\ttotal: 2.12s\tremaining: 2.14s\n",
      "497:\tlearn: 0.0574943\ttotal: 2.12s\tremaining: 2.14s\n",
      "498:\tlearn: 0.0574138\ttotal: 2.12s\tremaining: 2.13s\n",
      "499:\tlearn: 0.0573651\ttotal: 2.13s\tremaining: 2.13s\n",
      "500:\tlearn: 0.0572861\ttotal: 2.13s\tremaining: 2.12s\n",
      "501:\tlearn: 0.0572094\ttotal: 2.13s\tremaining: 2.12s\n",
      "502:\tlearn: 0.0570939\ttotal: 2.14s\tremaining: 2.11s\n",
      "503:\tlearn: 0.0570354\ttotal: 2.14s\tremaining: 2.11s\n",
      "504:\tlearn: 0.0569775\ttotal: 2.15s\tremaining: 2.1s\n",
      "505:\tlearn: 0.0568872\ttotal: 2.15s\tremaining: 2.1s\n",
      "506:\tlearn: 0.0568273\ttotal: 2.15s\tremaining: 2.09s\n",
      "507:\tlearn: 0.0567875\ttotal: 2.15s\tremaining: 2.09s\n",
      "508:\tlearn: 0.0567544\ttotal: 2.16s\tremaining: 2.08s\n",
      "509:\tlearn: 0.0566639\ttotal: 2.16s\tremaining: 2.08s\n",
      "510:\tlearn: 0.0565547\ttotal: 2.17s\tremaining: 2.07s\n",
      "511:\tlearn: 0.0565316\ttotal: 2.17s\tremaining: 2.07s\n",
      "512:\tlearn: 0.0565072\ttotal: 2.18s\tremaining: 2.06s\n",
      "513:\tlearn: 0.0564857\ttotal: 2.18s\tremaining: 2.06s\n",
      "514:\tlearn: 0.0564575\ttotal: 2.18s\tremaining: 2.06s\n",
      "515:\tlearn: 0.0564024\ttotal: 2.19s\tremaining: 2.05s\n",
      "516:\tlearn: 0.0563340\ttotal: 2.19s\tremaining: 2.05s\n",
      "517:\tlearn: 0.0562305\ttotal: 2.19s\tremaining: 2.04s\n",
      "518:\tlearn: 0.0561480\ttotal: 2.2s\tremaining: 2.04s\n",
      "519:\tlearn: 0.0560507\ttotal: 2.2s\tremaining: 2.03s\n",
      "520:\tlearn: 0.0559744\ttotal: 2.21s\tremaining: 2.03s\n",
      "521:\tlearn: 0.0558954\ttotal: 2.21s\tremaining: 2.02s\n",
      "522:\tlearn: 0.0558433\ttotal: 2.21s\tremaining: 2.02s\n",
      "523:\tlearn: 0.0557988\ttotal: 2.22s\tremaining: 2.01s\n",
      "524:\tlearn: 0.0557486\ttotal: 2.22s\tremaining: 2.01s\n",
      "525:\tlearn: 0.0557007\ttotal: 2.22s\tremaining: 2s\n",
      "526:\tlearn: 0.0556153\ttotal: 2.23s\tremaining: 2s\n",
      "527:\tlearn: 0.0555660\ttotal: 2.23s\tremaining: 2s\n",
      "528:\tlearn: 0.0554960\ttotal: 2.24s\tremaining: 1.99s\n",
      "529:\tlearn: 0.0554328\ttotal: 2.24s\tremaining: 1.99s\n",
      "530:\tlearn: 0.0553961\ttotal: 2.24s\tremaining: 1.98s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "531:\tlearn: 0.0553610\ttotal: 2.25s\tremaining: 1.98s\n",
      "532:\tlearn: 0.0552573\ttotal: 2.25s\tremaining: 1.97s\n",
      "533:\tlearn: 0.0551839\ttotal: 2.25s\tremaining: 1.97s\n",
      "534:\tlearn: 0.0551260\ttotal: 2.26s\tremaining: 1.96s\n",
      "535:\tlearn: 0.0550881\ttotal: 2.26s\tremaining: 1.96s\n",
      "536:\tlearn: 0.0550511\ttotal: 2.27s\tremaining: 1.96s\n",
      "537:\tlearn: 0.0549450\ttotal: 2.27s\tremaining: 1.95s\n",
      "538:\tlearn: 0.0548603\ttotal: 2.27s\tremaining: 1.95s\n",
      "539:\tlearn: 0.0548016\ttotal: 2.28s\tremaining: 1.94s\n",
      "540:\tlearn: 0.0547453\ttotal: 2.28s\tremaining: 1.94s\n",
      "541:\tlearn: 0.0547272\ttotal: 2.29s\tremaining: 1.93s\n",
      "542:\tlearn: 0.0546886\ttotal: 2.29s\tremaining: 1.93s\n",
      "543:\tlearn: 0.0546393\ttotal: 2.3s\tremaining: 1.92s\n",
      "544:\tlearn: 0.0545786\ttotal: 2.3s\tremaining: 1.92s\n",
      "545:\tlearn: 0.0544873\ttotal: 2.3s\tremaining: 1.92s\n",
      "546:\tlearn: 0.0544293\ttotal: 2.31s\tremaining: 1.91s\n",
      "547:\tlearn: 0.0543424\ttotal: 2.31s\tremaining: 1.91s\n",
      "548:\tlearn: 0.0542621\ttotal: 2.31s\tremaining: 1.9s\n",
      "549:\tlearn: 0.0541737\ttotal: 2.32s\tremaining: 1.9s\n",
      "550:\tlearn: 0.0540530\ttotal: 2.32s\tremaining: 1.89s\n",
      "551:\tlearn: 0.0540067\ttotal: 2.33s\tremaining: 1.89s\n",
      "552:\tlearn: 0.0539541\ttotal: 2.33s\tremaining: 1.88s\n",
      "553:\tlearn: 0.0538653\ttotal: 2.33s\tremaining: 1.88s\n",
      "554:\tlearn: 0.0537998\ttotal: 2.34s\tremaining: 1.87s\n",
      "555:\tlearn: 0.0537459\ttotal: 2.34s\tremaining: 1.87s\n",
      "556:\tlearn: 0.0536380\ttotal: 2.35s\tremaining: 1.86s\n",
      "557:\tlearn: 0.0536007\ttotal: 2.35s\tremaining: 1.86s\n",
      "558:\tlearn: 0.0535097\ttotal: 2.35s\tremaining: 1.86s\n",
      "559:\tlearn: 0.0534426\ttotal: 2.36s\tremaining: 1.85s\n",
      "560:\tlearn: 0.0533381\ttotal: 2.36s\tremaining: 1.85s\n",
      "561:\tlearn: 0.0532840\ttotal: 2.36s\tremaining: 1.84s\n",
      "562:\tlearn: 0.0532512\ttotal: 2.37s\tremaining: 1.84s\n",
      "563:\tlearn: 0.0531921\ttotal: 2.37s\tremaining: 1.83s\n",
      "564:\tlearn: 0.0531483\ttotal: 2.38s\tremaining: 1.83s\n",
      "565:\tlearn: 0.0530855\ttotal: 2.38s\tremaining: 1.82s\n",
      "566:\tlearn: 0.0530423\ttotal: 2.38s\tremaining: 1.82s\n",
      "567:\tlearn: 0.0529944\ttotal: 2.39s\tremaining: 1.81s\n",
      "568:\tlearn: 0.0529340\ttotal: 2.39s\tremaining: 1.81s\n",
      "569:\tlearn: 0.0529006\ttotal: 2.39s\tremaining: 1.8s\n",
      "570:\tlearn: 0.0528661\ttotal: 2.4s\tremaining: 1.8s\n",
      "571:\tlearn: 0.0527918\ttotal: 2.4s\tremaining: 1.8s\n",
      "572:\tlearn: 0.0527413\ttotal: 2.4s\tremaining: 1.79s\n",
      "573:\tlearn: 0.0526364\ttotal: 2.41s\tremaining: 1.79s\n",
      "574:\tlearn: 0.0526010\ttotal: 2.41s\tremaining: 1.78s\n",
      "575:\tlearn: 0.0525880\ttotal: 2.42s\tremaining: 1.78s\n",
      "576:\tlearn: 0.0524806\ttotal: 2.42s\tremaining: 1.77s\n",
      "577:\tlearn: 0.0524435\ttotal: 2.42s\tremaining: 1.77s\n",
      "578:\tlearn: 0.0523925\ttotal: 2.43s\tremaining: 1.76s\n",
      "579:\tlearn: 0.0523057\ttotal: 2.43s\tremaining: 1.76s\n",
      "580:\tlearn: 0.0522235\ttotal: 2.44s\tremaining: 1.76s\n",
      "581:\tlearn: 0.0521465\ttotal: 2.44s\tremaining: 1.75s\n",
      "582:\tlearn: 0.0520969\ttotal: 2.44s\tremaining: 1.75s\n",
      "583:\tlearn: 0.0520024\ttotal: 2.45s\tremaining: 1.74s\n",
      "584:\tlearn: 0.0519158\ttotal: 2.45s\tremaining: 1.74s\n",
      "585:\tlearn: 0.0518785\ttotal: 2.46s\tremaining: 1.73s\n",
      "586:\tlearn: 0.0518282\ttotal: 2.46s\tremaining: 1.73s\n",
      "587:\tlearn: 0.0517833\ttotal: 2.46s\tremaining: 1.73s\n",
      "588:\tlearn: 0.0517037\ttotal: 2.47s\tremaining: 1.72s\n",
      "589:\tlearn: 0.0515954\ttotal: 2.47s\tremaining: 1.72s\n",
      "590:\tlearn: 0.0515451\ttotal: 2.47s\tremaining: 1.71s\n",
      "591:\tlearn: 0.0515137\ttotal: 2.48s\tremaining: 1.71s\n",
      "592:\tlearn: 0.0514295\ttotal: 2.48s\tremaining: 1.7s\n",
      "593:\tlearn: 0.0513837\ttotal: 2.48s\tremaining: 1.7s\n",
      "594:\tlearn: 0.0513461\ttotal: 2.49s\tremaining: 1.69s\n",
      "595:\tlearn: 0.0512800\ttotal: 2.49s\tremaining: 1.69s\n",
      "596:\tlearn: 0.0512430\ttotal: 2.5s\tremaining: 1.69s\n",
      "597:\tlearn: 0.0511440\ttotal: 2.5s\tremaining: 1.68s\n",
      "598:\tlearn: 0.0511159\ttotal: 2.5s\tremaining: 1.68s\n",
      "599:\tlearn: 0.0510820\ttotal: 2.51s\tremaining: 1.67s\n",
      "600:\tlearn: 0.0510106\ttotal: 2.51s\tremaining: 1.67s\n",
      "601:\tlearn: 0.0509441\ttotal: 2.52s\tremaining: 1.66s\n",
      "602:\tlearn: 0.0509328\ttotal: 2.52s\tremaining: 1.66s\n",
      "603:\tlearn: 0.0508714\ttotal: 2.52s\tremaining: 1.65s\n",
      "604:\tlearn: 0.0507920\ttotal: 2.53s\tremaining: 1.65s\n",
      "605:\tlearn: 0.0507531\ttotal: 2.53s\tremaining: 1.65s\n",
      "606:\tlearn: 0.0507255\ttotal: 2.54s\tremaining: 1.64s\n",
      "607:\tlearn: 0.0506811\ttotal: 2.54s\tremaining: 1.64s\n",
      "608:\tlearn: 0.0506548\ttotal: 2.54s\tremaining: 1.63s\n",
      "609:\tlearn: 0.0506115\ttotal: 2.55s\tremaining: 1.63s\n",
      "610:\tlearn: 0.0505551\ttotal: 2.55s\tremaining: 1.63s\n",
      "611:\tlearn: 0.0505109\ttotal: 2.56s\tremaining: 1.62s\n",
      "612:\tlearn: 0.0504509\ttotal: 2.56s\tremaining: 1.62s\n",
      "613:\tlearn: 0.0504336\ttotal: 2.57s\tremaining: 1.61s\n",
      "614:\tlearn: 0.0504164\ttotal: 2.57s\tremaining: 1.61s\n",
      "615:\tlearn: 0.0503741\ttotal: 2.58s\tremaining: 1.61s\n",
      "616:\tlearn: 0.0503043\ttotal: 2.58s\tremaining: 1.6s\n",
      "617:\tlearn: 0.0502578\ttotal: 2.58s\tremaining: 1.6s\n",
      "618:\tlearn: 0.0502386\ttotal: 2.59s\tremaining: 1.59s\n",
      "619:\tlearn: 0.0501955\ttotal: 2.59s\tremaining: 1.59s\n",
      "620:\tlearn: 0.0501618\ttotal: 2.6s\tremaining: 1.59s\n",
      "621:\tlearn: 0.0500982\ttotal: 2.6s\tremaining: 1.58s\n",
      "622:\tlearn: 0.0500577\ttotal: 2.61s\tremaining: 1.58s\n",
      "623:\tlearn: 0.0500060\ttotal: 2.61s\tremaining: 1.57s\n",
      "624:\tlearn: 0.0499611\ttotal: 2.62s\tremaining: 1.57s\n",
      "625:\tlearn: 0.0499176\ttotal: 2.62s\tremaining: 1.56s\n",
      "626:\tlearn: 0.0499009\ttotal: 2.63s\tremaining: 1.56s\n",
      "627:\tlearn: 0.0498509\ttotal: 2.63s\tremaining: 1.56s\n",
      "628:\tlearn: 0.0498095\ttotal: 2.63s\tremaining: 1.55s\n",
      "629:\tlearn: 0.0497797\ttotal: 2.64s\tremaining: 1.55s\n",
      "630:\tlearn: 0.0497567\ttotal: 2.64s\tremaining: 1.54s\n",
      "631:\tlearn: 0.0497210\ttotal: 2.64s\tremaining: 1.54s\n",
      "632:\tlearn: 0.0496968\ttotal: 2.65s\tremaining: 1.53s\n",
      "633:\tlearn: 0.0496525\ttotal: 2.65s\tremaining: 1.53s\n",
      "634:\tlearn: 0.0496029\ttotal: 2.66s\tremaining: 1.53s\n",
      "635:\tlearn: 0.0495842\ttotal: 2.66s\tremaining: 1.52s\n",
      "636:\tlearn: 0.0495364\ttotal: 2.66s\tremaining: 1.52s\n",
      "637:\tlearn: 0.0495202\ttotal: 2.67s\tremaining: 1.51s\n",
      "638:\tlearn: 0.0494750\ttotal: 2.67s\tremaining: 1.51s\n",
      "639:\tlearn: 0.0494115\ttotal: 2.67s\tremaining: 1.5s\n",
      "640:\tlearn: 0.0493740\ttotal: 2.68s\tremaining: 1.5s\n",
      "641:\tlearn: 0.0493326\ttotal: 2.68s\tremaining: 1.5s\n",
      "642:\tlearn: 0.0492826\ttotal: 2.69s\tremaining: 1.49s\n",
      "643:\tlearn: 0.0492368\ttotal: 2.69s\tremaining: 1.49s\n",
      "644:\tlearn: 0.0491648\ttotal: 2.69s\tremaining: 1.48s\n",
      "645:\tlearn: 0.0491161\ttotal: 2.7s\tremaining: 1.48s\n",
      "646:\tlearn: 0.0490905\ttotal: 2.7s\tremaining: 1.47s\n",
      "647:\tlearn: 0.0490714\ttotal: 2.7s\tremaining: 1.47s\n",
      "648:\tlearn: 0.0489917\ttotal: 2.71s\tremaining: 1.47s\n",
      "649:\tlearn: 0.0489553\ttotal: 2.71s\tremaining: 1.46s\n",
      "650:\tlearn: 0.0489403\ttotal: 2.72s\tremaining: 1.46s\n",
      "651:\tlearn: 0.0488671\ttotal: 2.72s\tremaining: 1.45s\n",
      "652:\tlearn: 0.0488309\ttotal: 2.72s\tremaining: 1.45s\n",
      "653:\tlearn: 0.0488129\ttotal: 2.73s\tremaining: 1.44s\n",
      "654:\tlearn: 0.0487689\ttotal: 2.73s\tremaining: 1.44s\n",
      "655:\tlearn: 0.0487224\ttotal: 2.73s\tremaining: 1.43s\n",
      "656:\tlearn: 0.0486747\ttotal: 2.74s\tremaining: 1.43s\n",
      "657:\tlearn: 0.0486126\ttotal: 2.74s\tremaining: 1.43s\n",
      "658:\tlearn: 0.0485889\ttotal: 2.75s\tremaining: 1.42s\n",
      "659:\tlearn: 0.0485511\ttotal: 2.75s\tremaining: 1.42s\n",
      "660:\tlearn: 0.0485156\ttotal: 2.76s\tremaining: 1.41s\n",
      "661:\tlearn: 0.0484822\ttotal: 2.76s\tremaining: 1.41s\n",
      "662:\tlearn: 0.0484573\ttotal: 2.77s\tremaining: 1.41s\n",
      "663:\tlearn: 0.0484358\ttotal: 2.77s\tremaining: 1.4s\n",
      "664:\tlearn: 0.0483962\ttotal: 2.77s\tremaining: 1.4s\n",
      "665:\tlearn: 0.0483338\ttotal: 2.78s\tremaining: 1.39s\n",
      "666:\tlearn: 0.0482379\ttotal: 2.78s\tremaining: 1.39s\n",
      "667:\tlearn: 0.0481861\ttotal: 2.79s\tremaining: 1.39s\n",
      "668:\tlearn: 0.0481663\ttotal: 2.79s\tremaining: 1.38s\n",
      "669:\tlearn: 0.0481404\ttotal: 2.79s\tremaining: 1.38s\n",
      "670:\tlearn: 0.0480989\ttotal: 2.8s\tremaining: 1.37s\n",
      "671:\tlearn: 0.0480468\ttotal: 2.8s\tremaining: 1.37s\n",
      "672:\tlearn: 0.0479591\ttotal: 2.81s\tremaining: 1.36s\n",
      "673:\tlearn: 0.0479116\ttotal: 2.81s\tremaining: 1.36s\n",
      "674:\tlearn: 0.0478465\ttotal: 2.81s\tremaining: 1.35s\n",
      "675:\tlearn: 0.0477606\ttotal: 2.82s\tremaining: 1.35s\n",
      "676:\tlearn: 0.0476859\ttotal: 2.82s\tremaining: 1.35s\n",
      "677:\tlearn: 0.0476636\ttotal: 2.83s\tremaining: 1.34s\n",
      "678:\tlearn: 0.0476254\ttotal: 2.83s\tremaining: 1.34s\n",
      "679:\tlearn: 0.0475908\ttotal: 2.83s\tremaining: 1.33s\n",
      "680:\tlearn: 0.0475572\ttotal: 2.84s\tremaining: 1.33s\n",
      "681:\tlearn: 0.0475237\ttotal: 2.84s\tremaining: 1.32s\n",
      "682:\tlearn: 0.0474842\ttotal: 2.84s\tremaining: 1.32s\n",
      "683:\tlearn: 0.0474059\ttotal: 2.85s\tremaining: 1.31s\n",
      "684:\tlearn: 0.0473722\ttotal: 2.85s\tremaining: 1.31s\n",
      "685:\tlearn: 0.0473369\ttotal: 2.85s\tremaining: 1.31s\n",
      "686:\tlearn: 0.0472942\ttotal: 2.86s\tremaining: 1.3s\n",
      "687:\tlearn: 0.0472443\ttotal: 2.86s\tremaining: 1.3s\n",
      "688:\tlearn: 0.0471929\ttotal: 2.87s\tremaining: 1.29s\n",
      "689:\tlearn: 0.0471786\ttotal: 2.87s\tremaining: 1.29s\n",
      "690:\tlearn: 0.0471576\ttotal: 2.87s\tremaining: 1.28s\n",
      "691:\tlearn: 0.0471125\ttotal: 2.88s\tremaining: 1.28s\n",
      "692:\tlearn: 0.0471023\ttotal: 2.88s\tremaining: 1.28s\n",
      "693:\tlearn: 0.0470410\ttotal: 2.88s\tremaining: 1.27s\n",
      "694:\tlearn: 0.0470076\ttotal: 2.89s\tremaining: 1.27s\n",
      "695:\tlearn: 0.0469077\ttotal: 2.9s\tremaining: 1.26s\n",
      "696:\tlearn: 0.0468766\ttotal: 2.91s\tremaining: 1.26s\n",
      "697:\tlearn: 0.0468573\ttotal: 2.91s\tremaining: 1.26s\n",
      "698:\tlearn: 0.0467804\ttotal: 2.93s\tremaining: 1.26s\n",
      "699:\tlearn: 0.0467148\ttotal: 2.93s\tremaining: 1.26s\n",
      "700:\tlearn: 0.0466282\ttotal: 2.94s\tremaining: 1.25s\n",
      "701:\tlearn: 0.0465892\ttotal: 2.94s\tremaining: 1.25s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "702:\tlearn: 0.0465552\ttotal: 2.95s\tremaining: 1.25s\n",
      "703:\tlearn: 0.0465359\ttotal: 2.95s\tremaining: 1.24s\n",
      "704:\tlearn: 0.0464870\ttotal: 2.96s\tremaining: 1.24s\n",
      "705:\tlearn: 0.0464613\ttotal: 2.96s\tremaining: 1.23s\n",
      "706:\tlearn: 0.0464314\ttotal: 2.96s\tremaining: 1.23s\n",
      "707:\tlearn: 0.0463865\ttotal: 2.97s\tremaining: 1.22s\n",
      "708:\tlearn: 0.0463703\ttotal: 2.97s\tremaining: 1.22s\n",
      "709:\tlearn: 0.0463375\ttotal: 2.98s\tremaining: 1.22s\n",
      "710:\tlearn: 0.0463069\ttotal: 2.98s\tremaining: 1.21s\n",
      "711:\tlearn: 0.0462881\ttotal: 2.98s\tremaining: 1.21s\n",
      "712:\tlearn: 0.0462537\ttotal: 2.99s\tremaining: 1.2s\n",
      "713:\tlearn: 0.0462136\ttotal: 2.99s\tremaining: 1.2s\n",
      "714:\tlearn: 0.0461808\ttotal: 3s\tremaining: 1.2s\n",
      "715:\tlearn: 0.0461343\ttotal: 3s\tremaining: 1.19s\n",
      "716:\tlearn: 0.0460925\ttotal: 3.01s\tremaining: 1.19s\n",
      "717:\tlearn: 0.0460320\ttotal: 3.01s\tremaining: 1.18s\n",
      "718:\tlearn: 0.0459936\ttotal: 3.02s\tremaining: 1.18s\n",
      "719:\tlearn: 0.0459560\ttotal: 3.02s\tremaining: 1.17s\n",
      "720:\tlearn: 0.0459411\ttotal: 3.02s\tremaining: 1.17s\n",
      "721:\tlearn: 0.0458661\ttotal: 3.03s\tremaining: 1.17s\n",
      "722:\tlearn: 0.0458477\ttotal: 3.03s\tremaining: 1.16s\n",
      "723:\tlearn: 0.0458048\ttotal: 3.04s\tremaining: 1.16s\n",
      "724:\tlearn: 0.0457219\ttotal: 3.04s\tremaining: 1.15s\n",
      "725:\tlearn: 0.0456306\ttotal: 3.04s\tremaining: 1.15s\n",
      "726:\tlearn: 0.0455848\ttotal: 3.05s\tremaining: 1.14s\n",
      "727:\tlearn: 0.0455544\ttotal: 3.05s\tremaining: 1.14s\n",
      "728:\tlearn: 0.0454903\ttotal: 3.06s\tremaining: 1.14s\n",
      "729:\tlearn: 0.0454612\ttotal: 3.06s\tremaining: 1.13s\n",
      "730:\tlearn: 0.0454224\ttotal: 3.07s\tremaining: 1.13s\n",
      "731:\tlearn: 0.0453671\ttotal: 3.07s\tremaining: 1.12s\n",
      "732:\tlearn: 0.0452953\ttotal: 3.08s\tremaining: 1.12s\n",
      "733:\tlearn: 0.0452555\ttotal: 3.08s\tremaining: 1.12s\n",
      "734:\tlearn: 0.0452273\ttotal: 3.08s\tremaining: 1.11s\n",
      "735:\tlearn: 0.0452172\ttotal: 3.09s\tremaining: 1.11s\n",
      "736:\tlearn: 0.0451920\ttotal: 3.09s\tremaining: 1.1s\n",
      "737:\tlearn: 0.0451547\ttotal: 3.1s\tremaining: 1.1s\n",
      "738:\tlearn: 0.0451270\ttotal: 3.1s\tremaining: 1.09s\n",
      "739:\tlearn: 0.0450836\ttotal: 3.11s\tremaining: 1.09s\n",
      "740:\tlearn: 0.0450550\ttotal: 3.11s\tremaining: 1.09s\n",
      "741:\tlearn: 0.0449921\ttotal: 3.11s\tremaining: 1.08s\n",
      "742:\tlearn: 0.0449481\ttotal: 3.12s\tremaining: 1.08s\n",
      "743:\tlearn: 0.0449192\ttotal: 3.12s\tremaining: 1.07s\n",
      "744:\tlearn: 0.0448501\ttotal: 3.13s\tremaining: 1.07s\n",
      "745:\tlearn: 0.0448209\ttotal: 3.13s\tremaining: 1.07s\n",
      "746:\tlearn: 0.0447042\ttotal: 3.14s\tremaining: 1.06s\n",
      "747:\tlearn: 0.0446384\ttotal: 3.14s\tremaining: 1.06s\n",
      "748:\tlearn: 0.0446072\ttotal: 3.14s\tremaining: 1.05s\n",
      "749:\tlearn: 0.0445705\ttotal: 3.15s\tremaining: 1.05s\n",
      "750:\tlearn: 0.0445462\ttotal: 3.15s\tremaining: 1.04s\n",
      "751:\tlearn: 0.0445198\ttotal: 3.16s\tremaining: 1.04s\n",
      "752:\tlearn: 0.0444402\ttotal: 3.16s\tremaining: 1.04s\n",
      "753:\tlearn: 0.0444016\ttotal: 3.17s\tremaining: 1.03s\n",
      "754:\tlearn: 0.0443500\ttotal: 3.17s\tremaining: 1.03s\n",
      "755:\tlearn: 0.0443068\ttotal: 3.17s\tremaining: 1.02s\n",
      "756:\tlearn: 0.0442806\ttotal: 3.18s\tremaining: 1.02s\n",
      "757:\tlearn: 0.0442324\ttotal: 3.18s\tremaining: 1.02s\n",
      "758:\tlearn: 0.0442073\ttotal: 3.19s\tremaining: 1.01s\n",
      "759:\tlearn: 0.0441823\ttotal: 3.19s\tremaining: 1.01s\n",
      "760:\tlearn: 0.0441542\ttotal: 3.19s\tremaining: 1s\n",
      "761:\tlearn: 0.0440933\ttotal: 3.2s\tremaining: 999ms\n",
      "762:\tlearn: 0.0440445\ttotal: 3.2s\tremaining: 995ms\n",
      "763:\tlearn: 0.0439788\ttotal: 3.21s\tremaining: 991ms\n",
      "764:\tlearn: 0.0439533\ttotal: 3.21s\tremaining: 986ms\n",
      "765:\tlearn: 0.0439401\ttotal: 3.21s\tremaining: 982ms\n",
      "766:\tlearn: 0.0439010\ttotal: 3.22s\tremaining: 978ms\n",
      "767:\tlearn: 0.0437925\ttotal: 3.22s\tremaining: 973ms\n",
      "768:\tlearn: 0.0437521\ttotal: 3.23s\tremaining: 969ms\n",
      "769:\tlearn: 0.0437265\ttotal: 3.23s\tremaining: 965ms\n",
      "770:\tlearn: 0.0437147\ttotal: 3.23s\tremaining: 961ms\n",
      "771:\tlearn: 0.0436887\ttotal: 3.24s\tremaining: 956ms\n",
      "772:\tlearn: 0.0436634\ttotal: 3.24s\tremaining: 952ms\n",
      "773:\tlearn: 0.0436386\ttotal: 3.25s\tremaining: 948ms\n",
      "774:\tlearn: 0.0436013\ttotal: 3.25s\tremaining: 944ms\n",
      "775:\tlearn: 0.0435544\ttotal: 3.25s\tremaining: 939ms\n",
      "776:\tlearn: 0.0435306\ttotal: 3.26s\tremaining: 935ms\n",
      "777:\tlearn: 0.0434918\ttotal: 3.26s\tremaining: 931ms\n",
      "778:\tlearn: 0.0434327\ttotal: 3.27s\tremaining: 927ms\n",
      "779:\tlearn: 0.0433952\ttotal: 3.27s\tremaining: 923ms\n",
      "780:\tlearn: 0.0433500\ttotal: 3.27s\tremaining: 918ms\n",
      "781:\tlearn: 0.0433234\ttotal: 3.28s\tremaining: 914ms\n",
      "782:\tlearn: 0.0432674\ttotal: 3.28s\tremaining: 910ms\n",
      "783:\tlearn: 0.0432494\ttotal: 3.29s\tremaining: 905ms\n",
      "784:\tlearn: 0.0432004\ttotal: 3.29s\tremaining: 901ms\n",
      "785:\tlearn: 0.0431775\ttotal: 3.29s\tremaining: 897ms\n",
      "786:\tlearn: 0.0431019\ttotal: 3.3s\tremaining: 893ms\n",
      "787:\tlearn: 0.0430319\ttotal: 3.3s\tremaining: 889ms\n",
      "788:\tlearn: 0.0429734\ttotal: 3.31s\tremaining: 885ms\n",
      "789:\tlearn: 0.0428715\ttotal: 3.31s\tremaining: 880ms\n",
      "790:\tlearn: 0.0428386\ttotal: 3.32s\tremaining: 876ms\n",
      "791:\tlearn: 0.0428211\ttotal: 3.32s\tremaining: 872ms\n",
      "792:\tlearn: 0.0427772\ttotal: 3.32s\tremaining: 868ms\n",
      "793:\tlearn: 0.0427437\ttotal: 3.33s\tremaining: 864ms\n",
      "794:\tlearn: 0.0427251\ttotal: 3.33s\tremaining: 859ms\n",
      "795:\tlearn: 0.0427166\ttotal: 3.34s\tremaining: 855ms\n",
      "796:\tlearn: 0.0426938\ttotal: 3.34s\tremaining: 851ms\n",
      "797:\tlearn: 0.0426078\ttotal: 3.34s\tremaining: 847ms\n",
      "798:\tlearn: 0.0425511\ttotal: 3.35s\tremaining: 842ms\n",
      "799:\tlearn: 0.0425233\ttotal: 3.35s\tremaining: 838ms\n",
      "800:\tlearn: 0.0424198\ttotal: 3.35s\tremaining: 834ms\n",
      "801:\tlearn: 0.0423657\ttotal: 3.36s\tremaining: 829ms\n",
      "802:\tlearn: 0.0422860\ttotal: 3.36s\tremaining: 825ms\n",
      "803:\tlearn: 0.0422342\ttotal: 3.37s\tremaining: 821ms\n",
      "804:\tlearn: 0.0422115\ttotal: 3.37s\tremaining: 816ms\n",
      "805:\tlearn: 0.0421103\ttotal: 3.37s\tremaining: 812ms\n",
      "806:\tlearn: 0.0420931\ttotal: 3.38s\tremaining: 808ms\n",
      "807:\tlearn: 0.0420704\ttotal: 3.38s\tremaining: 803ms\n",
      "808:\tlearn: 0.0420477\ttotal: 3.38s\tremaining: 799ms\n",
      "809:\tlearn: 0.0420259\ttotal: 3.39s\tremaining: 795ms\n",
      "810:\tlearn: 0.0419830\ttotal: 3.39s\tremaining: 790ms\n",
      "811:\tlearn: 0.0419648\ttotal: 3.4s\tremaining: 786ms\n",
      "812:\tlearn: 0.0419260\ttotal: 3.4s\tremaining: 782ms\n",
      "813:\tlearn: 0.0418948\ttotal: 3.4s\tremaining: 777ms\n",
      "814:\tlearn: 0.0418522\ttotal: 3.4s\tremaining: 773ms\n",
      "815:\tlearn: 0.0417586\ttotal: 3.41s\tremaining: 769ms\n",
      "816:\tlearn: 0.0417205\ttotal: 3.41s\tremaining: 764ms\n",
      "817:\tlearn: 0.0416817\ttotal: 3.42s\tremaining: 760ms\n",
      "818:\tlearn: 0.0416608\ttotal: 3.42s\tremaining: 756ms\n",
      "819:\tlearn: 0.0416147\ttotal: 3.42s\tremaining: 752ms\n",
      "820:\tlearn: 0.0415981\ttotal: 3.43s\tremaining: 747ms\n",
      "821:\tlearn: 0.0415428\ttotal: 3.43s\tremaining: 743ms\n",
      "822:\tlearn: 0.0415255\ttotal: 3.43s\tremaining: 739ms\n",
      "823:\tlearn: 0.0415033\ttotal: 3.44s\tremaining: 734ms\n",
      "824:\tlearn: 0.0414821\ttotal: 3.44s\tremaining: 730ms\n",
      "825:\tlearn: 0.0414556\ttotal: 3.44s\tremaining: 726ms\n",
      "826:\tlearn: 0.0414347\ttotal: 3.45s\tremaining: 721ms\n",
      "827:\tlearn: 0.0413412\ttotal: 3.45s\tremaining: 717ms\n",
      "828:\tlearn: 0.0413097\ttotal: 3.45s\tremaining: 713ms\n",
      "829:\tlearn: 0.0412929\ttotal: 3.46s\tremaining: 708ms\n",
      "830:\tlearn: 0.0412549\ttotal: 3.46s\tremaining: 704ms\n",
      "831:\tlearn: 0.0412020\ttotal: 3.47s\tremaining: 700ms\n",
      "832:\tlearn: 0.0411501\ttotal: 3.47s\tremaining: 696ms\n",
      "833:\tlearn: 0.0411212\ttotal: 3.47s\tremaining: 692ms\n",
      "834:\tlearn: 0.0411025\ttotal: 3.48s\tremaining: 687ms\n",
      "835:\tlearn: 0.0410546\ttotal: 3.48s\tremaining: 683ms\n",
      "836:\tlearn: 0.0410061\ttotal: 3.49s\tremaining: 679ms\n",
      "837:\tlearn: 0.0409898\ttotal: 3.49s\tremaining: 675ms\n",
      "838:\tlearn: 0.0409683\ttotal: 3.49s\tremaining: 671ms\n",
      "839:\tlearn: 0.0409223\ttotal: 3.5s\tremaining: 666ms\n",
      "840:\tlearn: 0.0409031\ttotal: 3.5s\tremaining: 662ms\n",
      "841:\tlearn: 0.0408867\ttotal: 3.51s\tremaining: 658ms\n",
      "842:\tlearn: 0.0408469\ttotal: 3.51s\tremaining: 654ms\n",
      "843:\tlearn: 0.0408315\ttotal: 3.51s\tremaining: 649ms\n",
      "844:\tlearn: 0.0407746\ttotal: 3.52s\tremaining: 645ms\n",
      "845:\tlearn: 0.0406943\ttotal: 3.52s\tremaining: 641ms\n",
      "846:\tlearn: 0.0406590\ttotal: 3.52s\tremaining: 637ms\n",
      "847:\tlearn: 0.0406233\ttotal: 3.53s\tremaining: 633ms\n",
      "848:\tlearn: 0.0405451\ttotal: 3.53s\tremaining: 628ms\n",
      "849:\tlearn: 0.0405298\ttotal: 3.54s\tremaining: 624ms\n",
      "850:\tlearn: 0.0405138\ttotal: 3.54s\tremaining: 620ms\n",
      "851:\tlearn: 0.0404969\ttotal: 3.54s\tremaining: 616ms\n",
      "852:\tlearn: 0.0404693\ttotal: 3.55s\tremaining: 612ms\n",
      "853:\tlearn: 0.0404490\ttotal: 3.55s\tremaining: 608ms\n",
      "854:\tlearn: 0.0404150\ttotal: 3.56s\tremaining: 603ms\n",
      "855:\tlearn: 0.0403996\ttotal: 3.56s\tremaining: 599ms\n",
      "856:\tlearn: 0.0403548\ttotal: 3.57s\tremaining: 595ms\n",
      "857:\tlearn: 0.0403352\ttotal: 3.57s\tremaining: 591ms\n",
      "858:\tlearn: 0.0403011\ttotal: 3.57s\tremaining: 587ms\n",
      "859:\tlearn: 0.0402511\ttotal: 3.58s\tremaining: 582ms\n",
      "860:\tlearn: 0.0401987\ttotal: 3.58s\tremaining: 578ms\n",
      "861:\tlearn: 0.0401231\ttotal: 3.58s\tremaining: 574ms\n",
      "862:\tlearn: 0.0400524\ttotal: 3.59s\tremaining: 570ms\n",
      "863:\tlearn: 0.0400318\ttotal: 3.59s\tremaining: 566ms\n",
      "864:\tlearn: 0.0400111\ttotal: 3.6s\tremaining: 562ms\n",
      "865:\tlearn: 0.0399904\ttotal: 3.6s\tremaining: 557ms\n",
      "866:\tlearn: 0.0399356\ttotal: 3.6s\tremaining: 553ms\n",
      "867:\tlearn: 0.0398681\ttotal: 3.61s\tremaining: 549ms\n",
      "868:\tlearn: 0.0398363\ttotal: 3.61s\tremaining: 545ms\n",
      "869:\tlearn: 0.0397999\ttotal: 3.62s\tremaining: 540ms\n",
      "870:\tlearn: 0.0397777\ttotal: 3.62s\tremaining: 536ms\n",
      "871:\tlearn: 0.0397556\ttotal: 3.62s\tremaining: 532ms\n",
      "872:\tlearn: 0.0397351\ttotal: 3.63s\tremaining: 528ms\n",
      "873:\tlearn: 0.0397134\ttotal: 3.63s\tremaining: 523ms\n",
      "874:\tlearn: 0.0396944\ttotal: 3.63s\tremaining: 519ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "875:\tlearn: 0.0396709\ttotal: 3.64s\tremaining: 515ms\n",
      "876:\tlearn: 0.0396509\ttotal: 3.64s\tremaining: 511ms\n",
      "877:\tlearn: 0.0396235\ttotal: 3.65s\tremaining: 507ms\n",
      "878:\tlearn: 0.0396098\ttotal: 3.65s\tremaining: 503ms\n",
      "879:\tlearn: 0.0395913\ttotal: 3.65s\tremaining: 498ms\n",
      "880:\tlearn: 0.0395718\ttotal: 3.66s\tremaining: 494ms\n",
      "881:\tlearn: 0.0395462\ttotal: 3.66s\tremaining: 490ms\n",
      "882:\tlearn: 0.0395176\ttotal: 3.67s\tremaining: 486ms\n",
      "883:\tlearn: 0.0394974\ttotal: 3.67s\tremaining: 482ms\n",
      "884:\tlearn: 0.0394306\ttotal: 3.67s\tremaining: 477ms\n",
      "885:\tlearn: 0.0393987\ttotal: 3.68s\tremaining: 473ms\n",
      "886:\tlearn: 0.0393349\ttotal: 3.68s\tremaining: 469ms\n",
      "887:\tlearn: 0.0392475\ttotal: 3.69s\tremaining: 465ms\n",
      "888:\tlearn: 0.0392341\ttotal: 3.69s\tremaining: 461ms\n",
      "889:\tlearn: 0.0392037\ttotal: 3.69s\tremaining: 457ms\n",
      "890:\tlearn: 0.0391829\ttotal: 3.7s\tremaining: 452ms\n",
      "891:\tlearn: 0.0391520\ttotal: 3.7s\tremaining: 448ms\n",
      "892:\tlearn: 0.0391001\ttotal: 3.71s\tremaining: 444ms\n",
      "893:\tlearn: 0.0390297\ttotal: 3.71s\tremaining: 440ms\n",
      "894:\tlearn: 0.0390054\ttotal: 3.71s\tremaining: 435ms\n",
      "895:\tlearn: 0.0389359\ttotal: 3.71s\tremaining: 431ms\n",
      "896:\tlearn: 0.0388619\ttotal: 3.72s\tremaining: 427ms\n",
      "897:\tlearn: 0.0388427\ttotal: 3.72s\tremaining: 423ms\n",
      "898:\tlearn: 0.0388195\ttotal: 3.73s\tremaining: 419ms\n",
      "899:\tlearn: 0.0388006\ttotal: 3.73s\tremaining: 414ms\n",
      "900:\tlearn: 0.0387797\ttotal: 3.73s\tremaining: 410ms\n",
      "901:\tlearn: 0.0387108\ttotal: 3.74s\tremaining: 406ms\n",
      "902:\tlearn: 0.0386489\ttotal: 3.74s\tremaining: 402ms\n",
      "903:\tlearn: 0.0386288\ttotal: 3.74s\tremaining: 398ms\n",
      "904:\tlearn: 0.0385616\ttotal: 3.75s\tremaining: 393ms\n",
      "905:\tlearn: 0.0385311\ttotal: 3.75s\tremaining: 389ms\n",
      "906:\tlearn: 0.0384953\ttotal: 3.75s\tremaining: 385ms\n",
      "907:\tlearn: 0.0384690\ttotal: 3.76s\tremaining: 381ms\n",
      "908:\tlearn: 0.0384042\ttotal: 3.76s\tremaining: 376ms\n",
      "909:\tlearn: 0.0383561\ttotal: 3.76s\tremaining: 372ms\n",
      "910:\tlearn: 0.0383371\ttotal: 3.77s\tremaining: 368ms\n",
      "911:\tlearn: 0.0383115\ttotal: 3.77s\tremaining: 364ms\n",
      "912:\tlearn: 0.0382464\ttotal: 3.77s\tremaining: 360ms\n",
      "913:\tlearn: 0.0382276\ttotal: 3.78s\tremaining: 356ms\n",
      "914:\tlearn: 0.0381935\ttotal: 3.78s\tremaining: 351ms\n",
      "915:\tlearn: 0.0381722\ttotal: 3.79s\tremaining: 347ms\n",
      "916:\tlearn: 0.0381318\ttotal: 3.79s\tremaining: 343ms\n",
      "917:\tlearn: 0.0381125\ttotal: 3.79s\tremaining: 339ms\n",
      "918:\tlearn: 0.0380875\ttotal: 3.8s\tremaining: 335ms\n",
      "919:\tlearn: 0.0380611\ttotal: 3.8s\tremaining: 330ms\n",
      "920:\tlearn: 0.0380417\ttotal: 3.8s\tremaining: 326ms\n",
      "921:\tlearn: 0.0380224\ttotal: 3.81s\tremaining: 322ms\n",
      "922:\tlearn: 0.0380088\ttotal: 3.81s\tremaining: 318ms\n",
      "923:\tlearn: 0.0379754\ttotal: 3.81s\tremaining: 314ms\n",
      "924:\tlearn: 0.0379401\ttotal: 3.82s\tremaining: 310ms\n",
      "925:\tlearn: 0.0379221\ttotal: 3.82s\tremaining: 305ms\n",
      "926:\tlearn: 0.0379033\ttotal: 3.83s\tremaining: 301ms\n",
      "927:\tlearn: 0.0378792\ttotal: 3.83s\tremaining: 297ms\n",
      "928:\tlearn: 0.0378611\ttotal: 3.83s\tremaining: 293ms\n",
      "929:\tlearn: 0.0378438\ttotal: 3.84s\tremaining: 289ms\n",
      "930:\tlearn: 0.0378178\ttotal: 3.84s\tremaining: 285ms\n",
      "931:\tlearn: 0.0377868\ttotal: 3.84s\tremaining: 280ms\n",
      "932:\tlearn: 0.0377692\ttotal: 3.85s\tremaining: 276ms\n",
      "933:\tlearn: 0.0377274\ttotal: 3.85s\tremaining: 272ms\n",
      "934:\tlearn: 0.0377009\ttotal: 3.86s\tremaining: 268ms\n",
      "935:\tlearn: 0.0376826\ttotal: 3.86s\tremaining: 264ms\n",
      "936:\tlearn: 0.0376661\ttotal: 3.86s\tremaining: 260ms\n",
      "937:\tlearn: 0.0376312\ttotal: 3.87s\tremaining: 256ms\n",
      "938:\tlearn: 0.0376139\ttotal: 3.87s\tremaining: 251ms\n",
      "939:\tlearn: 0.0375730\ttotal: 3.87s\tremaining: 247ms\n",
      "940:\tlearn: 0.0375605\ttotal: 3.88s\tremaining: 243ms\n",
      "941:\tlearn: 0.0375204\ttotal: 3.88s\tremaining: 239ms\n",
      "942:\tlearn: 0.0374881\ttotal: 3.88s\tremaining: 235ms\n",
      "943:\tlearn: 0.0374679\ttotal: 3.89s\tremaining: 231ms\n",
      "944:\tlearn: 0.0374497\ttotal: 3.89s\tremaining: 227ms\n",
      "945:\tlearn: 0.0374298\ttotal: 3.9s\tremaining: 222ms\n",
      "946:\tlearn: 0.0374128\ttotal: 3.9s\tremaining: 218ms\n",
      "947:\tlearn: 0.0373734\ttotal: 3.9s\tremaining: 214ms\n",
      "948:\tlearn: 0.0373454\ttotal: 3.91s\tremaining: 210ms\n",
      "949:\tlearn: 0.0373285\ttotal: 3.91s\tremaining: 206ms\n",
      "950:\tlearn: 0.0372701\ttotal: 3.92s\tremaining: 202ms\n",
      "951:\tlearn: 0.0372406\ttotal: 3.92s\tremaining: 198ms\n",
      "952:\tlearn: 0.0372069\ttotal: 3.92s\tremaining: 193ms\n",
      "953:\tlearn: 0.0371462\ttotal: 3.93s\tremaining: 189ms\n",
      "954:\tlearn: 0.0371052\ttotal: 3.93s\tremaining: 185ms\n",
      "955:\tlearn: 0.0370821\ttotal: 3.93s\tremaining: 181ms\n",
      "956:\tlearn: 0.0370407\ttotal: 3.94s\tremaining: 177ms\n",
      "957:\tlearn: 0.0370023\ttotal: 3.94s\tremaining: 173ms\n",
      "958:\tlearn: 0.0369846\ttotal: 3.94s\tremaining: 169ms\n",
      "959:\tlearn: 0.0369667\ttotal: 3.95s\tremaining: 165ms\n",
      "960:\tlearn: 0.0369501\ttotal: 3.95s\tremaining: 160ms\n",
      "961:\tlearn: 0.0369351\ttotal: 3.96s\tremaining: 156ms\n",
      "962:\tlearn: 0.0369126\ttotal: 3.96s\tremaining: 152ms\n",
      "963:\tlearn: 0.0368962\ttotal: 3.96s\tremaining: 148ms\n",
      "964:\tlearn: 0.0368682\ttotal: 3.96s\tremaining: 144ms\n",
      "965:\tlearn: 0.0368272\ttotal: 3.97s\tremaining: 140ms\n",
      "966:\tlearn: 0.0367877\ttotal: 3.97s\tremaining: 136ms\n",
      "967:\tlearn: 0.0367611\ttotal: 3.98s\tremaining: 131ms\n",
      "968:\tlearn: 0.0367449\ttotal: 3.98s\tremaining: 127ms\n",
      "969:\tlearn: 0.0366671\ttotal: 3.98s\tremaining: 123ms\n",
      "970:\tlearn: 0.0366375\ttotal: 3.99s\tremaining: 119ms\n",
      "971:\tlearn: 0.0365976\ttotal: 3.99s\tremaining: 115ms\n",
      "972:\tlearn: 0.0365390\ttotal: 4s\tremaining: 111ms\n",
      "973:\tlearn: 0.0364955\ttotal: 4s\tremaining: 107ms\n",
      "974:\tlearn: 0.0364795\ttotal: 4s\tremaining: 103ms\n",
      "975:\tlearn: 0.0364394\ttotal: 4.01s\tremaining: 98.5ms\n",
      "976:\tlearn: 0.0364217\ttotal: 4.01s\tremaining: 94.4ms\n",
      "977:\tlearn: 0.0363925\ttotal: 4.01s\tremaining: 90.3ms\n",
      "978:\tlearn: 0.0363565\ttotal: 4.02s\tremaining: 86.2ms\n",
      "979:\tlearn: 0.0363183\ttotal: 4.02s\tremaining: 82.1ms\n",
      "980:\tlearn: 0.0363025\ttotal: 4.03s\tremaining: 78ms\n",
      "981:\tlearn: 0.0362823\ttotal: 4.03s\tremaining: 73.9ms\n",
      "982:\tlearn: 0.0362462\ttotal: 4.03s\tremaining: 69.7ms\n",
      "983:\tlearn: 0.0361970\ttotal: 4.04s\tremaining: 65.6ms\n",
      "984:\tlearn: 0.0361854\ttotal: 4.04s\tremaining: 61.5ms\n",
      "985:\tlearn: 0.0361507\ttotal: 4.04s\tremaining: 57.4ms\n",
      "986:\tlearn: 0.0360812\ttotal: 4.05s\tremaining: 53.3ms\n",
      "987:\tlearn: 0.0360529\ttotal: 4.05s\tremaining: 49.2ms\n",
      "988:\tlearn: 0.0360372\ttotal: 4.05s\tremaining: 45.1ms\n",
      "989:\tlearn: 0.0360201\ttotal: 4.06s\tremaining: 41ms\n",
      "990:\tlearn: 0.0359940\ttotal: 4.06s\tremaining: 36.9ms\n",
      "991:\tlearn: 0.0359535\ttotal: 4.06s\tremaining: 32.8ms\n",
      "992:\tlearn: 0.0359193\ttotal: 4.07s\tremaining: 28.7ms\n",
      "993:\tlearn: 0.0359038\ttotal: 4.07s\tremaining: 24.6ms\n",
      "994:\tlearn: 0.0358778\ttotal: 4.07s\tremaining: 20.5ms\n",
      "995:\tlearn: 0.0358430\ttotal: 4.08s\tremaining: 16.4ms\n",
      "996:\tlearn: 0.0358086\ttotal: 4.08s\tremaining: 12.3ms\n",
      "997:\tlearn: 0.0357711\ttotal: 4.08s\tremaining: 8.19ms\n",
      "998:\tlearn: 0.0357020\ttotal: 4.09s\tremaining: 4.09ms\n",
      "999:\tlearn: 0.0356859\ttotal: 4.09s\tremaining: 0us\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20:26:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:541: \n",
      "Parameters: { silent } might not be used.\n",
      "\n",
      "  This may not be accurate due to some parameters are only used in language bindings but\n",
      "  passed down to XGBoost core.  Or some parameters are not used but slip through this\n",
      "  verification. Please open an issue if you find above cases.\n",
      "\n",
      "\n",
      "Learning rate set to 0.013279\n",
      "0:\tlearn: 0.6670020\ttotal: 5.11ms\tremaining: 5.1s\n",
      "1:\tlearn: 0.6436223\ttotal: 9.1ms\tremaining: 4.54s\n",
      "2:\tlearn: 0.6183057\ttotal: 13ms\tremaining: 4.32s\n",
      "3:\tlearn: 0.5951680\ttotal: 16.8ms\tremaining: 4.17s\n",
      "4:\tlearn: 0.5721400\ttotal: 20.3ms\tremaining: 4.04s\n",
      "5:\tlearn: 0.5562126\ttotal: 23.8ms\tremaining: 3.94s\n",
      "6:\tlearn: 0.5357049\ttotal: 27.2ms\tremaining: 3.86s\n",
      "7:\tlearn: 0.5172265\ttotal: 31.3ms\tremaining: 3.88s\n",
      "8:\tlearn: 0.5014498\ttotal: 35.2ms\tremaining: 3.87s\n",
      "9:\tlearn: 0.4833970\ttotal: 39ms\tremaining: 3.86s\n",
      "10:\tlearn: 0.4670895\ttotal: 43.5ms\tremaining: 3.91s\n",
      "11:\tlearn: 0.4501686\ttotal: 48.5ms\tremaining: 3.99s\n",
      "12:\tlearn: 0.4352198\ttotal: 52.7ms\tremaining: 4s\n",
      "13:\tlearn: 0.4208442\ttotal: 56.4ms\tremaining: 3.97s\n",
      "14:\tlearn: 0.4068705\ttotal: 60.1ms\tremaining: 3.94s\n",
      "15:\tlearn: 0.3933191\ttotal: 63.8ms\tremaining: 3.93s\n",
      "16:\tlearn: 0.3821710\ttotal: 67.9ms\tremaining: 3.93s\n",
      "17:\tlearn: 0.3706670\ttotal: 71.6ms\tremaining: 3.91s\n",
      "18:\tlearn: 0.3593258\ttotal: 75.5ms\tremaining: 3.9s\n",
      "19:\tlearn: 0.3486093\ttotal: 80ms\tremaining: 3.92s\n",
      "20:\tlearn: 0.3390162\ttotal: 84.2ms\tremaining: 3.93s\n",
      "21:\tlearn: 0.3320539\ttotal: 88.4ms\tremaining: 3.93s\n",
      "22:\tlearn: 0.3230546\ttotal: 92.1ms\tremaining: 3.91s\n",
      "23:\tlearn: 0.3148268\ttotal: 96.4ms\tremaining: 3.92s\n",
      "24:\tlearn: 0.3066168\ttotal: 100ms\tremaining: 3.92s\n",
      "25:\tlearn: 0.2980942\ttotal: 104ms\tremaining: 3.9s\n",
      "26:\tlearn: 0.2914667\ttotal: 107ms\tremaining: 3.87s\n",
      "27:\tlearn: 0.2836484\ttotal: 111ms\tremaining: 3.87s\n",
      "28:\tlearn: 0.2772593\ttotal: 115ms\tremaining: 3.85s\n",
      "29:\tlearn: 0.2707386\ttotal: 119ms\tremaining: 3.84s\n",
      "30:\tlearn: 0.2643731\ttotal: 122ms\tremaining: 3.82s\n",
      "31:\tlearn: 0.2572202\ttotal: 126ms\tremaining: 3.81s\n",
      "32:\tlearn: 0.2510904\ttotal: 130ms\tremaining: 3.81s\n",
      "33:\tlearn: 0.2455515\ttotal: 134ms\tremaining: 3.8s\n",
      "34:\tlearn: 0.2407722\ttotal: 137ms\tremaining: 3.79s\n",
      "35:\tlearn: 0.2358191\ttotal: 141ms\tremaining: 3.77s\n",
      "36:\tlearn: 0.2307229\ttotal: 145ms\tremaining: 3.76s\n",
      "37:\tlearn: 0.2262473\ttotal: 148ms\tremaining: 3.76s\n",
      "38:\tlearn: 0.2219300\ttotal: 152ms\tremaining: 3.75s\n",
      "39:\tlearn: 0.2173136\ttotal: 155ms\tremaining: 3.73s\n",
      "40:\tlearn: 0.2132531\ttotal: 159ms\tremaining: 3.72s\n",
      "41:\tlearn: 0.2091779\ttotal: 163ms\tremaining: 3.71s\n",
      "42:\tlearn: 0.2052679\ttotal: 166ms\tremaining: 3.7s\n",
      "43:\tlearn: 0.2013766\ttotal: 170ms\tremaining: 3.7s\n",
      "44:\tlearn: 0.1975295\ttotal: 175ms\tremaining: 3.71s\n",
      "45:\tlearn: 0.1942106\ttotal: 179ms\tremaining: 3.71s\n",
      "46:\tlearn: 0.1908437\ttotal: 182ms\tremaining: 3.7s\n",
      "47:\tlearn: 0.1872687\ttotal: 186ms\tremaining: 3.69s\n",
      "48:\tlearn: 0.1840940\ttotal: 190ms\tremaining: 3.68s\n",
      "49:\tlearn: 0.1812444\ttotal: 194ms\tremaining: 3.68s\n",
      "50:\tlearn: 0.1786518\ttotal: 198ms\tremaining: 3.69s\n",
      "51:\tlearn: 0.1761419\ttotal: 202ms\tremaining: 3.69s\n",
      "52:\tlearn: 0.1737073\ttotal: 206ms\tremaining: 3.68s\n",
      "53:\tlearn: 0.1710113\ttotal: 209ms\tremaining: 3.67s\n",
      "54:\tlearn: 0.1690939\ttotal: 213ms\tremaining: 3.66s\n",
      "55:\tlearn: 0.1666968\ttotal: 216ms\tremaining: 3.65s\n",
      "56:\tlearn: 0.1645963\ttotal: 220ms\tremaining: 3.64s\n",
      "57:\tlearn: 0.1627150\ttotal: 224ms\tremaining: 3.64s\n",
      "58:\tlearn: 0.1608218\ttotal: 228ms\tremaining: 3.63s\n",
      "59:\tlearn: 0.1586738\ttotal: 231ms\tremaining: 3.62s\n",
      "60:\tlearn: 0.1572542\ttotal: 235ms\tremaining: 3.62s\n",
      "61:\tlearn: 0.1553753\ttotal: 239ms\tremaining: 3.62s\n",
      "62:\tlearn: 0.1539250\ttotal: 244ms\tremaining: 3.62s\n",
      "63:\tlearn: 0.1524888\ttotal: 248ms\tremaining: 3.63s\n",
      "64:\tlearn: 0.1507377\ttotal: 252ms\tremaining: 3.62s\n",
      "65:\tlearn: 0.1494278\ttotal: 256ms\tremaining: 3.62s\n",
      "66:\tlearn: 0.1480960\ttotal: 259ms\tremaining: 3.61s\n",
      "67:\tlearn: 0.1465885\ttotal: 263ms\tremaining: 3.6s\n",
      "68:\tlearn: 0.1451591\ttotal: 267ms\tremaining: 3.6s\n",
      "69:\tlearn: 0.1438940\ttotal: 271ms\tremaining: 3.59s\n",
      "70:\tlearn: 0.1428524\ttotal: 274ms\tremaining: 3.59s\n",
      "71:\tlearn: 0.1413033\ttotal: 278ms\tremaining: 3.58s\n",
      "72:\tlearn: 0.1400146\ttotal: 281ms\tremaining: 3.57s\n",
      "73:\tlearn: 0.1390425\ttotal: 285ms\tremaining: 3.57s\n",
      "74:\tlearn: 0.1377563\ttotal: 289ms\tremaining: 3.56s\n",
      "75:\tlearn: 0.1363543\ttotal: 293ms\tremaining: 3.56s\n",
      "76:\tlearn: 0.1353263\ttotal: 297ms\tremaining: 3.56s\n",
      "77:\tlearn: 0.1342293\ttotal: 301ms\tremaining: 3.55s\n",
      "78:\tlearn: 0.1331543\ttotal: 304ms\tremaining: 3.55s\n",
      "79:\tlearn: 0.1320885\ttotal: 308ms\tremaining: 3.54s\n",
      "80:\tlearn: 0.1311940\ttotal: 311ms\tremaining: 3.53s\n",
      "81:\tlearn: 0.1302403\ttotal: 315ms\tremaining: 3.53s\n",
      "82:\tlearn: 0.1291690\ttotal: 319ms\tremaining: 3.53s\n",
      "83:\tlearn: 0.1283653\ttotal: 323ms\tremaining: 3.52s\n",
      "84:\tlearn: 0.1272167\ttotal: 326ms\tremaining: 3.51s\n",
      "85:\tlearn: 0.1262359\ttotal: 330ms\tremaining: 3.51s\n",
      "86:\tlearn: 0.1253118\ttotal: 334ms\tremaining: 3.5s\n",
      "87:\tlearn: 0.1244763\ttotal: 338ms\tremaining: 3.5s\n",
      "88:\tlearn: 0.1234367\ttotal: 341ms\tremaining: 3.49s\n",
      "89:\tlearn: 0.1225255\ttotal: 346ms\tremaining: 3.5s\n",
      "90:\tlearn: 0.1218238\ttotal: 350ms\tremaining: 3.49s\n",
      "91:\tlearn: 0.1213155\ttotal: 353ms\tremaining: 3.49s\n",
      "92:\tlearn: 0.1205714\ttotal: 357ms\tremaining: 3.48s\n",
      "93:\tlearn: 0.1195684\ttotal: 361ms\tremaining: 3.48s\n",
      "94:\tlearn: 0.1188021\ttotal: 365ms\tremaining: 3.48s\n",
      "95:\tlearn: 0.1181917\ttotal: 369ms\tremaining: 3.47s\n",
      "96:\tlearn: 0.1173085\ttotal: 372ms\tremaining: 3.46s\n",
      "97:\tlearn: 0.1166318\ttotal: 376ms\tremaining: 3.46s\n",
      "98:\tlearn: 0.1159554\ttotal: 380ms\tremaining: 3.45s\n",
      "99:\tlearn: 0.1154256\ttotal: 384ms\tremaining: 3.45s\n",
      "100:\tlearn: 0.1148072\ttotal: 388ms\tremaining: 3.45s\n",
      "101:\tlearn: 0.1141239\ttotal: 393ms\tremaining: 3.46s\n",
      "102:\tlearn: 0.1134830\ttotal: 397ms\tremaining: 3.46s\n",
      "103:\tlearn: 0.1130283\ttotal: 401ms\tremaining: 3.46s\n",
      "104:\tlearn: 0.1126746\ttotal: 405ms\tremaining: 3.45s\n",
      "105:\tlearn: 0.1121413\ttotal: 409ms\tremaining: 3.45s\n",
      "106:\tlearn: 0.1117010\ttotal: 413ms\tremaining: 3.44s\n",
      "107:\tlearn: 0.1112503\ttotal: 417ms\tremaining: 3.44s\n",
      "108:\tlearn: 0.1106644\ttotal: 421ms\tremaining: 3.44s\n",
      "109:\tlearn: 0.1100350\ttotal: 425ms\tremaining: 3.44s\n",
      "110:\tlearn: 0.1094871\ttotal: 429ms\tremaining: 3.44s\n",
      "111:\tlearn: 0.1088910\ttotal: 434ms\tremaining: 3.44s\n",
      "112:\tlearn: 0.1084067\ttotal: 438ms\tremaining: 3.44s\n",
      "113:\tlearn: 0.1078001\ttotal: 442ms\tremaining: 3.44s\n",
      "114:\tlearn: 0.1072904\ttotal: 446ms\tremaining: 3.43s\n",
      "115:\tlearn: 0.1068166\ttotal: 450ms\tremaining: 3.43s\n",
      "116:\tlearn: 0.1062883\ttotal: 454ms\tremaining: 3.42s\n",
      "117:\tlearn: 0.1058712\ttotal: 458ms\tremaining: 3.42s\n",
      "118:\tlearn: 0.1055432\ttotal: 462ms\tremaining: 3.42s\n",
      "119:\tlearn: 0.1050885\ttotal: 466ms\tremaining: 3.42s\n",
      "120:\tlearn: 0.1047445\ttotal: 469ms\tremaining: 3.41s\n",
      "121:\tlearn: 0.1043052\ttotal: 473ms\tremaining: 3.4s\n",
      "122:\tlearn: 0.1039783\ttotal: 476ms\tremaining: 3.4s\n",
      "123:\tlearn: 0.1036514\ttotal: 480ms\tremaining: 3.39s\n",
      "124:\tlearn: 0.1032763\ttotal: 484ms\tremaining: 3.39s\n",
      "125:\tlearn: 0.1026447\ttotal: 488ms\tremaining: 3.38s\n",
      "126:\tlearn: 0.1022961\ttotal: 491ms\tremaining: 3.38s\n",
      "127:\tlearn: 0.1019444\ttotal: 495ms\tremaining: 3.37s\n",
      "128:\tlearn: 0.1014889\ttotal: 499ms\tremaining: 3.37s\n",
      "129:\tlearn: 0.1011560\ttotal: 503ms\tremaining: 3.36s\n",
      "130:\tlearn: 0.1008358\ttotal: 506ms\tremaining: 3.36s\n",
      "131:\tlearn: 0.1005981\ttotal: 510ms\tremaining: 3.35s\n",
      "132:\tlearn: 0.1002057\ttotal: 514ms\tremaining: 3.35s\n",
      "133:\tlearn: 0.0999221\ttotal: 517ms\tremaining: 3.34s\n",
      "134:\tlearn: 0.0995880\ttotal: 521ms\tremaining: 3.34s\n",
      "135:\tlearn: 0.0993680\ttotal: 526ms\tremaining: 3.34s\n",
      "136:\tlearn: 0.0991830\ttotal: 530ms\tremaining: 3.34s\n",
      "137:\tlearn: 0.0987866\ttotal: 534ms\tremaining: 3.33s\n",
      "138:\tlearn: 0.0983260\ttotal: 538ms\tremaining: 3.33s\n",
      "139:\tlearn: 0.0978310\ttotal: 542ms\tremaining: 3.33s\n",
      "140:\tlearn: 0.0976281\ttotal: 546ms\tremaining: 3.33s\n",
      "141:\tlearn: 0.0971771\ttotal: 550ms\tremaining: 3.32s\n",
      "142:\tlearn: 0.0969249\ttotal: 555ms\tremaining: 3.32s\n",
      "143:\tlearn: 0.0966073\ttotal: 560ms\tremaining: 3.33s\n",
      "144:\tlearn: 0.0963742\ttotal: 564ms\tremaining: 3.32s\n",
      "145:\tlearn: 0.0960275\ttotal: 567ms\tremaining: 3.32s\n",
      "146:\tlearn: 0.0957379\ttotal: 571ms\tremaining: 3.31s\n",
      "147:\tlearn: 0.0955147\ttotal: 574ms\tremaining: 3.31s\n",
      "148:\tlearn: 0.0952489\ttotal: 579ms\tremaining: 3.3s\n",
      "149:\tlearn: 0.0949770\ttotal: 582ms\tremaining: 3.3s\n",
      "150:\tlearn: 0.0947869\ttotal: 586ms\tremaining: 3.29s\n",
      "151:\tlearn: 0.0946178\ttotal: 590ms\tremaining: 3.29s\n",
      "152:\tlearn: 0.0943329\ttotal: 594ms\tremaining: 3.29s\n",
      "153:\tlearn: 0.0940030\ttotal: 598ms\tremaining: 3.28s\n",
      "154:\tlearn: 0.0936160\ttotal: 602ms\tremaining: 3.28s\n",
      "155:\tlearn: 0.0933608\ttotal: 606ms\tremaining: 3.28s\n",
      "156:\tlearn: 0.0931759\ttotal: 609ms\tremaining: 3.27s\n",
      "157:\tlearn: 0.0929346\ttotal: 613ms\tremaining: 3.27s\n",
      "158:\tlearn: 0.0927450\ttotal: 618ms\tremaining: 3.27s\n",
      "159:\tlearn: 0.0926033\ttotal: 621ms\tremaining: 3.26s\n",
      "160:\tlearn: 0.0923161\ttotal: 625ms\tremaining: 3.26s\n",
      "161:\tlearn: 0.0919793\ttotal: 628ms\tremaining: 3.25s\n",
      "162:\tlearn: 0.0917742\ttotal: 632ms\tremaining: 3.25s\n",
      "163:\tlearn: 0.0916005\ttotal: 636ms\tremaining: 3.24s\n",
      "164:\tlearn: 0.0912837\ttotal: 639ms\tremaining: 3.23s\n",
      "165:\tlearn: 0.0910710\ttotal: 643ms\tremaining: 3.23s\n",
      "166:\tlearn: 0.0908645\ttotal: 647ms\tremaining: 3.23s\n",
      "167:\tlearn: 0.0906323\ttotal: 651ms\tremaining: 3.22s\n",
      "168:\tlearn: 0.0904186\ttotal: 654ms\tremaining: 3.22s\n",
      "169:\tlearn: 0.0902044\ttotal: 658ms\tremaining: 3.21s\n",
      "170:\tlearn: 0.0899186\ttotal: 662ms\tremaining: 3.21s\n",
      "171:\tlearn: 0.0896739\ttotal: 665ms\tremaining: 3.2s\n",
      "172:\tlearn: 0.0895085\ttotal: 669ms\tremaining: 3.2s\n",
      "173:\tlearn: 0.0892350\ttotal: 673ms\tremaining: 3.19s\n",
      "174:\tlearn: 0.0889666\ttotal: 677ms\tremaining: 3.19s\n",
      "175:\tlearn: 0.0887516\ttotal: 680ms\tremaining: 3.19s\n",
      "176:\tlearn: 0.0884887\ttotal: 684ms\tremaining: 3.18s\n",
      "177:\tlearn: 0.0882245\ttotal: 688ms\tremaining: 3.18s\n",
      "178:\tlearn: 0.0881075\ttotal: 691ms\tremaining: 3.17s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "179:\tlearn: 0.0878961\ttotal: 695ms\tremaining: 3.17s\n",
      "180:\tlearn: 0.0876761\ttotal: 700ms\tremaining: 3.17s\n",
      "181:\tlearn: 0.0873882\ttotal: 704ms\tremaining: 3.16s\n",
      "182:\tlearn: 0.0872549\ttotal: 708ms\tremaining: 3.16s\n",
      "183:\tlearn: 0.0870889\ttotal: 711ms\tremaining: 3.15s\n",
      "184:\tlearn: 0.0867497\ttotal: 715ms\tremaining: 3.15s\n",
      "185:\tlearn: 0.0865116\ttotal: 719ms\tremaining: 3.15s\n",
      "186:\tlearn: 0.0862326\ttotal: 723ms\tremaining: 3.14s\n",
      "187:\tlearn: 0.0860391\ttotal: 727ms\tremaining: 3.14s\n",
      "188:\tlearn: 0.0858940\ttotal: 731ms\tremaining: 3.13s\n",
      "189:\tlearn: 0.0856447\ttotal: 735ms\tremaining: 3.13s\n",
      "190:\tlearn: 0.0853738\ttotal: 739ms\tremaining: 3.13s\n",
      "191:\tlearn: 0.0851417\ttotal: 742ms\tremaining: 3.12s\n",
      "192:\tlearn: 0.0848703\ttotal: 746ms\tremaining: 3.12s\n",
      "193:\tlearn: 0.0847635\ttotal: 750ms\tremaining: 3.11s\n",
      "194:\tlearn: 0.0845018\ttotal: 753ms\tremaining: 3.11s\n",
      "195:\tlearn: 0.0842452\ttotal: 757ms\tremaining: 3.1s\n",
      "196:\tlearn: 0.0840682\ttotal: 761ms\tremaining: 3.1s\n",
      "197:\tlearn: 0.0839359\ttotal: 765ms\tremaining: 3.1s\n",
      "198:\tlearn: 0.0838665\ttotal: 769ms\tremaining: 3.09s\n",
      "199:\tlearn: 0.0836312\ttotal: 772ms\tremaining: 3.09s\n",
      "200:\tlearn: 0.0834627\ttotal: 777ms\tremaining: 3.09s\n",
      "201:\tlearn: 0.0832736\ttotal: 780ms\tremaining: 3.08s\n",
      "202:\tlearn: 0.0830956\ttotal: 784ms\tremaining: 3.08s\n",
      "203:\tlearn: 0.0829534\ttotal: 788ms\tremaining: 3.07s\n",
      "204:\tlearn: 0.0827516\ttotal: 792ms\tremaining: 3.07s\n",
      "205:\tlearn: 0.0826363\ttotal: 796ms\tremaining: 3.07s\n",
      "206:\tlearn: 0.0824122\ttotal: 800ms\tremaining: 3.06s\n",
      "207:\tlearn: 0.0822141\ttotal: 804ms\tremaining: 3.06s\n",
      "208:\tlearn: 0.0819608\ttotal: 807ms\tremaining: 3.06s\n",
      "209:\tlearn: 0.0817225\ttotal: 811ms\tremaining: 3.05s\n",
      "210:\tlearn: 0.0815438\ttotal: 815ms\tremaining: 3.05s\n",
      "211:\tlearn: 0.0813497\ttotal: 819ms\tremaining: 3.04s\n",
      "212:\tlearn: 0.0812021\ttotal: 823ms\tremaining: 3.04s\n",
      "213:\tlearn: 0.0809875\ttotal: 826ms\tremaining: 3.03s\n",
      "214:\tlearn: 0.0808042\ttotal: 830ms\tremaining: 3.03s\n",
      "215:\tlearn: 0.0805121\ttotal: 834ms\tremaining: 3.02s\n",
      "216:\tlearn: 0.0803362\ttotal: 838ms\tremaining: 3.02s\n",
      "217:\tlearn: 0.0800934\ttotal: 842ms\tremaining: 3.02s\n",
      "218:\tlearn: 0.0799257\ttotal: 846ms\tremaining: 3.02s\n",
      "219:\tlearn: 0.0797774\ttotal: 849ms\tremaining: 3.01s\n",
      "220:\tlearn: 0.0796256\ttotal: 853ms\tremaining: 3.01s\n",
      "221:\tlearn: 0.0794801\ttotal: 857ms\tremaining: 3s\n",
      "222:\tlearn: 0.0793084\ttotal: 861ms\tremaining: 3s\n",
      "223:\tlearn: 0.0791128\ttotal: 865ms\tremaining: 3s\n",
      "224:\tlearn: 0.0789891\ttotal: 869ms\tremaining: 2.99s\n",
      "225:\tlearn: 0.0787755\ttotal: 873ms\tremaining: 2.99s\n",
      "226:\tlearn: 0.0785381\ttotal: 877ms\tremaining: 2.99s\n",
      "227:\tlearn: 0.0784763\ttotal: 881ms\tremaining: 2.98s\n",
      "228:\tlearn: 0.0783417\ttotal: 885ms\tremaining: 2.98s\n",
      "229:\tlearn: 0.0781098\ttotal: 889ms\tremaining: 2.98s\n",
      "230:\tlearn: 0.0779782\ttotal: 893ms\tremaining: 2.97s\n",
      "231:\tlearn: 0.0778870\ttotal: 897ms\tremaining: 2.97s\n",
      "232:\tlearn: 0.0777378\ttotal: 901ms\tremaining: 2.96s\n",
      "233:\tlearn: 0.0775994\ttotal: 905ms\tremaining: 2.96s\n",
      "234:\tlearn: 0.0774460\ttotal: 908ms\tremaining: 2.96s\n",
      "235:\tlearn: 0.0772250\ttotal: 912ms\tremaining: 2.95s\n",
      "236:\tlearn: 0.0770047\ttotal: 916ms\tremaining: 2.95s\n",
      "237:\tlearn: 0.0768649\ttotal: 920ms\tremaining: 2.94s\n",
      "238:\tlearn: 0.0767518\ttotal: 924ms\tremaining: 2.94s\n",
      "239:\tlearn: 0.0766414\ttotal: 927ms\tremaining: 2.94s\n",
      "240:\tlearn: 0.0765675\ttotal: 931ms\tremaining: 2.93s\n",
      "241:\tlearn: 0.0763425\ttotal: 934ms\tremaining: 2.93s\n",
      "242:\tlearn: 0.0761008\ttotal: 938ms\tremaining: 2.92s\n",
      "243:\tlearn: 0.0759309\ttotal: 942ms\tremaining: 2.92s\n",
      "244:\tlearn: 0.0757946\ttotal: 945ms\tremaining: 2.91s\n",
      "245:\tlearn: 0.0755013\ttotal: 949ms\tremaining: 2.91s\n",
      "246:\tlearn: 0.0752867\ttotal: 953ms\tremaining: 2.91s\n",
      "247:\tlearn: 0.0751113\ttotal: 957ms\tremaining: 2.9s\n",
      "248:\tlearn: 0.0749216\ttotal: 961ms\tremaining: 2.9s\n",
      "249:\tlearn: 0.0748286\ttotal: 965ms\tremaining: 2.89s\n",
      "250:\tlearn: 0.0746478\ttotal: 968ms\tremaining: 2.89s\n",
      "251:\tlearn: 0.0746019\ttotal: 972ms\tremaining: 2.88s\n",
      "252:\tlearn: 0.0745081\ttotal: 976ms\tremaining: 2.88s\n",
      "253:\tlearn: 0.0743492\ttotal: 979ms\tremaining: 2.88s\n",
      "254:\tlearn: 0.0741761\ttotal: 983ms\tremaining: 2.87s\n",
      "255:\tlearn: 0.0740155\ttotal: 987ms\tremaining: 2.87s\n",
      "256:\tlearn: 0.0738371\ttotal: 990ms\tremaining: 2.86s\n",
      "257:\tlearn: 0.0735975\ttotal: 994ms\tremaining: 2.86s\n",
      "258:\tlearn: 0.0735112\ttotal: 997ms\tremaining: 2.85s\n",
      "259:\tlearn: 0.0734531\ttotal: 1s\tremaining: 2.85s\n",
      "260:\tlearn: 0.0733238\ttotal: 1s\tremaining: 2.84s\n",
      "261:\tlearn: 0.0731595\ttotal: 1.01s\tremaining: 2.84s\n",
      "262:\tlearn: 0.0729970\ttotal: 1.01s\tremaining: 2.83s\n",
      "263:\tlearn: 0.0728601\ttotal: 1.01s\tremaining: 2.83s\n",
      "264:\tlearn: 0.0727326\ttotal: 1.02s\tremaining: 2.83s\n",
      "265:\tlearn: 0.0725972\ttotal: 1.02s\tremaining: 2.82s\n",
      "266:\tlearn: 0.0724494\ttotal: 1.03s\tremaining: 2.82s\n",
      "267:\tlearn: 0.0723477\ttotal: 1.03s\tremaining: 2.81s\n",
      "268:\tlearn: 0.0722241\ttotal: 1.03s\tremaining: 2.81s\n",
      "269:\tlearn: 0.0721500\ttotal: 1.04s\tremaining: 2.8s\n",
      "270:\tlearn: 0.0719895\ttotal: 1.04s\tremaining: 2.8s\n",
      "271:\tlearn: 0.0719199\ttotal: 1.04s\tremaining: 2.8s\n",
      "272:\tlearn: 0.0717270\ttotal: 1.05s\tremaining: 2.79s\n",
      "273:\tlearn: 0.0716246\ttotal: 1.05s\tremaining: 2.79s\n",
      "274:\tlearn: 0.0715170\ttotal: 1.06s\tremaining: 2.79s\n",
      "275:\tlearn: 0.0714155\ttotal: 1.06s\tremaining: 2.78s\n",
      "276:\tlearn: 0.0712833\ttotal: 1.06s\tremaining: 2.78s\n",
      "277:\tlearn: 0.0711259\ttotal: 1.07s\tremaining: 2.78s\n",
      "278:\tlearn: 0.0709761\ttotal: 1.07s\tremaining: 2.77s\n",
      "279:\tlearn: 0.0709317\ttotal: 1.08s\tremaining: 2.77s\n",
      "280:\tlearn: 0.0708320\ttotal: 1.08s\tremaining: 2.76s\n",
      "281:\tlearn: 0.0706770\ttotal: 1.08s\tremaining: 2.76s\n",
      "282:\tlearn: 0.0705429\ttotal: 1.09s\tremaining: 2.75s\n",
      "283:\tlearn: 0.0703877\ttotal: 1.09s\tremaining: 2.75s\n",
      "284:\tlearn: 0.0702239\ttotal: 1.09s\tremaining: 2.75s\n",
      "285:\tlearn: 0.0701000\ttotal: 1.1s\tremaining: 2.74s\n",
      "286:\tlearn: 0.0700375\ttotal: 1.1s\tremaining: 2.74s\n",
      "287:\tlearn: 0.0699166\ttotal: 1.1s\tremaining: 2.73s\n",
      "288:\tlearn: 0.0697637\ttotal: 1.11s\tremaining: 2.73s\n",
      "289:\tlearn: 0.0696574\ttotal: 1.11s\tremaining: 2.73s\n",
      "290:\tlearn: 0.0696088\ttotal: 1.12s\tremaining: 2.72s\n",
      "291:\tlearn: 0.0694161\ttotal: 1.12s\tremaining: 2.72s\n",
      "292:\tlearn: 0.0693159\ttotal: 1.12s\tremaining: 2.71s\n",
      "293:\tlearn: 0.0691908\ttotal: 1.13s\tremaining: 2.71s\n",
      "294:\tlearn: 0.0690469\ttotal: 1.13s\tremaining: 2.7s\n",
      "295:\tlearn: 0.0689852\ttotal: 1.14s\tremaining: 2.7s\n",
      "296:\tlearn: 0.0688737\ttotal: 1.14s\tremaining: 2.7s\n",
      "297:\tlearn: 0.0686928\ttotal: 1.14s\tremaining: 2.69s\n",
      "298:\tlearn: 0.0686518\ttotal: 1.15s\tremaining: 2.69s\n",
      "299:\tlearn: 0.0685817\ttotal: 1.15s\tremaining: 2.68s\n",
      "300:\tlearn: 0.0684587\ttotal: 1.15s\tremaining: 2.68s\n",
      "301:\tlearn: 0.0684332\ttotal: 1.16s\tremaining: 2.67s\n",
      "302:\tlearn: 0.0682868\ttotal: 1.16s\tremaining: 2.67s\n",
      "303:\tlearn: 0.0681124\ttotal: 1.16s\tremaining: 2.67s\n",
      "304:\tlearn: 0.0680062\ttotal: 1.17s\tremaining: 2.66s\n",
      "305:\tlearn: 0.0679116\ttotal: 1.17s\tremaining: 2.66s\n",
      "306:\tlearn: 0.0677901\ttotal: 1.18s\tremaining: 2.66s\n",
      "307:\tlearn: 0.0677015\ttotal: 1.18s\tremaining: 2.66s\n",
      "308:\tlearn: 0.0676347\ttotal: 1.19s\tremaining: 2.65s\n",
      "309:\tlearn: 0.0675352\ttotal: 1.19s\tremaining: 2.65s\n",
      "310:\tlearn: 0.0674658\ttotal: 1.19s\tremaining: 2.65s\n",
      "311:\tlearn: 0.0673421\ttotal: 1.2s\tremaining: 2.64s\n",
      "312:\tlearn: 0.0672971\ttotal: 1.2s\tremaining: 2.64s\n",
      "313:\tlearn: 0.0672451\ttotal: 1.21s\tremaining: 2.63s\n",
      "314:\tlearn: 0.0671549\ttotal: 1.21s\tremaining: 2.63s\n",
      "315:\tlearn: 0.0670477\ttotal: 1.21s\tremaining: 2.63s\n",
      "316:\tlearn: 0.0669196\ttotal: 1.22s\tremaining: 2.62s\n",
      "317:\tlearn: 0.0668490\ttotal: 1.22s\tremaining: 2.62s\n",
      "318:\tlearn: 0.0667563\ttotal: 1.22s\tremaining: 2.61s\n",
      "319:\tlearn: 0.0666067\ttotal: 1.23s\tremaining: 2.61s\n",
      "320:\tlearn: 0.0664533\ttotal: 1.23s\tremaining: 2.6s\n",
      "321:\tlearn: 0.0663557\ttotal: 1.24s\tremaining: 2.6s\n",
      "322:\tlearn: 0.0662642\ttotal: 1.24s\tremaining: 2.6s\n",
      "323:\tlearn: 0.0661811\ttotal: 1.24s\tremaining: 2.59s\n",
      "324:\tlearn: 0.0660123\ttotal: 1.25s\tremaining: 2.59s\n",
      "325:\tlearn: 0.0659261\ttotal: 1.25s\tremaining: 2.59s\n",
      "326:\tlearn: 0.0658674\ttotal: 1.25s\tremaining: 2.58s\n",
      "327:\tlearn: 0.0658052\ttotal: 1.26s\tremaining: 2.58s\n",
      "328:\tlearn: 0.0656993\ttotal: 1.26s\tremaining: 2.57s\n",
      "329:\tlearn: 0.0655428\ttotal: 1.26s\tremaining: 2.57s\n",
      "330:\tlearn: 0.0654565\ttotal: 1.27s\tremaining: 2.57s\n",
      "331:\tlearn: 0.0653243\ttotal: 1.27s\tremaining: 2.56s\n",
      "332:\tlearn: 0.0651299\ttotal: 1.28s\tremaining: 2.56s\n",
      "333:\tlearn: 0.0649411\ttotal: 1.28s\tremaining: 2.56s\n",
      "334:\tlearn: 0.0648366\ttotal: 1.28s\tremaining: 2.55s\n",
      "335:\tlearn: 0.0646938\ttotal: 1.29s\tremaining: 2.55s\n",
      "336:\tlearn: 0.0645883\ttotal: 1.29s\tremaining: 2.54s\n",
      "337:\tlearn: 0.0644621\ttotal: 1.3s\tremaining: 2.54s\n",
      "338:\tlearn: 0.0643767\ttotal: 1.3s\tremaining: 2.54s\n",
      "339:\tlearn: 0.0643262\ttotal: 1.3s\tremaining: 2.53s\n",
      "340:\tlearn: 0.0641818\ttotal: 1.31s\tremaining: 2.53s\n",
      "341:\tlearn: 0.0640625\ttotal: 1.31s\tremaining: 2.52s\n",
      "342:\tlearn: 0.0639147\ttotal: 1.31s\tremaining: 2.52s\n",
      "343:\tlearn: 0.0638242\ttotal: 1.32s\tremaining: 2.52s\n",
      "344:\tlearn: 0.0637072\ttotal: 1.32s\tremaining: 2.51s\n",
      "345:\tlearn: 0.0635947\ttotal: 1.33s\tremaining: 2.51s\n",
      "346:\tlearn: 0.0634198\ttotal: 1.33s\tremaining: 2.5s\n",
      "347:\tlearn: 0.0633358\ttotal: 1.33s\tremaining: 2.5s\n",
      "348:\tlearn: 0.0632619\ttotal: 1.34s\tremaining: 2.5s\n",
      "349:\tlearn: 0.0631498\ttotal: 1.34s\tremaining: 2.49s\n",
      "350:\tlearn: 0.0630938\ttotal: 1.34s\tremaining: 2.49s\n",
      "351:\tlearn: 0.0629702\ttotal: 1.35s\tremaining: 2.48s\n",
      "352:\tlearn: 0.0628533\ttotal: 1.35s\tremaining: 2.48s\n",
      "353:\tlearn: 0.0627277\ttotal: 1.36s\tremaining: 2.48s\n",
      "354:\tlearn: 0.0626105\ttotal: 1.36s\tremaining: 2.47s\n",
      "355:\tlearn: 0.0625470\ttotal: 1.36s\tremaining: 2.47s\n",
      "356:\tlearn: 0.0624123\ttotal: 1.37s\tremaining: 2.46s\n",
      "357:\tlearn: 0.0622975\ttotal: 1.37s\tremaining: 2.46s\n",
      "358:\tlearn: 0.0621769\ttotal: 1.38s\tremaining: 2.46s\n",
      "359:\tlearn: 0.0620696\ttotal: 1.38s\tremaining: 2.45s\n",
      "360:\tlearn: 0.0619855\ttotal: 1.38s\tremaining: 2.45s\n",
      "361:\tlearn: 0.0619317\ttotal: 1.39s\tremaining: 2.44s\n",
      "362:\tlearn: 0.0618405\ttotal: 1.39s\tremaining: 2.44s\n",
      "363:\tlearn: 0.0617407\ttotal: 1.39s\tremaining: 2.44s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "364:\tlearn: 0.0616145\ttotal: 1.4s\tremaining: 2.43s\n",
      "365:\tlearn: 0.0614820\ttotal: 1.4s\tremaining: 2.43s\n",
      "366:\tlearn: 0.0613990\ttotal: 1.41s\tremaining: 2.43s\n",
      "367:\tlearn: 0.0612637\ttotal: 1.41s\tremaining: 2.42s\n",
      "368:\tlearn: 0.0612171\ttotal: 1.42s\tremaining: 2.42s\n",
      "369:\tlearn: 0.0611095\ttotal: 1.42s\tremaining: 2.42s\n",
      "370:\tlearn: 0.0609933\ttotal: 1.42s\tremaining: 2.41s\n",
      "371:\tlearn: 0.0609154\ttotal: 1.43s\tremaining: 2.41s\n",
      "372:\tlearn: 0.0608313\ttotal: 1.43s\tremaining: 2.41s\n",
      "373:\tlearn: 0.0607825\ttotal: 1.44s\tremaining: 2.41s\n",
      "374:\tlearn: 0.0606887\ttotal: 1.44s\tremaining: 2.4s\n",
      "375:\tlearn: 0.0606280\ttotal: 1.45s\tremaining: 2.4s\n",
      "376:\tlearn: 0.0605026\ttotal: 1.45s\tremaining: 2.4s\n",
      "377:\tlearn: 0.0603126\ttotal: 1.46s\tremaining: 2.4s\n",
      "378:\tlearn: 0.0602308\ttotal: 1.46s\tremaining: 2.39s\n",
      "379:\tlearn: 0.0601280\ttotal: 1.46s\tremaining: 2.39s\n",
      "380:\tlearn: 0.0599841\ttotal: 1.47s\tremaining: 2.38s\n",
      "381:\tlearn: 0.0598544\ttotal: 1.47s\tremaining: 2.38s\n",
      "382:\tlearn: 0.0598049\ttotal: 1.48s\tremaining: 2.38s\n",
      "383:\tlearn: 0.0597321\ttotal: 1.48s\tremaining: 2.37s\n",
      "384:\tlearn: 0.0596554\ttotal: 1.48s\tremaining: 2.37s\n",
      "385:\tlearn: 0.0595306\ttotal: 1.49s\tremaining: 2.37s\n",
      "386:\tlearn: 0.0594290\ttotal: 1.49s\tremaining: 2.36s\n",
      "387:\tlearn: 0.0593535\ttotal: 1.49s\tremaining: 2.36s\n",
      "388:\tlearn: 0.0592335\ttotal: 1.5s\tremaining: 2.35s\n",
      "389:\tlearn: 0.0591911\ttotal: 1.5s\tremaining: 2.35s\n",
      "390:\tlearn: 0.0590861\ttotal: 1.5s\tremaining: 2.35s\n",
      "391:\tlearn: 0.0590125\ttotal: 1.51s\tremaining: 2.34s\n",
      "392:\tlearn: 0.0589616\ttotal: 1.51s\tremaining: 2.34s\n",
      "393:\tlearn: 0.0588575\ttotal: 1.52s\tremaining: 2.33s\n",
      "394:\tlearn: 0.0587595\ttotal: 1.52s\tremaining: 2.33s\n",
      "395:\tlearn: 0.0587119\ttotal: 1.52s\tremaining: 2.33s\n",
      "396:\tlearn: 0.0586146\ttotal: 1.53s\tremaining: 2.32s\n",
      "397:\tlearn: 0.0584674\ttotal: 1.53s\tremaining: 2.32s\n",
      "398:\tlearn: 0.0583884\ttotal: 1.54s\tremaining: 2.31s\n",
      "399:\tlearn: 0.0582765\ttotal: 1.54s\tremaining: 2.31s\n",
      "400:\tlearn: 0.0581649\ttotal: 1.55s\tremaining: 2.31s\n",
      "401:\tlearn: 0.0580758\ttotal: 1.55s\tremaining: 2.31s\n",
      "402:\tlearn: 0.0580141\ttotal: 1.55s\tremaining: 2.3s\n",
      "403:\tlearn: 0.0579731\ttotal: 1.56s\tremaining: 2.3s\n",
      "404:\tlearn: 0.0579348\ttotal: 1.56s\tremaining: 2.29s\n",
      "405:\tlearn: 0.0578719\ttotal: 1.56s\tremaining: 2.29s\n",
      "406:\tlearn: 0.0577630\ttotal: 1.57s\tremaining: 2.29s\n",
      "407:\tlearn: 0.0576419\ttotal: 1.57s\tremaining: 2.28s\n",
      "408:\tlearn: 0.0575669\ttotal: 1.58s\tremaining: 2.28s\n",
      "409:\tlearn: 0.0574752\ttotal: 1.58s\tremaining: 2.28s\n",
      "410:\tlearn: 0.0573967\ttotal: 1.59s\tremaining: 2.27s\n",
      "411:\tlearn: 0.0573127\ttotal: 1.59s\tremaining: 2.27s\n",
      "412:\tlearn: 0.0572217\ttotal: 1.59s\tremaining: 2.27s\n",
      "413:\tlearn: 0.0571124\ttotal: 1.6s\tremaining: 2.26s\n",
      "414:\tlearn: 0.0569759\ttotal: 1.6s\tremaining: 2.26s\n",
      "415:\tlearn: 0.0569019\ttotal: 1.6s\tremaining: 2.25s\n",
      "416:\tlearn: 0.0568272\ttotal: 1.61s\tremaining: 2.25s\n",
      "417:\tlearn: 0.0567284\ttotal: 1.61s\tremaining: 2.25s\n",
      "418:\tlearn: 0.0566434\ttotal: 1.62s\tremaining: 2.24s\n",
      "419:\tlearn: 0.0565651\ttotal: 1.62s\tremaining: 2.24s\n",
      "420:\tlearn: 0.0564552\ttotal: 1.63s\tremaining: 2.23s\n",
      "421:\tlearn: 0.0563276\ttotal: 1.63s\tremaining: 2.23s\n",
      "422:\tlearn: 0.0562392\ttotal: 1.63s\tremaining: 2.23s\n",
      "423:\tlearn: 0.0561776\ttotal: 1.64s\tremaining: 2.22s\n",
      "424:\tlearn: 0.0560807\ttotal: 1.64s\tremaining: 2.22s\n",
      "425:\tlearn: 0.0560052\ttotal: 1.64s\tremaining: 2.21s\n",
      "426:\tlearn: 0.0558899\ttotal: 1.65s\tremaining: 2.21s\n",
      "427:\tlearn: 0.0558372\ttotal: 1.65s\tremaining: 2.21s\n",
      "428:\tlearn: 0.0557421\ttotal: 1.66s\tremaining: 2.2s\n",
      "429:\tlearn: 0.0556417\ttotal: 1.66s\tremaining: 2.2s\n",
      "430:\tlearn: 0.0555259\ttotal: 1.66s\tremaining: 2.19s\n",
      "431:\tlearn: 0.0554526\ttotal: 1.67s\tremaining: 2.19s\n",
      "432:\tlearn: 0.0554058\ttotal: 1.67s\tremaining: 2.19s\n",
      "433:\tlearn: 0.0553284\ttotal: 1.67s\tremaining: 2.18s\n",
      "434:\tlearn: 0.0552376\ttotal: 1.68s\tremaining: 2.18s\n",
      "435:\tlearn: 0.0551557\ttotal: 1.68s\tremaining: 2.17s\n",
      "436:\tlearn: 0.0550973\ttotal: 1.69s\tremaining: 2.17s\n",
      "437:\tlearn: 0.0550320\ttotal: 1.69s\tremaining: 2.17s\n",
      "438:\tlearn: 0.0549511\ttotal: 1.69s\tremaining: 2.16s\n",
      "439:\tlearn: 0.0548150\ttotal: 1.7s\tremaining: 2.16s\n",
      "440:\tlearn: 0.0547242\ttotal: 1.7s\tremaining: 2.16s\n",
      "441:\tlearn: 0.0546506\ttotal: 1.71s\tremaining: 2.15s\n",
      "442:\tlearn: 0.0545716\ttotal: 1.71s\tremaining: 2.15s\n",
      "443:\tlearn: 0.0545000\ttotal: 1.71s\tremaining: 2.15s\n",
      "444:\tlearn: 0.0544005\ttotal: 1.72s\tremaining: 2.14s\n",
      "445:\tlearn: 0.0542716\ttotal: 1.72s\tremaining: 2.14s\n",
      "446:\tlearn: 0.0542395\ttotal: 1.72s\tremaining: 2.13s\n",
      "447:\tlearn: 0.0541367\ttotal: 1.73s\tremaining: 2.13s\n",
      "448:\tlearn: 0.0540479\ttotal: 1.73s\tremaining: 2.13s\n",
      "449:\tlearn: 0.0539410\ttotal: 1.74s\tremaining: 2.12s\n",
      "450:\tlearn: 0.0538708\ttotal: 1.74s\tremaining: 2.12s\n",
      "451:\tlearn: 0.0537666\ttotal: 1.74s\tremaining: 2.11s\n",
      "452:\tlearn: 0.0536803\ttotal: 1.75s\tremaining: 2.11s\n",
      "453:\tlearn: 0.0536169\ttotal: 1.75s\tremaining: 2.1s\n",
      "454:\tlearn: 0.0535272\ttotal: 1.75s\tremaining: 2.1s\n",
      "455:\tlearn: 0.0534616\ttotal: 1.76s\tremaining: 2.1s\n",
      "456:\tlearn: 0.0533723\ttotal: 1.76s\tremaining: 2.09s\n",
      "457:\tlearn: 0.0533061\ttotal: 1.77s\tremaining: 2.09s\n",
      "458:\tlearn: 0.0532470\ttotal: 1.77s\tremaining: 2.09s\n",
      "459:\tlearn: 0.0531813\ttotal: 1.77s\tremaining: 2.08s\n",
      "460:\tlearn: 0.0531258\ttotal: 1.78s\tremaining: 2.08s\n",
      "461:\tlearn: 0.0530104\ttotal: 1.78s\tremaining: 2.08s\n",
      "462:\tlearn: 0.0529125\ttotal: 1.78s\tremaining: 2.07s\n",
      "463:\tlearn: 0.0528187\ttotal: 1.79s\tremaining: 2.07s\n",
      "464:\tlearn: 0.0527293\ttotal: 1.79s\tremaining: 2.06s\n",
      "465:\tlearn: 0.0526796\ttotal: 1.8s\tremaining: 2.06s\n",
      "466:\tlearn: 0.0525730\ttotal: 1.8s\tremaining: 2.06s\n",
      "467:\tlearn: 0.0525152\ttotal: 1.8s\tremaining: 2.05s\n",
      "468:\tlearn: 0.0524723\ttotal: 1.81s\tremaining: 2.05s\n",
      "469:\tlearn: 0.0524004\ttotal: 1.81s\tremaining: 2.04s\n",
      "470:\tlearn: 0.0523774\ttotal: 1.81s\tremaining: 2.04s\n",
      "471:\tlearn: 0.0522553\ttotal: 1.82s\tremaining: 2.04s\n",
      "472:\tlearn: 0.0521706\ttotal: 1.82s\tremaining: 2.03s\n",
      "473:\tlearn: 0.0520793\ttotal: 1.83s\tremaining: 2.03s\n",
      "474:\tlearn: 0.0519757\ttotal: 1.83s\tremaining: 2.02s\n",
      "475:\tlearn: 0.0518880\ttotal: 1.83s\tremaining: 2.02s\n",
      "476:\tlearn: 0.0518075\ttotal: 1.84s\tremaining: 2.02s\n",
      "477:\tlearn: 0.0517640\ttotal: 1.84s\tremaining: 2.01s\n",
      "478:\tlearn: 0.0516888\ttotal: 1.85s\tremaining: 2.01s\n",
      "479:\tlearn: 0.0516480\ttotal: 1.85s\tremaining: 2s\n",
      "480:\tlearn: 0.0515658\ttotal: 1.85s\tremaining: 2s\n",
      "481:\tlearn: 0.0515106\ttotal: 1.86s\tremaining: 2s\n",
      "482:\tlearn: 0.0513310\ttotal: 1.86s\tremaining: 1.99s\n",
      "483:\tlearn: 0.0512452\ttotal: 1.87s\tremaining: 1.99s\n",
      "484:\tlearn: 0.0511339\ttotal: 1.87s\tremaining: 1.99s\n",
      "485:\tlearn: 0.0510627\ttotal: 1.87s\tremaining: 1.98s\n",
      "486:\tlearn: 0.0509859\ttotal: 1.88s\tremaining: 1.98s\n",
      "487:\tlearn: 0.0509296\ttotal: 1.88s\tremaining: 1.97s\n",
      "488:\tlearn: 0.0508661\ttotal: 1.89s\tremaining: 1.97s\n",
      "489:\tlearn: 0.0507681\ttotal: 1.89s\tremaining: 1.97s\n",
      "490:\tlearn: 0.0507237\ttotal: 1.89s\tremaining: 1.96s\n",
      "491:\tlearn: 0.0507009\ttotal: 1.9s\tremaining: 1.96s\n",
      "492:\tlearn: 0.0505925\ttotal: 1.9s\tremaining: 1.96s\n",
      "493:\tlearn: 0.0505145\ttotal: 1.9s\tremaining: 1.95s\n",
      "494:\tlearn: 0.0504385\ttotal: 1.91s\tremaining: 1.95s\n",
      "495:\tlearn: 0.0503695\ttotal: 1.91s\tremaining: 1.94s\n",
      "496:\tlearn: 0.0502950\ttotal: 1.92s\tremaining: 1.94s\n",
      "497:\tlearn: 0.0502243\ttotal: 1.92s\tremaining: 1.94s\n",
      "498:\tlearn: 0.0501614\ttotal: 1.92s\tremaining: 1.93s\n",
      "499:\tlearn: 0.0500819\ttotal: 1.93s\tremaining: 1.93s\n",
      "500:\tlearn: 0.0500273\ttotal: 1.93s\tremaining: 1.92s\n",
      "501:\tlearn: 0.0499829\ttotal: 1.94s\tremaining: 1.92s\n",
      "502:\tlearn: 0.0499240\ttotal: 1.94s\tremaining: 1.92s\n",
      "503:\tlearn: 0.0498933\ttotal: 1.94s\tremaining: 1.91s\n",
      "504:\tlearn: 0.0498094\ttotal: 1.95s\tremaining: 1.91s\n",
      "505:\tlearn: 0.0497511\ttotal: 1.95s\tremaining: 1.9s\n",
      "506:\tlearn: 0.0496996\ttotal: 1.95s\tremaining: 1.9s\n",
      "507:\tlearn: 0.0495961\ttotal: 1.96s\tremaining: 1.9s\n",
      "508:\tlearn: 0.0495401\ttotal: 1.96s\tremaining: 1.89s\n",
      "509:\tlearn: 0.0493785\ttotal: 1.97s\tremaining: 1.89s\n",
      "510:\tlearn: 0.0493228\ttotal: 1.97s\tremaining: 1.89s\n",
      "511:\tlearn: 0.0492624\ttotal: 1.97s\tremaining: 1.88s\n",
      "512:\tlearn: 0.0492171\ttotal: 1.98s\tremaining: 1.88s\n",
      "513:\tlearn: 0.0491607\ttotal: 1.98s\tremaining: 1.87s\n",
      "514:\tlearn: 0.0491043\ttotal: 1.99s\tremaining: 1.87s\n",
      "515:\tlearn: 0.0490182\ttotal: 1.99s\tremaining: 1.86s\n",
      "516:\tlearn: 0.0489423\ttotal: 1.99s\tremaining: 1.86s\n",
      "517:\tlearn: 0.0488971\ttotal: 2s\tremaining: 1.86s\n",
      "518:\tlearn: 0.0488495\ttotal: 2s\tremaining: 1.85s\n",
      "519:\tlearn: 0.0487493\ttotal: 2s\tremaining: 1.85s\n",
      "520:\tlearn: 0.0487218\ttotal: 2.01s\tremaining: 1.85s\n",
      "521:\tlearn: 0.0486492\ttotal: 2.01s\tremaining: 1.84s\n",
      "522:\tlearn: 0.0485674\ttotal: 2.02s\tremaining: 1.84s\n",
      "523:\tlearn: 0.0485077\ttotal: 2.02s\tremaining: 1.83s\n",
      "524:\tlearn: 0.0484574\ttotal: 2.02s\tremaining: 1.83s\n",
      "525:\tlearn: 0.0484029\ttotal: 2.03s\tremaining: 1.83s\n",
      "526:\tlearn: 0.0483624\ttotal: 2.03s\tremaining: 1.82s\n",
      "527:\tlearn: 0.0482540\ttotal: 2.03s\tremaining: 1.82s\n",
      "528:\tlearn: 0.0482318\ttotal: 2.04s\tremaining: 1.81s\n",
      "529:\tlearn: 0.0481202\ttotal: 2.04s\tremaining: 1.81s\n",
      "530:\tlearn: 0.0480500\ttotal: 2.05s\tremaining: 1.81s\n",
      "531:\tlearn: 0.0479698\ttotal: 2.05s\tremaining: 1.8s\n",
      "532:\tlearn: 0.0479243\ttotal: 2.05s\tremaining: 1.8s\n",
      "533:\tlearn: 0.0478265\ttotal: 2.06s\tremaining: 1.8s\n",
      "534:\tlearn: 0.0477485\ttotal: 2.06s\tremaining: 1.79s\n",
      "535:\tlearn: 0.0477121\ttotal: 2.06s\tremaining: 1.79s\n",
      "536:\tlearn: 0.0476611\ttotal: 2.07s\tremaining: 1.78s\n",
      "537:\tlearn: 0.0476255\ttotal: 2.07s\tremaining: 1.78s\n",
      "538:\tlearn: 0.0475768\ttotal: 2.08s\tremaining: 1.78s\n",
      "539:\tlearn: 0.0475458\ttotal: 2.08s\tremaining: 1.77s\n",
      "540:\tlearn: 0.0474780\ttotal: 2.08s\tremaining: 1.77s\n",
      "541:\tlearn: 0.0474252\ttotal: 2.09s\tremaining: 1.76s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "542:\tlearn: 0.0473551\ttotal: 2.09s\tremaining: 1.76s\n",
      "543:\tlearn: 0.0473133\ttotal: 2.1s\tremaining: 1.76s\n",
      "544:\tlearn: 0.0472605\ttotal: 2.1s\tremaining: 1.75s\n",
      "545:\tlearn: 0.0472000\ttotal: 2.1s\tremaining: 1.75s\n",
      "546:\tlearn: 0.0471129\ttotal: 2.11s\tremaining: 1.75s\n",
      "547:\tlearn: 0.0470847\ttotal: 2.11s\tremaining: 1.74s\n",
      "548:\tlearn: 0.0469985\ttotal: 2.12s\tremaining: 1.74s\n",
      "549:\tlearn: 0.0469538\ttotal: 2.12s\tremaining: 1.74s\n",
      "550:\tlearn: 0.0468677\ttotal: 2.13s\tremaining: 1.73s\n",
      "551:\tlearn: 0.0468211\ttotal: 2.13s\tremaining: 1.73s\n",
      "552:\tlearn: 0.0467913\ttotal: 2.13s\tremaining: 1.72s\n",
      "553:\tlearn: 0.0467658\ttotal: 2.14s\tremaining: 1.72s\n",
      "554:\tlearn: 0.0466983\ttotal: 2.14s\tremaining: 1.72s\n",
      "555:\tlearn: 0.0466179\ttotal: 2.15s\tremaining: 1.71s\n",
      "556:\tlearn: 0.0465770\ttotal: 2.15s\tremaining: 1.71s\n",
      "557:\tlearn: 0.0465202\ttotal: 2.15s\tremaining: 1.71s\n",
      "558:\tlearn: 0.0464792\ttotal: 2.16s\tremaining: 1.7s\n",
      "559:\tlearn: 0.0464071\ttotal: 2.16s\tremaining: 1.7s\n",
      "560:\tlearn: 0.0463551\ttotal: 2.16s\tremaining: 1.69s\n",
      "561:\tlearn: 0.0463077\ttotal: 2.17s\tremaining: 1.69s\n",
      "562:\tlearn: 0.0461963\ttotal: 2.17s\tremaining: 1.69s\n",
      "563:\tlearn: 0.0461126\ttotal: 2.18s\tremaining: 1.68s\n",
      "564:\tlearn: 0.0460505\ttotal: 2.18s\tremaining: 1.68s\n",
      "565:\tlearn: 0.0460171\ttotal: 2.18s\tremaining: 1.67s\n",
      "566:\tlearn: 0.0459572\ttotal: 2.19s\tremaining: 1.67s\n",
      "567:\tlearn: 0.0459026\ttotal: 2.19s\tremaining: 1.67s\n",
      "568:\tlearn: 0.0458340\ttotal: 2.19s\tremaining: 1.66s\n",
      "569:\tlearn: 0.0457624\ttotal: 2.2s\tremaining: 1.66s\n",
      "570:\tlearn: 0.0456502\ttotal: 2.2s\tremaining: 1.65s\n",
      "571:\tlearn: 0.0455892\ttotal: 2.21s\tremaining: 1.65s\n",
      "572:\tlearn: 0.0455362\ttotal: 2.21s\tremaining: 1.65s\n",
      "573:\tlearn: 0.0454587\ttotal: 2.21s\tremaining: 1.64s\n",
      "574:\tlearn: 0.0454004\ttotal: 2.22s\tremaining: 1.64s\n",
      "575:\tlearn: 0.0453669\ttotal: 2.22s\tremaining: 1.63s\n",
      "576:\tlearn: 0.0453407\ttotal: 2.22s\tremaining: 1.63s\n",
      "577:\tlearn: 0.0453063\ttotal: 2.23s\tremaining: 1.63s\n",
      "578:\tlearn: 0.0452589\ttotal: 2.23s\tremaining: 1.62s\n",
      "579:\tlearn: 0.0451439\ttotal: 2.24s\tremaining: 1.62s\n",
      "580:\tlearn: 0.0450965\ttotal: 2.24s\tremaining: 1.61s\n",
      "581:\tlearn: 0.0450429\ttotal: 2.24s\tremaining: 1.61s\n",
      "582:\tlearn: 0.0449816\ttotal: 2.25s\tremaining: 1.61s\n",
      "583:\tlearn: 0.0449305\ttotal: 2.25s\tremaining: 1.6s\n",
      "584:\tlearn: 0.0448792\ttotal: 2.26s\tremaining: 1.6s\n",
      "585:\tlearn: 0.0448103\ttotal: 2.26s\tremaining: 1.6s\n",
      "586:\tlearn: 0.0447571\ttotal: 2.26s\tremaining: 1.59s\n",
      "587:\tlearn: 0.0446829\ttotal: 2.27s\tremaining: 1.59s\n",
      "588:\tlearn: 0.0446053\ttotal: 2.27s\tremaining: 1.59s\n",
      "589:\tlearn: 0.0445600\ttotal: 2.28s\tremaining: 1.58s\n",
      "590:\tlearn: 0.0445063\ttotal: 2.28s\tremaining: 1.58s\n",
      "591:\tlearn: 0.0444424\ttotal: 2.29s\tremaining: 1.57s\n",
      "592:\tlearn: 0.0444209\ttotal: 2.29s\tremaining: 1.57s\n",
      "593:\tlearn: 0.0443469\ttotal: 2.29s\tremaining: 1.57s\n",
      "594:\tlearn: 0.0443336\ttotal: 2.3s\tremaining: 1.56s\n",
      "595:\tlearn: 0.0442778\ttotal: 2.3s\tremaining: 1.56s\n",
      "596:\tlearn: 0.0442414\ttotal: 2.3s\tremaining: 1.55s\n",
      "597:\tlearn: 0.0442009\ttotal: 2.31s\tremaining: 1.55s\n",
      "598:\tlearn: 0.0441181\ttotal: 2.31s\tremaining: 1.55s\n",
      "599:\tlearn: 0.0440544\ttotal: 2.32s\tremaining: 1.54s\n",
      "600:\tlearn: 0.0440359\ttotal: 2.32s\tremaining: 1.54s\n",
      "601:\tlearn: 0.0439494\ttotal: 2.33s\tremaining: 1.54s\n",
      "602:\tlearn: 0.0439184\ttotal: 2.33s\tremaining: 1.53s\n",
      "603:\tlearn: 0.0438801\ttotal: 2.33s\tremaining: 1.53s\n",
      "604:\tlearn: 0.0438491\ttotal: 2.34s\tremaining: 1.53s\n",
      "605:\tlearn: 0.0438278\ttotal: 2.34s\tremaining: 1.52s\n",
      "606:\tlearn: 0.0437969\ttotal: 2.35s\tremaining: 1.52s\n",
      "607:\tlearn: 0.0437745\ttotal: 2.35s\tremaining: 1.52s\n",
      "608:\tlearn: 0.0437292\ttotal: 2.35s\tremaining: 1.51s\n",
      "609:\tlearn: 0.0436820\ttotal: 2.36s\tremaining: 1.51s\n",
      "610:\tlearn: 0.0436371\ttotal: 2.36s\tremaining: 1.5s\n",
      "611:\tlearn: 0.0436144\ttotal: 2.37s\tremaining: 1.5s\n",
      "612:\tlearn: 0.0435566\ttotal: 2.37s\tremaining: 1.5s\n",
      "613:\tlearn: 0.0434875\ttotal: 2.38s\tremaining: 1.49s\n",
      "614:\tlearn: 0.0434614\ttotal: 2.38s\tremaining: 1.49s\n",
      "615:\tlearn: 0.0434351\ttotal: 2.38s\tremaining: 1.49s\n",
      "616:\tlearn: 0.0433863\ttotal: 2.39s\tremaining: 1.48s\n",
      "617:\tlearn: 0.0433544\ttotal: 2.39s\tremaining: 1.48s\n",
      "618:\tlearn: 0.0433145\ttotal: 2.4s\tremaining: 1.47s\n",
      "619:\tlearn: 0.0432726\ttotal: 2.4s\tremaining: 1.47s\n",
      "620:\tlearn: 0.0432119\ttotal: 2.4s\tremaining: 1.47s\n",
      "621:\tlearn: 0.0431728\ttotal: 2.41s\tremaining: 1.46s\n",
      "622:\tlearn: 0.0431184\ttotal: 2.41s\tremaining: 1.46s\n",
      "623:\tlearn: 0.0430421\ttotal: 2.42s\tremaining: 1.46s\n",
      "624:\tlearn: 0.0430027\ttotal: 2.42s\tremaining: 1.45s\n",
      "625:\tlearn: 0.0429373\ttotal: 2.43s\tremaining: 1.45s\n",
      "626:\tlearn: 0.0428526\ttotal: 2.43s\tremaining: 1.45s\n",
      "627:\tlearn: 0.0427945\ttotal: 2.44s\tremaining: 1.44s\n",
      "628:\tlearn: 0.0427224\ttotal: 2.44s\tremaining: 1.44s\n",
      "629:\tlearn: 0.0427066\ttotal: 2.44s\tremaining: 1.44s\n",
      "630:\tlearn: 0.0426847\ttotal: 2.45s\tremaining: 1.43s\n",
      "631:\tlearn: 0.0426233\ttotal: 2.45s\tremaining: 1.43s\n",
      "632:\tlearn: 0.0425746\ttotal: 2.46s\tremaining: 1.43s\n",
      "633:\tlearn: 0.0425227\ttotal: 2.46s\tremaining: 1.42s\n",
      "634:\tlearn: 0.0424345\ttotal: 2.47s\tremaining: 1.42s\n",
      "635:\tlearn: 0.0424096\ttotal: 2.47s\tremaining: 1.41s\n",
      "636:\tlearn: 0.0423515\ttotal: 2.48s\tremaining: 1.41s\n",
      "637:\tlearn: 0.0423111\ttotal: 2.48s\tremaining: 1.41s\n",
      "638:\tlearn: 0.0422405\ttotal: 2.48s\tremaining: 1.4s\n",
      "639:\tlearn: 0.0421646\ttotal: 2.49s\tremaining: 1.4s\n",
      "640:\tlearn: 0.0421482\ttotal: 2.49s\tremaining: 1.4s\n",
      "641:\tlearn: 0.0420250\ttotal: 2.5s\tremaining: 1.39s\n",
      "642:\tlearn: 0.0419814\ttotal: 2.5s\tremaining: 1.39s\n",
      "643:\tlearn: 0.0419405\ttotal: 2.51s\tremaining: 1.39s\n",
      "644:\tlearn: 0.0418370\ttotal: 2.51s\tremaining: 1.38s\n",
      "645:\tlearn: 0.0418195\ttotal: 2.51s\tremaining: 1.38s\n",
      "646:\tlearn: 0.0417875\ttotal: 2.52s\tremaining: 1.37s\n",
      "647:\tlearn: 0.0417233\ttotal: 2.52s\tremaining: 1.37s\n",
      "648:\tlearn: 0.0416692\ttotal: 2.52s\tremaining: 1.36s\n",
      "649:\tlearn: 0.0416366\ttotal: 2.53s\tremaining: 1.36s\n",
      "650:\tlearn: 0.0415392\ttotal: 2.53s\tremaining: 1.36s\n",
      "651:\tlearn: 0.0414817\ttotal: 2.54s\tremaining: 1.35s\n",
      "652:\tlearn: 0.0414297\ttotal: 2.54s\tremaining: 1.35s\n",
      "653:\tlearn: 0.0414110\ttotal: 2.54s\tremaining: 1.34s\n",
      "654:\tlearn: 0.0413560\ttotal: 2.55s\tremaining: 1.34s\n",
      "655:\tlearn: 0.0413135\ttotal: 2.55s\tremaining: 1.34s\n",
      "656:\tlearn: 0.0412801\ttotal: 2.56s\tremaining: 1.33s\n",
      "657:\tlearn: 0.0412483\ttotal: 2.56s\tremaining: 1.33s\n",
      "658:\tlearn: 0.0411350\ttotal: 2.56s\tremaining: 1.33s\n",
      "659:\tlearn: 0.0410809\ttotal: 2.57s\tremaining: 1.32s\n",
      "660:\tlearn: 0.0410307\ttotal: 2.57s\tremaining: 1.32s\n",
      "661:\tlearn: 0.0409845\ttotal: 2.57s\tremaining: 1.31s\n",
      "662:\tlearn: 0.0409401\ttotal: 2.58s\tremaining: 1.31s\n",
      "663:\tlearn: 0.0408921\ttotal: 2.58s\tremaining: 1.31s\n",
      "664:\tlearn: 0.0408232\ttotal: 2.58s\tremaining: 1.3s\n",
      "665:\tlearn: 0.0407705\ttotal: 2.59s\tremaining: 1.3s\n",
      "666:\tlearn: 0.0406949\ttotal: 2.59s\tremaining: 1.29s\n",
      "667:\tlearn: 0.0406541\ttotal: 2.6s\tremaining: 1.29s\n",
      "668:\tlearn: 0.0405907\ttotal: 2.6s\tremaining: 1.29s\n",
      "669:\tlearn: 0.0405753\ttotal: 2.6s\tremaining: 1.28s\n",
      "670:\tlearn: 0.0405332\ttotal: 2.61s\tremaining: 1.28s\n",
      "671:\tlearn: 0.0404994\ttotal: 2.61s\tremaining: 1.27s\n",
      "672:\tlearn: 0.0404754\ttotal: 2.62s\tremaining: 1.27s\n",
      "673:\tlearn: 0.0404474\ttotal: 2.62s\tremaining: 1.27s\n",
      "674:\tlearn: 0.0404016\ttotal: 2.62s\tremaining: 1.26s\n",
      "675:\tlearn: 0.0403540\ttotal: 2.63s\tremaining: 1.26s\n",
      "676:\tlearn: 0.0402575\ttotal: 2.63s\tremaining: 1.25s\n",
      "677:\tlearn: 0.0402298\ttotal: 2.63s\tremaining: 1.25s\n",
      "678:\tlearn: 0.0401834\ttotal: 2.64s\tremaining: 1.25s\n",
      "679:\tlearn: 0.0401509\ttotal: 2.64s\tremaining: 1.24s\n",
      "680:\tlearn: 0.0400989\ttotal: 2.65s\tremaining: 1.24s\n",
      "681:\tlearn: 0.0400749\ttotal: 2.65s\tremaining: 1.24s\n",
      "682:\tlearn: 0.0400482\ttotal: 2.65s\tremaining: 1.23s\n",
      "683:\tlearn: 0.0399837\ttotal: 2.66s\tremaining: 1.23s\n",
      "684:\tlearn: 0.0399475\ttotal: 2.66s\tremaining: 1.22s\n",
      "685:\tlearn: 0.0399233\ttotal: 2.67s\tremaining: 1.22s\n",
      "686:\tlearn: 0.0398815\ttotal: 2.67s\tremaining: 1.22s\n",
      "687:\tlearn: 0.0398466\ttotal: 2.68s\tremaining: 1.21s\n",
      "688:\tlearn: 0.0398042\ttotal: 2.68s\tremaining: 1.21s\n",
      "689:\tlearn: 0.0397524\ttotal: 2.68s\tremaining: 1.21s\n",
      "690:\tlearn: 0.0397242\ttotal: 2.69s\tremaining: 1.2s\n",
      "691:\tlearn: 0.0397011\ttotal: 2.69s\tremaining: 1.2s\n",
      "692:\tlearn: 0.0396549\ttotal: 2.7s\tremaining: 1.2s\n",
      "693:\tlearn: 0.0395637\ttotal: 2.7s\tremaining: 1.19s\n",
      "694:\tlearn: 0.0395314\ttotal: 2.71s\tremaining: 1.19s\n",
      "695:\tlearn: 0.0394837\ttotal: 2.71s\tremaining: 1.18s\n",
      "696:\tlearn: 0.0394574\ttotal: 2.71s\tremaining: 1.18s\n",
      "697:\tlearn: 0.0394308\ttotal: 2.72s\tremaining: 1.18s\n",
      "698:\tlearn: 0.0393905\ttotal: 2.72s\tremaining: 1.17s\n",
      "699:\tlearn: 0.0393069\ttotal: 2.73s\tremaining: 1.17s\n",
      "700:\tlearn: 0.0392731\ttotal: 2.73s\tremaining: 1.16s\n",
      "701:\tlearn: 0.0392115\ttotal: 2.73s\tremaining: 1.16s\n",
      "702:\tlearn: 0.0391568\ttotal: 2.74s\tremaining: 1.16s\n",
      "703:\tlearn: 0.0390962\ttotal: 2.74s\tremaining: 1.15s\n",
      "704:\tlearn: 0.0390667\ttotal: 2.75s\tremaining: 1.15s\n",
      "705:\tlearn: 0.0390503\ttotal: 2.75s\tremaining: 1.15s\n",
      "706:\tlearn: 0.0390181\ttotal: 2.76s\tremaining: 1.14s\n",
      "707:\tlearn: 0.0389839\ttotal: 2.76s\tremaining: 1.14s\n",
      "708:\tlearn: 0.0389111\ttotal: 2.76s\tremaining: 1.13s\n",
      "709:\tlearn: 0.0388929\ttotal: 2.77s\tremaining: 1.13s\n",
      "710:\tlearn: 0.0388453\ttotal: 2.77s\tremaining: 1.13s\n",
      "711:\tlearn: 0.0388015\ttotal: 2.78s\tremaining: 1.12s\n",
      "712:\tlearn: 0.0387661\ttotal: 2.78s\tremaining: 1.12s\n",
      "713:\tlearn: 0.0387012\ttotal: 2.79s\tremaining: 1.11s\n",
      "714:\tlearn: 0.0386815\ttotal: 2.79s\tremaining: 1.11s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "715:\tlearn: 0.0386573\ttotal: 2.79s\tremaining: 1.11s\n",
      "716:\tlearn: 0.0386314\ttotal: 2.8s\tremaining: 1.1s\n",
      "717:\tlearn: 0.0385965\ttotal: 2.8s\tremaining: 1.1s\n",
      "718:\tlearn: 0.0385432\ttotal: 2.8s\tremaining: 1.09s\n",
      "719:\tlearn: 0.0385118\ttotal: 2.81s\tremaining: 1.09s\n",
      "720:\tlearn: 0.0384817\ttotal: 2.81s\tremaining: 1.09s\n",
      "721:\tlearn: 0.0384387\ttotal: 2.81s\tremaining: 1.08s\n",
      "722:\tlearn: 0.0383851\ttotal: 2.82s\tremaining: 1.08s\n",
      "723:\tlearn: 0.0383331\ttotal: 2.82s\tremaining: 1.08s\n",
      "724:\tlearn: 0.0382764\ttotal: 2.83s\tremaining: 1.07s\n",
      "725:\tlearn: 0.0382580\ttotal: 2.83s\tremaining: 1.07s\n",
      "726:\tlearn: 0.0382392\ttotal: 2.83s\tremaining: 1.06s\n",
      "727:\tlearn: 0.0381957\ttotal: 2.84s\tremaining: 1.06s\n",
      "728:\tlearn: 0.0381681\ttotal: 2.84s\tremaining: 1.06s\n",
      "729:\tlearn: 0.0381019\ttotal: 2.85s\tremaining: 1.05s\n",
      "730:\tlearn: 0.0380591\ttotal: 2.85s\tremaining: 1.05s\n",
      "731:\tlearn: 0.0380273\ttotal: 2.85s\tremaining: 1.04s\n",
      "732:\tlearn: 0.0379893\ttotal: 2.86s\tremaining: 1.04s\n",
      "733:\tlearn: 0.0379419\ttotal: 2.86s\tremaining: 1.04s\n",
      "734:\tlearn: 0.0379101\ttotal: 2.87s\tremaining: 1.03s\n",
      "735:\tlearn: 0.0378909\ttotal: 2.87s\tremaining: 1.03s\n",
      "736:\tlearn: 0.0378659\ttotal: 2.87s\tremaining: 1.02s\n",
      "737:\tlearn: 0.0378154\ttotal: 2.88s\tremaining: 1.02s\n",
      "738:\tlearn: 0.0377811\ttotal: 2.88s\tremaining: 1.02s\n",
      "739:\tlearn: 0.0377416\ttotal: 2.88s\tremaining: 1.01s\n",
      "740:\tlearn: 0.0377232\ttotal: 2.89s\tremaining: 1.01s\n",
      "741:\tlearn: 0.0376870\ttotal: 2.89s\tremaining: 1s\n",
      "742:\tlearn: 0.0376635\ttotal: 2.89s\tremaining: 1s\n",
      "743:\tlearn: 0.0376365\ttotal: 2.9s\tremaining: 997ms\n",
      "744:\tlearn: 0.0375900\ttotal: 2.9s\tremaining: 993ms\n",
      "745:\tlearn: 0.0375718\ttotal: 2.9s\tremaining: 989ms\n",
      "746:\tlearn: 0.0375474\ttotal: 2.91s\tremaining: 985ms\n",
      "747:\tlearn: 0.0375172\ttotal: 2.91s\tremaining: 981ms\n",
      "748:\tlearn: 0.0374912\ttotal: 2.92s\tremaining: 977ms\n",
      "749:\tlearn: 0.0374607\ttotal: 2.92s\tremaining: 973ms\n",
      "750:\tlearn: 0.0374038\ttotal: 2.92s\tremaining: 969ms\n",
      "751:\tlearn: 0.0373579\ttotal: 2.93s\tremaining: 965ms\n",
      "752:\tlearn: 0.0373222\ttotal: 2.93s\tremaining: 961ms\n",
      "753:\tlearn: 0.0373029\ttotal: 2.93s\tremaining: 957ms\n",
      "754:\tlearn: 0.0372769\ttotal: 2.94s\tremaining: 953ms\n",
      "755:\tlearn: 0.0372132\ttotal: 2.94s\tremaining: 949ms\n",
      "756:\tlearn: 0.0371566\ttotal: 2.94s\tremaining: 945ms\n",
      "757:\tlearn: 0.0371315\ttotal: 2.95s\tremaining: 941ms\n",
      "758:\tlearn: 0.0370728\ttotal: 2.95s\tremaining: 937ms\n",
      "759:\tlearn: 0.0370416\ttotal: 2.96s\tremaining: 933ms\n",
      "760:\tlearn: 0.0370144\ttotal: 2.96s\tremaining: 929ms\n",
      "761:\tlearn: 0.0369926\ttotal: 2.96s\tremaining: 925ms\n",
      "762:\tlearn: 0.0369596\ttotal: 2.97s\tremaining: 921ms\n",
      "763:\tlearn: 0.0369331\ttotal: 2.97s\tremaining: 918ms\n",
      "764:\tlearn: 0.0369073\ttotal: 2.97s\tremaining: 914ms\n",
      "765:\tlearn: 0.0368807\ttotal: 2.98s\tremaining: 910ms\n",
      "766:\tlearn: 0.0368397\ttotal: 2.98s\tremaining: 906ms\n",
      "767:\tlearn: 0.0367729\ttotal: 2.98s\tremaining: 902ms\n",
      "768:\tlearn: 0.0367467\ttotal: 2.99s\tremaining: 898ms\n",
      "769:\tlearn: 0.0367134\ttotal: 2.99s\tremaining: 894ms\n",
      "770:\tlearn: 0.0366373\ttotal: 3s\tremaining: 890ms\n",
      "771:\tlearn: 0.0366037\ttotal: 3s\tremaining: 886ms\n",
      "772:\tlearn: 0.0365627\ttotal: 3s\tremaining: 882ms\n",
      "773:\tlearn: 0.0365349\ttotal: 3.01s\tremaining: 879ms\n",
      "774:\tlearn: 0.0365009\ttotal: 3.01s\tremaining: 875ms\n",
      "775:\tlearn: 0.0364678\ttotal: 3.02s\tremaining: 871ms\n",
      "776:\tlearn: 0.0364288\ttotal: 3.02s\tremaining: 867ms\n",
      "777:\tlearn: 0.0363679\ttotal: 3.02s\tremaining: 863ms\n",
      "778:\tlearn: 0.0363394\ttotal: 3.03s\tremaining: 859ms\n",
      "779:\tlearn: 0.0363089\ttotal: 3.03s\tremaining: 855ms\n",
      "780:\tlearn: 0.0362359\ttotal: 3.04s\tremaining: 851ms\n",
      "781:\tlearn: 0.0361743\ttotal: 3.04s\tremaining: 847ms\n",
      "782:\tlearn: 0.0361398\ttotal: 3.04s\tremaining: 844ms\n",
      "783:\tlearn: 0.0361110\ttotal: 3.05s\tremaining: 840ms\n",
      "784:\tlearn: 0.0360702\ttotal: 3.05s\tremaining: 836ms\n",
      "785:\tlearn: 0.0360414\ttotal: 3.05s\tremaining: 832ms\n",
      "786:\tlearn: 0.0360175\ttotal: 3.06s\tremaining: 828ms\n",
      "787:\tlearn: 0.0359860\ttotal: 3.06s\tremaining: 824ms\n",
      "788:\tlearn: 0.0359259\ttotal: 3.07s\tremaining: 820ms\n",
      "789:\tlearn: 0.0358744\ttotal: 3.07s\tremaining: 816ms\n",
      "790:\tlearn: 0.0358161\ttotal: 3.07s\tremaining: 812ms\n",
      "791:\tlearn: 0.0357878\ttotal: 3.08s\tremaining: 808ms\n",
      "792:\tlearn: 0.0357441\ttotal: 3.08s\tremaining: 805ms\n",
      "793:\tlearn: 0.0357292\ttotal: 3.08s\tremaining: 801ms\n",
      "794:\tlearn: 0.0357090\ttotal: 3.09s\tremaining: 797ms\n",
      "795:\tlearn: 0.0356900\ttotal: 3.09s\tremaining: 793ms\n",
      "796:\tlearn: 0.0356521\ttotal: 3.1s\tremaining: 789ms\n",
      "797:\tlearn: 0.0355905\ttotal: 3.1s\tremaining: 785ms\n",
      "798:\tlearn: 0.0355688\ttotal: 3.11s\tremaining: 782ms\n",
      "799:\tlearn: 0.0355192\ttotal: 3.11s\tremaining: 778ms\n",
      "800:\tlearn: 0.0354943\ttotal: 3.11s\tremaining: 774ms\n",
      "801:\tlearn: 0.0354220\ttotal: 3.12s\tremaining: 770ms\n",
      "802:\tlearn: 0.0353929\ttotal: 3.12s\tremaining: 766ms\n",
      "803:\tlearn: 0.0353674\ttotal: 3.13s\tremaining: 762ms\n",
      "804:\tlearn: 0.0353421\ttotal: 3.13s\tremaining: 758ms\n",
      "805:\tlearn: 0.0353102\ttotal: 3.13s\tremaining: 754ms\n",
      "806:\tlearn: 0.0352796\ttotal: 3.14s\tremaining: 750ms\n",
      "807:\tlearn: 0.0352570\ttotal: 3.14s\tremaining: 747ms\n",
      "808:\tlearn: 0.0352258\ttotal: 3.15s\tremaining: 743ms\n",
      "809:\tlearn: 0.0351856\ttotal: 3.15s\tremaining: 739ms\n",
      "810:\tlearn: 0.0351577\ttotal: 3.15s\tremaining: 735ms\n",
      "811:\tlearn: 0.0351417\ttotal: 3.16s\tremaining: 731ms\n",
      "812:\tlearn: 0.0351166\ttotal: 3.16s\tremaining: 727ms\n",
      "813:\tlearn: 0.0350914\ttotal: 3.17s\tremaining: 723ms\n",
      "814:\tlearn: 0.0350508\ttotal: 3.17s\tremaining: 719ms\n",
      "815:\tlearn: 0.0349859\ttotal: 3.17s\tremaining: 715ms\n",
      "816:\tlearn: 0.0349174\ttotal: 3.17s\tremaining: 711ms\n",
      "817:\tlearn: 0.0348849\ttotal: 3.18s\tremaining: 707ms\n",
      "818:\tlearn: 0.0348649\ttotal: 3.18s\tremaining: 703ms\n",
      "819:\tlearn: 0.0348305\ttotal: 3.19s\tremaining: 699ms\n",
      "820:\tlearn: 0.0348059\ttotal: 3.19s\tremaining: 696ms\n",
      "821:\tlearn: 0.0347772\ttotal: 3.19s\tremaining: 692ms\n",
      "822:\tlearn: 0.0347602\ttotal: 3.2s\tremaining: 688ms\n",
      "823:\tlearn: 0.0347358\ttotal: 3.2s\tremaining: 684ms\n",
      "824:\tlearn: 0.0346897\ttotal: 3.21s\tremaining: 680ms\n",
      "825:\tlearn: 0.0346338\ttotal: 3.21s\tremaining: 676ms\n",
      "826:\tlearn: 0.0346035\ttotal: 3.21s\tremaining: 672ms\n",
      "827:\tlearn: 0.0345696\ttotal: 3.22s\tremaining: 668ms\n",
      "828:\tlearn: 0.0345458\ttotal: 3.22s\tremaining: 664ms\n",
      "829:\tlearn: 0.0345216\ttotal: 3.23s\tremaining: 661ms\n",
      "830:\tlearn: 0.0344645\ttotal: 3.23s\tremaining: 657ms\n",
      "831:\tlearn: 0.0344381\ttotal: 3.23s\tremaining: 653ms\n",
      "832:\tlearn: 0.0344108\ttotal: 3.24s\tremaining: 649ms\n",
      "833:\tlearn: 0.0343869\ttotal: 3.24s\tremaining: 645ms\n",
      "834:\tlearn: 0.0343537\ttotal: 3.24s\tremaining: 641ms\n",
      "835:\tlearn: 0.0343242\ttotal: 3.25s\tremaining: 637ms\n",
      "836:\tlearn: 0.0342957\ttotal: 3.25s\tremaining: 633ms\n",
      "837:\tlearn: 0.0342560\ttotal: 3.26s\tremaining: 630ms\n",
      "838:\tlearn: 0.0341894\ttotal: 3.26s\tremaining: 626ms\n",
      "839:\tlearn: 0.0341497\ttotal: 3.26s\tremaining: 622ms\n",
      "840:\tlearn: 0.0341158\ttotal: 3.27s\tremaining: 618ms\n",
      "841:\tlearn: 0.0340922\ttotal: 3.27s\tremaining: 614ms\n",
      "842:\tlearn: 0.0340690\ttotal: 3.27s\tremaining: 610ms\n",
      "843:\tlearn: 0.0340457\ttotal: 3.28s\tremaining: 606ms\n",
      "844:\tlearn: 0.0340165\ttotal: 3.28s\tremaining: 602ms\n",
      "845:\tlearn: 0.0339770\ttotal: 3.29s\tremaining: 598ms\n",
      "846:\tlearn: 0.0339534\ttotal: 3.29s\tremaining: 594ms\n",
      "847:\tlearn: 0.0339140\ttotal: 3.29s\tremaining: 590ms\n",
      "848:\tlearn: 0.0338940\ttotal: 3.29s\tremaining: 586ms\n",
      "849:\tlearn: 0.0338399\ttotal: 3.3s\tremaining: 582ms\n",
      "850:\tlearn: 0.0338111\ttotal: 3.3s\tremaining: 578ms\n",
      "851:\tlearn: 0.0337906\ttotal: 3.31s\tremaining: 574ms\n",
      "852:\tlearn: 0.0337363\ttotal: 3.31s\tremaining: 570ms\n",
      "853:\tlearn: 0.0337092\ttotal: 3.31s\tremaining: 567ms\n",
      "854:\tlearn: 0.0336802\ttotal: 3.32s\tremaining: 563ms\n",
      "855:\tlearn: 0.0336569\ttotal: 3.32s\tremaining: 559ms\n",
      "856:\tlearn: 0.0336303\ttotal: 3.33s\tremaining: 555ms\n",
      "857:\tlearn: 0.0336074\ttotal: 3.33s\tremaining: 551ms\n",
      "858:\tlearn: 0.0335848\ttotal: 3.33s\tremaining: 547ms\n",
      "859:\tlearn: 0.0335156\ttotal: 3.34s\tremaining: 543ms\n",
      "860:\tlearn: 0.0334889\ttotal: 3.34s\tremaining: 539ms\n",
      "861:\tlearn: 0.0334615\ttotal: 3.35s\tremaining: 536ms\n",
      "862:\tlearn: 0.0334353\ttotal: 3.35s\tremaining: 532ms\n",
      "863:\tlearn: 0.0334122\ttotal: 3.35s\tremaining: 528ms\n",
      "864:\tlearn: 0.0333689\ttotal: 3.36s\tremaining: 524ms\n",
      "865:\tlearn: 0.0333529\ttotal: 3.36s\tremaining: 520ms\n",
      "866:\tlearn: 0.0333310\ttotal: 3.36s\tremaining: 516ms\n",
      "867:\tlearn: 0.0333036\ttotal: 3.37s\tremaining: 512ms\n",
      "868:\tlearn: 0.0332800\ttotal: 3.37s\tremaining: 508ms\n",
      "869:\tlearn: 0.0332550\ttotal: 3.38s\tremaining: 504ms\n",
      "870:\tlearn: 0.0332325\ttotal: 3.38s\tremaining: 501ms\n",
      "871:\tlearn: 0.0332106\ttotal: 3.38s\tremaining: 497ms\n",
      "872:\tlearn: 0.0331882\ttotal: 3.39s\tremaining: 493ms\n",
      "873:\tlearn: 0.0331256\ttotal: 3.39s\tremaining: 489ms\n",
      "874:\tlearn: 0.0330895\ttotal: 3.39s\tremaining: 485ms\n",
      "875:\tlearn: 0.0330652\ttotal: 3.4s\tremaining: 481ms\n",
      "876:\tlearn: 0.0330394\ttotal: 3.4s\tremaining: 477ms\n",
      "877:\tlearn: 0.0330188\ttotal: 3.41s\tremaining: 473ms\n",
      "878:\tlearn: 0.0329969\ttotal: 3.41s\tremaining: 470ms\n",
      "879:\tlearn: 0.0329751\ttotal: 3.42s\tremaining: 466ms\n",
      "880:\tlearn: 0.0329390\ttotal: 3.42s\tremaining: 462ms\n",
      "881:\tlearn: 0.0328850\ttotal: 3.42s\tremaining: 458ms\n",
      "882:\tlearn: 0.0328351\ttotal: 3.43s\tremaining: 454ms\n",
      "883:\tlearn: 0.0328088\ttotal: 3.43s\tremaining: 450ms\n",
      "884:\tlearn: 0.0327732\ttotal: 3.44s\tremaining: 447ms\n",
      "885:\tlearn: 0.0327558\ttotal: 3.44s\tremaining: 443ms\n",
      "886:\tlearn: 0.0327342\ttotal: 3.45s\tremaining: 439ms\n",
      "887:\tlearn: 0.0327081\ttotal: 3.45s\tremaining: 435ms\n",
      "888:\tlearn: 0.0326867\ttotal: 3.45s\tremaining: 431ms\n",
      "889:\tlearn: 0.0326763\ttotal: 3.46s\tremaining: 427ms\n",
      "890:\tlearn: 0.0326391\ttotal: 3.46s\tremaining: 423ms\n",
      "891:\tlearn: 0.0326186\ttotal: 3.46s\tremaining: 420ms\n",
      "892:\tlearn: 0.0325977\ttotal: 3.47s\tremaining: 416ms\n",
      "893:\tlearn: 0.0325754\ttotal: 3.47s\tremaining: 412ms\n",
      "894:\tlearn: 0.0325529\ttotal: 3.48s\tremaining: 408ms\n",
      "895:\tlearn: 0.0325326\ttotal: 3.48s\tremaining: 404ms\n",
      "896:\tlearn: 0.0325075\ttotal: 3.48s\tremaining: 400ms\n",
      "897:\tlearn: 0.0324633\ttotal: 3.49s\tremaining: 396ms\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "898:\tlearn: 0.0324430\ttotal: 3.49s\tremaining: 392ms\n",
      "899:\tlearn: 0.0324133\ttotal: 3.5s\tremaining: 389ms\n",
      "900:\tlearn: 0.0323885\ttotal: 3.5s\tremaining: 385ms\n",
      "901:\tlearn: 0.0323630\ttotal: 3.5s\tremaining: 381ms\n",
      "902:\tlearn: 0.0323426\ttotal: 3.51s\tremaining: 377ms\n",
      "903:\tlearn: 0.0323221\ttotal: 3.51s\tremaining: 373ms\n",
      "904:\tlearn: 0.0322531\ttotal: 3.52s\tremaining: 369ms\n",
      "905:\tlearn: 0.0321789\ttotal: 3.52s\tremaining: 365ms\n",
      "906:\tlearn: 0.0321551\ttotal: 3.52s\tremaining: 361ms\n",
      "907:\tlearn: 0.0321310\ttotal: 3.53s\tremaining: 358ms\n",
      "908:\tlearn: 0.0321108\ttotal: 3.53s\tremaining: 354ms\n",
      "909:\tlearn: 0.0320943\ttotal: 3.54s\tremaining: 350ms\n",
      "910:\tlearn: 0.0320647\ttotal: 3.54s\tremaining: 346ms\n",
      "911:\tlearn: 0.0320401\ttotal: 3.54s\tremaining: 342ms\n",
      "912:\tlearn: 0.0320093\ttotal: 3.55s\tremaining: 338ms\n",
      "913:\tlearn: 0.0319853\ttotal: 3.55s\tremaining: 334ms\n",
      "914:\tlearn: 0.0319653\ttotal: 3.55s\tremaining: 330ms\n",
      "915:\tlearn: 0.0319353\ttotal: 3.56s\tremaining: 326ms\n",
      "916:\tlearn: 0.0319126\ttotal: 3.56s\tremaining: 322ms\n",
      "917:\tlearn: 0.0318533\ttotal: 3.56s\tremaining: 318ms\n",
      "918:\tlearn: 0.0318320\ttotal: 3.57s\tremaining: 314ms\n",
      "919:\tlearn: 0.0318111\ttotal: 3.57s\tremaining: 311ms\n",
      "920:\tlearn: 0.0317612\ttotal: 3.57s\tremaining: 307ms\n",
      "921:\tlearn: 0.0316947\ttotal: 3.58s\tremaining: 303ms\n",
      "922:\tlearn: 0.0316229\ttotal: 3.58s\tremaining: 299ms\n",
      "923:\tlearn: 0.0316069\ttotal: 3.58s\tremaining: 295ms\n",
      "924:\tlearn: 0.0315846\ttotal: 3.59s\tremaining: 291ms\n",
      "925:\tlearn: 0.0315621\ttotal: 3.59s\tremaining: 287ms\n",
      "926:\tlearn: 0.0315393\ttotal: 3.6s\tremaining: 283ms\n",
      "927:\tlearn: 0.0315197\ttotal: 3.6s\tremaining: 279ms\n",
      "928:\tlearn: 0.0314962\ttotal: 3.6s\tremaining: 275ms\n",
      "929:\tlearn: 0.0314771\ttotal: 3.61s\tremaining: 272ms\n",
      "930:\tlearn: 0.0314579\ttotal: 3.61s\tremaining: 268ms\n",
      "931:\tlearn: 0.0314391\ttotal: 3.61s\tremaining: 264ms\n",
      "932:\tlearn: 0.0314176\ttotal: 3.62s\tremaining: 260ms\n",
      "933:\tlearn: 0.0313984\ttotal: 3.62s\tremaining: 256ms\n",
      "934:\tlearn: 0.0313410\ttotal: 3.63s\tremaining: 252ms\n",
      "935:\tlearn: 0.0313247\ttotal: 3.63s\tremaining: 248ms\n",
      "936:\tlearn: 0.0313055\ttotal: 3.63s\tremaining: 244ms\n",
      "937:\tlearn: 0.0312866\ttotal: 3.63s\tremaining: 240ms\n",
      "938:\tlearn: 0.0312683\ttotal: 3.64s\tremaining: 236ms\n",
      "939:\tlearn: 0.0312122\ttotal: 3.64s\tremaining: 233ms\n",
      "940:\tlearn: 0.0311929\ttotal: 3.65s\tremaining: 229ms\n",
      "941:\tlearn: 0.0311771\ttotal: 3.65s\tremaining: 225ms\n",
      "942:\tlearn: 0.0311131\ttotal: 3.65s\tremaining: 221ms\n",
      "943:\tlearn: 0.0310838\ttotal: 3.66s\tremaining: 217ms\n",
      "944:\tlearn: 0.0310353\ttotal: 3.66s\tremaining: 213ms\n",
      "945:\tlearn: 0.0310022\ttotal: 3.66s\tremaining: 209ms\n",
      "946:\tlearn: 0.0309834\ttotal: 3.67s\tremaining: 205ms\n",
      "947:\tlearn: 0.0309742\ttotal: 3.67s\tremaining: 201ms\n",
      "948:\tlearn: 0.0309586\ttotal: 3.68s\tremaining: 198ms\n",
      "949:\tlearn: 0.0308988\ttotal: 3.68s\tremaining: 194ms\n",
      "950:\tlearn: 0.0308801\ttotal: 3.68s\tremaining: 190ms\n",
      "951:\tlearn: 0.0308589\ttotal: 3.69s\tremaining: 186ms\n",
      "952:\tlearn: 0.0308119\ttotal: 3.69s\tremaining: 182ms\n",
      "953:\tlearn: 0.0308012\ttotal: 3.7s\tremaining: 178ms\n",
      "954:\tlearn: 0.0307395\ttotal: 3.7s\tremaining: 174ms\n",
      "955:\tlearn: 0.0307172\ttotal: 3.7s\tremaining: 171ms\n",
      "956:\tlearn: 0.0306991\ttotal: 3.71s\tremaining: 167ms\n",
      "957:\tlearn: 0.0306804\ttotal: 3.71s\tremaining: 163ms\n",
      "958:\tlearn: 0.0306691\ttotal: 3.72s\tremaining: 159ms\n",
      "959:\tlearn: 0.0306088\ttotal: 3.72s\tremaining: 155ms\n",
      "960:\tlearn: 0.0305906\ttotal: 3.72s\tremaining: 151ms\n",
      "961:\tlearn: 0.0305241\ttotal: 3.73s\tremaining: 147ms\n",
      "962:\tlearn: 0.0304954\ttotal: 3.73s\tremaining: 143ms\n",
      "963:\tlearn: 0.0304770\ttotal: 3.73s\tremaining: 139ms\n",
      "964:\tlearn: 0.0304488\ttotal: 3.74s\tremaining: 136ms\n",
      "965:\tlearn: 0.0304307\ttotal: 3.74s\tremaining: 132ms\n",
      "966:\tlearn: 0.0304148\ttotal: 3.75s\tremaining: 128ms\n",
      "967:\tlearn: 0.0303995\ttotal: 3.75s\tremaining: 124ms\n",
      "968:\tlearn: 0.0303758\ttotal: 3.75s\tremaining: 120ms\n",
      "969:\tlearn: 0.0303577\ttotal: 3.76s\tremaining: 116ms\n",
      "970:\tlearn: 0.0302992\ttotal: 3.76s\tremaining: 112ms\n",
      "971:\tlearn: 0.0302882\ttotal: 3.77s\tremaining: 108ms\n",
      "972:\tlearn: 0.0302650\ttotal: 3.77s\tremaining: 105ms\n",
      "973:\tlearn: 0.0302473\ttotal: 3.77s\tremaining: 101ms\n",
      "974:\tlearn: 0.0302261\ttotal: 3.78s\tremaining: 96.9ms\n",
      "975:\tlearn: 0.0302086\ttotal: 3.78s\tremaining: 93ms\n",
      "976:\tlearn: 0.0301888\ttotal: 3.78s\tremaining: 89.1ms\n",
      "977:\tlearn: 0.0301511\ttotal: 3.79s\tremaining: 85.2ms\n",
      "978:\tlearn: 0.0301361\ttotal: 3.79s\tremaining: 81.3ms\n",
      "979:\tlearn: 0.0300836\ttotal: 3.79s\tremaining: 77.5ms\n",
      "980:\tlearn: 0.0300662\ttotal: 3.8s\tremaining: 73.6ms\n",
      "981:\tlearn: 0.0300513\ttotal: 3.8s\tremaining: 69.7ms\n",
      "982:\tlearn: 0.0300234\ttotal: 3.81s\tremaining: 65.8ms\n",
      "983:\tlearn: 0.0299786\ttotal: 3.81s\tremaining: 62ms\n",
      "984:\tlearn: 0.0299382\ttotal: 3.81s\tremaining: 58.1ms\n",
      "985:\tlearn: 0.0299094\ttotal: 3.82s\tremaining: 54.2ms\n",
      "986:\tlearn: 0.0298714\ttotal: 3.82s\tremaining: 50.3ms\n",
      "987:\tlearn: 0.0298516\ttotal: 3.82s\tremaining: 46.5ms\n",
      "988:\tlearn: 0.0298008\ttotal: 3.83s\tremaining: 42.6ms\n",
      "989:\tlearn: 0.0297599\ttotal: 3.83s\tremaining: 38.7ms\n",
      "990:\tlearn: 0.0297102\ttotal: 3.84s\tremaining: 34.8ms\n",
      "991:\tlearn: 0.0296556\ttotal: 3.84s\tremaining: 31ms\n",
      "992:\tlearn: 0.0296071\ttotal: 3.85s\tremaining: 27.1ms\n",
      "993:\tlearn: 0.0295877\ttotal: 3.85s\tremaining: 23.2ms\n",
      "994:\tlearn: 0.0295731\ttotal: 3.85s\tremaining: 19.4ms\n",
      "995:\tlearn: 0.0295399\ttotal: 3.86s\tremaining: 15.5ms\n",
      "996:\tlearn: 0.0295229\ttotal: 3.86s\tremaining: 11.6ms\n",
      "997:\tlearn: 0.0294804\ttotal: 3.86s\tremaining: 7.74ms\n",
      "998:\tlearn: 0.0294635\ttotal: 3.87s\tremaining: 3.87ms\n",
      "999:\tlearn: 0.0294449\ttotal: 3.87s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model1 = RandomForestClassifier(n_estimators=500, max_features=5,\n",
    "                                   max_depth=8, random_state=20,\n",
    "                                   criterion='entropy',)\n",
    "\n",
    "model2 = XGBClassifier( objective= 'binary:logistic', nthread= 10,\n",
    "                              eval_metric= 'auc', silent= 1, seed= 20,\n",
    "\n",
    "                              max_depth= 6, gamma= 0, base_score= 0.50,\n",
    "                              min_child_weight= 4, subsample= 0.5,\n",
    "                              colsample_bytree= 1, eta= 0.01,)\n",
    "\n",
    "model3 = GradientBoostingClassifier(n_estimators=200,\n",
    "                                       random_state=20,\n",
    "                                       max_depth=5,\n",
    "                                       learning_rate=0.03,\n",
    "                                       max_features=5,)\n",
    "model4 = CatBoostClassifier(random_state=20)\n",
    "\n",
    "k_fold_accuracy = []\n",
    "kf = KFold(n_splits=10,shuffle = True)\n",
    "\n",
    "for train_index, test_index in kf.split(X):\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "\n",
    "    model1.fit(X_train,y_train)\n",
    "    model2.fit(X_train,y_train)\n",
    "    model3.fit(X_train,y_train)\n",
    "    model4.fit(X_train,y_train)\n",
    "\n",
    "\n",
    "    y_pred1 = model1.predict_proba(X_test)\n",
    "    y_pred2 = model2.predict_proba(X_test)\n",
    "    y_pred3 = model3.predict_proba(X_test)\n",
    "    y_pred4 = model4.predict_proba(X_test)\n",
    "\n",
    "\n",
    "    accu1 = model1.predict(X_test)\n",
    "    accu2 = model2.predict(X_test)\n",
    "    accu3 = model3.predict(X_test)\n",
    "    accu4 = model4.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Accuracy_score on RandomForest :  0.9154228855721394\n",
      "\n",
      "Accuracy_score on XGB :  0.9054726368159204\n",
      "\n",
      "Accuracy_score on GradientBoost :  0.9154228855721394\n",
      "\n",
      "Accuracy_score on CatBoost :  0.9104477611940298\n",
      "\n",
      "Average Accuracy :  0.9116915422885572\n"
     ]
    }
   ],
   "source": [
    "print('\\nAccuracy_score on RandomForest : ', accuracy_score(y_test, accu1))\n",
    "print('\\nAccuracy_score on XGB : ', accuracy_score(y_test, accu2))\n",
    "print('\\nAccuracy_score on GradientBoost : ', accuracy_score(y_test, accu3))\n",
    "print('\\nAccuracy_score on CatBoost : ', accuracy_score(y_test, accu4))\n",
    "\n",
    "averaging_accuracy = (accuracy_score(y_test, accu1) + accuracy_score(y_test, accu2) +accuracy_score(y_test, accu3)+accuracy_score(y_test, accu4))/4\n",
    "print('\\nAverage Accuracy : ', averaging_accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC SCORES\n",
      "-----------------------------------\n",
      "RandomForest :  0.931845780206436\n",
      "XGB :  0.920916818457802\n",
      "Gradient Boost :  0.9335154826958106\n",
      "Cat Boost :  0.9181845780206436\n"
     ]
    }
   ],
   "source": [
    "print(\"AUC SCORES\")\n",
    "print(\"-----------------------------------\")\n",
    "print(\"RandomForest : \" , roc_auc_score(y_test,y_pred1[:,1]))\n",
    "\n",
    "print(\"XGB : \" , roc_auc_score(y_test,y_pred2[:,1]))\n",
    "print(\"Gradient Boost : \" , roc_auc_score(y_test,y_pred3[:,1]))\n",
    "print(\"Cat Boost : \", roc_auc_score(y_test,y_pred4[:,1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backward Elimination\n",
    "Feed all possible features, then iteratively remove the worst performing features one by one till the overall performance of the model comes in acceptable range. Uses pvalue as the performance metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\statsmodels\\tsa\\tsatools.py:130: FutureWarning: In a future version of pandas all arguments of concat except for the argument 'objs' will be keyword-only\n",
      "  x = pd.concat(x[::order], 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "const                        1.824828e-02\n",
       "auction                      2.738904e-03\n",
       "device                       4.782674e-04\n",
       "time                         6.243006e-02\n",
       "country                      8.897465e-01\n",
       "ip                           3.358943e-04\n",
       "url                          8.614995e-03\n",
       "num_bids                     8.147937e-02\n",
       "num_first_bids               1.003762e-04\n",
       "num_last_bids                7.206207e-02\n",
       "time_to_bid                  5.935722e-01\n",
       "inst_resp                    1.141590e-01\n",
       "perc_inst_resp               1.310237e-18\n",
       "auto parts                   7.978792e-01\n",
       "books and music              2.436783e-01\n",
       "clothing                     4.832760e-01\n",
       "computers                    5.597922e-02\n",
       "furniture                    2.659315e-01\n",
       "home goods                   2.540598e-01\n",
       "jewelry                      2.533597e-01\n",
       "mobile                       3.358926e-01\n",
       "office equipment             3.201563e-01\n",
       "sporting goods               2.563400e-01\n",
       "num_bids_per_auction         1.769349e-01\n",
       "num_bids_per_device          1.277499e-09\n",
       "num_bids_per_country         7.549817e-01\n",
       "num_bids_per_ip              2.010961e-12\n",
       "on_ip_that_has_a_bot_mean    6.053652e-01\n",
       "ip_entropy                   2.571483e-04\n",
       "url_entropy                  3.595401e-03\n",
       "dtype: float64"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# from this step we can see which pvalues are significant\n",
    "X_1 = sm.add_constant(X)\n",
    "model = sm.OLS(y, X_1).fit()\n",
    "model.pvalues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2013, 22)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['device', 'time', 'ip', 'num_bids', 'num_first_bids', 'num_last_bids', 'inst_resp', 'perc_inst_resp', 'auto parts', 'books and music', 'clothing', 'computers', 'furniture', 'home goods', 'jewelry', 'mobile', 'office equipment', 'sporting goods', 'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip']\n"
     ]
    }
   ],
   "source": [
    "cols = list(X.columns)\n",
    "pmax = 1 # we can adjust this\n",
    "\n",
    "while (len(cols)>0):\n",
    "    p = []\n",
    "    X_1 = X[cols]\n",
    "    X_1 = sm.add_constant(X_1)\n",
    "    model = sm.OLS(y,X_1).fit()\n",
    "    p = pd.Series(model.pvalues.values[1:],index = cols)      \n",
    "    pmax = max(p)\n",
    "    feature_with_p_max = p.idxmax()\n",
    "    if(pmax>0.05):\n",
    "        cols.remove(feature_with_p_max)\n",
    "    else:\n",
    "        break\n",
    "        \n",
    "selected_features_BE = cols\n",
    "print(selected_features_BE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recursive Feature Elimination\n",
    "Recursively removing attributes and building a model on those attributes that remain. Uses accuracy as the performance metric to rank the feature according to their importance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=1 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:25] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:26] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:27] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:28] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:29] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=2 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:30] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:31] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:32] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:33] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=3 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:34] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:35] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:36] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:37] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:38] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=4 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:39] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:40] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:41] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:42] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:43] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=5 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:44] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:45] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:47] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=6 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:48] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:49] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:50] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:51] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=7 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:52] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:53] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:54] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:55] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=8 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:56] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:57] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:58] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:29:59] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=9 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:00] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:01] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:02] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:03] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass n_features_to_select=10 as keyword args. From version 1.0 (renaming of 0.25) passing these as positional arguments will result in an error\n",
      "  warnings.warn(f\"Pass {args_msg} as keyword args. From version \"\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:04] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:05] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:06] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n",
      "C:\\Anaconda\\lib\\site-packages\\xgboost\\sklearn.py:888: UserWarning: The use of label encoder in XGBClassifier is deprecated and will be removed in a future release. To remove this warning, do the following: 1) Pass option use_label_encoder=False when constructing XGBClassifier object; and 2) Encode your labels (y) as integers starting with 0, i.e. 0, 1, 2, ..., [num_class - 1].\n",
      "  warnings.warn(label_encoder_deprecation_msg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
      "[15:30:07] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.3.0/src/learner.cc:1061: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nof_list = np.arange(1,11) # 11 is our maximum number of features\n",
    "high_score = 0 # keeps track of the highest accuracy model\n",
    "\n",
    "nof = 0 # returns us the ideal number of features based on the highest accuracy\n",
    "score_list = []\n",
    "for n in range(len(nof_list)):\n",
    "    # we can modify to add smote and stratified kfold later\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X,y, test_size = 0.3, random_state = 0) \n",
    "\n",
    "    model = XGBClassifier()\n",
    "    rfe = RFE(model, nof_list[n])\n",
    "    X_train_rfe = rfe.fit_transform(X_train,y_train)\n",
    "    X_test_rfe = rfe.transform(X_test)\n",
    "\n",
    "    model.fit(X_train_rfe, y_train)\n",
    "    score = model.score(X_test_rfe, y_test)\n",
    "    score_list.append(score)\n",
    "    if score > high_score:\n",
    "        high_score = score\n",
    "#         nof = nof_list[n]\n",
    "#         for i in range(X.shape[1]):\n",
    "#             print('Column: %d, Selected %s, Rank: %.3f' % (i, rfe.support[i], rfe.ranking_[i]))\n",
    "        \n",
    "nof"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embedded Method\n",
    "Takes care of each iteration of the model training process and carefully extract features which contribute the most to the training for a particular iteration. Uses regularization methods to penalize a feature given a coefficient threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.54655789537257, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 5.203456963415412, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.43962683742683, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.53657454196692, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.69673772064754, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.4326279401178, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.6825557438954, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8864360297375, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.72362815773614, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.52947376305857, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.426618282724135, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8748181778076, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.86209332205104, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.672046232273686, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.52266063219061, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.86653152507314, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.85338564952493, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.7162555856998, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.520710351909656, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.858710146970104, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.70926828848005, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.84646332648652, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.496912603851094, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.509367645935065, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.51581534480639, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.4207926471193, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.48528445822167, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.94351743399101, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.85088212376085, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.164071587063724, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.50101071189266, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.83968256597593, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.70225869183141, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.842966620025194, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.414905239381675, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.47679618177705, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.508894143068154, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.50001738819185, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.66225701220463, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.69515030281794, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.155199791684154, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.83285200273166, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.523652253151674, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.65249979134441, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.14826406024665, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.49626110766245, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.46875375035857, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.937835165900566, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.50187001576544, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40888366675659, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65586011628496, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.8259382087423, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.642629504410586, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.46070338670576, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.141472231609306, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.83493760977719, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93171945910384, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.49216619271772, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65029716879438, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40270121764163, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.49309528483035, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.494725387150204, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.818917698949264, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.6879181793501, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.92539369194407, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.452565430297454, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.48789315372992, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39634552245469, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.632606653644245, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.485172103365315, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.483468382148004, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82678031026981, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.644393398788445, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.389810307459285, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.811777014529355, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.68054951776242, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.13460425740596, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.622413000004244, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.444313734928265, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.63829839146456, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.487452203123986, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.80451043992518, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.91889787598701, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.477157917533745, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38309237190006, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.612038645850745, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.91224522963106, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.673038052201676, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.47889969340203, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.43593332623817, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.4800473285164, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.127617169996526, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.37619010448321, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.797115840339245, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.90544122526157, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.818487095875064, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.120483476061324, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.427416387443394, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.469025847604925, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.63203819740529, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.3691027032004, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.60147858660147, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.36182977156198, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.66538101981542, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.89848835520486, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.46076102223259, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.47250961723481, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.11318822993253, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.35437111426732, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.625606487006586, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.474189849347226, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.41875937324624, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.65757726975145, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.789592455673464, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.59073046394982, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.810054554073105, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.46483865985263, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.34672663529744, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.105725156491204, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.89138780446935, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.46933988877272, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.80148126510697, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.45703431132021, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.781940019897114, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.40996600917116, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.64962633460257, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.619001797792286, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.09809190469593, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.449096520406414, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.452355627497916, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.77415844046914, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.79277196310129, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.5797932090374, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.6415280265327, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.090287630854796, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.40100571079496, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33889628748716, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.443806047049, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.612223805311906, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.884140147991964, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.46435021163034, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.3918740465808, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.60527243804415, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.08231203689695, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.435110795276, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33088004768013, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.76624768526868, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.5686663463982, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.87674566744268, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.441025269037056, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.426271338559516, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.38257469938434, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.07416501810593, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.32267790451207, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.78389817199102, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.633282270383134, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.75820774315516, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.5573496663312, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.59814768024688, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.432820550838564, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.459220973297434, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.86920450146862, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.065846537768955, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.62488903613501, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.3731090878796, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.314289852404244, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.424482363564, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.41724937014894, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.75003861026782, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.590849528456516, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30571588862105, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.7748529199348, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.45395223434515, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.057356583025, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.36347777573168, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.74174028526783, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.861516718473034, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.545843076704045, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.61634831180771, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.41601070642167, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.76564026386287, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.448544018416975, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.408051818887, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58337798191141, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.29695601181632, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.73331573466879, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.60766009262037, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.53414653710747, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.353680989607206, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.28797010751926, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.7247474680216, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.44299633474649, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.5222600298368, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.598829398911555, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.04869514937034, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.343718821094264, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.716029361675126, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.39868131396555, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.75626174040811, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.853682352240384, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.43730918693981, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.57573304044391, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.278798476264576, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.40740557913176, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.58982112101581, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.03986223522784, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.84570492574713, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.33350414517858, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.51018354713302, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.567930357052404, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.26971328550049, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.431482576405706, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.3986689577475, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.83755006786467, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.03085784004496, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.55995066275129, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.38914551609384, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.580625478986775, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.02168196362894, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.74650320420841, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.32311909903458, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.82922183874183, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.70716418021437, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.425516503693956, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.55176455230378, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.49791708559988, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.82072274129402, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.73668859437155, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.31277424574701, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.260376874806056, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.69815567476218, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.38979400381733, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.37941625553799, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.01233460591172, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.485466935277124, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54338695046383, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.726975593225575, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.00281576687058, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.81205397999106, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.571246355841026, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.250836677713025, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.41941096901988, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.534820996209056, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.47281373368245, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.30227835124158, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.38076247270009, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.71719938984761, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.36947078865129, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.413165972467084, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.45994854820731, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.707325943394885, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.24109915961723, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.37157808117651, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.52603793926154, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.29162972193351, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.35921707056975, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.688978932015424, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.803216146161525, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.99312544649555, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.280828107498046, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.34882072135451, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.40678151406854, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.983263644785055, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.44687556005819, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.69735107328606, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.51704457507897, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.679620807734494, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.362242085797064, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.26987347078803, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.79420953289765, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.33842297100534, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23116539623213, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.68727430120035, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.400257593836706, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.43359648483816, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.67007690408002, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.561685200112485, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.677147677565245, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.97323036173799, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.393594211776936, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.25876980054477, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.6603486980945, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.352754923544225, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.32797061450198, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.50791513953796, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.22103557244458, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.65043665432595, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.785034286142995, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24753808100049, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6669951308891, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.963025597353536, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.551942574808265, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.21070972020912, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.420112079666765, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.34311674787983, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.38679136789071, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.3173266746244, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.33332761287639, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.23610783026041, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.64034093294122, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.49861621811877, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.775690478733765, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.200187845047296, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.65654499331286, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.54200224921575, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.95264935163202, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.379849062179446, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.76617814706035, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.63006158943949, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.323387537611644, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.406422684001846, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.64592814301393, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.53190572176611, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.306489597018135, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.489137997602306, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.189469947917935, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.224506926248026, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.392528450917716, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.756497309312365, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.313296528813495, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.63515745508903, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.619542238341666, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.479478554968544, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.303054588859396, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.212739171153096, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.94210162457317, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.29547947173302, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.372767294642685, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.746647974583674, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.37842944960797, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.46963752774428, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.521668312425035, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.20080515427858, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.62423467928898, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.29266171858637, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.73663014742099, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.931278811170465, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.60876783239111, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.28429926761179, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.28211791828973, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.365546065281166, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.61316006372174, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.726443830099065, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.17855602898544, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.18870496833021, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.4596148481542, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.511282199878636, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.920357677814074, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.2714231880742, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.59798581678537, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.364125711380694, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.27285020022297, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.60193364377748, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.35818537409498, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.71608902375413, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.176438627923595, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.167446088279924, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.50074391415127, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.90934070190595, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44942011280885, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.26129080186773, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.26057752797675, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.34961895333568, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.590555424505176, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.70556572895339, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.35068522108333, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.16400613536313, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.156140125804704, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24958093800971, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.49005203660789, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.343045606246974, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.58707217859116, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.479206008072495, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.898174817694006, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.57902540662819, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24961331115473, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.33488702506841, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.576002824648626, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.238433418179156, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.33526652958566, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.151407491012776, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.14463814156115, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.886849975032156, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.46820561138738, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.327349634058194, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.43902857671716, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.56734359024709, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.31992766291096, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.237777851183935, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.564774887346275, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.138642694930695, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.8753646144533, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.69487394598294, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.227134968485686, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.31914598140358, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.45705076271939, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.132939820430686, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.553388049774725, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.55550997537912, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.304744556465124, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.42843948410155, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.12571174712487, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.215685588929105, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.12104432964557, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.445741429781094, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.86371850197323, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.54354846696667, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.68401367498239, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.31083708758595, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.541842277211344, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.28933947673935, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.112614647596054, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.41765771925881, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.10894807636902, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.225779438898606, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.204085279509684, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.67289554726681, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40668420560269, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53138221262909, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.30258566842886, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.09665151393437, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.85191160267169, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.434277600149606, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.53013756585772, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.19233404023013, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39551912148953, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.08415472018893, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.099351396345845, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.518984015965465, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.66151766609308, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.29426473949734, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.21361751834265, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.18043186963567, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.27371328150103, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38416250151144, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.51827391529792, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.085921993374114, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.5064989807045, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.28589934751103, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.16837877068124, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.83994391134158, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.0714652355757, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.25786638977207, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.650253392424105, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.37261435238276, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.49386715888581, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.20129202829471, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.506251325485216, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.42221234274611, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.82781542720637, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.05850898094918, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.27743059030208, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.072326438680705, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.156029427047436, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.4107379757968, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.49406979641523, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.24179900708441, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.815526150151854, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.481076982857495, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.639045005737636, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.36087467540618, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.18880296202403, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.04533694442643, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.26875511923589, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.05856473226443, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.39891329130372, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.80307608015878, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.48172932808854, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.17615031879033, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.259934857477305, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.468127188850644, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.14337008363655, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.34894347083416, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.22551123445513, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.62725709241978, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.79046521722615, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.38689862641714, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.044636874127136, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.46922992050386, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.031932338366666, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.250976775110225, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.614866825361744, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.45622600886401, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33682073871544, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.163334092254345, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.030542864267396, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.2090031215755, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.455017643649725, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.01829164542157, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.13094331663634, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.77769356135121, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.37471927826573, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.24188182514293, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.442464812243124, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.19227469288418, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.603196403626185, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.32450647906071, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.44174833326948, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.76476111253739, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.15035429512117, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.23265014128586, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.016249307724216, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.00441432614088, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.36237763649705, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42831925624676, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.13721092093151, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.751667870782285, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.427906961793504, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.175325960415705, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.59147616325282, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.31200069187074, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.118475606961816, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.00176799468917, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.22328174236167, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.12390396968257, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.4125425427585, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.57965025225512, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.73841383608754, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.15815693009683, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.10591115435985, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.349873945830225, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.99030030021876, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.9871772214799, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.110433441379016, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.396370417960206, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.724999008451185, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.213776631023556, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.09324516277901, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.14076760483728, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.33720823152941, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.29930337714634, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.56771665941137, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.41473041242377, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.71142338787496, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.97243366124194, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.09679933601845, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.286414534887655, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.32438049620387, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.97594955574637, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.20413480764338, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.37939046099276, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.12315798607364, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.55567531473234, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.273334165094326, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.311390740121894, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.697687755882306, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.194402735716785, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.40098180178896, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.08047725697824, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.95752936498192, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.9613623755264, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.36160265785726, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.387073424335675, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.18444678799285, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.94635268680214, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.067155136844555, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.68378544998475, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.260062267766564, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.543526215781995, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.29823896331129, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.0830016536017, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94246171746849, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.343007007007095, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.17398775666597, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.37300786608451, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.930929892626544, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.10532807450875, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.66970983331269, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.04704279660168, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.28492516577625, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.246595114179655, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.32360350826986, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.53099629145123, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.92697027156182, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.163055915162204, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.069040394126645, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.03851457067047, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.30345057587082, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.3585292851108, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23268609307668, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.271449347516985, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.655463411533006, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.51931777764495, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.02367386727489, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.91446856607842, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.05491555759544, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.1517094537035, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.91102055684206, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34359647303935, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.50614063062741, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.641046550551664, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.25781150853177, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.282377600999126, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.21828825882186, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.08727787049043, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.49233664779075, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8945692142848, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.13984973324199, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.89710745659821, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.244011648823715, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.328162731315885, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.00739350130423, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.626459304351776, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.26001406862756, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.87761035103725, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.06900737419401, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.20337329037875, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.04062714400715, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.47801481535114, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.12745596449643, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.31202777912735, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.230049768388184, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.87886804664015, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.18793408599132, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.46318556965907, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.99010178752455, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.114525090469364, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.02617515336156, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.05051658569845, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.21575922483871, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.1719691724743, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.23663563231153, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.860143288760064, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.03180068584329, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.611712037266614, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.29494288637814, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.20088734723133, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.44785017309758, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.01154350316518, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.59627909485751, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.277226214984076, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.212142871864195, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.85971541759918, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8421679509636, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.153712521898164, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.101056686282824, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.432008782546454, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.97187460704053, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.580283749191366, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.99640311653874, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.82368432904975, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.1849714884233, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.41566141756192, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.08705069338006, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.56364810993896, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.80469242204677, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.258706320866075, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.13382262643402, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.398327734433444, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.98071096081111, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.18649379086276, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.0128628792784, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.072507103702826, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.239584375615124, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.95272497827229, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.839450116773286, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.11610587365462, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.16839228184532, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.54630665859705, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.21956037752204, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.38022933977619, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.96442427385918, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.05742591614321, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.818046752375494, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.78519222985081, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.159680007350474, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.52824499707358, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.99373891534243, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.93265558612373, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.15098092426803, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.0979751563959, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.36132716513628, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.19838944895089, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94753742416372, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.50946059476341, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.79550172733737, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.13268535875578, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.97441615160377, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.041807130548435, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.76518375244342, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.4899530247787, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.176276689629866, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.07388239180189, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.77181358315663, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.91166700599484, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.131700079927285, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.34153420267514, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.930049771686654, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.153239769998144, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.05393355725376, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.469722215649156, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.11349796895058, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.88975936219179, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.746981746508354, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.911961244981654, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.74477395020679, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.954889474375975, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.03305358066125, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.02565074689688, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.102553767304734, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.093417765928386, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.72371365361813, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.86693268160791, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.12928167107474, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.320920058006905, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.70200336660499, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.93515676085053, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.44876815543104, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.072241029297125, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.07244462339822, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.721005993887935, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.299412974111455, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.89327183609248, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.050578525273096, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.01116408709172, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.843186970058994, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.427269899266776, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.008956765187136, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.04076185922174, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.104402951642896, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.6796873538481, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.02781946950631, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.98826448932045, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.91521714605883, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.9917251854175, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.27700314176939, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.81852222880286, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.404838591602164, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.693799754779604, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65677094125911, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.87398154413502, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.9643547823371, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.00811625596552, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.66511861704307, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.253689004953536, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.381421355663214, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.895070282611236, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.97392390806424, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.633255001468456, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.97430421934708, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.00416745583717, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.35666580670919, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.85409036900933, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.93932574933553, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.078603718515716, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.79293845811207, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.93943496682129, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.87460964619934, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.63496777479317, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.229470237404215, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.33039178454248, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.95525736246777, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.979622484231705, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.76643565804505, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.90318084591937, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.83359831070404, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.30260653601289, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.85361174221282, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.204346792810604, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.05188399217696, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.609139684529296, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.93580049072146, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.739013828612364, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.60335961169339, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.02424377655929, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.95418455468638, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.91350504235403, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.86606066347419, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.27331147890997, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.83207851153277, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58442501645554, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.7106729698207, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.17831866519053, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.81250536921783, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.570302905299926, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.92785366720114, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.24250690783644, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.995683072407914, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.91572207652319, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82749582434639, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.88656500910303, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.559111001760186, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.79081154455292, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.80999852055196, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.681413081667955, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.53577976820053, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.966201879878, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.85861486700352, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.78763065625484, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.76863572940076, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.21019288475988, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.533197641223936, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.89451517196914, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65123416415249, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.49977085346557, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.151385853773434, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.17636942274047, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.78736588120076, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.74649680314279, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.74569630642189, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.90062982177537, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.83148649107882, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.50668493498052, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.87228855974273, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.935800198989384, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.704099305158735, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.62013621727909, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.76417780771494, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.14103652453332, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.872513018409016, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.72201052019253, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.801271915706856, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58811924104496, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.12358137317511, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.90447802975204, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.46229193232326, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.849102316404405, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.10419419071113, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.660439216490396, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.47957288305409, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.69762211147958, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.74043308547973, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.843503257101965, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.55518323544836, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.770364976605364, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8249642118098, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.87223537216307, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.06584242139707, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.42334151228359, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.095351344437816, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.81360053785531, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.71596918488685, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.67253644819189, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.739542702769754, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.61551677082463, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.7998756502332, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.7828048606675, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.451861485448845, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.38291874036065, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5206879928624, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.065576274767714, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.839072226226996, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.690638268109595, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.02598121662028, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.70577605274489, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.42355074216757, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.77383690108705, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48662333717268, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.569332020608165, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.646754419833215, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.751116225539405, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.74684801663489, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.03471191658859, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39449265151065, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.66443616839333, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.620276180991425, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.341023168136694, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.521884977640006, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.98461057638681, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.45028971506163, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.718909007027456, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.002806618973956, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.71853463247034, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.67071501780831, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.29767772588849, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.63735594889168, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.47313366807499, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.59303733392133, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.69001987423864, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.63436764496412, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.41244772369385, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.94173050068985, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.8049885919411, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.36445493782095, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5647732817604, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42272214127453, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.96986799830282, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.66018061864693, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.6093941492772, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.25302086534757, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.685290932585005, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.37315256690139, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.3333555267858, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.59673399147242, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.53549491040914, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.76998446930533, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.93589775127946, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.89734098953934, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.58054921106884, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.50517660870626, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.207026427251485, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.370697319919245, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33229771441819, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.629391240329284, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30120637645283, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.900896285999295, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.55082046991832, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.85144204292957, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.159677335953425, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.47381062920387, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.597651739299096, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.5578140577695, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.65088769782365, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.73405985832102, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.268040522441154, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.441395293057454, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.317071129501414, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.520207649548055, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.864863702400335, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.11096723201944, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.56496211556145, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.697214758987, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.61546293317182, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.80403366086252, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.233545441716714, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.289691668458204, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.51760784386978, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.26184676268431, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.06089352346723, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.827800025049065, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.488710636349985, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.659449171301645, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53132236911476, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.24534442042358, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20504286485649, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.478270827184836, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.197657786369994, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.78970525997604, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.00945511573839, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.620779316920576, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.75502052840032, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.407930262858, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.57612642816446, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.49673249995882, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.146745564199236, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.750579408665935, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.43548399598657, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.160404339851056, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.45632938382627, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.199263484707416, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.956651539455876, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.54154529037961, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.5810923152868, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.70406514414294, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.461192508093994, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.37341547190349, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.390912793810564, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.71042247148055, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.90248259192339, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.65092669084452, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.12179054466607, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.50301327512253, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.42306387301189, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.08683995401501, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42470239214838, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.463846497955046, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.59544104180974, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.38891409616614, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.54040957594162, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.84677797039391, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.66925231705016, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.02511560521693, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.15145145016162, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.08181802862058, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.34482297991841, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42357059285123, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.387262144137004, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.337850907063064, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.78935566161624, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.62694717183122, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53748788439043, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.96156179832485, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.35388005014493, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.38233301730463, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34881228125603, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.10190691029774, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30123656575192, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.498768353327996, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.297111649701016, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.5834849168914, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.04048729234973, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.89618639545552, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.730244144184724, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.477117210697585, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.31796173367752, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.26357244746988, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.24780645344318, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.45591782362915, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.53886976195583, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.340131792815924, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.28115914623196, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.41432706779334, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.82899288563265, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.05059474136062, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.30917521532009, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6694520854111, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.411580871968326, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.493100843419036, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.9977984901133, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.22488734941139, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24347228761145, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.75934940143375, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.29688498085378, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.26834194572223, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.19691190901233, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34849500697802, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.36569729707983, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.99750796324104, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.606983646882185, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.68546362867993, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.18510670224098, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.25257354681773, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.445850465420925, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.22631396997231, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.20490115772445, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.14442852762047, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.942646832972144, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.27758858516932, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.144188742992974, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20676594435879, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.54284091676211, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.39633332057954, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.318276709740715, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.95375166942367, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.0903563720065, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.165445756532726, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.886011476302045, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15939937284013, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.18308232535062, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.60692797166625, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20112053552781, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.47702492374455, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.10215750277947, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.26931999983843, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.90834788320797, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.12510608403122, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.034695449928655, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.82760256632982, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.0590173238206, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.13859446228099, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.40953616869468, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.110518943568586, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.11912540103148, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.217247763438905, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.97644097593772, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.523712669127, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.34285972015139, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.01465967286025, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.092862449277185, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.86039720688661, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.03162944488909, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.08388214020591, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06025699742498, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.161422643160606, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.915196224455634, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.28505644381541, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.766033235418334, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.43582859499415, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34037489408223, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93262182007926, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.041773925053576, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.044992049921646, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.96881545153054, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.80842930223041, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.00859848069968, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.77631773824857, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.26883996025292, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.22287671362448, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.341718862251035, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.84904788861129, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.921510220739734, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.99878759064781, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.95552909951131, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.70005580751358, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.75207161084123, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.99312454486897, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.19306152036288, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.10118701614645, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.69133412584355, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.90102102829884, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.778533157455925, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.156342587228906, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.954879009131574, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.629439191140406, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.204399031184394, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.551880017576146, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93722723715036, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.87275426789955, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.62332066117211, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.09345712961414, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.008086116836864, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.843264144044205, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.91004776284052, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.03667469114483, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.55421540778201, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.822552578011575, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.08546351081673, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.702859822605475, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.24900946759428, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.934889714573, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.78102698855636, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.50914996648456, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.74967289521016, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.86409287415678, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.96789440361984, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.474398561318544, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.864891951344866, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.85984517425687, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.81691996502675, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.716388930144625, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.77095830502743, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.009887189342805, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.71425515964758, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.58262980237455, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.41766792465296, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.89485330022043, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.33694685759556, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.724684987376335, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.76852445294063, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.38653664600378, tolerance: 0.008822682119205295\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.915085810322275, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.433102109435296, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.38233108977467, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.81755587869291, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.71793494822867, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.395902644619454, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.10661666721201, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.99077176021894, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.6224258048421, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.530567112239886, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.75408829544402, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.71834823187889, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.01293985590289, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.47309747831593, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.73412691414931, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.238160427414556, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.14221074239181, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.663471987988096, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.66470655790967, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.81105678719985, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.33702652440462, tolerance: 0.008822682119205297\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.27753869551813, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.5114828080721, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.606128230144684, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.26586491597953, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.607393684227624, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.60650549824713, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.814340622766615, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.96587167132416, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.44201951332339, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.031039857908844, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.170551533362556, tolerance: 0.008282054113749313\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.41908649169446, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.59329734978001, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.544080995698124, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.997784424575094, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54343534668154, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.4057969392735, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.752923343365296, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.990451594584435, tolerance: 0.009091109884041966\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.15563244037923, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.476738095041604, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.658798172124804, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.91596551022892, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.13179593185779, tolerance: 0.008642991169977927\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.468826578859016, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.80791263591142, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.403250124203595, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.373166923253955, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.24594360263349, tolerance: 0.008732891832229582\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.286913002419276, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.358722165279964, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.31118503188818, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.201491279485246, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.26928298835183, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.258293055900445, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.96593520145586, tolerance: 0.009091109884041963\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.048715614560976, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.46726879821212, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.95561660404528, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.495263541121425, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.680243758152386, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.248861712262105, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.91155024006606, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.624505924947954, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.239726508010314, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.18968787827395, tolerance: 0.009358807288790724\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.9028660997746, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44594546119055, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20703747691881, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.37661727944788, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.72195065165885, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.89570056110134, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.440034225926354, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.23056413480089, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.354152835325316, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.712298687063154, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.08504380842283, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.888708118582706, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.435828978229324, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.69316746506738, tolerance: 0.00909110988404196\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.22128497387183, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.34191319833926, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.70506463437424, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8816611745967, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.43154167960305, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.0730964991183, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.55008046407158, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.211858180968036, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.698134458486585, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.543396945236005, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.06472366041142, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.874513302920484, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.33136235434697, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.427169003161076, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.536710043506545, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65901650995219, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20226995197013, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.691171414781564, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.422710942598776, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.056649056235564, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.68411641436449, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.192513333752686, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.63406340882585, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.32099957156402, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.04853027813332, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53012232752703, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.18258479307257, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.86724443675769, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.62500952371724, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.676946486023695, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.31055996051935, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.41816749772865, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.17248256504593, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.52357818208385, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.04032433792928, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.85984336439856, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.61882844268782, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.299984860353185, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.669648297822214, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.85230461832463, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.16199704515506, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.413538668820415, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.612561689517605, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.28925279241355, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.03199406710698, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.5170029735262, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.86620287939835, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.151548825001086, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.66221524383672, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.84462580599359, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40882445556529, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.023516272611495, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.14119769099976, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.510372208026105, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.860489325878056, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.606197475119274, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.6546444612258, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8368059336995, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.50371186108969, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.13079603175584, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.27835317478504, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40402485841492, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.768979297772376, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.64693478535893, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.49733301014541, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.014881201104025, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.85441936974871, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.12031098698407, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.76308475848392, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5997357587362, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82884459787266, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.26728666541446, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.49043989798374, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.848169441728984, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39913987680133, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.48333803803388, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.758016448095525, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.109738082025046, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.59317653993146, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.00608534169683, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.108968901054304, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.6390857548266, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82074163612425, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.47606401550719, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58651981876294, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.09907675025683, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.2560159599916, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39416951143839, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.095052922304845, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.84175900281228, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.752999469524184, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.81249698336366, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.63109718876179, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.468628859245676, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.088549905927785, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.83519155237748, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.62296901657094, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24452401455447, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.08542118428197, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.99712749812172, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82846405304298, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.46103694194408, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5797655958201, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.430869842639744, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.80411061353921, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.61470121074641, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.23274851771117, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.821567389548484, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07774216625037, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.076470522280935, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.57291387065884, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.220868437581096, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06662362479725, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.453290171800575, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.7479025093309, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.98800727035131, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8145062064442, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.60605347986703, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.445389413437475, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.425778566676485, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.06750324382266, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.795582516232976, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.2089629652583, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.055295538407854, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.565964642900354, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.978724525470774, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.80729391875156, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.597340350817895, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.74269196160615, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.786915113111235, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.43733506491387, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.05837738333425, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.969279219413345, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.419961825957294, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.19681847797262, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.82219715133683, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.558917913308505, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.778006507087795, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.73735052070466, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.04377026775405, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42912731078777, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.79987674191741, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.04905189607532, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.588781202393676, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.413911080247345, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.7688048205333, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.551773681282555, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.0320500210607, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.9596713375814, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.16177323533018, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.184471591675525, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.79226826469782, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.420766236899375, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.03950808411515, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5445319471816, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.75974726049765, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.580183930798604, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.171928627941426, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.73186908637149, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40766756819833, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.41225188323294, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.02973670512975, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5371927107572, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.784473252778, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15734813985822, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.949900875140905, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.75065865928374, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.72624350756512, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.57150853605868, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.01973347108718, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.15919079530961, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.020135128602064, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.93997718728838, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.77649280963334, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40124195608479, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.40358426842446, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.00949649115097, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.52975597235043, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.008028320336976, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39463783361073, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.720472041469435, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.152793391723804, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.92987394555551, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.74147829770728, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.995719078870366, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.76832719781711, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.539578563648746, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.99902495300247, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.394763401161825, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.14625833320312, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.562910143604455, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.983210658032, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38785651677567, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.91958829035741, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.73226431937063, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.75997648020176, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.53251551686879, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.71455398297644, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38089850306182, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.97050364269553, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.133131289386846, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.90908698252901, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.14812197982235, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.38579167444429, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.988318511778374, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.72298733293491, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.554110404303735, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.119809673402635, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.751440671864195, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.52450913093593, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.70848905116841, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.95759814631478, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.3737639826975, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.37663570058874, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.14333395826073, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.713434959007934, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.10629348715562, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.97737702182466, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.3664530287388, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.898409976031544, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.70227713482353, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.742719776420714, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.94450589867676, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.516258812504105, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54512919110025, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.703719062834466, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.695918190017046, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.3589656692873, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.507809205869364, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.96620042176546, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.092582731030326, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.733818732824695, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.13842928589187, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.53597448160952, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.88760486586701, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.36729225347908, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93120727657251, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.689412199421795, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.13340796977032, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.724746560545114, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.954788685759944, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.078677405098915, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.69385109883147, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.49917218138826, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.876646443975424, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.526677265322974, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.35130191515852, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.917696269039226, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.06457750937858, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.35776444487741, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.49035210415942, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.12827002416196, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.715439837818344, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.682759156204575, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.86552623935867, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.517241449617494, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.343461770515766, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.68383264122144, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.05028304387285, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94314180293436, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.481350761475525, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.507667573761374, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.85424168165411, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.03579400858091, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33544523696221, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34805369623506, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.675907560033174, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.90397968749304, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.70592005987078, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.12301544663494, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.497955713099074, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.84249664197355, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.931259768716835, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.67366391493841, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.47216891530427, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.33815750255012, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.327252315113455, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.668862735314825, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.830743249250176, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.11764421933411, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.02111040350163, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.890058868535945, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.46280689585261, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.661836240196266, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48810587817473, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.919142581179145, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.663344952300164, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.11215636684, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.69619169258702, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.006232228639874, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.65473290855783, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8190222062587, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.318883005208015, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.47811807046332, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.87593408743473, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.9067952777916, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6528757579507, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.99115948398959, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.68625585080106, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.328045118699336, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.10655187035592, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.31033730733724, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.80718254098101, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.64752423889655, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.45326484720773, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.642256332559555, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.467992285126286, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.1008307339283, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.89414674457264, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.86160540143228, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.31771834310781, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.63148667622091, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.67604276388642, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.79520431757968, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44354283242617, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30161522153497, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.881406712410076, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.97589216955586, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.84707282245331, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.45772853242954, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.64020517849587, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.30717938737815, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.094992963838855, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.665696797367296, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.83233635298329, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.29271674781667, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8685068771234, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.96043028533512, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.433640879137776, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.78308549810478, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.63262184318506, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44732680718386, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.283641886185876, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94477383132944, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.62056678894904, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.77082588010593, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.296429297640515, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.08903856105324, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.65517766366024, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.27439063664556, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.85542136992322, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.625022047890376, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.81739599354253, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.60949667074816, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.42355899945629, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.75842544353263, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.92892280753778, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.264962999196165, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.08296751685703, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.84214385313703, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.61741839433254, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.644469983913694, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.28546857417202, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.436824725083326, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.41329719869142, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.80225174423494, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.82867298182731, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.5982763216148, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.74588418640093, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.633570402711804, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.91287721395959, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.25535897383832, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.60973995175517, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.42615714453015, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07677984563585, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.27429745725079, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40285627029022, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.24557856057184, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.62247825010589, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.89663705059719, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.58690574155185, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.73320210851363, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.601977037897704, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.81500847933604, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.7869036050852, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.26291606249257, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07047552068587, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.57538493055811, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.41528313986876, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.235621759396416, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.880202317448756, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.392221485796114, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.59412853410413, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.72037920985122, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.77135157609787, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.25132444557824, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.16621134397588, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.5637138886334, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.80115247189536, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.404233156360526, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.61119339480596, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.70741549041251, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38139143968865, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.55189261577894, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.22548857031222, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.18721009656946, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.78710850196507, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.5861943137354, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.2151789933207, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.75559565727494, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39301135477909, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53992111199261, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.178110610073986, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.37036764261182, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8635730145161, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38161838247027, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.69431095019779, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.239522633330004, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.20470262012775, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.578174362490245, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.7396358486167, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.527799377277134, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8467491417967, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.77285798472336, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.35915074701692, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.59971581118313, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.370054342190755, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.68106558920458, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.22751063867357, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.51553890292851, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.57006867875512, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.194015400997394, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.168690464596914, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.829730699292455, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.58804549423998, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.34774104008606, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.21528846783435, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.72347215012002, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.50312713477226, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.18311630961703, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.5618772623477, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.75840786486237, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.35831925029902, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15902546462393, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.336138648919345, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.576182443001194, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.667679407436296, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.490534263131444, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.553600113247676, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.81251768700329, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.17201091907725, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.70710456178971, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20285612381555, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.74375951527993, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.34641310940163, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.5641266572773, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.149123446496354, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.16070135953548, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.32434362990218, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.654152404890084, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.477775477379424, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.690533083617424, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.795110104925904, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.190213608062024, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.54523723145178, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.551763083591005, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.14918848953723, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.728913217095794, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.64048458156739, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.138991188528195, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.6737650288065, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53877993641919, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.46485290377713, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33433591991316, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.17736092126943, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.626675937467795, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.5367886169613, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.12863301673306, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.31235600806703, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.7775079530625, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.16429806377424, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.52327712485292, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.65640226880986, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.713869028281216, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.32208768189984, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.52830184884841, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30017579453245, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.118052071736884, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.75971123141575, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.61272647259229, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15102503573668, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.45176686444912, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.137385088966276, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.69862696080793, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.28780299424136, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.507449266347564, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.63836569018234, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30966839537232, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.1072506730507, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.13754183723815, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.4385174087436, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.74171993998673, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.61965586191574, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.51968729466628, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.59863618693913, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.27523760938629, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.49254193739553, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.123848468313426, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.68318701715177, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.12507511858187, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.7235340787654, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.296887963811855, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.096230520068524, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.584405080509626, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.6002729688331, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.26247964094184, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42510454423135, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.511048104658656, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.109944928981356, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.47711501658305, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.705153647762785, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.112240038065515, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5700331533025, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.08498779664912, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.58021706881757, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.283328287765116, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.09583121924957, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.502161229017084, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.2495290893426, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.46053505348783, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.0988441092518, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.5555204053187, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.66755947088926, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.411528272072715, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54085848586234, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07313551212419, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.08488130240634, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.08150626972927, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.493110671907786, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.525224440352545, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.39778859244715, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.68657864697175, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.651718626052556, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23638595477911, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.269349581546656, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.5594881800151, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.4422468254989, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06028102948246, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.66780907639806, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.63565164457604, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06676182628564, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.509479807532976, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.22305023733773, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.070271434459904, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.04642624487927, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.254798980977384, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.051408490101615, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.49329797929505, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.648844936037555, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.483914097989505, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.383885505381635, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.61936701092168, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.20941860311198, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.53808630811838, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.47657713729518, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23962569809493, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42418821975571, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.03157100109084, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.629688022817014, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.03572411362212, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.369819010879986, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.19528053465278, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.47457385671431, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.51601145491537, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.60286640975089, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.45930332437572, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.054786657564875, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.40516785677875, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.019614559374915, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.18062797847769, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.49326362096448, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.015723537400824, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.6101276787692, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.2238218728392, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58615019317708, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44147485335428, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.35558245070304, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.165456252232204, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.99889740189493, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.03842242425535, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.46509028410744, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.20738644079156, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.385170701480405, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.59006327235766, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.003040669798324, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.423091523571564, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.469842806444426, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34086531029099, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.14965109964511, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.36419660812418, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.4041533112145, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.4554634287235, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.981087166226814, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.0211703912191, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.19031926047812, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.56921843557754, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.445749011412154, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.32543293495687, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38466021346582, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.962293547202975, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.98598697364147, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.445693297584945, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.13299219772254, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.42098223587346, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.003025158772935, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.172891299225796, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.552071152699156, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.36461222998467, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.56947554575455, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34224557529936, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.968005421682655, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.30916439330695, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.53470834787423, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.11548706474963, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.39554247984554, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.43577989170856, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.34402593181112, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.94250695146686, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.3193176030353, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.94926308191579, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.15449502353191, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.51713002180487, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.29210244793604, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.09712889105396, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54835929481859, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.92172092357285, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.929848924311564, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.135339282556984, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.4993361746481, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.983983812900206, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.425723211241184, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.369429743323, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.322908095177624, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.526713390250855, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.274254207315856, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.077911414758795, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.295412691231945, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.11541811808019, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.909611359501284, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.8999362996661, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.41546640012264, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30076885049216, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48132680643186, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.2556213521969, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.888518622712766, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.96404494499211, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.27053083993469, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.342644026314794, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.40452936105743, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.05783041771649, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.09451738083747, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.50449825792035, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.87715380160897, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.463101917161715, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.277885290495924, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.943207909711255, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.86656640626483, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.244672049163036, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.31516033601998, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.39349204029024, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.23620431405853, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.25437147119922, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48150598001626, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.92147672038107, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.03688356468909, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.853374038585805, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.2160032060265, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.07263158021427, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.84436489098884, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.44466150683946, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.38164223026345, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.89882537171524, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.2298133006686, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.015069682337035, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.04974062659846, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.217836318931376, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.45757001626324, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.28647916618648, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.828597518993995, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.42600558131566, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.36898731722528, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.194983805559225, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.820528814401044, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.20461437952232, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.87501193833611, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.992417779653934, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.02583984621961, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.25623710652735, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.17803095297156, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.43267637280533, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.17323023443004, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.190023649168836, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.35561481679446, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.80282466367021, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40697905785701, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.000928307722894, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.85008083380707, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.150723462356844, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.22445229953635, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.150359006162645, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.7955509642817, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.968838130697506, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.16123403991048, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38744078830425, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.34150129258801, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.776055818768704, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.12745275282355, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.9750058313738, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.76958607427975, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40683468394653, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.8240408569212, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.944336853572096, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.36737858544804, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.1911434636779, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.918923523345235, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.131467491195906, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.12165467408241, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.10341579022608, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.74279872653292, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.748291267613375, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.32643450419099, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.796974854481554, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.9480723827242, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.892601793278615, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.7151706469955, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.15631321196794, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.34677795669256, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38004742992778, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.078612128874006, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.719531241187916, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.09192504319293, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.920127955178145, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.310398771466524, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.86537328168892, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.769007054799715, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.10072400293534, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.68667101108407, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.68977083766182, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.05304168495928, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.352315325968526, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.11996123402225, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.8372386190958, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.891172547478256, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.06117118087091, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.3256211740418, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.2933811526254, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.657286719317355, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.74015559747454, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.3236385855952, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06822434842592, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.026704442806846, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.808200962375764, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.659103621378335, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.86120615938393, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.02944487988352, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.082089978677935, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30395111914824, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.27537683012423, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.6270142194013, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.03447131146726, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.99960039948595, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.83022879085013, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.29401727323339, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.28175252750655, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.62752568277347, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.9966414064686, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.778256369324, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.256384335619344, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.710389152942874, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.042700797741475, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.97172955445443, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.263451408343414, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.25906972648237, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.00078113299362, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.59585265780374, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.74740489482832, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.96271730532285, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.798240441866966, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.679680158132136, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.23640324784273, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.59498797627076, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.001794396745694, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23576477102156, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.94309190760818, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23192373188939, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.96609084199303, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.76524111243182, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.21543344807971, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.56380183562437, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.6480214696564, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.927708567966455, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.71564702036078, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93039022689705, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.21172674936859, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.95937113973917, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.91368745892833, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.530861706881254, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.5612970864362, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.68298298282236, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.193474903056824, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.731230802546655, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.89162050013168, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.18691317451473, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.19946402406535, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.61541168339232, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.4970322609808, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.893679209639025, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.696209512210274, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.915431213610525, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.5264194140722, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.64941290333455, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.88351620841011, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.85445406028815, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.170527603469296, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.16111243556632, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.86997309177455, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.66017724141964, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.462379242775, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.16607220276079, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.58185053871629, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.61493684412634, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.8525781560546, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.14659154671773, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.13434205803667, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.42656538342821, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.81620942791575, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.82310259768399, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.85595778950535, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.62313399018085, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.490349350081914, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.12134049312389, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.57955483723193, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.82087330186255, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.13174164461563, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.81722596654381, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.77484592982538, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.38935861769386, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.106581915828436, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.7768866368276, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.54326879005256, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.45306504143817, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.5473379878254, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.585079758493364, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.78840164583207, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.09523594042128, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.7364856933881, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.096470523134336, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.777483740821935, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.725177171225006, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.35082126620334, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.41439928572902, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.511874021978144, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.505901501044846, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.546014546349504, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.06843825803749, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.75514834792445, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.73673111225584, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.06025838603178, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.31096312682869, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.50593835375533, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.7205848366042, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.67408879045923, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.69500659880333, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.040747341636816, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.46741888872324, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.07780987271383, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.475458639579564, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.37463384189599, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.69496808091406, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.02310512417743, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.68424982828503, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.43809184033977, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.42782532197205, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.62157813604562, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.65244935328518, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.26978841264763, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.04804465603663, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.65219464665719, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.5676442625143, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.39981281533205, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.46485118071083, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.387124984475385, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.645711351854494, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.60881395688373, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.012123406490794, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.33382338937299, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.017279472389184, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.22718601552274, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.36013893753208, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.60930930883882, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.6049497092658, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.98256198573812, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.98551128752515, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.345321738729375, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.5641367103192, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.985010711448496, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.51228683475762, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.42275302721517, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.31911316321864, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.952062613833085, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.18302337132999, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.56198487214877, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.29205807644395, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.95273906537928, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.30241868249647, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.5645020116681, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.455448288037665, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.51772760265148, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.945975141583894, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.9210626317631, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.516821350236434, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.27658232744307, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.37964389326931, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.24870967283272, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.519902903646695, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.469495611008, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.13730128641674, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.25841809110367, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.469460506920164, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.918962465639936, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.905998413102374, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.335523778870574, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.396998587667916, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.20261014175423, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.232511826243126, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.09002032114451, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.88866035512967, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.419291513970755, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.88418137802809, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.213185556762575, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.33693651752303, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.41990276052168, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.29039268401983, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.47238060927063, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.8650805256524, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.15216034718719, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.186903503188624, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.84839576698398, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.275169336320346, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.04118067741643, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.36519576301622, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.36814823924842, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.85523213365123, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.8232214791432, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.166617184917676, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.13975809524003, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.42283130679787, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.097488043192975, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.244258556956716, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.21167458871058, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.314196982347646, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.30647225184258, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.99078242552607, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.81160562108187, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.3716038436625, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.78042127355801, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.820814376660955, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.11871291071882, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.091075887837476, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.03837524602443, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.93882558988085, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.24315486010621, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.19708988834233, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.7738109366387, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.25778643462891, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.069472778183965, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.14646104330388, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.78541269520033, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.17519376898284, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.73668337944525, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.318703252131954, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.04085699099384, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.197133542432454, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.885309894709685, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.148844991246804, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.01852961642788, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.73501171248409, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.69185044907086, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.95909229553327, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.102556632747586, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.749028250183656, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.989101447031814, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.83023041068368, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.07872620492449, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.09953863462164, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.26403694407853, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.964194188703225, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.13152041369134, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.815574357106584, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.69520794823677, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.7116345381325, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.935812804298436, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.645931683825005, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.77332141336735, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.02274007701699, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.205834970725476, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.060913057674654, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.006747628655205, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.905211472129245, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.60490448297459, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.67318101419594, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8797603004153, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.598928838497635, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.1431812439887, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.65442858187352, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.93168310921086, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.04910396263136, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.98428386458804, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.712643856333074, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.84163636782774, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.92423490080823, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.63368303893808, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.55080482191566, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.32668013594333, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.64761863133687, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.81981216746744, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.827140234509365, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.076086963123736, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.612235324343445, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.59313933243329, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.86141326171921, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.773502759484586, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.7916868586818, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.99601983510985, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.75557991071673, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.65088261887179, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.5011324356673, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.576723852908714, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.004557319366306, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.5515680724842, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.97826881865137, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.36980811727403, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.568649847548116, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.671298357954996, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.700859287624226, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.59599578296294, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.449881723729284, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.68712528705555, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.938929879044025, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.928641465814884, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.982811684831, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.50855935493217, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.407728008451436, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.53461079932406, tolerance: 0.00837262693156732\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.46391756749917, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.523788736454826, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.620572064588096, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.3254541559912, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.84837618182909, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.60971633586267, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.48462345108857, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.39707189562178, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.4641303007523, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.2869499893098, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.04836152916332, tolerance: 0.008552980132450325\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.49289916093852, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.9793739233283, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.74297763174566, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.877881913144236, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.34270826719449, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.48323634811206, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.41829005018542, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.47766039972324, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.812736875721036, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.30578650000933, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.29853627931482, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.371039411722975, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.28675852464996, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.55726864110494, tolerance: 0.008462617338487018\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.579211970951654, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.430255060080135, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.03817823164064, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.743491452858024, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.05192472395835, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.32237315441916, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.35665943306129, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.670136291995995, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.04914939793743, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.381569243915344, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.7159366858288, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.63159356652381, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.22907973800672, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.34725913863703, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.07509649031129, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.56180502769081, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.272317572640375, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.33166206598122, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.318713150696844, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.33962866675926, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.728813668208815, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.95201596863682, tolerance: 0.008912092766427406\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.388266532603694, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.3320399840122, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.727715812940566, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.62466143169846, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.220866902619015, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.827832211569444, tolerance: 0.008552733296521255\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.59472806950143, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.16830301084047, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.32441751317243, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.14954834301409, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.26279274481744, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.28061283162036, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.58547432595789, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.16801303021383, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.1032173598048, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.29184464391246, tolerance: 0.008552980132450327\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57816043784581, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.2283971849461, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.316731711138225, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6197860483818, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.517778942884526, tolerance: 0.008822682119205292\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.17499388657697, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.11375667852626, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.57108406213206, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.02227972668551, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.84510127965367, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.308916347873954, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.61484582521551, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.058098345576795, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.88543597466948, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.46499737131988, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.12006473607811, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.30096005929988, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.69567808856823, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6098054932658, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.56396636928272, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.68780513772961, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.998688530217436, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.29283189110246, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.60464675036979, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.55675521878271, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.689466564018076, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.00133838639997, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.0633590947344, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.28452877138625, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.549428775085914, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.683464807599705, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.929890532185496, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.59935952594068, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.41978060016922, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.00288316000031, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.83708138479321, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.83279775419996, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.593939082878016, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.27605522683114, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82887634108037, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07858139756917, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.677414083251996, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.58838339356823, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.93854648352671, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.54197431906642, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82134066082293, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.66219757812024, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.6712634756764, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.582691626453354, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.26741621119085, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.81388126421128, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.66499168269622, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.534385528920566, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.86936187714334, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.25856531057069, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.98607597053141, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.57686344656075, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.52665963580774, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.65784702753379, tolerance: 0.009091390728476832\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.806364152154, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.658586699213444, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.41434261166754, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.764665113613646, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.24956360798022, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.9717047484852, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.5708987199437, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.51879549768049, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.79875318564235, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 37.088126493867136, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.96258138657255, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65204262648101, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.24038983154374, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6017135684843, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.510792655312606, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.95416150523005, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.56477725563711, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.79102941149392, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.23100603771664, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.645356878536944, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 36.67476284561937, tolerance: 0.008101049144119276\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.50265092595624, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.55854037492321, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.37751579949542, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.63852838254673, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.78317993206722, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.94575364125192, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.22141755356368, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.494370237193365, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.77519692330577, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.93729140713735, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.63155670382717, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.08220671334883, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.55218296016856, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.48595056037776, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.92873894985059, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.21162862298893, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.545700354623385, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.624441667967474, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.76707616701866, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.714185662036655, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.47739188418435, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.92007308770142, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.201640063486856, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.758815539596235, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53909063375675, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.61718320526715, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.468693800044385, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.191452035182984, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.53235895636235, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.91128060538726, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.75041400880436, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.45984938152733, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.273137164759, tolerance: 0.009001931567328907\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.60978128791727, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.741871081473064, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.52548733923735, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.450838336049294, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.181064569540226, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.90235579725033, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.602235904830735, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.733190499245964, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.4416478896789, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.1704776727438, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.51842627382212, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.724368430119554, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.59454705158807, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.89329648942049, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.511186442792564, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.43228057053905, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.71537009552226, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.15969134601005, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.884101892360505, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.58671472642958, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.503771222175395, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.70620222445311, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.422737382260095, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.14870558957727, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.87477172430189, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.57873892865204, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.6968677384556, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.49618185374565, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.41303125160771, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.13752040349318, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.57062372269371, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.86530588532634, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.687327346925, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.48841880797793, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.40298181657614, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.85570434008369, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.56234850335097, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.677657336297685, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.12613578776663, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.480482265061866, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.392936378658554, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.55390053078951, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.845967076078054, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.66785709118936, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.382792340962844, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.47237229428865, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.11455174239931, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.836094088895365, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.54528392621725, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.37250881858643, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.10276826739174, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.65791684799273, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.53649603049593, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.46408892234768, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.82497853744722, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.09078536274438, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.52753559385935, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.362078408013595, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.64783163266141, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.45563215952133, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.81481173708729, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.51839498594482, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.35149997450004, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.63759912623979, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.07860302845606, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.80483229756292, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.447002009774465, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.50907296237512, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.34077334869998, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.79465135127243, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.62721829132578, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.06622126452853, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.43819847463375, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.499568953492386, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.32989850544753, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.616688672363765, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.42922155468705, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.05364007096027, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.78494328963939, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.31887544100578, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48988271979812, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.606010070949836, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.774752063336244, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.420071250163524, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.03935940548174, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.30770415481977, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.59518240099565, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.410747561148206, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.76416076873386, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.48001416121917, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.58420562520641, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.29638464680756, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.02412634034381, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.75339580007372, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.40125048767572, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.572775419343934, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.46996323603536, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.284941703621875, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.74246996617185, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 45.01094006677146, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.45972992687217, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.39158002975945, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.55970922762641, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.273310734701255, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.99774326246661, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.449314226498075, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.73138440194722, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.381736187402964, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.54815775270975, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.26151406475353, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.98438234928632, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.438716131902545, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.72013923032138, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.37171896061007, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24947831160562, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.536803732962625, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.970856192277346, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.708734464645055, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.36152210426521, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.23732278052636, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.42793564183276, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.95716478330189, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.52536398322263, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.69717010636878, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.35115668782298, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.416972755768164, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.51382566109982, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.68544615565062, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.22505126760752, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.94330812233098, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34064057553396, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.50218825104466, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.40582747349183, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.21262850458461, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.673562612507695, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.92928620939686, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.32980706544621, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.490451732455035, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.6615194769418, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.20005012160707, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.394500442668615, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.47861610453519, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.6493167489528, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.91509904444846, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.31897023667189, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.38295131753346, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.18731564058309, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.63695442854139, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.30804180493981, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.467627712658775, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.9007466275152, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.371201003189846, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.17442500991817, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.29697536963103, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.45627881980277, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.62443251570699, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.88622895857715, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.35917839951787, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.161378224050985, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.44407843613221, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.87154603767124, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.28576164996737, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.611751010448884, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.34705802760219, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.148175282382084, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.27440116108965, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.43169181310976, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.59890991276949, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.85669786473785, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.13481618485092, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.262893618841986, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.419153664884455, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33484032138199, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.585909222666096, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.84113649371998, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.25123899407966, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.406467597333155, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.1213009314459, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.572748940140166, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.32246709692487, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.82366228598971, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.23936332172263, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.39363400811533, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.10762952216793, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.559429065191274, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30992889263597, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.380652941363465, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.22701895751744, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.8070255279439, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.09380195701789, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.545949597818876, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.297224529934304, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.21419406166555, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.36752440197855, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.789622281153484, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.07984134137953, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.532310538025094, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.28435386741651, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20086632016844, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.354248390503564, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.771429630330786, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.06519878980429, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.271204551043716, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.51851188580653, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.187033172571354, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.34082490699888, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.75231270929195, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.25748729980375, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.05020974978972, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.17269434660321, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.504553641166424, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.32725395147265, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.24319176163513, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.73104020009194, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.03471752338196, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15784981356431, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.49043580410286, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.31353552392609, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.22829680893412, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.70999818898829, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.01866855631021, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.29966962435582, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.476158374618485, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.212799617551234, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.687892477773616, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.14249957043514, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.00205488296747, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.46172135270994, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.28565625276648, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.19669984053094, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.1266436168949, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.271436187206085, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.66470631962854, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.984875468341464, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.44712473837657, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.179997435715094, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.25641143450538, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.64043954286236, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.432356112905815, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.110281952913596, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.96713018044927, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.24118900265889, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.16269239799096, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.41714643035575, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.94881900250892, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.61509214568486, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.09341457848337, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.225519676695484, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.929941932387315, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.144784726738365, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.588664128120385, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.40128918269782, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.20933075022508, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.07604149360735, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.56115549018013, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.12627442188314, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.38442031892124, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.910498969814824, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.19233132822395, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.05816269828473, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.53256623179782, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.36689226868936, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.107161483415396, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.17439968723326, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.50289635301896, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.0397781925138, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.08744591133541, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.34852340231904, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.89049011475688, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.47214585384963, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15552776933688, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.067127705641504, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.02088797345736, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.329266644573735, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.87017406168581, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.4404381101227, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.13565240173763, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.046206866333236, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.3091151897931, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.11476457821377, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.00131626625767, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.84892826862283, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.02468339341571, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.40891159336252, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.092863118596824, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.28806814062451, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.98063214970562, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.82699362846136, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.002557286878215, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.37483871754976, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.26612538028505, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.06994787010026, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.95895604147219, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.33963867062116, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.80439597559138, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.04670979724827, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.97982854673086, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93618663384359, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.24328689360797, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.78113917725661, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.30332463674056, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.021701811162536, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.956497172968454, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.91230695560036, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.21955267862385, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.75722392552224, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.2658967920636, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.99550770062884, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.88723057888421, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.93256316559357, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.2273551389151, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.1952816967066, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.73265034822217, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.96818947318315, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.90791278524139, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.86104514034553, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.187699677374276, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.93976140779883, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.169729482693185, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.70741846909966, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.8822229966413, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.8337592785736, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.14693040743793, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.68152829256599, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.85569817706759, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.91020906073156, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.14316347300661, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.8053382119436, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.65497981943405, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.828233449279175, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.10592759441771, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.879493823960495, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.77577796460199, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.11563175629889, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.62778532106708, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.79979761810855, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.064080985703555, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.84762661535668, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.74507816355572, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.08714112753059, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.770385689776155, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.01970623496393, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.81460984713611, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.599910587469104, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.7134826256489, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.05769282209032, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.73996746322619, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.78044410726174, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.97407277986507, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.68049151090946, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 44.02728707508915, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.70849808149662, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.57116657588278, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.74512954250017, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.92719380240499, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.67609617581609, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.9959239316392, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.64617836037124, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.70866618967459, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.541317294357405, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.879070067704795, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.61061827948764, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.642931317044216, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.67106046972068, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.96360340041517, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8297870989747, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.57381801348395, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.51042796639861, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.60857149965432, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.63225589062806, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.77887772417893, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.930325483073624, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.53577859243534, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.572953466766485, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.5922512929934, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.726354301512565, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.478506104204534, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.896090179934056, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.536196093523245, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.49650018571411, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.55105165426222, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.67223757150347, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.445553944964324, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.860897491062154, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.498308726293004, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.45587981960206, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.61642734046017, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.50861452457763, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.8247474164639, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.411572195230626, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.41364057848616, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.46452232766652, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.45929294013252, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.78763995614593, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.55848860167969, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.37656107853603, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.36984858807037, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.41915425133864, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.41881162132279, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.74957511011003, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.32451146996844, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.37756953617987, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.49837178399111, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.340520665533774, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.37149736420655, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.71061678849909, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.334535056962544, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.27763138048767, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.303450978547836, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.32258343042672, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.436076625469006, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.67033938456878, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.290066802296465, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.22920878903768, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.2653520246217, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.2720276431078, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.37159687194006, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.24416872832972, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.62831193680221, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.226237846730825, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.1793138263286, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.219678107904755, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.19684205406402, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.30498498902733, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.584506466369284, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.18619098367288, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.127957428016934, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.163878431264315, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.14808715962159, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.23627280987403, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.14516152514828, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.538931474689164, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.0970622119602, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.104188808827296, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.0750519118001, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.16545335859839, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.1012768699715, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.491589848508745, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.04203484058893, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.03964650510703, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.02059494005793, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.09244489646138, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.053450326907154, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.442482531128455, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.98246254297001, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.01591702033033, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.97048823830934, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.9641602344426, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.91839175652625, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.39160982798683, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.00138303918683, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.93436240210872, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.8968404955751, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.90389565587792, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.8498615606995, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.33897183769304, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.847730718225925, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.79518847345555, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.94507023711064, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.83770747037155, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.76210670706632, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.75603504865655, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.28456859203895, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.63461734771109, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.73069905310132, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.88405910544926, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.618239287999295, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.6541040100251, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.22840010127921, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.81823695130841, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.41630756332292, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.41499692271053, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.56907856344432, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.492379028243654, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.16957576319374, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.74761073386677, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.13084251467085, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.15528837960888, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.35273030417722, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.24895022537932, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.10717448526473, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.77133414836078, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.82431805738988, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.075630476144525, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.66637388834977, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.9218885701468, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 43.040001388753545, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 40.41966574241283, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.31346027934089, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.72732424960408, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.51326793194052, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.96831076585485, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.50620339707646, tolerance: 0.009269977924944803\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 39.93499785263579, tolerance: 0.008912362030905072\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.89211887147851, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.26430307364343, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 38.30081473811617, tolerance: 0.00846285871964679\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.91557498620141, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.81143570187942, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.45351310662998, tolerance: 0.00909139072847683\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.72504615700514, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.59599935090239, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.40677204043817, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 42.15317453545881, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.82659324841206, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n",
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:526: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 41.40951299958463, tolerance: 0.009180739514348777\n",
      "  model = cd_fast.enet_coordinate_descent_gram(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best alpha using built-in LassoCV: 6.800000\n",
      "Best score using built-in LassoCV: 0.037735\n",
      "Lasso picked 9 variables and eliminated the other 20 variables\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda\\lib\\site-packages\\sklearn\\linear_model\\_coordinate_descent.py:530: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Duality gap: 47.70153500927998, tolerance: 0.009772975658221562\n",
      "  model = cd_fast.enet_coordinate_descent(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Feature importance using Lasso Model')"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "cv = RepeatedKFold(n_splits=10, n_repeats=3, random_state=1)\n",
    "model = LassoCV(alphas=np.arange(0.1, 10, 0.1), cv=cv, n_jobs=-1)\n",
    "\n",
    "model.fit(X, y)\n",
    "print(\"Best alpha using built-in LassoCV: %f\" % model.alpha_)\n",
    "print(\"Best score using built-in LassoCV: %f\" %model.score(X,y))\n",
    "coef = pd.Series(model.coef_, index = X.columns)\n",
    "\n",
    "print(\"Lasso picked \" + str(sum(coef != 0)) + \" variables and eliminated the other \" +  str(sum(coef == 0)) + \" variables\")\n",
    "\n",
    "imp_coef = coef.sort_values()\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 10.0)\n",
    "imp_coef.plot(kind = \"barh\")\n",
    "plt.title(\"Feature importance using Lasso Model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_entropy(x):\n",
    "    e = np.sum(np.log(np.array(range(1,np.sum(x)))))\n",
    "    first = range(1,np.sum(x))\n",
    "    second = np.log(np.array(first))\n",
    "    print('range(1,np.sum(x)): ' + str(first))\n",
    "    print('last value of first: ' + str(first[-1]))\n",
    "    print('np.log(np.array(range(1,np.sum(x)))): ' + str(second))\n",
    "    print('np.sum(np.log(np.array(range(1,np.sum(x))))): ' + str(e))\n",
    "    \n",
    "    for i in x:\n",
    "        e -= np.sum(np.log(np.array(range(1,i))))\n",
    "    return e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_df = bids_df[bids_df['bidder_id'] == \"8dac2b259fd1c6d1120e519fb1ac14fbqvax8\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "range(1,np.sum(x)): range(1, 62529)\n",
      "last value of first: 62528\n",
      "np.log(np.array(range(1,np.sum(x)))): [ 0.          0.69314718  1.09861229 ... 11.04333775 11.04335374\n",
      " 11.04336974]\n",
      "np.sum(np.log(np.array(range(1,np.sum(x))))): 627998.2634399784\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "490367.9005934045"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_entropy(temp_df.groupby('ip')['ip'].count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.043369735402454"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.log(62528)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
