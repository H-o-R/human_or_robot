{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import statsmodels.api as sm\n",
    "import matplotlib.pyplot as plt\n",
    "import statistics\n",
    "import sklearn.metrics as metrics\n",
    "import tensorflow as tf\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.linear_model import RidgeCV, LassoCV, Ridge, Lasso\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.feature_selection import RFE\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, mutual_info_regression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import fbeta_score\n",
    "from sklearn.feature_selection import RFECV\n",
    "from imblearn.pipeline import Pipeline\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "# from catboost import CatBoostClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import accuracy_score, roc_curve, auc, roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"../new_train.csv\")\n",
    "test = pd.read_csv(\"../new_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.drop(train.filter(regex=\"Unname\"),axis=1, inplace=True)\n",
    "test.drop(test.filter(regex=\"Unname\"),axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = train.drop(columns=['bidder_id', 'payment_account', 'address', 'outcome','merchandise']) \n",
    "y = train['outcome']\n",
    "X_test_original = test.drop(columns=['bidder_id', 'payment_account', 'address', 'merchandise'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scaling the training and test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "# scaled_features = data.copy()\n",
    "col_names = ['auction', 'device', 'time', 'country', 'ip', 'url', 'num_bids',\n",
    "       'num_first_bids', 'num_last_bids', 'time_to_bid', 'inst_resp',\n",
    "       'perc_inst_resp', 'num_bids_per_auction',\n",
    "       'num_bids_per_device', 'num_bids_per_country', 'num_bids_per_ip',\n",
    "       'on_ip_that_has_a_bot_mean', 'ip_entropy', 'url_entropy',\n",
    "       'mean_country_per_auction', 'max_country_per_auction',\n",
    "       'min_country_per_auction', 'std_country_per_auction',\n",
    "       'mean_devices_per_auction', 'max_devices_per_auction',\n",
    "       'min_devices_per_auction', 'std_devices_per_auction',\n",
    "       'mean_ip_per_auction', 'max_ip_per_auction', 'min_ip_per_auction',\n",
    "       'std_ip_per_auction', 'mean_url_per_auction', 'max_url_per_auction',\n",
    "       'min_url_per_auction', 'std_url_per_auction',\n",
    "       'total_no_of_participated_auctions', 'no_of_auction_exceeds_threshold',\n",
    "       'percentage_of_auctions_above_threshold', 'total_no_of_bidded_category',\n",
    "       'no_of_merchandise_exceeds_threshold',\n",
    "       'percentage_of_merchandise_above_threshold',\n",
    "       'on_url_that_has_a_bot_mean']\n",
    "\n",
    "train_features = X[col_names]\n",
    "scaler = StandardScaler().fit(train_features.values)\n",
    "train_features = scaler.transform(train_features.values)\n",
    "X[col_names] = train_features\n",
    "\n",
    "test_features = X_test_original[col_names]\n",
    "scaler_test = StandardScaler().fit(test_features.values)\n",
    "test_features = scaler_test.transform(test_features.values)\n",
    "X_test_original[col_names] = test_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = ['num_bids_per_ip', 'num_bids_per_auction', 'num_bids_per_country', 'mean_ip_per_auction', 'perc_inst_resp', 'time', 'mean_url_per_auction', 'inst_resp', 'num_bids', 'time_to_bid', 'num_last_bids', 'on_url_that_has_a_bot_mean', 'device', 'percentage_of_auctions_above_threshold', 'num_bids_per_device', 'ip_entropy', 'ip', 'max_country_per_auction', 'max_ip_per_auction', 'mean_devices_per_auction', 'url_entropy', 'std_ip_per_auction', 'url', 'max_devices_per_auction', 'no_of_auction_exceeds_threshold']\n",
    "X = X[selected_features]\n",
    "X_test_original = X_test_original[selected_features]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, X_train, y_train, X_test, y_test):\n",
    "    print(\"TRAIN\")\n",
    "    train_predictions = model.predict_proba(X_train)\n",
    "    train_pred = model.predict(X_train)\n",
    "        \n",
    "    train_accuracy = accuracy_score(y_train, train_pred)\n",
    "    train_auc_roc_score = roc_auc_score(y_train,train_predictions[:,1])\n",
    "    train_fbeta = fbeta_score(y_train, train_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_train, train_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_train, train_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(train_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(train_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    print(\"TEST\")\n",
    "    \n",
    "    test_predictions = model.predict_proba(X_test)\n",
    "    test_pred = model.predict(X_test)\n",
    "        \n",
    "    test_accuracy = accuracy_score(y_test, test_pred)\n",
    "    test_auc_roc_score = roc_auc_score(y_test,test_predictions[:,1])\n",
    "    test_fbeta = fbeta_score(y_test, test_pred, average='binary', beta=2.0)\n",
    "    \n",
    "    print(\"Classification report\")\n",
    "    print(classification_report(y_test, test_pred, digits = 4))\n",
    "    \n",
    "    print(\"FBeta Score\")\n",
    "    print(fbeta_score(y_test, test_pred, average='binary', beta=2.0))\n",
    "    \n",
    "    print('Model Performance')\n",
    "    print('Accuracy = {:0.4f}%.'.format(test_accuracy))\n",
    "    print('AUC ROC = {:0.4f}%.'.format(test_auc_roc_score))\n",
    "    print(\"*\" * 100)\n",
    "    \n",
    "    return [train_accuracy, train_auc_roc_score, train_fbeta, test_accuracy, test_auc_roc_score, test_fbeta]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_results(arr):\n",
    "    train_accuracy = []\n",
    "    train_auc_roc_score = [] \n",
    "    train_fbeta = []\n",
    "    test_accuracy = []\n",
    "    test_auc_roc_score = []\n",
    "    test_fbeta = []\n",
    "    \n",
    "    for item in arr:\n",
    "        train_accuracy.append(item[0])\n",
    "        train_auc_roc_score.append(item[1])\n",
    "        train_fbeta.append(item[2])\n",
    "        test_accuracy.append(item[3])\n",
    "        test_auc_roc_score.append(item[4])\n",
    "        test_fbeta.append(item[5])\n",
    "    \n",
    "    mean_accuracy = np.array(train_accuracy).mean()\n",
    "    mean_train_auc_roc_score = np.array(train_auc_roc_score).mean()\n",
    "    mean_train_fbeta = np.array(train_fbeta).mean()\n",
    "    mean_test_accuracy = np.array(test_accuracy).mean()\n",
    "    mean_test_auc_roc_score = np.array(test_auc_roc_score).mean()\n",
    "    mean_test_fbeta = np.array(test_fbeta).mean()\n",
    "    \n",
    "    print(\"final train accuracy: \" + str(mean_accuracy))\n",
    "    print(\"final train AUC: \" + str(mean_train_auc_roc_score))\n",
    "    print(\"final train fbeta: \" + str(mean_train_fbeta))\n",
    "    print(\"final test accuracy: \" + str(mean_test_accuracy))\n",
    "    print(\"final test AUC: \" + str(mean_test_auc_roc_score))\n",
    "    print(\"final test fbeta: \" + str(mean_test_fbeta))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Base Model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def create_model(learn_rate=0.01, momentum=0):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "counter = 1\n",
    "ann_result = []\n",
    "\n",
    "over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "steps = [('o', over), ('u', under)]\n",
    "pipeline = Pipeline(steps=steps)\n",
    "\n",
    "for train_index, test_index in skf.split(X, y):\n",
    "    print(\"Fold number \" + str(counter))\n",
    "    counter += 1\n",
    "    X_train, X_test = X.iloc[train_index], X.iloc[test_index]\n",
    "    y_train, y_test = y.iloc[train_index], y.iloc[test_index]\n",
    "    \n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    # ann\n",
    "    print(\"ANN\")\n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann.fit(X_train, y_train)\n",
    "    ann_result.append(evaluate(ann, X_train, y_train, X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_results(ann_result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Random Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def random_search_ann(X, y):\n",
    "    print(\"RANDOM SEARCH ANN EXPERIMENT\")\n",
    "    learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "    momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "    batch_size = [10, 20, 40, 60, 80, 100]\n",
    "    epochs = [10, 50, 100]\n",
    "\n",
    "    ann_random_grid = dict(learn_rate=learn_rate,momentum=momentum,batch_size=batch_size, epochs=epochs)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "\n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann_random = RandomizedSearchCV(estimator = ann, param_distributions = ann_random_grid, n_iter = 100, cv = skf, \n",
    "                                verbose=2, random_state=42, n_jobs = -1, scoring='roc_auc')\n",
    "    ann_random.fit(X_train, y_train)\n",
    "    ann_best_random = ann_random.best_estimator_\n",
    "    ann_random_accuracy = evaluate(ann_best_random, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Random Search Param for ANN\")\n",
    "    print(ann_random.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "random_search_ann(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "*****************************************************************************************\n",
    "## Best Random Search Param for ANN\n",
    "{}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SKFold + SMOTE (Grid Search)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_ann(X, y):\n",
    "    learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "    momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "    batch_size = [10, 20, 40, 60, 80, 100]\n",
    "    epochs = [10, 50, 100]\n",
    "    \n",
    "    ann_grid = dict(learn_rate=learn_rate,momentum=momentum,batch_size=batch_size, epochs=epochs)\n",
    "    \n",
    "    skf = StratifiedKFold(n_splits=5, random_state=42, shuffle=True)\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "    over = SMOTE(sampling_strategy=0.2, random_state = 42)\n",
    "    under = RandomUnderSampler(sampling_strategy=0.4, random_state = 42)\n",
    "    steps = [('o', over), ('u', under)]\n",
    "    pipeline = Pipeline(steps=steps)\n",
    "    X_train, y_train = pipeline.fit_resample(X_train, y_train)\n",
    "    \n",
    "    ann = KerasClassifier(build_fn=create_model, verbose=0)\n",
    "    ann_grid = GridSearchCV(estimator = ann, param_grid = ann_grid, n_jobs=-1, cv=skf, scoring='roc_auc')\n",
    "    ann_grid.fit(X_train, y_train)\n",
    "    \n",
    "    ann_best_grid = ann_grid.best_estimator_\n",
    "    ann_grid_accuracy = evaluate(ann_best_grid, X_train, y_train, X_test, y_test)\n",
    "    print(\"Best Params Grid Search for ANN\")\n",
    "    print(ann_grid.best_params_)\n",
    "    return ann_best_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ann_best_grid = grid_search_ann(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
